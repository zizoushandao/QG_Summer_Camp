{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:15:58.201456Z",
     "start_time": "2024-07-19T11:15:54.639158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mindspore.ops as ops\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from PIL import Image\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "from mindspore import CheckpointConfig,ModelCheckpoint\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import mindspore as ms\n",
    "from mindspore import nn, Tensor\n",
    "from mindspore import dataset as ds\n",
    "from mindspore.train import Model, LossMonitor, Callback\n",
    "from mindspore.nn import Accuracy\n",
    "from sklearn.utils import shuffle\n",
    "from mindspore import CheckpointConfig, ModelCheckpoint```"
   ],
   "id": "8cb3ba77829ef08e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:16:08.946349Z",
     "start_time": "2024-07-19T11:16:08.919349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义基础路径\n",
    "basic_root = 'cassava-leaf-disease-classification'\n",
    "image_path = os.path.join(basic_root, 'train_images')\n",
    "csv_path = os.path.join(basic_root, 'train.csv')\n",
    "json_path = os.path.join(basic_root, 'label_num_to_disease_map.json')\n",
    "\n",
    "# 读取CSV和JSON文件\n",
    "image_csv = pd.read_csv(csv_path)\n",
    "image_json = json.load(open(json_path))\n",
    "image_json_tolabel = {int(i): j for i, j in image_json.items()}\n",
    "image_csv['label_name'] = image_csv['label'].map(image_json_tolabel)\n",
    "\n",
    "# 只处理前3000张图像\n",
    "image_csv = image_csv.iloc[:2000]\n"
   ],
   "id": "a0b5eaf216a1a329",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:16:11.980919Z",
     "start_time": "2024-07-19T11:16:11.964316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据增强和归一化\n",
    "transform = ms.dataset.transforms.Compose([\n",
    "    \n",
    "    ms.dataset.vision.RandomHorizontalFlip(),\n",
    "    ms.dataset.vision.RandomVerticalFlip(),\n",
    "    ms.dataset.vision.RandomRotation(20),\n",
    "    ms.dataset.vision.ToTensor(),   \n",
    "    ms.dataset.vision.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ],
   "id": "6fe4038c10cbdb4f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:16:11.996919Z",
     "start_time": "2024-07-19T11:16:11.982919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class CassavaDataset:\n",
    "    def __init__(self, annotations, img_dir, transform=None, num_classes=5):\n",
    "        self.annotations = annotations\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_dir, self.annotations.iloc[index, 0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.annotations.iloc[index, 1]\n",
    "        # 转换标签为One-hot编码并确保为二维\n",
    "        label_one_hot = np.zeros((1, self.num_classes), dtype=np.float32)  # 使用二维数组\n",
    "        label_one_hot[0, label] = 1\n",
    "        return image, Tensor(label_one_hot, ms.float32)\n",
    "     \n",
    "transforms = ms.dataset.transforms.Compose([\n",
    "    ms.dataset.vision.Resize((256, 256)),\n",
    "    ms.dataset.vision.RandomHorizontalFlip(),\n",
    "    ms.dataset.vision.RandomVerticalFlip(),\n",
    "    ms.dataset.vision.RandomRotation(20),\n",
    "    \n",
    "\n",
    "    ms.dataset.vision.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ms.dataset.vision.ToTensor(),\n",
    "])   \n",
    "\n",
    "dataset = CassavaDataset(image_csv, image_path, transform=transforms,num_classes=5)\n"
   ],
   "id": "ef4202c4e4548242",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:16:12.028919Z",
     "start_time": "2024-07-19T11:16:12.019919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建 MindSpore 数据集\n",
    "ms_dataset = ds.GeneratorDataset(dataset, [\"image\", \"label\"], shuffle=True)"
   ],
   "id": "d22c4c8cfbe726b8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:16:12.058919Z",
     "start_time": "2024-07-19T11:16:12.040919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取数据集的实际大小\n",
    "dataset_size = len(dataset)\n",
    "print(\"Dataset size:\", dataset_size)"
   ],
   "id": "a36e614e77fe4306",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 2000\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:16:12.074918Z",
     "start_time": "2024-07-19T11:16:12.060921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 计算训练集和验证集的大小\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size \n",
    "train_size"
   ],
   "id": "5f2bb8e0e4f8f8f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:16:12.089919Z",
     "start_time": "2024-07-19T11:16:12.077919Z"
    }
   },
   "cell_type": "code",
   "source": "len(dataset)",
   "id": "5a3be949e6c54c76",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:16:12.136922Z",
     "start_time": "2024-07-19T11:16:12.119919Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset, val_dataset = ms_dataset.split([train_size, val_size])",
   "id": "174292b19053d4b1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(12048:13668,MainProcess):2024-07-19-19:16:12.121.920 [mindspore\\dataset\\engine\\datasets.py:2480] Dataset is shuffled before split.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:16:12.152919Z",
     "start_time": "2024-07-19T11:16:12.139919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train dataset size:\", train_dataset.get_dataset_size())\n",
    "print(\"Validation dataset size:\", val_dataset.get_dataset_size())"
   ],
   "id": "9451ce492af2b493",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 1600\n",
      "Validation dataset size: 400\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:16:12.200919Z",
     "start_time": "2024-07-19T11:16:12.181919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResidualBlock(nn.Cell):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, pad_mode='pad')\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, pad_mode='pad')\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "    def construct(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += identity  # Add the input x to the output\n",
    "        out = self.relu(out)\n",
    "        return out"
   ],
   "id": "73f1e9c74ffebb09",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:16:12.360919Z",
     "start_time": "2024-07-19T11:16:12.202919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class CNN(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layers = nn.SequentialCell([\n",
    "            nn.Conv2d(3, 32, kernel_size=3, pad_mode='pad', padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            ResidualBlock(32),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, pad_mode='pad', padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            ResidualBlock(64),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, pad_mode='pad', padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            ResidualBlock(128)\n",
    "        ])\n",
    "        self.fc_layers = nn.SequentialCell([\n",
    "            nn.Dense(128 * 32 * 32, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Dense(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dense(128, 5)\n",
    "        ])\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = ops.Reshape()(x, (-1, 128 * 32 * 32))\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    def trainable_params(self):\n",
    "        return super(CNN, self).trainable_params()\n",
    "\n",
    "\n",
    "\n",
    "model = CNN()\n",
    " \n",
    "   "
   ],
   "id": "b533e317cc0c7a28",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:16:12.376920Z",
     "start_time": "2024-07-19T11:16:12.361919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 检查CUDA是否可用并选择设备\n",
    "device = ms.context.set_context(mode=ms.context.GRAPH_MODE, device_target=\"CPU\")"
   ],
   "id": "99c85885c86e1ceb",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:16:12.646919Z",
     "start_time": "2024-07-19T11:16:12.379919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义模型、损失函数和优化器\n",
    "criterion = nn.SoftmaxCrossEntropyWithLogits(sparse=False)\n",
    "optimizer = nn.Momentum(params=model.trainable_params(), learning_rate=0.001, momentum=0.01)\n",
    "\n",
    "loss_monitor = LossMonitor(per_print_times=1)\n",
    "\n",
    "cassavamodel = Model(model, criterion, optimizer, metrics={\"Accuracy\": Accuracy()})"
   ],
   "id": "e6cd0bea93b7eea0",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:35:41.458752Z",
     "start_time": "2024-07-19T11:16:12.647919Z"
    }
   },
   "cell_type": "code",
   "source": "cassavamodel.train(5, train_dataset,callbacks=[loss_monitor]) ",
   "id": "69d1f8fdd72b48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1, loss is 1.8656156063079834\n",
      "epoch: 1 step: 2, loss is 1.4584769010543823\n",
      "epoch: 1 step: 3, loss is 1.5712664127349854\n",
      "epoch: 1 step: 4, loss is 1.9721381664276123\n",
      "epoch: 1 step: 5, loss is 2.2915191650390625\n",
      "epoch: 1 step: 6, loss is 0.6684342622756958\n",
      "epoch: 1 step: 7, loss is 0.5484127998352051\n",
      "epoch: 1 step: 8, loss is 0.15597717463970184\n",
      "epoch: 1 step: 9, loss is 6.352414131164551\n",
      "epoch: 1 step: 10, loss is 0.5682287812232971\n",
      "epoch: 1 step: 11, loss is 0.41289278864860535\n",
      "epoch: 1 step: 12, loss is 2.273200035095215\n",
      "epoch: 1 step: 13, loss is 5.202949523925781\n",
      "epoch: 1 step: 14, loss is 0.9405927062034607\n",
      "epoch: 1 step: 15, loss is 0.4710458219051361\n",
      "epoch: 1 step: 16, loss is 2.7968122959136963\n",
      "epoch: 1 step: 17, loss is 4.194579601287842\n",
      "epoch: 1 step: 18, loss is 3.061596155166626\n",
      "epoch: 1 step: 19, loss is 2.0740466117858887\n",
      "epoch: 1 step: 20, loss is 3.3191823959350586\n",
      "epoch: 1 step: 21, loss is 1.9752196073532104\n",
      "epoch: 1 step: 22, loss is 0.46177881956100464\n",
      "epoch: 1 step: 23, loss is 5.2178168296813965\n",
      "epoch: 1 step: 24, loss is 1.3040425777435303\n",
      "epoch: 1 step: 25, loss is 0.38105589151382446\n",
      "epoch: 1 step: 26, loss is 0.3019074499607086\n",
      "epoch: 1 step: 27, loss is 2.834059476852417\n",
      "epoch: 1 step: 28, loss is 0.5405147671699524\n",
      "epoch: 1 step: 29, loss is 0.1281934380531311\n",
      "epoch: 1 step: 30, loss is 1.5590476989746094\n",
      "epoch: 1 step: 31, loss is 4.130649566650391\n",
      "epoch: 1 step: 32, loss is 0.6712519526481628\n",
      "epoch: 1 step: 33, loss is 0.21176716685295105\n",
      "epoch: 1 step: 34, loss is 3.1063551902770996\n",
      "epoch: 1 step: 35, loss is 3.5639400482177734\n",
      "epoch: 1 step: 36, loss is 1.6073533296585083\n",
      "epoch: 1 step: 37, loss is 1.5781242847442627\n",
      "epoch: 1 step: 38, loss is 0.9998764395713806\n",
      "epoch: 1 step: 39, loss is 0.11862128227949142\n",
      "epoch: 1 step: 40, loss is 3.20855712890625\n",
      "epoch: 1 step: 41, loss is 0.932260274887085\n",
      "epoch: 1 step: 42, loss is 0.8426222205162048\n",
      "epoch: 1 step: 43, loss is 0.03337370976805687\n",
      "epoch: 1 step: 44, loss is 4.956777095794678\n",
      "epoch: 1 step: 45, loss is 3.423367977142334\n",
      "epoch: 1 step: 46, loss is 1.1707981824874878\n",
      "epoch: 1 step: 47, loss is 0.6576914191246033\n",
      "epoch: 1 step: 48, loss is 0.07452315092086792\n",
      "epoch: 1 step: 49, loss is 0.03222377225756645\n",
      "epoch: 1 step: 50, loss is 0.07252372801303864\n",
      "epoch: 1 step: 51, loss is 3.94777512550354\n",
      "epoch: 1 step: 52, loss is 0.9437143802642822\n",
      "epoch: 1 step: 53, loss is 1.5133492946624756\n",
      "epoch: 1 step: 54, loss is 0.2839412987232208\n",
      "epoch: 1 step: 55, loss is 5.148244857788086\n",
      "epoch: 1 step: 56, loss is 0.5188428163528442\n",
      "epoch: 1 step: 57, loss is 1.375622272491455\n",
      "epoch: 1 step: 58, loss is 4.013104438781738\n",
      "epoch: 1 step: 59, loss is 0.9282584190368652\n",
      "epoch: 1 step: 60, loss is 1.3166236877441406\n",
      "epoch: 1 step: 61, loss is 0.7683287858963013\n",
      "epoch: 1 step: 62, loss is 0.7513511180877686\n",
      "epoch: 1 step: 63, loss is 3.951763868331909\n",
      "epoch: 1 step: 64, loss is 0.9746297597885132\n",
      "epoch: 1 step: 65, loss is 0.5280815958976746\n",
      "epoch: 1 step: 66, loss is 0.27292531728744507\n",
      "epoch: 1 step: 67, loss is 0.48356783390045166\n",
      "epoch: 1 step: 68, loss is 4.141329288482666\n",
      "epoch: 1 step: 69, loss is 0.4379137456417084\n",
      "epoch: 1 step: 70, loss is 0.2312420755624771\n",
      "epoch: 1 step: 71, loss is 0.21538802981376648\n",
      "epoch: 1 step: 72, loss is 0.12870033085346222\n",
      "epoch: 1 step: 73, loss is 0.17954792082309723\n",
      "epoch: 1 step: 74, loss is 0.08268898725509644\n",
      "epoch: 1 step: 75, loss is 2.955775022506714\n",
      "epoch: 1 step: 76, loss is 4.69514274597168\n",
      "epoch: 1 step: 77, loss is 1.5541377067565918\n",
      "epoch: 1 step: 78, loss is 0.9120893478393555\n",
      "epoch: 1 step: 79, loss is 1.8116915225982666\n",
      "epoch: 1 step: 80, loss is 1.2556912899017334\n",
      "epoch: 1 step: 81, loss is 0.367423415184021\n",
      "epoch: 1 step: 82, loss is 0.53265780210495\n",
      "epoch: 1 step: 83, loss is 0.6619818210601807\n",
      "epoch: 1 step: 84, loss is 3.622424602508545\n",
      "epoch: 1 step: 85, loss is 0.768672525882721\n",
      "epoch: 1 step: 86, loss is 0.2687154710292816\n",
      "epoch: 1 step: 87, loss is 0.4448384642601013\n",
      "epoch: 1 step: 88, loss is 2.469494581222534\n",
      "epoch: 1 step: 89, loss is 0.5687151551246643\n",
      "epoch: 1 step: 90, loss is 3.9861035346984863\n",
      "epoch: 1 step: 91, loss is 0.39911481738090515\n",
      "epoch: 1 step: 92, loss is 2.142995595932007\n",
      "epoch: 1 step: 93, loss is 1.4021122455596924\n",
      "epoch: 1 step: 94, loss is 0.799627423286438\n",
      "epoch: 1 step: 95, loss is 1.9806544780731201\n",
      "epoch: 1 step: 96, loss is 0.7452940344810486\n",
      "epoch: 1 step: 97, loss is 0.5447793006896973\n",
      "epoch: 1 step: 98, loss is 0.3912140727043152\n",
      "epoch: 1 step: 99, loss is 0.22280970215797424\n",
      "epoch: 1 step: 100, loss is 0.11029639095067978\n",
      "epoch: 1 step: 101, loss is 0.26713067293167114\n",
      "epoch: 1 step: 102, loss is 2.5169456005096436\n",
      "epoch: 1 step: 103, loss is 2.786656618118286\n",
      "epoch: 1 step: 104, loss is 0.8467580676078796\n",
      "epoch: 1 step: 105, loss is 0.11420130729675293\n",
      "epoch: 1 step: 106, loss is 0.579848051071167\n",
      "epoch: 1 step: 107, loss is 0.19716157019138336\n",
      "epoch: 1 step: 108, loss is 0.20383448898792267\n",
      "epoch: 1 step: 109, loss is 2.5009424686431885\n",
      "epoch: 1 step: 110, loss is 0.7293635010719299\n",
      "epoch: 1 step: 111, loss is 0.9906865358352661\n",
      "epoch: 1 step: 112, loss is 0.507107675075531\n",
      "epoch: 1 step: 113, loss is 3.396456718444824\n",
      "epoch: 1 step: 114, loss is 2.0775580406188965\n",
      "epoch: 1 step: 115, loss is 0.38709744811058044\n",
      "epoch: 1 step: 116, loss is 1.0887207984924316\n",
      "epoch: 1 step: 117, loss is 0.062040891498327255\n",
      "epoch: 1 step: 118, loss is 4.00280237197876\n",
      "epoch: 1 step: 119, loss is 0.25036388635635376\n",
      "epoch: 1 step: 120, loss is 0.6061769723892212\n",
      "epoch: 1 step: 121, loss is 0.20299963653087616\n",
      "epoch: 1 step: 122, loss is 4.121063232421875\n",
      "epoch: 1 step: 123, loss is 1.7357616424560547\n",
      "epoch: 1 step: 124, loss is 0.3712467849254608\n",
      "epoch: 1 step: 125, loss is 0.4633648097515106\n",
      "epoch: 1 step: 126, loss is 0.48989665508270264\n",
      "epoch: 1 step: 127, loss is 4.360952854156494\n",
      "epoch: 1 step: 128, loss is 1.775122880935669\n",
      "epoch: 1 step: 129, loss is 1.6060115098953247\n",
      "epoch: 1 step: 130, loss is 1.3698232173919678\n",
      "epoch: 1 step: 131, loss is 0.40428003668785095\n",
      "epoch: 1 step: 132, loss is 0.7065258026123047\n",
      "epoch: 1 step: 133, loss is 2.890072822570801\n",
      "epoch: 1 step: 134, loss is 2.647604465484619\n",
      "epoch: 1 step: 135, loss is 0.8315159678459167\n",
      "epoch: 1 step: 136, loss is 1.028259515762329\n",
      "epoch: 1 step: 137, loss is 1.2444424629211426\n",
      "epoch: 1 step: 138, loss is 3.1852355003356934\n",
      "epoch: 1 step: 139, loss is 3.8354320526123047\n",
      "epoch: 1 step: 140, loss is 1.6992671489715576\n",
      "epoch: 1 step: 141, loss is 3.736870288848877\n",
      "epoch: 1 step: 142, loss is 1.8378428220748901\n",
      "epoch: 1 step: 143, loss is 1.4453468322753906\n",
      "epoch: 1 step: 144, loss is 1.3467745780944824\n",
      "epoch: 1 step: 145, loss is 1.3435258865356445\n",
      "epoch: 1 step: 146, loss is 0.3418920934200287\n",
      "epoch: 1 step: 147, loss is 3.86588978767395\n",
      "epoch: 1 step: 148, loss is 0.8045982718467712\n",
      "epoch: 1 step: 149, loss is 0.8648048639297485\n",
      "epoch: 1 step: 150, loss is 2.0928711891174316\n",
      "epoch: 1 step: 151, loss is 2.236915111541748\n",
      "epoch: 1 step: 152, loss is 1.6757676601409912\n",
      "epoch: 1 step: 153, loss is 2.5529937744140625\n",
      "epoch: 1 step: 154, loss is 1.370827555656433\n",
      "epoch: 1 step: 155, loss is 0.7794584631919861\n",
      "epoch: 1 step: 156, loss is 2.649078845977783\n",
      "epoch: 1 step: 157, loss is 0.47451913356781006\n",
      "epoch: 1 step: 158, loss is 1.0385980606079102\n",
      "epoch: 1 step: 159, loss is 0.5727133750915527\n",
      "epoch: 1 step: 160, loss is 0.4934041500091553\n",
      "epoch: 1 step: 161, loss is 0.19838301837444305\n",
      "epoch: 1 step: 162, loss is 0.4104003310203552\n",
      "epoch: 1 step: 163, loss is 0.05135493725538254\n",
      "epoch: 1 step: 164, loss is 1.8116662502288818\n",
      "epoch: 1 step: 165, loss is 0.29100948572158813\n",
      "epoch: 1 step: 166, loss is 0.3235056400299072\n",
      "epoch: 1 step: 167, loss is 1.6802105903625488\n",
      "epoch: 1 step: 168, loss is 1.8038880825042725\n",
      "epoch: 1 step: 169, loss is 4.14914083480835\n",
      "epoch: 1 step: 170, loss is 1.1039241552352905\n",
      "epoch: 1 step: 171, loss is 0.7960654497146606\n",
      "epoch: 1 step: 172, loss is 0.9466632604598999\n",
      "epoch: 1 step: 173, loss is 0.9061021208763123\n",
      "epoch: 1 step: 174, loss is 0.7000995874404907\n",
      "epoch: 1 step: 175, loss is 0.4578419327735901\n",
      "epoch: 1 step: 176, loss is 1.6445400714874268\n",
      "epoch: 1 step: 177, loss is 0.21563653647899628\n",
      "epoch: 1 step: 178, loss is 1.044230580329895\n",
      "epoch: 1 step: 179, loss is 4.291835308074951\n",
      "epoch: 1 step: 180, loss is 0.43120476603507996\n",
      "epoch: 1 step: 181, loss is 0.6277198195457458\n",
      "epoch: 1 step: 182, loss is 2.8409008979797363\n",
      "epoch: 1 step: 183, loss is 0.7864668965339661\n",
      "epoch: 1 step: 184, loss is 0.31495118141174316\n",
      "epoch: 1 step: 185, loss is 0.4244074821472168\n",
      "epoch: 1 step: 186, loss is 0.1869545429944992\n",
      "epoch: 1 step: 187, loss is 0.12254767119884491\n",
      "epoch: 1 step: 188, loss is 0.1924619972705841\n",
      "epoch: 1 step: 189, loss is 2.223597288131714\n",
      "epoch: 1 step: 190, loss is 1.9136966466903687\n",
      "epoch: 1 step: 191, loss is 1.0642368793487549\n",
      "epoch: 1 step: 192, loss is 2.360633373260498\n",
      "epoch: 1 step: 193, loss is 0.9431720972061157\n",
      "epoch: 1 step: 194, loss is 1.0044281482696533\n",
      "epoch: 1 step: 195, loss is 0.5009203553199768\n",
      "epoch: 1 step: 196, loss is 3.0711355209350586\n",
      "epoch: 1 step: 197, loss is 2.257324457168579\n",
      "epoch: 1 step: 198, loss is 0.2795961797237396\n",
      "epoch: 1 step: 199, loss is 5.3558220863342285\n",
      "epoch: 1 step: 200, loss is 0.7100776433944702\n",
      "epoch: 1 step: 201, loss is 0.37467315793037415\n",
      "epoch: 1 step: 202, loss is 0.28615960478782654\n",
      "epoch: 1 step: 203, loss is 0.3054940402507782\n",
      "epoch: 1 step: 204, loss is 0.3145669996738434\n",
      "epoch: 1 step: 205, loss is 0.11905315518379211\n",
      "epoch: 1 step: 206, loss is 0.9725185632705688\n",
      "epoch: 1 step: 207, loss is 2.663205862045288\n",
      "epoch: 1 step: 208, loss is 0.584065854549408\n",
      "epoch: 1 step: 209, loss is 2.930945634841919\n",
      "epoch: 1 step: 210, loss is 4.2819647789001465\n",
      "epoch: 1 step: 211, loss is 1.28788161277771\n",
      "epoch: 1 step: 212, loss is 0.9250123500823975\n",
      "epoch: 1 step: 213, loss is 0.7086538076400757\n",
      "epoch: 1 step: 214, loss is 2.2477049827575684\n",
      "epoch: 1 step: 215, loss is 0.46444064378738403\n",
      "epoch: 1 step: 216, loss is 0.38706061244010925\n",
      "epoch: 1 step: 217, loss is 0.24936997890472412\n",
      "epoch: 1 step: 218, loss is 2.2230403423309326\n",
      "epoch: 1 step: 219, loss is 0.246909037232399\n",
      "epoch: 1 step: 220, loss is 0.3929927349090576\n",
      "epoch: 1 step: 221, loss is 0.5445900559425354\n",
      "epoch: 1 step: 222, loss is 0.5458850264549255\n",
      "epoch: 1 step: 223, loss is 2.2730283737182617\n",
      "epoch: 1 step: 224, loss is 0.4699769616127014\n",
      "epoch: 1 step: 225, loss is 0.3487972021102905\n",
      "epoch: 1 step: 226, loss is 2.917820453643799\n",
      "epoch: 1 step: 227, loss is 1.5201103687286377\n",
      "epoch: 1 step: 228, loss is 3.78836989402771\n",
      "epoch: 1 step: 229, loss is 0.7038384675979614\n",
      "epoch: 1 step: 230, loss is 1.306776523590088\n",
      "epoch: 1 step: 231, loss is 0.26901549100875854\n",
      "epoch: 1 step: 232, loss is 2.349959135055542\n",
      "epoch: 1 step: 233, loss is 0.845592200756073\n",
      "epoch: 1 step: 234, loss is 0.506032407283783\n",
      "epoch: 1 step: 235, loss is 0.6483643651008606\n",
      "epoch: 1 step: 236, loss is 0.5161765813827515\n",
      "epoch: 1 step: 237, loss is 2.597344398498535\n",
      "epoch: 1 step: 238, loss is 2.070568323135376\n",
      "epoch: 1 step: 239, loss is 0.5413932204246521\n",
      "epoch: 1 step: 240, loss is 2.6950337886810303\n",
      "epoch: 1 step: 241, loss is 4.007089138031006\n",
      "epoch: 1 step: 242, loss is 1.1982861757278442\n",
      "epoch: 1 step: 243, loss is 2.8999266624450684\n",
      "epoch: 1 step: 244, loss is 0.9946738481521606\n",
      "epoch: 1 step: 245, loss is 0.5139542818069458\n",
      "epoch: 1 step: 246, loss is 2.9580891132354736\n",
      "epoch: 1 step: 247, loss is 1.9272099733352661\n",
      "epoch: 1 step: 248, loss is 0.4500310719013214\n",
      "epoch: 1 step: 249, loss is 0.4282633364200592\n",
      "epoch: 1 step: 250, loss is 0.7777366042137146\n",
      "epoch: 1 step: 251, loss is 0.13747161626815796\n",
      "epoch: 1 step: 252, loss is 0.36419692635536194\n",
      "epoch: 1 step: 253, loss is 0.404117226600647\n",
      "epoch: 1 step: 254, loss is 0.18483960628509521\n",
      "epoch: 1 step: 255, loss is 0.12023880332708359\n",
      "epoch: 1 step: 256, loss is 2.158493757247925\n",
      "epoch: 1 step: 257, loss is 0.15958283841609955\n",
      "epoch: 1 step: 258, loss is 0.1821269690990448\n",
      "epoch: 1 step: 259, loss is 0.12777839601039886\n",
      "epoch: 1 step: 260, loss is 2.09539794921875\n",
      "epoch: 1 step: 261, loss is 0.9135761260986328\n",
      "epoch: 1 step: 262, loss is 0.640580952167511\n",
      "epoch: 1 step: 263, loss is 0.15150929987430573\n",
      "epoch: 1 step: 264, loss is 0.1016027107834816\n",
      "epoch: 1 step: 265, loss is 0.030401911586523056\n",
      "epoch: 1 step: 266, loss is 1.9836907386779785\n",
      "epoch: 1 step: 267, loss is 4.401356220245361\n",
      "epoch: 1 step: 268, loss is 1.2492525577545166\n",
      "epoch: 1 step: 269, loss is 0.23318295180797577\n",
      "epoch: 1 step: 270, loss is 3.1368327140808105\n",
      "epoch: 1 step: 271, loss is 1.9603898525238037\n",
      "epoch: 1 step: 272, loss is 1.8044763803482056\n",
      "epoch: 1 step: 273, loss is 3.158202648162842\n",
      "epoch: 1 step: 274, loss is 2.203270435333252\n",
      "epoch: 1 step: 275, loss is 2.0102767944335938\n",
      "epoch: 1 step: 276, loss is 1.238159418106079\n",
      "epoch: 1 step: 277, loss is 0.7905399799346924\n",
      "epoch: 1 step: 278, loss is 1.2535420656204224\n",
      "epoch: 1 step: 279, loss is 0.6785749793052673\n",
      "epoch: 1 step: 280, loss is 0.510096549987793\n",
      "epoch: 1 step: 281, loss is 0.6322420835494995\n",
      "epoch: 1 step: 282, loss is 3.7428317070007324\n",
      "epoch: 1 step: 283, loss is 0.8219980001449585\n",
      "epoch: 1 step: 284, loss is 0.6398265957832336\n",
      "epoch: 1 step: 285, loss is 0.15915389358997345\n",
      "epoch: 1 step: 286, loss is 2.4989736080169678\n",
      "epoch: 1 step: 287, loss is 0.7942861914634705\n",
      "epoch: 1 step: 288, loss is 1.6399056911468506\n",
      "epoch: 1 step: 289, loss is 0.5406416654586792\n",
      "epoch: 1 step: 290, loss is 3.463937997817993\n",
      "epoch: 1 step: 291, loss is 3.3257617950439453\n",
      "epoch: 1 step: 292, loss is 2.5572123527526855\n",
      "epoch: 1 step: 293, loss is 1.4792617559432983\n",
      "epoch: 1 step: 294, loss is 1.8170669078826904\n",
      "epoch: 1 step: 295, loss is 1.6827845573425293\n",
      "epoch: 1 step: 296, loss is 1.5259578227996826\n",
      "epoch: 1 step: 297, loss is 1.2319190502166748\n",
      "epoch: 1 step: 298, loss is 1.5329699516296387\n",
      "epoch: 1 step: 299, loss is 1.353273868560791\n",
      "epoch: 1 step: 300, loss is 1.3700157403945923\n",
      "epoch: 1 step: 301, loss is 1.6364754438400269\n",
      "epoch: 1 step: 302, loss is 2.1775245666503906\n",
      "epoch: 1 step: 303, loss is 1.827478051185608\n",
      "epoch: 1 step: 304, loss is 1.932861089706421\n",
      "epoch: 1 step: 305, loss is 1.6882781982421875\n",
      "epoch: 1 step: 306, loss is 1.1968302726745605\n",
      "epoch: 1 step: 307, loss is 1.238246202468872\n",
      "epoch: 1 step: 308, loss is 1.4996848106384277\n",
      "epoch: 1 step: 309, loss is 0.9286118149757385\n",
      "epoch: 1 step: 310, loss is 0.6808091998100281\n",
      "epoch: 1 step: 311, loss is 0.9151230454444885\n",
      "epoch: 1 step: 312, loss is 0.2769545912742615\n",
      "epoch: 1 step: 313, loss is 0.4370879828929901\n",
      "epoch: 1 step: 314, loss is 2.247074842453003\n",
      "epoch: 1 step: 315, loss is 0.5783248543739319\n",
      "epoch: 1 step: 316, loss is 0.6448118686676025\n",
      "epoch: 1 step: 317, loss is 0.26863428950309753\n",
      "epoch: 1 step: 318, loss is 0.6391661167144775\n",
      "epoch: 1 step: 319, loss is 1.07290780544281\n",
      "epoch: 1 step: 320, loss is 0.12113223224878311\n",
      "epoch: 1 step: 321, loss is 0.7439542412757874\n",
      "epoch: 1 step: 322, loss is 2.7806739807128906\n",
      "epoch: 1 step: 323, loss is 0.6160126328468323\n",
      "epoch: 1 step: 324, loss is 0.21454893052577972\n",
      "epoch: 1 step: 325, loss is 0.18284966051578522\n",
      "epoch: 1 step: 326, loss is 0.18315699696540833\n",
      "epoch: 1 step: 327, loss is 0.16864338517189026\n",
      "epoch: 1 step: 328, loss is 0.5185642838478088\n",
      "epoch: 1 step: 329, loss is 0.04637463390827179\n",
      "epoch: 1 step: 330, loss is 4.812783241271973\n",
      "epoch: 1 step: 331, loss is 0.348849356174469\n",
      "epoch: 1 step: 332, loss is 0.8344357013702393\n",
      "epoch: 1 step: 333, loss is 0.2908841669559479\n",
      "epoch: 1 step: 334, loss is 0.15570563077926636\n",
      "epoch: 1 step: 335, loss is 0.3673892319202423\n",
      "epoch: 1 step: 336, loss is 0.18888059258460999\n",
      "epoch: 1 step: 337, loss is 2.7959940433502197\n",
      "epoch: 1 step: 338, loss is 3.7175374031066895\n",
      "epoch: 1 step: 339, loss is 2.1342790126800537\n",
      "epoch: 1 step: 340, loss is 2.2419533729553223\n",
      "epoch: 1 step: 341, loss is 1.79161536693573\n",
      "epoch: 1 step: 342, loss is 3.027576446533203\n",
      "epoch: 1 step: 343, loss is 1.9793531894683838\n",
      "epoch: 1 step: 344, loss is 1.577026128768921\n",
      "epoch: 1 step: 345, loss is 1.0762135982513428\n",
      "epoch: 1 step: 346, loss is 2.034679889678955\n",
      "epoch: 1 step: 347, loss is 1.4456610679626465\n",
      "epoch: 1 step: 348, loss is 1.8045419454574585\n",
      "epoch: 1 step: 349, loss is 1.195641279220581\n",
      "epoch: 1 step: 350, loss is 3.500657558441162\n",
      "epoch: 1 step: 351, loss is 1.6596193313598633\n",
      "epoch: 1 step: 352, loss is 1.039944052696228\n",
      "epoch: 1 step: 353, loss is 0.7620007395744324\n",
      "epoch: 1 step: 354, loss is 1.266412615776062\n",
      "epoch: 1 step: 355, loss is 0.793307900428772\n",
      "epoch: 1 step: 356, loss is 0.7405399680137634\n",
      "epoch: 1 step: 357, loss is 0.8566353917121887\n",
      "epoch: 1 step: 358, loss is 2.016934633255005\n",
      "epoch: 1 step: 359, loss is 4.0075178146362305\n",
      "epoch: 1 step: 360, loss is 0.9385199546813965\n",
      "epoch: 1 step: 361, loss is 1.7719874382019043\n",
      "epoch: 1 step: 362, loss is 0.9514240622520447\n",
      "epoch: 1 step: 363, loss is 0.7519476413726807\n",
      "epoch: 1 step: 364, loss is 2.844599962234497\n",
      "epoch: 1 step: 365, loss is 0.9472866058349609\n",
      "epoch: 1 step: 366, loss is 0.9289165735244751\n",
      "epoch: 1 step: 367, loss is 2.211313247680664\n",
      "epoch: 1 step: 368, loss is 0.5807311534881592\n",
      "epoch: 1 step: 369, loss is 1.077494740486145\n",
      "epoch: 1 step: 370, loss is 2.493847131729126\n",
      "epoch: 1 step: 371, loss is 1.5920571088790894\n",
      "epoch: 1 step: 372, loss is 2.0633738040924072\n",
      "epoch: 1 step: 373, loss is 2.432366371154785\n",
      "epoch: 1 step: 374, loss is 2.128777027130127\n",
      "epoch: 1 step: 375, loss is 1.8834528923034668\n",
      "epoch: 1 step: 376, loss is 0.9782864451408386\n",
      "epoch: 1 step: 377, loss is 0.9689286947250366\n",
      "epoch: 1 step: 378, loss is 0.7234784364700317\n",
      "epoch: 1 step: 379, loss is 0.3756311237812042\n",
      "epoch: 1 step: 380, loss is 0.7649151682853699\n",
      "epoch: 1 step: 381, loss is 0.5080543756484985\n",
      "epoch: 1 step: 382, loss is 2.5437204837799072\n",
      "epoch: 1 step: 383, loss is 3.0103511810302734\n",
      "epoch: 1 step: 384, loss is 1.3492499589920044\n",
      "epoch: 1 step: 385, loss is 2.5172619819641113\n",
      "epoch: 1 step: 386, loss is 1.217187523841858\n",
      "epoch: 1 step: 387, loss is 1.5982606410980225\n",
      "epoch: 1 step: 388, loss is 0.9450942277908325\n",
      "epoch: 1 step: 389, loss is 0.7413998246192932\n",
      "epoch: 1 step: 390, loss is 2.510982036590576\n",
      "epoch: 1 step: 391, loss is 1.897646427154541\n",
      "epoch: 1 step: 392, loss is 0.9429550170898438\n",
      "epoch: 1 step: 393, loss is 1.624370813369751\n",
      "epoch: 1 step: 394, loss is 1.1494389772415161\n",
      "epoch: 1 step: 395, loss is 0.6679726839065552\n",
      "epoch: 1 step: 396, loss is 1.754387617111206\n",
      "epoch: 1 step: 397, loss is 2.1033458709716797\n",
      "epoch: 1 step: 398, loss is 0.9539217352867126\n",
      "epoch: 1 step: 399, loss is 0.7947384715080261\n",
      "epoch: 1 step: 400, loss is 0.7096390724182129\n",
      "epoch: 1 step: 401, loss is 2.5965635776519775\n",
      "epoch: 1 step: 402, loss is 0.4710918664932251\n",
      "epoch: 1 step: 403, loss is 2.019947052001953\n",
      "epoch: 1 step: 404, loss is 0.8395676612854004\n",
      "epoch: 1 step: 405, loss is 1.0692003965377808\n",
      "epoch: 1 step: 406, loss is 1.9889023303985596\n",
      "epoch: 1 step: 407, loss is 0.4416325092315674\n",
      "epoch: 1 step: 408, loss is 0.3803917169570923\n",
      "epoch: 1 step: 409, loss is 0.6382886171340942\n",
      "epoch: 1 step: 410, loss is 0.35900166630744934\n",
      "epoch: 1 step: 411, loss is 2.905492067337036\n",
      "epoch: 1 step: 412, loss is 2.8053672313690186\n",
      "epoch: 1 step: 413, loss is 0.5963810086250305\n",
      "epoch: 1 step: 414, loss is 1.9361937046051025\n",
      "epoch: 1 step: 415, loss is 2.6913633346557617\n",
      "epoch: 1 step: 416, loss is 1.9020966291427612\n",
      "epoch: 1 step: 417, loss is 0.812491774559021\n",
      "epoch: 1 step: 418, loss is 2.036977767944336\n",
      "epoch: 1 step: 419, loss is 2.9273247718811035\n",
      "epoch: 1 step: 420, loss is 2.8606700897216797\n",
      "epoch: 1 step: 421, loss is 1.8431587219238281\n",
      "epoch: 1 step: 422, loss is 0.9863815903663635\n",
      "epoch: 1 step: 423, loss is 0.9585627317428589\n",
      "epoch: 1 step: 424, loss is 0.862913966178894\n",
      "epoch: 1 step: 425, loss is 1.7262015342712402\n",
      "epoch: 1 step: 426, loss is 2.233179807662964\n",
      "epoch: 1 step: 427, loss is 0.6913471817970276\n",
      "epoch: 1 step: 428, loss is 0.5957270860671997\n",
      "epoch: 1 step: 429, loss is 1.8507869243621826\n",
      "epoch: 1 step: 430, loss is 0.4383079707622528\n",
      "epoch: 1 step: 431, loss is 0.6313124299049377\n",
      "epoch: 1 step: 432, loss is 0.6248467564582825\n",
      "epoch: 1 step: 433, loss is 2.6662023067474365\n",
      "epoch: 1 step: 434, loss is 0.7828975319862366\n",
      "epoch: 1 step: 435, loss is 0.5484933853149414\n",
      "epoch: 1 step: 436, loss is 0.8001864552497864\n",
      "epoch: 1 step: 437, loss is 0.6943899989128113\n",
      "epoch: 1 step: 438, loss is 0.3254150152206421\n",
      "epoch: 1 step: 439, loss is 0.21978507936000824\n",
      "epoch: 1 step: 440, loss is 0.20939718186855316\n",
      "epoch: 1 step: 441, loss is 2.3523223400115967\n",
      "epoch: 1 step: 442, loss is 0.15961810946464539\n",
      "epoch: 1 step: 443, loss is 1.391108512878418\n",
      "epoch: 1 step: 444, loss is 3.504030227661133\n",
      "epoch: 1 step: 445, loss is 0.5846732258796692\n",
      "epoch: 1 step: 446, loss is 0.20184090733528137\n",
      "epoch: 1 step: 447, loss is 0.4293363094329834\n",
      "epoch: 1 step: 448, loss is 0.18217863142490387\n",
      "epoch: 1 step: 449, loss is 0.39477935433387756\n",
      "epoch: 1 step: 450, loss is 0.02907394990324974\n",
      "epoch: 1 step: 451, loss is 0.14192700386047363\n",
      "epoch: 1 step: 452, loss is 3.7994601726531982\n",
      "epoch: 1 step: 453, loss is 3.699000835418701\n",
      "epoch: 1 step: 454, loss is 1.7044674158096313\n",
      "epoch: 1 step: 455, loss is 0.821588397026062\n",
      "epoch: 1 step: 456, loss is 0.40195563435554504\n",
      "epoch: 1 step: 457, loss is 2.1457149982452393\n",
      "epoch: 1 step: 458, loss is 2.77462100982666\n",
      "epoch: 1 step: 459, loss is 1.8490653038024902\n",
      "epoch: 1 step: 460, loss is 0.76751309633255\n",
      "epoch: 1 step: 461, loss is 1.9110064506530762\n",
      "epoch: 1 step: 462, loss is 0.5969591736793518\n",
      "epoch: 1 step: 463, loss is 0.38687750697135925\n",
      "epoch: 1 step: 464, loss is 2.014261245727539\n",
      "epoch: 1 step: 465, loss is 0.7421307563781738\n",
      "epoch: 1 step: 466, loss is 0.5593806505203247\n",
      "epoch: 1 step: 467, loss is 2.1889078617095947\n",
      "epoch: 1 step: 468, loss is 0.3648751676082611\n",
      "epoch: 1 step: 469, loss is 0.47424423694610596\n",
      "epoch: 1 step: 470, loss is 0.5178317427635193\n",
      "epoch: 1 step: 471, loss is 0.2178581804037094\n",
      "epoch: 1 step: 472, loss is 2.1477439403533936\n",
      "epoch: 1 step: 473, loss is 1.777206540107727\n",
      "epoch: 1 step: 474, loss is 3.145461320877075\n",
      "epoch: 1 step: 475, loss is 0.3479190170764923\n",
      "epoch: 1 step: 476, loss is 0.4389508366584778\n",
      "epoch: 1 step: 477, loss is 3.082972288131714\n",
      "epoch: 1 step: 478, loss is 1.3079677820205688\n",
      "epoch: 1 step: 479, loss is 0.5712684392929077\n",
      "epoch: 1 step: 480, loss is 1.8059659004211426\n",
      "epoch: 1 step: 481, loss is 0.9446178078651428\n",
      "epoch: 1 step: 482, loss is 0.8144402503967285\n",
      "epoch: 1 step: 483, loss is 0.3974878489971161\n",
      "epoch: 1 step: 484, loss is 0.25387147068977356\n",
      "epoch: 1 step: 485, loss is 0.5119001865386963\n",
      "epoch: 1 step: 486, loss is 0.16935071349143982\n",
      "epoch: 1 step: 487, loss is 0.4297008812427521\n",
      "epoch: 1 step: 488, loss is 1.8103015422821045\n",
      "epoch: 1 step: 489, loss is 0.07850618660449982\n",
      "epoch: 1 step: 490, loss is 4.282864570617676\n",
      "epoch: 1 step: 491, loss is 0.5245795845985413\n",
      "epoch: 1 step: 492, loss is 0.3803466260433197\n",
      "epoch: 1 step: 493, loss is 0.4517563581466675\n",
      "epoch: 1 step: 494, loss is 0.7841464877128601\n",
      "epoch: 1 step: 495, loss is 0.5511593222618103\n",
      "epoch: 1 step: 496, loss is 0.2457682341337204\n",
      "epoch: 1 step: 497, loss is 0.20336340367794037\n",
      "epoch: 1 step: 498, loss is 0.2573089301586151\n",
      "epoch: 1 step: 499, loss is 0.32979339361190796\n",
      "epoch: 1 step: 500, loss is 0.13894028961658478\n",
      "epoch: 1 step: 501, loss is 0.04134904593229294\n",
      "epoch: 1 step: 502, loss is 3.9248123168945312\n",
      "epoch: 1 step: 503, loss is 0.5303272604942322\n",
      "epoch: 1 step: 504, loss is 0.11985164135694504\n",
      "epoch: 1 step: 505, loss is 0.2303871065378189\n",
      "epoch: 1 step: 506, loss is 2.602846622467041\n",
      "epoch: 1 step: 507, loss is 0.08726653456687927\n",
      "epoch: 1 step: 508, loss is 5.646169185638428\n",
      "epoch: 1 step: 509, loss is 0.589371383190155\n",
      "epoch: 1 step: 510, loss is 0.2844066917896271\n",
      "epoch: 1 step: 511, loss is 0.7075893878936768\n",
      "epoch: 1 step: 512, loss is 0.13490736484527588\n",
      "epoch: 1 step: 513, loss is 0.40597137808799744\n",
      "epoch: 1 step: 514, loss is 0.4457032084465027\n",
      "epoch: 1 step: 515, loss is 2.6210598945617676\n",
      "epoch: 1 step: 516, loss is 2.978515625\n",
      "epoch: 1 step: 517, loss is 0.5781311392784119\n",
      "epoch: 1 step: 518, loss is 0.27255505323410034\n",
      "epoch: 1 step: 519, loss is 0.5210033059120178\n",
      "epoch: 1 step: 520, loss is 0.19720707833766937\n",
      "epoch: 1 step: 521, loss is 0.3103681206703186\n",
      "epoch: 1 step: 522, loss is 2.8204734325408936\n",
      "epoch: 1 step: 523, loss is 0.20755009353160858\n",
      "epoch: 1 step: 524, loss is 2.4038734436035156\n",
      "epoch: 1 step: 525, loss is 0.7050076127052307\n",
      "epoch: 1 step: 526, loss is 0.5286439061164856\n",
      "epoch: 1 step: 527, loss is 0.8472527861595154\n",
      "epoch: 1 step: 528, loss is 0.2064381241798401\n",
      "epoch: 1 step: 529, loss is 2.3929741382598877\n",
      "epoch: 1 step: 530, loss is 1.7946783304214478\n",
      "epoch: 1 step: 531, loss is 0.4498322904109955\n",
      "epoch: 1 step: 532, loss is 2.5917484760284424\n",
      "epoch: 1 step: 533, loss is 2.3491721153259277\n",
      "epoch: 1 step: 534, loss is 1.2789597511291504\n",
      "epoch: 1 step: 535, loss is 1.749718427658081\n",
      "epoch: 1 step: 536, loss is 2.3672332763671875\n",
      "epoch: 1 step: 537, loss is 2.188962459564209\n",
      "epoch: 1 step: 538, loss is 0.8806387186050415\n",
      "epoch: 1 step: 539, loss is 0.7678573131561279\n",
      "epoch: 1 step: 540, loss is 2.399876117706299\n",
      "epoch: 1 step: 541, loss is 0.7925555109977722\n",
      "epoch: 1 step: 542, loss is 1.5657100677490234\n",
      "epoch: 1 step: 543, loss is 0.7804635167121887\n",
      "epoch: 1 step: 544, loss is 0.7155252695083618\n",
      "epoch: 1 step: 545, loss is 2.6860079765319824\n",
      "epoch: 1 step: 546, loss is 1.327449083328247\n",
      "epoch: 1 step: 547, loss is 0.9923704862594604\n",
      "epoch: 1 step: 548, loss is 0.42694443464279175\n",
      "epoch: 1 step: 549, loss is 0.5387397408485413\n",
      "epoch: 1 step: 550, loss is 0.48186469078063965\n",
      "epoch: 1 step: 551, loss is 1.9897854328155518\n",
      "epoch: 1 step: 552, loss is 0.9377959966659546\n",
      "epoch: 1 step: 553, loss is 0.8885549902915955\n",
      "epoch: 1 step: 554, loss is 2.8405325412750244\n",
      "epoch: 1 step: 555, loss is 3.074016571044922\n",
      "epoch: 1 step: 556, loss is 0.5838775038719177\n",
      "epoch: 1 step: 557, loss is 0.871811032295227\n",
      "epoch: 1 step: 558, loss is 2.3859782218933105\n",
      "epoch: 1 step: 559, loss is 0.6990533471107483\n",
      "epoch: 1 step: 560, loss is 0.3452622890472412\n",
      "epoch: 1 step: 561, loss is 0.7909496426582336\n",
      "epoch: 1 step: 562, loss is 0.6474241614341736\n",
      "epoch: 1 step: 563, loss is 2.168480157852173\n",
      "epoch: 1 step: 564, loss is 0.33731603622436523\n",
      "epoch: 1 step: 565, loss is 0.6880094408988953\n",
      "epoch: 1 step: 566, loss is 0.19537919759750366\n",
      "epoch: 1 step: 567, loss is 0.3952585458755493\n",
      "epoch: 1 step: 568, loss is 0.4712447226047516\n",
      "epoch: 1 step: 569, loss is 2.503427267074585\n",
      "epoch: 1 step: 570, loss is 1.687795639038086\n",
      "epoch: 1 step: 571, loss is 2.885502815246582\n",
      "epoch: 1 step: 572, loss is 0.7135159969329834\n",
      "epoch: 1 step: 573, loss is 2.4276680946350098\n",
      "epoch: 1 step: 574, loss is 0.31816038489341736\n",
      "epoch: 1 step: 575, loss is 0.7676053643226624\n",
      "epoch: 1 step: 576, loss is 0.5035871863365173\n",
      "epoch: 1 step: 577, loss is 0.25184082984924316\n",
      "epoch: 1 step: 578, loss is 0.3075800836086273\n",
      "epoch: 1 step: 579, loss is 0.6621500849723816\n",
      "epoch: 1 step: 580, loss is 0.2427346408367157\n",
      "epoch: 1 step: 581, loss is 0.4690566062927246\n",
      "epoch: 1 step: 582, loss is 0.42864668369293213\n",
      "epoch: 1 step: 583, loss is 0.20253896713256836\n",
      "epoch: 1 step: 584, loss is 3.0170514583587646\n",
      "epoch: 1 step: 585, loss is 2.515063762664795\n",
      "epoch: 1 step: 586, loss is 0.6460471749305725\n",
      "epoch: 1 step: 587, loss is 0.31992608308792114\n",
      "epoch: 1 step: 588, loss is 1.7576545476913452\n",
      "epoch: 1 step: 589, loss is 0.30151522159576416\n",
      "epoch: 1 step: 590, loss is 2.729050636291504\n",
      "epoch: 1 step: 591, loss is 2.5497608184814453\n",
      "epoch: 1 step: 592, loss is 1.7326374053955078\n",
      "epoch: 1 step: 593, loss is 3.2099928855895996\n",
      "epoch: 1 step: 594, loss is 0.518967866897583\n",
      "epoch: 1 step: 595, loss is 1.4914591312408447\n",
      "epoch: 1 step: 596, loss is 0.5275225639343262\n",
      "epoch: 1 step: 597, loss is 1.8904870748519897\n",
      "epoch: 1 step: 598, loss is 1.7206026315689087\n",
      "epoch: 1 step: 599, loss is 0.6320238709449768\n",
      "epoch: 1 step: 600, loss is 1.445052146911621\n",
      "epoch: 1 step: 601, loss is 1.077356219291687\n",
      "epoch: 1 step: 602, loss is 2.960176467895508\n",
      "epoch: 1 step: 603, loss is 0.617283284664154\n",
      "epoch: 1 step: 604, loss is 0.665503740310669\n",
      "epoch: 1 step: 605, loss is 0.8269168138504028\n",
      "epoch: 1 step: 606, loss is 0.56446772813797\n",
      "epoch: 1 step: 607, loss is 1.9907488822937012\n",
      "epoch: 1 step: 608, loss is 2.463167905807495\n",
      "epoch: 1 step: 609, loss is 0.9265613555908203\n",
      "epoch: 1 step: 610, loss is 2.412494659423828\n",
      "epoch: 1 step: 611, loss is 0.47406354546546936\n",
      "epoch: 1 step: 612, loss is 3.1256275177001953\n",
      "epoch: 1 step: 613, loss is 0.8108691573143005\n",
      "epoch: 1 step: 614, loss is 0.6271069645881653\n",
      "epoch: 1 step: 615, loss is 1.8663629293441772\n",
      "epoch: 1 step: 616, loss is 2.9906294345855713\n",
      "epoch: 1 step: 617, loss is 2.4038047790527344\n",
      "epoch: 1 step: 618, loss is 1.8856648206710815\n",
      "epoch: 1 step: 619, loss is 2.342435121536255\n",
      "epoch: 1 step: 620, loss is 1.9782066345214844\n",
      "epoch: 1 step: 621, loss is 1.2781087160110474\n",
      "epoch: 1 step: 622, loss is 1.7722368240356445\n",
      "epoch: 1 step: 623, loss is 1.093831181526184\n",
      "epoch: 1 step: 624, loss is 0.8844523429870605\n",
      "epoch: 1 step: 625, loss is 1.7132365703582764\n",
      "epoch: 1 step: 626, loss is 0.7776028513908386\n",
      "epoch: 1 step: 627, loss is 0.8314054012298584\n",
      "epoch: 1 step: 628, loss is 2.127749443054199\n",
      "epoch: 1 step: 629, loss is 2.0807948112487793\n",
      "epoch: 1 step: 630, loss is 0.9261432886123657\n",
      "epoch: 1 step: 631, loss is 2.0190656185150146\n",
      "epoch: 1 step: 632, loss is 2.227531909942627\n",
      "epoch: 1 step: 633, loss is 1.9956555366516113\n",
      "epoch: 1 step: 634, loss is 0.9599218368530273\n",
      "epoch: 1 step: 635, loss is 2.3097596168518066\n",
      "epoch: 1 step: 636, loss is 1.8357837200164795\n",
      "epoch: 1 step: 637, loss is 2.303159236907959\n",
      "epoch: 1 step: 638, loss is 0.9375082850456238\n",
      "epoch: 1 step: 639, loss is 0.970803439617157\n",
      "epoch: 1 step: 640, loss is 0.7934181690216064\n",
      "epoch: 1 step: 641, loss is 0.8970759510993958\n",
      "epoch: 1 step: 642, loss is 0.5997622013092041\n",
      "epoch: 1 step: 643, loss is 0.6597480177879333\n",
      "epoch: 1 step: 644, loss is 0.5386852025985718\n",
      "epoch: 1 step: 645, loss is 0.6371834874153137\n",
      "epoch: 1 step: 646, loss is 0.2573949992656708\n",
      "epoch: 1 step: 647, loss is 0.568880558013916\n",
      "epoch: 1 step: 648, loss is 0.49836862087249756\n",
      "epoch: 1 step: 649, loss is 0.14920707046985626\n",
      "epoch: 1 step: 650, loss is 2.3393197059631348\n",
      "epoch: 1 step: 651, loss is 0.3925798535346985\n",
      "epoch: 1 step: 652, loss is 0.2770574986934662\n",
      "epoch: 1 step: 653, loss is 0.3152879774570465\n",
      "epoch: 1 step: 654, loss is 5.8143510818481445\n",
      "epoch: 1 step: 655, loss is 1.973555564880371\n",
      "epoch: 1 step: 656, loss is 0.6577272415161133\n",
      "epoch: 1 step: 657, loss is 2.0670273303985596\n",
      "epoch: 1 step: 658, loss is 0.5930972099304199\n",
      "epoch: 1 step: 659, loss is 0.5293050408363342\n",
      "epoch: 1 step: 660, loss is 0.36002156138420105\n",
      "epoch: 1 step: 661, loss is 0.3711305558681488\n",
      "epoch: 1 step: 662, loss is 0.17044365406036377\n",
      "epoch: 1 step: 663, loss is 0.24439683556556702\n",
      "epoch: 1 step: 664, loss is 0.22928719222545624\n",
      "epoch: 1 step: 665, loss is 2.2252235412597656\n",
      "epoch: 1 step: 666, loss is 0.09640578180551529\n",
      "epoch: 1 step: 667, loss is 0.6694191694259644\n",
      "epoch: 1 step: 668, loss is 2.3957340717315674\n",
      "epoch: 1 step: 669, loss is 0.11325971782207489\n",
      "epoch: 1 step: 670, loss is 0.26102572679519653\n",
      "epoch: 1 step: 671, loss is 0.24837464094161987\n",
      "epoch: 1 step: 672, loss is 0.24667266011238098\n",
      "epoch: 1 step: 673, loss is 4.082501411437988\n",
      "epoch: 1 step: 674, loss is 0.22681815922260284\n",
      "epoch: 1 step: 675, loss is 0.1657172292470932\n",
      "epoch: 1 step: 676, loss is 3.261697292327881\n",
      "epoch: 1 step: 677, loss is 2.1117210388183594\n",
      "epoch: 1 step: 678, loss is 2.206784248352051\n",
      "epoch: 1 step: 679, loss is 1.008393406867981\n",
      "epoch: 1 step: 680, loss is 2.080843210220337\n",
      "epoch: 1 step: 681, loss is 0.6917693018913269\n",
      "epoch: 1 step: 682, loss is 0.4908972978591919\n",
      "epoch: 1 step: 683, loss is 0.5172839760780334\n",
      "epoch: 1 step: 684, loss is 0.3023340702056885\n",
      "epoch: 1 step: 685, loss is 2.879768133163452\n",
      "epoch: 1 step: 686, loss is 1.9868143796920776\n",
      "epoch: 1 step: 687, loss is 0.5442671775817871\n",
      "epoch: 1 step: 688, loss is 0.3654707372188568\n",
      "epoch: 1 step: 689, loss is 0.21975532174110413\n",
      "epoch: 1 step: 690, loss is 2.346673011779785\n",
      "epoch: 1 step: 691, loss is 0.480573445558548\n",
      "epoch: 1 step: 692, loss is 0.9764496684074402\n",
      "epoch: 1 step: 693, loss is 0.5133769512176514\n",
      "epoch: 1 step: 694, loss is 0.3155537545681\n",
      "epoch: 1 step: 695, loss is 0.24966350197792053\n",
      "epoch: 1 step: 696, loss is 1.7807246446609497\n",
      "epoch: 1 step: 697, loss is 2.452256202697754\n",
      "epoch: 1 step: 698, loss is 0.2403852641582489\n",
      "epoch: 1 step: 699, loss is 2.8230888843536377\n",
      "epoch: 1 step: 700, loss is 0.4107728898525238\n",
      "epoch: 1 step: 701, loss is 0.5806306600570679\n",
      "epoch: 1 step: 702, loss is 1.575553059577942\n",
      "epoch: 1 step: 703, loss is 2.055161237716675\n",
      "epoch: 1 step: 704, loss is 2.346395254135132\n",
      "epoch: 1 step: 705, loss is 0.3025442659854889\n",
      "epoch: 1 step: 706, loss is 0.9065389633178711\n",
      "epoch: 1 step: 707, loss is 0.8467950820922852\n",
      "epoch: 1 step: 708, loss is 0.3854879140853882\n",
      "epoch: 1 step: 709, loss is 2.968088150024414\n",
      "epoch: 1 step: 710, loss is 0.7035489678382874\n",
      "epoch: 1 step: 711, loss is 0.7817752361297607\n",
      "epoch: 1 step: 712, loss is 0.845397412776947\n",
      "epoch: 1 step: 713, loss is 2.2846338748931885\n",
      "epoch: 1 step: 714, loss is 2.7050986289978027\n",
      "epoch: 1 step: 715, loss is 1.1406571865081787\n",
      "epoch: 1 step: 716, loss is 0.3673817813396454\n",
      "epoch: 1 step: 717, loss is 0.764398992061615\n",
      "epoch: 1 step: 718, loss is 1.6567199230194092\n",
      "epoch: 1 step: 719, loss is 1.7894892692565918\n",
      "epoch: 1 step: 720, loss is 3.034496784210205\n",
      "epoch: 1 step: 721, loss is 0.8765947818756104\n",
      "epoch: 1 step: 722, loss is 4.188365459442139\n",
      "epoch: 1 step: 723, loss is 1.0929617881774902\n",
      "epoch: 1 step: 724, loss is 0.9704427719116211\n",
      "epoch: 1 step: 725, loss is 1.9487378597259521\n",
      "epoch: 1 step: 726, loss is 1.164665937423706\n",
      "epoch: 1 step: 727, loss is 0.6647713780403137\n",
      "epoch: 1 step: 728, loss is 0.898068368434906\n",
      "epoch: 1 step: 729, loss is 1.993241310119629\n",
      "epoch: 1 step: 730, loss is 1.9442040920257568\n",
      "epoch: 1 step: 731, loss is 0.9298798441886902\n",
      "epoch: 1 step: 732, loss is 0.9837555885314941\n",
      "epoch: 1 step: 733, loss is 0.763313353061676\n",
      "epoch: 1 step: 734, loss is 2.7374191284179688\n",
      "epoch: 1 step: 735, loss is 1.3138015270233154\n",
      "epoch: 1 step: 736, loss is 0.662385106086731\n",
      "epoch: 1 step: 737, loss is 0.644364595413208\n",
      "epoch: 1 step: 738, loss is 1.7998645305633545\n",
      "epoch: 1 step: 739, loss is 2.956315755844116\n",
      "epoch: 1 step: 740, loss is 0.5849065780639648\n",
      "epoch: 1 step: 741, loss is 0.8207046985626221\n",
      "epoch: 1 step: 742, loss is 0.45473960041999817\n",
      "epoch: 1 step: 743, loss is 2.34743332862854\n",
      "epoch: 1 step: 744, loss is 0.28899723291397095\n",
      "epoch: 1 step: 745, loss is 2.9644064903259277\n",
      "epoch: 1 step: 746, loss is 0.3375932574272156\n",
      "epoch: 1 step: 747, loss is 1.8470964431762695\n",
      "epoch: 1 step: 748, loss is 1.0104080438613892\n",
      "epoch: 1 step: 749, loss is 1.7439343929290771\n",
      "epoch: 1 step: 750, loss is 2.2044882774353027\n",
      "epoch: 1 step: 751, loss is 3.324413299560547\n",
      "epoch: 1 step: 752, loss is 1.609062910079956\n",
      "epoch: 1 step: 753, loss is 1.4324963092803955\n",
      "epoch: 1 step: 754, loss is 0.47836774587631226\n",
      "epoch: 1 step: 755, loss is 1.3820260763168335\n",
      "epoch: 1 step: 756, loss is 0.5044915676116943\n",
      "epoch: 1 step: 757, loss is 2.1798787117004395\n",
      "epoch: 1 step: 758, loss is 1.5709517002105713\n",
      "epoch: 1 step: 759, loss is 0.6028187870979309\n",
      "epoch: 1 step: 760, loss is 1.3695828914642334\n",
      "epoch: 1 step: 761, loss is 1.0962715148925781\n",
      "epoch: 1 step: 762, loss is 1.2531636953353882\n",
      "epoch: 1 step: 763, loss is 0.4831479787826538\n",
      "epoch: 1 step: 764, loss is 3.1012234687805176\n",
      "epoch: 1 step: 765, loss is 0.49465546011924744\n",
      "epoch: 1 step: 766, loss is 1.6747655868530273\n",
      "epoch: 1 step: 767, loss is 2.777714729309082\n",
      "epoch: 1 step: 768, loss is 2.672069549560547\n",
      "epoch: 1 step: 769, loss is 0.7675054669380188\n",
      "epoch: 1 step: 770, loss is 0.5597010850906372\n",
      "epoch: 1 step: 771, loss is 1.2643179893493652\n",
      "epoch: 1 step: 772, loss is 0.5915021300315857\n",
      "epoch: 1 step: 773, loss is 2.043487071990967\n",
      "epoch: 1 step: 774, loss is 1.724107265472412\n",
      "epoch: 1 step: 775, loss is 0.35659828782081604\n",
      "epoch: 1 step: 776, loss is 3.0391762256622314\n",
      "epoch: 1 step: 777, loss is 1.1907299757003784\n",
      "epoch: 1 step: 778, loss is 0.6552169322967529\n",
      "epoch: 1 step: 779, loss is 2.1669270992279053\n",
      "epoch: 1 step: 780, loss is 0.8253469467163086\n",
      "epoch: 1 step: 781, loss is 0.43269363045692444\n",
      "epoch: 1 step: 782, loss is 0.7266185283660889\n",
      "epoch: 1 step: 783, loss is 2.724646806716919\n",
      "epoch: 1 step: 784, loss is 2.07169246673584\n",
      "epoch: 1 step: 785, loss is 0.8395096063613892\n",
      "epoch: 1 step: 786, loss is 0.831092894077301\n",
      "epoch: 1 step: 787, loss is 0.9165499806404114\n",
      "epoch: 1 step: 788, loss is 3.0177698135375977\n",
      "epoch: 1 step: 789, loss is 0.9842942357063293\n",
      "epoch: 1 step: 790, loss is 2.1199729442596436\n",
      "epoch: 1 step: 791, loss is 1.7725456953048706\n",
      "epoch: 1 step: 792, loss is 1.8835153579711914\n",
      "epoch: 1 step: 793, loss is 0.6521971821784973\n",
      "epoch: 1 step: 794, loss is 0.7012307643890381\n",
      "epoch: 1 step: 795, loss is 1.8620015382766724\n",
      "epoch: 1 step: 796, loss is 0.8084966540336609\n",
      "epoch: 1 step: 797, loss is 1.5406771898269653\n",
      "epoch: 1 step: 798, loss is 1.6736927032470703\n",
      "epoch: 1 step: 799, loss is 0.5462844371795654\n",
      "epoch: 1 step: 800, loss is 1.011035680770874\n",
      "epoch: 1 step: 801, loss is 0.37773948907852173\n",
      "epoch: 1 step: 802, loss is 0.5657423734664917\n",
      "epoch: 1 step: 803, loss is 2.857865333557129\n",
      "epoch: 1 step: 804, loss is 1.5986294746398926\n",
      "epoch: 1 step: 805, loss is 1.3515450954437256\n",
      "epoch: 1 step: 806, loss is 0.9748209118843079\n",
      "epoch: 1 step: 807, loss is 0.46184131503105164\n",
      "epoch: 1 step: 808, loss is 0.2727239429950714\n",
      "epoch: 1 step: 809, loss is 0.6345896124839783\n",
      "epoch: 1 step: 810, loss is 0.2633891701698303\n",
      "epoch: 1 step: 811, loss is 0.6513119339942932\n",
      "epoch: 1 step: 812, loss is 0.6556320786476135\n",
      "epoch: 1 step: 813, loss is 0.4207804501056671\n",
      "epoch: 1 step: 814, loss is 2.96919322013855\n",
      "epoch: 1 step: 815, loss is 0.5367915630340576\n",
      "epoch: 1 step: 816, loss is 0.08708003163337708\n",
      "epoch: 1 step: 817, loss is 2.9967918395996094\n",
      "epoch: 1 step: 818, loss is 2.5325560569763184\n",
      "epoch: 1 step: 819, loss is 3.044034004211426\n",
      "epoch: 1 step: 820, loss is 0.5451477766036987\n",
      "epoch: 1 step: 821, loss is 0.587043285369873\n",
      "epoch: 1 step: 822, loss is 1.8465542793273926\n",
      "epoch: 1 step: 823, loss is 2.572920322418213\n",
      "epoch: 1 step: 824, loss is 1.565843939781189\n",
      "epoch: 1 step: 825, loss is 0.45771780610084534\n",
      "epoch: 1 step: 826, loss is 0.8760029673576355\n",
      "epoch: 1 step: 827, loss is 0.4634391963481903\n",
      "epoch: 1 step: 828, loss is 2.3426904678344727\n",
      "epoch: 1 step: 829, loss is 2.3705077171325684\n",
      "epoch: 1 step: 830, loss is 2.0629472732543945\n",
      "epoch: 1 step: 831, loss is 2.4165968894958496\n",
      "epoch: 1 step: 832, loss is 1.6127535104751587\n",
      "epoch: 1 step: 833, loss is 1.5122365951538086\n",
      "epoch: 1 step: 834, loss is 1.8284425735473633\n",
      "epoch: 1 step: 835, loss is 1.6108672618865967\n",
      "epoch: 1 step: 836, loss is 1.0766888856887817\n",
      "epoch: 1 step: 837, loss is 1.8847029209136963\n",
      "epoch: 1 step: 838, loss is 1.2198307514190674\n",
      "epoch: 1 step: 839, loss is 1.1984518766403198\n",
      "epoch: 1 step: 840, loss is 0.7912005186080933\n",
      "epoch: 1 step: 841, loss is 0.6529311537742615\n",
      "epoch: 1 step: 842, loss is 1.6966421604156494\n",
      "epoch: 1 step: 843, loss is 0.9765562415122986\n",
      "epoch: 1 step: 844, loss is 0.3903729021549225\n",
      "epoch: 1 step: 845, loss is 0.9144549369812012\n",
      "epoch: 1 step: 846, loss is 0.2644612193107605\n",
      "epoch: 1 step: 847, loss is 0.6379715800285339\n",
      "epoch: 1 step: 848, loss is 2.428635835647583\n",
      "epoch: 1 step: 849, loss is 0.5959806442260742\n",
      "epoch: 1 step: 850, loss is 0.29668939113616943\n",
      "epoch: 1 step: 851, loss is 0.2833483815193176\n",
      "epoch: 1 step: 852, loss is 0.45311394333839417\n",
      "epoch: 1 step: 853, loss is 0.3318251371383667\n",
      "epoch: 1 step: 854, loss is 0.34884917736053467\n",
      "epoch: 1 step: 855, loss is 0.13020798563957214\n",
      "epoch: 1 step: 856, loss is 3.7784407138824463\n",
      "epoch: 1 step: 857, loss is 0.8778840899467468\n",
      "epoch: 1 step: 858, loss is 0.3115251064300537\n",
      "epoch: 1 step: 859, loss is 0.6547474265098572\n",
      "epoch: 1 step: 860, loss is 0.28411394357681274\n",
      "epoch: 1 step: 861, loss is 2.7538399696350098\n",
      "epoch: 1 step: 862, loss is 0.4765445291996002\n",
      "epoch: 1 step: 863, loss is 1.8411089181900024\n",
      "epoch: 1 step: 864, loss is 0.3394070863723755\n",
      "epoch: 1 step: 865, loss is 0.9742690324783325\n",
      "epoch: 1 step: 866, loss is 2.3093860149383545\n",
      "epoch: 1 step: 867, loss is 0.8252496123313904\n",
      "epoch: 1 step: 868, loss is 0.5740071535110474\n",
      "epoch: 1 step: 869, loss is 0.12933896481990814\n",
      "epoch: 1 step: 870, loss is 3.2762887477874756\n",
      "epoch: 1 step: 871, loss is 0.4883553087711334\n",
      "epoch: 1 step: 872, loss is 1.8728976249694824\n",
      "epoch: 1 step: 873, loss is 0.8573322296142578\n",
      "epoch: 1 step: 874, loss is 0.6780493855476379\n",
      "epoch: 1 step: 875, loss is 2.4898324012756348\n",
      "epoch: 1 step: 876, loss is 1.6188886165618896\n",
      "epoch: 1 step: 877, loss is 2.611387014389038\n",
      "epoch: 1 step: 878, loss is 0.5095292329788208\n",
      "epoch: 1 step: 879, loss is 2.203291893005371\n",
      "epoch: 1 step: 880, loss is 0.9345963597297668\n",
      "epoch: 1 step: 881, loss is 2.790182590484619\n",
      "epoch: 1 step: 882, loss is 0.5996249914169312\n",
      "epoch: 1 step: 883, loss is 0.6010189652442932\n",
      "epoch: 1 step: 884, loss is 0.44653213024139404\n",
      "epoch: 1 step: 885, loss is 1.7535828351974487\n",
      "epoch: 1 step: 886, loss is 0.4093235433101654\n",
      "epoch: 1 step: 887, loss is 0.4314632713794708\n",
      "epoch: 1 step: 888, loss is 1.983188271522522\n",
      "epoch: 1 step: 889, loss is 0.6144760251045227\n",
      "epoch: 1 step: 890, loss is 0.9965234398841858\n",
      "epoch: 1 step: 891, loss is 0.3830086886882782\n",
      "epoch: 1 step: 892, loss is 0.44322946667671204\n",
      "epoch: 1 step: 893, loss is 0.14302799105644226\n",
      "epoch: 1 step: 894, loss is 0.35700711607933044\n",
      "epoch: 1 step: 895, loss is 3.68634295463562\n",
      "epoch: 1 step: 896, loss is 0.2002926617860794\n",
      "epoch: 1 step: 897, loss is 0.29138651490211487\n",
      "epoch: 1 step: 898, loss is 0.15409740805625916\n",
      "epoch: 1 step: 899, loss is 0.4943641424179077\n",
      "epoch: 1 step: 900, loss is 1.7903568744659424\n",
      "epoch: 1 step: 901, loss is 0.5038660764694214\n",
      "epoch: 1 step: 902, loss is 0.49646079540252686\n",
      "epoch: 1 step: 903, loss is 0.1615123748779297\n",
      "epoch: 1 step: 904, loss is 2.076712131500244\n",
      "epoch: 1 step: 905, loss is 0.1494060456752777\n",
      "epoch: 1 step: 906, loss is 0.19444245100021362\n",
      "epoch: 1 step: 907, loss is 2.585028886795044\n",
      "epoch: 1 step: 908, loss is 3.1229283809661865\n",
      "epoch: 1 step: 909, loss is 0.7872357368469238\n",
      "epoch: 1 step: 910, loss is 0.6475103497505188\n",
      "epoch: 1 step: 911, loss is 2.048102617263794\n",
      "epoch: 1 step: 912, loss is 0.44430968165397644\n",
      "epoch: 1 step: 913, loss is 2.0348544120788574\n",
      "epoch: 1 step: 914, loss is 0.273150235414505\n",
      "epoch: 1 step: 915, loss is 0.36638110876083374\n",
      "epoch: 1 step: 916, loss is 0.40887385606765747\n",
      "epoch: 1 step: 917, loss is 2.3953170776367188\n",
      "epoch: 1 step: 918, loss is 3.7349038124084473\n",
      "epoch: 1 step: 919, loss is 1.5920214653015137\n",
      "epoch: 1 step: 920, loss is 0.6271774172782898\n",
      "epoch: 1 step: 921, loss is 0.45619362592697144\n",
      "epoch: 1 step: 922, loss is 0.4615206718444824\n",
      "epoch: 1 step: 923, loss is 2.0345849990844727\n",
      "epoch: 1 step: 924, loss is 0.38577958941459656\n",
      "epoch: 1 step: 925, loss is 0.5476580262184143\n",
      "epoch: 1 step: 926, loss is 3.5453782081604004\n",
      "epoch: 1 step: 927, loss is 2.4923527240753174\n",
      "epoch: 1 step: 928, loss is 0.6148521900177002\n",
      "epoch: 1 step: 929, loss is 1.7856054306030273\n",
      "epoch: 1 step: 930, loss is 0.5617659091949463\n",
      "epoch: 1 step: 931, loss is 1.773486614227295\n",
      "epoch: 1 step: 932, loss is 0.3130769729614258\n",
      "epoch: 1 step: 933, loss is 0.6408829689025879\n",
      "epoch: 1 step: 934, loss is 2.598337411880493\n",
      "epoch: 1 step: 935, loss is 0.6442972421646118\n",
      "epoch: 1 step: 936, loss is 0.9565558433532715\n",
      "epoch: 1 step: 937, loss is 2.3859660625457764\n",
      "epoch: 1 step: 938, loss is 0.8377490043640137\n",
      "epoch: 1 step: 939, loss is 0.6096159219741821\n",
      "epoch: 1 step: 940, loss is 1.7933356761932373\n",
      "epoch: 1 step: 941, loss is 0.6165913343429565\n",
      "epoch: 1 step: 942, loss is 0.4153960645198822\n",
      "epoch: 1 step: 943, loss is 0.28638315200805664\n",
      "epoch: 1 step: 944, loss is 0.21882066130638123\n",
      "epoch: 1 step: 945, loss is 1.9470924139022827\n",
      "epoch: 1 step: 946, loss is 0.4731574058532715\n",
      "epoch: 1 step: 947, loss is 3.9117534160614014\n",
      "epoch: 1 step: 948, loss is 1.8842774629592896\n",
      "epoch: 1 step: 949, loss is 0.6580865383148193\n",
      "epoch: 1 step: 950, loss is 0.4780499339103699\n",
      "epoch: 1 step: 951, loss is 2.4784159660339355\n",
      "epoch: 1 step: 952, loss is 0.7554235458374023\n",
      "epoch: 1 step: 953, loss is 0.5622379779815674\n",
      "epoch: 1 step: 954, loss is 0.18181383609771729\n",
      "epoch: 1 step: 955, loss is 1.941558599472046\n",
      "epoch: 1 step: 956, loss is 2.0886948108673096\n",
      "epoch: 1 step: 957, loss is 0.9200145602226257\n",
      "epoch: 1 step: 958, loss is 3.3373327255249023\n",
      "epoch: 1 step: 959, loss is 0.3010897636413574\n",
      "epoch: 1 step: 960, loss is 0.4997967779636383\n",
      "epoch: 1 step: 961, loss is 0.3965286314487457\n",
      "epoch: 1 step: 962, loss is 0.6336631178855896\n",
      "epoch: 1 step: 963, loss is 0.5207923650741577\n",
      "epoch: 1 step: 964, loss is 0.20572958886623383\n",
      "epoch: 1 step: 965, loss is 4.401952743530273\n",
      "epoch: 1 step: 966, loss is 0.7479943633079529\n",
      "epoch: 1 step: 967, loss is 1.762040138244629\n",
      "epoch: 1 step: 968, loss is 0.4997308850288391\n",
      "epoch: 1 step: 969, loss is 1.8556183576583862\n",
      "epoch: 1 step: 970, loss is 1.6061822175979614\n",
      "epoch: 1 step: 971, loss is 0.38873252272605896\n",
      "epoch: 1 step: 972, loss is 1.5311124324798584\n",
      "epoch: 1 step: 973, loss is 0.47121959924697876\n",
      "epoch: 1 step: 974, loss is 2.3251609802246094\n",
      "epoch: 1 step: 975, loss is 0.7038965821266174\n",
      "epoch: 1 step: 976, loss is 2.999026298522949\n",
      "epoch: 1 step: 977, loss is 0.5472648739814758\n",
      "epoch: 1 step: 978, loss is 0.4823927581310272\n",
      "epoch: 1 step: 979, loss is 2.851477861404419\n",
      "epoch: 1 step: 980, loss is 0.8483815789222717\n",
      "epoch: 1 step: 981, loss is 2.22843599319458\n",
      "epoch: 1 step: 982, loss is 1.7956326007843018\n",
      "epoch: 1 step: 983, loss is 3.0505383014678955\n",
      "epoch: 1 step: 984, loss is 0.8774676322937012\n",
      "epoch: 1 step: 985, loss is 1.933447003364563\n",
      "epoch: 1 step: 986, loss is 0.8749366402626038\n",
      "epoch: 1 step: 987, loss is 1.2967886924743652\n",
      "epoch: 1 step: 988, loss is 1.7599855661392212\n",
      "epoch: 1 step: 989, loss is 1.551743507385254\n",
      "epoch: 1 step: 990, loss is 0.8371714353561401\n",
      "epoch: 1 step: 991, loss is 1.919060230255127\n",
      "epoch: 1 step: 992, loss is 1.0464489459991455\n",
      "epoch: 1 step: 993, loss is 0.9095586538314819\n",
      "epoch: 1 step: 994, loss is 2.293081283569336\n",
      "epoch: 1 step: 995, loss is 1.860167145729065\n",
      "epoch: 1 step: 996, loss is 2.1739273071289062\n",
      "epoch: 1 step: 997, loss is 0.8436273336410522\n",
      "epoch: 1 step: 998, loss is 1.6672935485839844\n",
      "epoch: 1 step: 999, loss is 1.345847725868225\n",
      "epoch: 1 step: 1000, loss is 0.874229907989502\n",
      "epoch: 1 step: 1001, loss is 0.6369159817695618\n",
      "epoch: 1 step: 1002, loss is 2.3401894569396973\n",
      "epoch: 1 step: 1003, loss is 1.1338160037994385\n",
      "epoch: 1 step: 1004, loss is 2.235227108001709\n",
      "epoch: 1 step: 1005, loss is 0.5088849663734436\n",
      "epoch: 1 step: 1006, loss is 2.0474965572357178\n",
      "epoch: 1 step: 1007, loss is 2.1042182445526123\n",
      "epoch: 1 step: 1008, loss is 1.6627931594848633\n",
      "epoch: 1 step: 1009, loss is 1.0454051494598389\n",
      "epoch: 1 step: 1010, loss is 0.9089844226837158\n",
      "epoch: 1 step: 1011, loss is 2.00996732711792\n",
      "epoch: 1 step: 1012, loss is 1.026370882987976\n",
      "epoch: 1 step: 1013, loss is 1.075952172279358\n",
      "epoch: 1 step: 1014, loss is 2.083967924118042\n",
      "epoch: 1 step: 1015, loss is 0.9671459794044495\n",
      "epoch: 1 step: 1016, loss is 1.4250986576080322\n",
      "epoch: 1 step: 1017, loss is 1.2241514921188354\n",
      "epoch: 1 step: 1018, loss is 0.8503710627555847\n",
      "epoch: 1 step: 1019, loss is 0.792911171913147\n",
      "epoch: 1 step: 1020, loss is 2.37318754196167\n",
      "epoch: 1 step: 1021, loss is 1.9052174091339111\n",
      "epoch: 1 step: 1022, loss is 3.59814453125\n",
      "epoch: 1 step: 1023, loss is 1.0742725133895874\n",
      "epoch: 1 step: 1024, loss is 0.7263321280479431\n",
      "epoch: 1 step: 1025, loss is 0.9765891432762146\n",
      "epoch: 1 step: 1026, loss is 1.9824705123901367\n",
      "epoch: 1 step: 1027, loss is 0.9125712513923645\n",
      "epoch: 1 step: 1028, loss is 2.1887834072113037\n",
      "epoch: 1 step: 1029, loss is 0.9583284854888916\n",
      "epoch: 1 step: 1030, loss is 0.6004571914672852\n",
      "epoch: 1 step: 1031, loss is 2.109421968460083\n",
      "epoch: 1 step: 1032, loss is 1.6695857048034668\n",
      "epoch: 1 step: 1033, loss is 1.6162190437316895\n",
      "epoch: 1 step: 1034, loss is 0.7625609636306763\n",
      "epoch: 1 step: 1035, loss is 0.7191416025161743\n",
      "epoch: 1 step: 1036, loss is 1.9873929023742676\n",
      "epoch: 1 step: 1037, loss is 0.9037350416183472\n",
      "epoch: 1 step: 1038, loss is 0.9069023132324219\n",
      "epoch: 1 step: 1039, loss is 2.0775599479675293\n",
      "epoch: 1 step: 1040, loss is 0.8276141285896301\n",
      "epoch: 1 step: 1041, loss is 0.5578696131706238\n",
      "epoch: 1 step: 1042, loss is 0.3302531838417053\n",
      "epoch: 1 step: 1043, loss is 2.3411128520965576\n",
      "epoch: 1 step: 1044, loss is 0.6339113116264343\n",
      "epoch: 1 step: 1045, loss is 3.503405809402466\n",
      "epoch: 1 step: 1046, loss is 0.7414959073066711\n",
      "epoch: 1 step: 1047, loss is 0.885459303855896\n",
      "epoch: 1 step: 1048, loss is 0.7159449458122253\n",
      "epoch: 1 step: 1049, loss is 2.861900806427002\n",
      "epoch: 1 step: 1050, loss is 2.0483484268188477\n",
      "epoch: 1 step: 1051, loss is 0.6468871831893921\n",
      "epoch: 1 step: 1052, loss is 0.6440895199775696\n",
      "epoch: 1 step: 1053, loss is 0.9601597189903259\n",
      "epoch: 1 step: 1054, loss is 0.9397656321525574\n",
      "epoch: 1 step: 1055, loss is 0.46576303243637085\n",
      "epoch: 1 step: 1056, loss is 3.1562652587890625\n",
      "epoch: 1 step: 1057, loss is 1.503432035446167\n",
      "epoch: 1 step: 1058, loss is 2.373758316040039\n",
      "epoch: 1 step: 1059, loss is 2.0265965461730957\n",
      "epoch: 1 step: 1060, loss is 0.7873789072036743\n",
      "epoch: 1 step: 1061, loss is 1.6090967655181885\n",
      "epoch: 1 step: 1062, loss is 0.8130630850791931\n",
      "epoch: 1 step: 1063, loss is 0.7273262739181519\n",
      "epoch: 1 step: 1064, loss is 1.730860710144043\n",
      "epoch: 1 step: 1065, loss is 1.709139108657837\n",
      "epoch: 1 step: 1066, loss is 2.0265798568725586\n",
      "epoch: 1 step: 1067, loss is 0.7032101154327393\n",
      "epoch: 1 step: 1068, loss is 0.33026954531669617\n",
      "epoch: 1 step: 1069, loss is 2.0403804779052734\n",
      "epoch: 1 step: 1070, loss is 2.250499963760376\n",
      "epoch: 1 step: 1071, loss is 0.3320726752281189\n",
      "epoch: 1 step: 1072, loss is 1.2784802913665771\n",
      "epoch: 1 step: 1073, loss is 1.8127896785736084\n",
      "epoch: 1 step: 1074, loss is 1.9629449844360352\n",
      "epoch: 1 step: 1075, loss is 0.41265928745269775\n",
      "epoch: 1 step: 1076, loss is 0.3333100378513336\n",
      "epoch: 1 step: 1077, loss is 0.3205758333206177\n",
      "epoch: 1 step: 1078, loss is 0.21685291826725006\n",
      "epoch: 1 step: 1079, loss is 0.7591789364814758\n",
      "epoch: 1 step: 1080, loss is 1.906839370727539\n",
      "epoch: 1 step: 1081, loss is 0.14501497149467468\n",
      "epoch: 1 step: 1082, loss is 2.7004668712615967\n",
      "epoch: 1 step: 1083, loss is 0.7157695293426514\n",
      "epoch: 1 step: 1084, loss is 0.4885852634906769\n",
      "epoch: 1 step: 1085, loss is 0.441213458776474\n",
      "epoch: 1 step: 1086, loss is 2.092548370361328\n",
      "epoch: 1 step: 1087, loss is 0.38381025195121765\n",
      "epoch: 1 step: 1088, loss is 1.8399837017059326\n",
      "epoch: 1 step: 1089, loss is 0.32884687185287476\n",
      "epoch: 1 step: 1090, loss is 2.981595993041992\n",
      "epoch: 1 step: 1091, loss is 0.3259143531322479\n",
      "epoch: 1 step: 1092, loss is 0.3844188451766968\n",
      "epoch: 1 step: 1093, loss is 2.113501787185669\n",
      "epoch: 1 step: 1094, loss is 3.3818697929382324\n",
      "epoch: 1 step: 1095, loss is 2.100332260131836\n",
      "epoch: 1 step: 1096, loss is 2.1030807495117188\n",
      "epoch: 1 step: 1097, loss is 1.1881760358810425\n",
      "epoch: 1 step: 1098, loss is 0.4989302456378937\n",
      "epoch: 1 step: 1099, loss is 0.32511475682258606\n",
      "epoch: 1 step: 1100, loss is 0.3281286954879761\n",
      "epoch: 1 step: 1101, loss is 0.34915393590927124\n",
      "epoch: 1 step: 1102, loss is 0.22061751782894135\n",
      "epoch: 1 step: 1103, loss is 0.215913325548172\n",
      "epoch: 1 step: 1104, loss is 0.5009956955909729\n",
      "epoch: 1 step: 1105, loss is 4.524875640869141\n",
      "epoch: 1 step: 1106, loss is 0.7496861219406128\n",
      "epoch: 1 step: 1107, loss is 3.1232502460479736\n",
      "epoch: 1 step: 1108, loss is 0.7514448165893555\n",
      "epoch: 1 step: 1109, loss is 0.8500816822052002\n",
      "epoch: 1 step: 1110, loss is 1.9657886028289795\n",
      "epoch: 1 step: 1111, loss is 0.8039503693580627\n",
      "epoch: 1 step: 1112, loss is 0.5737073421478271\n",
      "epoch: 1 step: 1113, loss is 0.722260057926178\n",
      "epoch: 1 step: 1114, loss is 2.862250328063965\n",
      "epoch: 1 step: 1115, loss is 0.4805825352668762\n",
      "epoch: 1 step: 1116, loss is 0.5942960977554321\n",
      "epoch: 1 step: 1117, loss is 0.9075982570648193\n",
      "epoch: 1 step: 1118, loss is 0.5084254145622253\n",
      "epoch: 1 step: 1119, loss is 1.9569010734558105\n",
      "epoch: 1 step: 1120, loss is 0.28959643840789795\n",
      "epoch: 1 step: 1121, loss is 2.0064220428466797\n",
      "epoch: 1 step: 1122, loss is 0.3007023334503174\n",
      "epoch: 1 step: 1123, loss is 0.14373715221881866\n",
      "epoch: 1 step: 1124, loss is 0.8673425316810608\n",
      "epoch: 1 step: 1125, loss is 0.5275987982749939\n",
      "epoch: 1 step: 1126, loss is 1.9530446529388428\n",
      "epoch: 1 step: 1127, loss is 3.1969029903411865\n",
      "epoch: 1 step: 1128, loss is 1.8554933071136475\n",
      "epoch: 1 step: 1129, loss is 0.40850770473480225\n",
      "epoch: 1 step: 1130, loss is 2.272212266921997\n",
      "epoch: 1 step: 1131, loss is 0.3911312520503998\n",
      "epoch: 1 step: 1132, loss is 0.36843037605285645\n",
      "epoch: 1 step: 1133, loss is 0.3770572543144226\n",
      "epoch: 1 step: 1134, loss is 0.2265087366104126\n",
      "epoch: 1 step: 1135, loss is 0.11586547642946243\n",
      "epoch: 1 step: 1136, loss is 2.443387985229492\n",
      "epoch: 1 step: 1137, loss is 0.2486557960510254\n",
      "epoch: 1 step: 1138, loss is 0.15179477632045746\n",
      "epoch: 1 step: 1139, loss is 0.6765652894973755\n",
      "epoch: 1 step: 1140, loss is 2.4808058738708496\n",
      "epoch: 1 step: 1141, loss is 0.12982875108718872\n",
      "epoch: 1 step: 1142, loss is 0.1145109310746193\n",
      "epoch: 1 step: 1143, loss is 0.0631890743970871\n",
      "epoch: 1 step: 1144, loss is 0.039533667266368866\n",
      "epoch: 1 step: 1145, loss is 0.08182324469089508\n",
      "epoch: 1 step: 1146, loss is 5.343737602233887\n",
      "epoch: 1 step: 1147, loss is 0.6807063221931458\n",
      "epoch: 1 step: 1148, loss is 0.16812822222709656\n",
      "epoch: 1 step: 1149, loss is 0.1457590013742447\n",
      "epoch: 1 step: 1150, loss is 3.7241342067718506\n",
      "epoch: 1 step: 1151, loss is 0.9282345771789551\n",
      "epoch: 1 step: 1152, loss is 1.751473307609558\n",
      "epoch: 1 step: 1153, loss is 0.5962679982185364\n",
      "epoch: 1 step: 1154, loss is 0.3862277865409851\n",
      "epoch: 1 step: 1155, loss is 0.6474773287773132\n",
      "epoch: 1 step: 1156, loss is 0.26661407947540283\n",
      "epoch: 1 step: 1157, loss is 0.3631341755390167\n",
      "epoch: 1 step: 1158, loss is 3.395698308944702\n",
      "epoch: 1 step: 1159, loss is 0.8299150466918945\n",
      "epoch: 1 step: 1160, loss is 1.8855843544006348\n",
      "epoch: 1 step: 1161, loss is 0.5451676249504089\n",
      "epoch: 1 step: 1162, loss is 0.5830632448196411\n",
      "epoch: 1 step: 1163, loss is 3.245185136795044\n",
      "epoch: 1 step: 1164, loss is 0.5573384165763855\n",
      "epoch: 1 step: 1165, loss is 1.9298551082611084\n",
      "epoch: 1 step: 1166, loss is 0.5280084609985352\n",
      "epoch: 1 step: 1167, loss is 1.890537142753601\n",
      "epoch: 1 step: 1168, loss is 0.7346420288085938\n",
      "epoch: 1 step: 1169, loss is 0.7434315085411072\n",
      "epoch: 1 step: 1170, loss is 0.2627195119857788\n",
      "epoch: 1 step: 1171, loss is 0.24165403842926025\n",
      "epoch: 1 step: 1172, loss is 2.085047721862793\n",
      "epoch: 1 step: 1173, loss is 0.2307499498128891\n",
      "epoch: 1 step: 1174, loss is 1.682444453239441\n",
      "epoch: 1 step: 1175, loss is 0.5005634427070618\n",
      "epoch: 1 step: 1176, loss is 2.367248773574829\n",
      "epoch: 1 step: 1177, loss is 0.4737127423286438\n",
      "epoch: 1 step: 1178, loss is 1.0915530920028687\n",
      "epoch: 1 step: 1179, loss is 0.1291421353816986\n",
      "epoch: 1 step: 1180, loss is 2.321071147918701\n",
      "epoch: 1 step: 1181, loss is 3.035386323928833\n",
      "epoch: 1 step: 1182, loss is 1.9487268924713135\n",
      "epoch: 1 step: 1183, loss is 2.757244348526001\n",
      "epoch: 1 step: 1184, loss is 0.5087902545928955\n",
      "epoch: 1 step: 1185, loss is 0.7233169674873352\n",
      "epoch: 1 step: 1186, loss is 0.45566076040267944\n",
      "epoch: 1 step: 1187, loss is 2.5953550338745117\n",
      "epoch: 1 step: 1188, loss is 1.4692620038986206\n",
      "epoch: 1 step: 1189, loss is 0.514700710773468\n",
      "epoch: 1 step: 1190, loss is 1.8500206470489502\n",
      "epoch: 1 step: 1191, loss is 0.3466111719608307\n",
      "epoch: 1 step: 1192, loss is 0.22900667786598206\n",
      "epoch: 1 step: 1193, loss is 0.7098863124847412\n",
      "epoch: 1 step: 1194, loss is 1.0912977457046509\n",
      "epoch: 1 step: 1195, loss is 2.0749096870422363\n",
      "epoch: 1 step: 1196, loss is 0.4990968406200409\n",
      "epoch: 1 step: 1197, loss is 0.5996124148368835\n",
      "epoch: 1 step: 1198, loss is 0.11027493327856064\n",
      "epoch: 1 step: 1199, loss is 0.12823832035064697\n",
      "epoch: 1 step: 1200, loss is 0.12293937802314758\n",
      "epoch: 1 step: 1201, loss is 1.4982296228408813\n",
      "epoch: 1 step: 1202, loss is 4.57129430770874\n",
      "epoch: 1 step: 1203, loss is 0.4379093647003174\n",
      "epoch: 1 step: 1204, loss is 2.494986057281494\n",
      "epoch: 1 step: 1205, loss is 0.5462294816970825\n",
      "epoch: 1 step: 1206, loss is 2.9757232666015625\n",
      "epoch: 1 step: 1207, loss is 0.6330726742744446\n",
      "epoch: 1 step: 1208, loss is 0.49613189697265625\n",
      "epoch: 1 step: 1209, loss is 0.7965640425682068\n",
      "epoch: 1 step: 1210, loss is 0.3833191990852356\n",
      "epoch: 1 step: 1211, loss is 0.34387245774269104\n",
      "epoch: 1 step: 1212, loss is 0.2146252989768982\n",
      "epoch: 1 step: 1213, loss is 0.5575500130653381\n",
      "epoch: 1 step: 1214, loss is 2.9654171466827393\n",
      "epoch: 1 step: 1215, loss is 0.3372168242931366\n",
      "epoch: 1 step: 1216, loss is 0.3382357358932495\n",
      "epoch: 1 step: 1217, loss is 3.1077921390533447\n",
      "epoch: 1 step: 1218, loss is 0.5072605013847351\n",
      "epoch: 1 step: 1219, loss is 1.751340627670288\n",
      "epoch: 1 step: 1220, loss is 0.44481033086776733\n",
      "epoch: 1 step: 1221, loss is 2.566591739654541\n",
      "epoch: 1 step: 1222, loss is 2.560980796813965\n",
      "epoch: 1 step: 1223, loss is 1.929789662361145\n",
      "epoch: 1 step: 1224, loss is 0.6796597838401794\n",
      "epoch: 1 step: 1225, loss is 4.505177974700928\n",
      "epoch: 1 step: 1226, loss is 2.19838285446167\n",
      "epoch: 1 step: 1227, loss is 0.8465765118598938\n",
      "epoch: 1 step: 1228, loss is 1.4607203006744385\n",
      "epoch: 1 step: 1229, loss is 1.5509753227233887\n",
      "epoch: 1 step: 1230, loss is 0.7327867150306702\n",
      "epoch: 1 step: 1231, loss is 0.9420089721679688\n",
      "epoch: 1 step: 1232, loss is 2.3248183727264404\n",
      "epoch: 1 step: 1233, loss is 0.817166805267334\n",
      "epoch: 1 step: 1234, loss is 0.9586168527603149\n",
      "epoch: 1 step: 1235, loss is 2.0994200706481934\n",
      "epoch: 1 step: 1236, loss is 0.5833985805511475\n",
      "epoch: 1 step: 1237, loss is 2.115220785140991\n",
      "epoch: 1 step: 1238, loss is 0.5672760009765625\n",
      "epoch: 1 step: 1239, loss is 1.719712734222412\n",
      "epoch: 1 step: 1240, loss is 1.8724925518035889\n",
      "epoch: 1 step: 1241, loss is 0.6890407204627991\n",
      "epoch: 1 step: 1242, loss is 0.4863387942314148\n",
      "epoch: 1 step: 1243, loss is 1.125856637954712\n",
      "epoch: 1 step: 1244, loss is 1.850022554397583\n",
      "epoch: 1 step: 1245, loss is 1.714773178100586\n",
      "epoch: 1 step: 1246, loss is 0.947725772857666\n",
      "epoch: 1 step: 1247, loss is 0.8978038430213928\n",
      "epoch: 1 step: 1248, loss is 0.525546133518219\n",
      "epoch: 1 step: 1249, loss is 0.434606671333313\n",
      "epoch: 1 step: 1250, loss is 0.17106874287128448\n",
      "epoch: 1 step: 1251, loss is 0.43757110834121704\n",
      "epoch: 1 step: 1252, loss is 0.17489956319332123\n",
      "epoch: 1 step: 1253, loss is 2.921844959259033\n",
      "epoch: 1 step: 1254, loss is 0.40309131145477295\n",
      "epoch: 1 step: 1255, loss is 0.3027111887931824\n",
      "epoch: 1 step: 1256, loss is 0.38104894757270813\n",
      "epoch: 1 step: 1257, loss is 0.2658166289329529\n",
      "epoch: 1 step: 1258, loss is 2.2738687992095947\n",
      "epoch: 1 step: 1259, loss is 0.15431861579418182\n",
      "epoch: 1 step: 1260, loss is 0.22352895140647888\n",
      "epoch: 1 step: 1261, loss is 0.13848702609539032\n",
      "epoch: 1 step: 1262, loss is 0.1571415513753891\n",
      "epoch: 1 step: 1263, loss is 0.040543023496866226\n",
      "epoch: 1 step: 1264, loss is 0.35917264223098755\n",
      "epoch: 1 step: 1265, loss is 0.425845742225647\n",
      "epoch: 1 step: 1266, loss is 0.18553805351257324\n",
      "epoch: 1 step: 1267, loss is 0.1447407454252243\n",
      "epoch: 1 step: 1268, loss is 1.5557446479797363\n",
      "epoch: 1 step: 1269, loss is 0.018742604181170464\n",
      "epoch: 1 step: 1270, loss is 0.0135923121124506\n",
      "epoch: 1 step: 1271, loss is 8.013447761535645\n",
      "epoch: 1 step: 1272, loss is 0.3327430486679077\n",
      "epoch: 1 step: 1273, loss is 0.14804336428642273\n",
      "epoch: 1 step: 1274, loss is 0.2807251513004303\n",
      "epoch: 1 step: 1275, loss is 3.332218885421753\n",
      "epoch: 1 step: 1276, loss is 0.7261521220207214\n",
      "epoch: 1 step: 1277, loss is 2.94690203666687\n",
      "epoch: 1 step: 1278, loss is 0.3115745186805725\n",
      "epoch: 1 step: 1279, loss is 2.888571262359619\n",
      "epoch: 1 step: 1280, loss is 0.4406638741493225\n",
      "epoch: 1 step: 1281, loss is 2.0175280570983887\n",
      "epoch: 1 step: 1282, loss is 1.684248685836792\n",
      "epoch: 1 step: 1283, loss is 0.4017844796180725\n",
      "epoch: 1 step: 1284, loss is 0.8116582632064819\n",
      "epoch: 1 step: 1285, loss is 0.46357104182243347\n",
      "epoch: 1 step: 1286, loss is 2.3018312454223633\n",
      "epoch: 1 step: 1287, loss is 0.2577269673347473\n",
      "epoch: 1 step: 1288, loss is 0.6494708061218262\n",
      "epoch: 1 step: 1289, loss is 2.3259010314941406\n",
      "epoch: 1 step: 1290, loss is 2.5480332374572754\n",
      "epoch: 1 step: 1291, loss is 0.6339489221572876\n",
      "epoch: 1 step: 1292, loss is 1.9660829305648804\n",
      "epoch: 1 step: 1293, loss is 2.1804394721984863\n",
      "epoch: 1 step: 1294, loss is 0.4840140640735626\n",
      "epoch: 1 step: 1295, loss is 1.0731779336929321\n",
      "epoch: 1 step: 1296, loss is 0.7460975646972656\n",
      "epoch: 1 step: 1297, loss is 0.7929487228393555\n",
      "epoch: 1 step: 1298, loss is 0.30525267124176025\n",
      "epoch: 1 step: 1299, loss is 0.9737027287483215\n",
      "epoch: 1 step: 1300, loss is 0.2159852683544159\n",
      "epoch: 1 step: 1301, loss is 0.5780147910118103\n",
      "epoch: 1 step: 1302, loss is 0.144917830824852\n",
      "epoch: 1 step: 1303, loss is 0.6542317271232605\n",
      "epoch: 1 step: 1304, loss is 0.111390620470047\n",
      "epoch: 1 step: 1305, loss is 2.348605155944824\n",
      "epoch: 1 step: 1306, loss is 0.2373645156621933\n",
      "epoch: 1 step: 1307, loss is 2.65069580078125\n",
      "epoch: 1 step: 1308, loss is 3.487494468688965\n",
      "epoch: 1 step: 1309, loss is 1.8567454814910889\n",
      "epoch: 1 step: 1310, loss is 2.5818378925323486\n",
      "epoch: 1 step: 1311, loss is 0.9629157781600952\n",
      "epoch: 1 step: 1312, loss is 1.6424392461776733\n",
      "epoch: 1 step: 1313, loss is 0.4915120005607605\n",
      "epoch: 1 step: 1314, loss is 1.5341451168060303\n",
      "epoch: 1 step: 1315, loss is 0.2979724705219269\n",
      "epoch: 1 step: 1316, loss is 1.8042296171188354\n",
      "epoch: 1 step: 1317, loss is 0.728079080581665\n",
      "epoch: 1 step: 1318, loss is 0.8741781711578369\n",
      "epoch: 1 step: 1319, loss is 0.7868840098381042\n",
      "epoch: 1 step: 1320, loss is 2.3272881507873535\n",
      "epoch: 1 step: 1321, loss is 0.8482024073600769\n",
      "epoch: 1 step: 1322, loss is 0.5865669846534729\n",
      "epoch: 1 step: 1323, loss is 1.9945251941680908\n",
      "epoch: 1 step: 1324, loss is 0.3197214901447296\n",
      "epoch: 1 step: 1325, loss is 1.6476260423660278\n",
      "epoch: 1 step: 1326, loss is 2.6423285007476807\n",
      "epoch: 1 step: 1327, loss is 2.3737034797668457\n",
      "epoch: 1 step: 1328, loss is 0.9454158544540405\n",
      "epoch: 1 step: 1329, loss is 1.533522367477417\n",
      "epoch: 1 step: 1330, loss is 1.921931266784668\n",
      "epoch: 1 step: 1331, loss is 1.8327438831329346\n",
      "epoch: 1 step: 1332, loss is 0.8307403326034546\n",
      "epoch: 1 step: 1333, loss is 3.3517911434173584\n",
      "epoch: 1 step: 1334, loss is 0.805780827999115\n",
      "epoch: 1 step: 1335, loss is 1.8803369998931885\n",
      "epoch: 1 step: 1336, loss is 2.0808370113372803\n",
      "epoch: 1 step: 1337, loss is 1.4952372312545776\n",
      "epoch: 1 step: 1338, loss is 0.7057861089706421\n",
      "epoch: 1 step: 1339, loss is 0.6147704124450684\n",
      "epoch: 1 step: 1340, loss is 0.5485557913780212\n",
      "epoch: 1 step: 1341, loss is 0.8303916454315186\n",
      "epoch: 1 step: 1342, loss is 1.4317197799682617\n",
      "epoch: 1 step: 1343, loss is 1.7967586517333984\n",
      "epoch: 1 step: 1344, loss is 0.6967481970787048\n",
      "epoch: 1 step: 1345, loss is 3.269859552383423\n",
      "epoch: 1 step: 1346, loss is 1.833242654800415\n",
      "epoch: 1 step: 1347, loss is 2.063814163208008\n",
      "epoch: 1 step: 1348, loss is 0.7655676007270813\n",
      "epoch: 1 step: 1349, loss is 0.8690505623817444\n",
      "epoch: 1 step: 1350, loss is 0.8509092926979065\n",
      "epoch: 1 step: 1351, loss is 2.2304317951202393\n",
      "epoch: 1 step: 1352, loss is 0.9373856782913208\n",
      "epoch: 1 step: 1353, loss is 1.8166463375091553\n",
      "epoch: 1 step: 1354, loss is 0.4847457706928253\n",
      "epoch: 1 step: 1355, loss is 0.6859423518180847\n",
      "epoch: 1 step: 1356, loss is 0.2542771100997925\n",
      "epoch: 1 step: 1357, loss is 2.9599668979644775\n",
      "epoch: 1 step: 1358, loss is 2.2336833477020264\n",
      "epoch: 1 step: 1359, loss is 0.8879510164260864\n",
      "epoch: 1 step: 1360, loss is 0.8845294117927551\n",
      "epoch: 1 step: 1361, loss is 0.6726828813552856\n",
      "epoch: 1 step: 1362, loss is 0.8158683180809021\n",
      "epoch: 1 step: 1363, loss is 0.8032949566841125\n",
      "epoch: 1 step: 1364, loss is 0.41193026304244995\n",
      "epoch: 1 step: 1365, loss is 0.26927250623703003\n",
      "epoch: 1 step: 1366, loss is 0.5333291888237\n",
      "epoch: 1 step: 1367, loss is 0.2057594656944275\n",
      "epoch: 1 step: 1368, loss is 0.8260319828987122\n",
      "epoch: 1 step: 1369, loss is 2.9897148609161377\n",
      "epoch: 1 step: 1370, loss is 2.4011688232421875\n",
      "epoch: 1 step: 1371, loss is 0.22763100266456604\n",
      "epoch: 1 step: 1372, loss is 0.19839514791965485\n",
      "epoch: 1 step: 1373, loss is 1.7160303592681885\n",
      "epoch: 1 step: 1374, loss is 0.14469721913337708\n",
      "epoch: 1 step: 1375, loss is 0.13199786841869354\n",
      "epoch: 1 step: 1376, loss is 0.13401134312152863\n",
      "epoch: 1 step: 1377, loss is 0.6404486298561096\n",
      "epoch: 1 step: 1378, loss is 0.10635538399219513\n",
      "epoch: 1 step: 1379, loss is 3.656808376312256\n",
      "epoch: 1 step: 1380, loss is 0.49411433935165405\n",
      "epoch: 1 step: 1381, loss is 2.881129264831543\n",
      "epoch: 1 step: 1382, loss is 1.7907190322875977\n",
      "epoch: 1 step: 1383, loss is 0.43918344378471375\n",
      "epoch: 1 step: 1384, loss is 0.36952731013298035\n",
      "epoch: 1 step: 1385, loss is 2.067542552947998\n",
      "epoch: 1 step: 1386, loss is 1.8069761991500854\n",
      "epoch: 1 step: 1387, loss is 0.7404166460037231\n",
      "epoch: 1 step: 1388, loss is 0.49750417470932007\n",
      "epoch: 1 step: 1389, loss is 2.595022678375244\n",
      "epoch: 1 step: 1390, loss is 0.40708646178245544\n",
      "epoch: 1 step: 1391, loss is 0.3843733072280884\n",
      "epoch: 1 step: 1392, loss is 0.3055816888809204\n",
      "epoch: 1 step: 1393, loss is 0.8128058314323425\n",
      "epoch: 1 step: 1394, loss is 0.47226762771606445\n",
      "epoch: 1 step: 1395, loss is 0.3461489677429199\n",
      "epoch: 1 step: 1396, loss is 3.4170517921447754\n",
      "epoch: 1 step: 1397, loss is 0.5185301303863525\n",
      "epoch: 1 step: 1398, loss is 1.8662694692611694\n",
      "epoch: 1 step: 1399, loss is 2.51120924949646\n",
      "epoch: 1 step: 1400, loss is 2.103822946548462\n",
      "epoch: 1 step: 1401, loss is 0.6650468707084656\n",
      "epoch: 1 step: 1402, loss is 0.5558943152427673\n",
      "epoch: 1 step: 1403, loss is 1.7714207172393799\n",
      "epoch: 1 step: 1404, loss is 0.9879304766654968\n",
      "epoch: 1 step: 1405, loss is 2.401350498199463\n",
      "epoch: 1 step: 1406, loss is 0.8879159092903137\n",
      "epoch: 1 step: 1407, loss is 2.2218730449676514\n",
      "epoch: 1 step: 1408, loss is 0.5888252854347229\n",
      "epoch: 1 step: 1409, loss is 0.4277525842189789\n",
      "epoch: 1 step: 1410, loss is 0.3305263817310333\n",
      "epoch: 1 step: 1411, loss is 0.7774491310119629\n",
      "epoch: 1 step: 1412, loss is 3.8701324462890625\n",
      "epoch: 1 step: 1413, loss is 0.7128663659095764\n",
      "epoch: 1 step: 1414, loss is 0.7174695134162903\n",
      "epoch: 1 step: 1415, loss is 0.3726840317249298\n",
      "epoch: 1 step: 1416, loss is 0.19104009866714478\n",
      "epoch: 1 step: 1417, loss is 2.9270894527435303\n",
      "epoch: 1 step: 1418, loss is 0.29810553789138794\n",
      "epoch: 1 step: 1419, loss is 3.2148187160491943\n",
      "epoch: 1 step: 1420, loss is 1.5464062690734863\n",
      "epoch: 1 step: 1421, loss is 0.9371137022972107\n",
      "epoch: 1 step: 1422, loss is 2.2200927734375\n",
      "epoch: 1 step: 1423, loss is 1.1063203811645508\n",
      "epoch: 1 step: 1424, loss is 0.630187451839447\n",
      "epoch: 1 step: 1425, loss is 0.716770589351654\n",
      "epoch: 1 step: 1426, loss is 0.6527453660964966\n",
      "epoch: 1 step: 1427, loss is 0.44296854734420776\n",
      "epoch: 1 step: 1428, loss is 0.45330026745796204\n",
      "epoch: 1 step: 1429, loss is 4.836836338043213\n",
      "epoch: 1 step: 1430, loss is 2.0338587760925293\n",
      "epoch: 1 step: 1431, loss is 0.46428778767585754\n",
      "epoch: 1 step: 1432, loss is 3.677838087081909\n",
      "epoch: 1 step: 1433, loss is 0.7419494390487671\n",
      "epoch: 1 step: 1434, loss is 0.5994777679443359\n",
      "epoch: 1 step: 1435, loss is 0.7775918245315552\n",
      "epoch: 1 step: 1436, loss is 0.44193506240844727\n",
      "epoch: 1 step: 1437, loss is 2.560755729675293\n",
      "epoch: 1 step: 1438, loss is 0.5332863330841064\n",
      "epoch: 1 step: 1439, loss is 0.437099426984787\n",
      "epoch: 1 step: 1440, loss is 0.8876706957817078\n",
      "epoch: 1 step: 1441, loss is 0.3242071270942688\n",
      "epoch: 1 step: 1442, loss is 2.1910738945007324\n",
      "epoch: 1 step: 1443, loss is 2.9796249866485596\n",
      "epoch: 1 step: 1444, loss is 0.4543202519416809\n",
      "epoch: 1 step: 1445, loss is 0.7218261957168579\n",
      "epoch: 1 step: 1446, loss is 0.35864579677581787\n",
      "epoch: 1 step: 1447, loss is 2.503969669342041\n",
      "epoch: 1 step: 1448, loss is 1.0646874904632568\n",
      "epoch: 1 step: 1449, loss is 2.1580684185028076\n",
      "epoch: 1 step: 1450, loss is 0.9804060459136963\n",
      "epoch: 1 step: 1451, loss is 0.7145624756813049\n",
      "epoch: 1 step: 1452, loss is 0.7399818301200867\n",
      "epoch: 1 step: 1453, loss is 0.9204399585723877\n",
      "epoch: 1 step: 1454, loss is 0.27583155035972595\n",
      "epoch: 1 step: 1455, loss is 0.5961443185806274\n",
      "epoch: 1 step: 1456, loss is 0.44073063135147095\n",
      "epoch: 1 step: 1457, loss is 0.3342292606830597\n",
      "epoch: 1 step: 1458, loss is 0.2041531503200531\n",
      "epoch: 1 step: 1459, loss is 0.16717728972434998\n",
      "epoch: 1 step: 1460, loss is 2.512662649154663\n",
      "epoch: 1 step: 1461, loss is 2.5369699001312256\n",
      "epoch: 1 step: 1462, loss is 0.3130495846271515\n",
      "epoch: 1 step: 1463, loss is 2.089479923248291\n",
      "epoch: 1 step: 1464, loss is 3.0969648361206055\n",
      "epoch: 1 step: 1465, loss is 0.6063938736915588\n",
      "epoch: 1 step: 1466, loss is 1.7079685926437378\n",
      "epoch: 1 step: 1467, loss is 1.7731587886810303\n",
      "epoch: 1 step: 1468, loss is 0.8371074199676514\n",
      "epoch: 1 step: 1469, loss is 2.26279878616333\n",
      "epoch: 1 step: 1470, loss is 0.41815099120140076\n",
      "epoch: 1 step: 1471, loss is 1.9598824977874756\n",
      "epoch: 1 step: 1472, loss is 0.6276451349258423\n",
      "epoch: 1 step: 1473, loss is 2.5570430755615234\n",
      "epoch: 1 step: 1474, loss is 0.7026894092559814\n",
      "epoch: 1 step: 1475, loss is 3.047081470489502\n",
      "epoch: 1 step: 1476, loss is 0.7170489430427551\n",
      "epoch: 1 step: 1477, loss is 0.5516261458396912\n",
      "epoch: 1 step: 1478, loss is 1.0486211776733398\n",
      "epoch: 1 step: 1479, loss is 0.49926379323005676\n",
      "epoch: 1 step: 1480, loss is 1.7768638134002686\n",
      "epoch: 1 step: 1481, loss is 0.6391319632530212\n",
      "epoch: 1 step: 1482, loss is 0.7719072699546814\n",
      "epoch: 1 step: 1483, loss is 2.6352388858795166\n",
      "epoch: 1 step: 1484, loss is 0.7812409996986389\n",
      "epoch: 1 step: 1485, loss is 0.5870116353034973\n",
      "epoch: 1 step: 1486, loss is 0.3727576732635498\n",
      "epoch: 1 step: 1487, loss is 2.1134328842163086\n",
      "epoch: 1 step: 1488, loss is 0.9138110876083374\n",
      "epoch: 1 step: 1489, loss is 0.4861546456813812\n",
      "epoch: 1 step: 1490, loss is 0.5092455744743347\n",
      "epoch: 1 step: 1491, loss is 0.26072099804878235\n",
      "epoch: 1 step: 1492, loss is 3.6838884353637695\n",
      "epoch: 1 step: 1493, loss is 3.4781875610351562\n",
      "epoch: 1 step: 1494, loss is 3.0062601566314697\n",
      "epoch: 1 step: 1495, loss is 0.8023476004600525\n",
      "epoch: 1 step: 1496, loss is 0.6260213255882263\n",
      "epoch: 1 step: 1497, loss is 2.197791576385498\n",
      "epoch: 1 step: 1498, loss is 2.3292386531829834\n",
      "epoch: 1 step: 1499, loss is 2.2801034450531006\n",
      "epoch: 1 step: 1500, loss is 2.2633841037750244\n",
      "epoch: 1 step: 1501, loss is 0.896109938621521\n",
      "epoch: 1 step: 1502, loss is 0.6752183437347412\n",
      "epoch: 1 step: 1503, loss is 0.7272816896438599\n",
      "epoch: 1 step: 1504, loss is 0.6160606145858765\n",
      "epoch: 1 step: 1505, loss is 0.8076596260070801\n",
      "epoch: 1 step: 1506, loss is 1.7999022006988525\n",
      "epoch: 1 step: 1507, loss is 0.5490245819091797\n",
      "epoch: 1 step: 1508, loss is 0.7799898386001587\n",
      "epoch: 1 step: 1509, loss is 1.0334677696228027\n",
      "epoch: 1 step: 1510, loss is 0.8584793210029602\n",
      "epoch: 1 step: 1511, loss is 1.2207896709442139\n",
      "epoch: 1 step: 1512, loss is 0.4466039836406708\n",
      "epoch: 1 step: 1513, loss is 0.21370449662208557\n",
      "epoch: 1 step: 1514, loss is 0.2150096744298935\n",
      "epoch: 1 step: 1515, loss is 0.7915593981742859\n",
      "epoch: 1 step: 1516, loss is 2.5571963787078857\n",
      "epoch: 1 step: 1517, loss is 0.6609379053115845\n",
      "epoch: 1 step: 1518, loss is 0.22327953577041626\n",
      "epoch: 1 step: 1519, loss is 2.6790149211883545\n",
      "epoch: 1 step: 1520, loss is 0.6443307399749756\n",
      "epoch: 1 step: 1521, loss is 2.1170318126678467\n",
      "epoch: 1 step: 1522, loss is 0.6670787334442139\n",
      "epoch: 1 step: 1523, loss is 0.6121931076049805\n",
      "epoch: 1 step: 1524, loss is 1.4682608842849731\n",
      "epoch: 1 step: 1525, loss is 0.5995798707008362\n",
      "epoch: 1 step: 1526, loss is 2.3646721839904785\n",
      "epoch: 1 step: 1527, loss is 0.604744017124176\n",
      "epoch: 1 step: 1528, loss is 3.3793790340423584\n",
      "epoch: 1 step: 1529, loss is 0.7807706594467163\n",
      "epoch: 1 step: 1530, loss is 1.9578895568847656\n",
      "epoch: 1 step: 1531, loss is 0.499112993478775\n",
      "epoch: 1 step: 1532, loss is 2.9017648696899414\n",
      "epoch: 1 step: 1533, loss is 1.9102784395217896\n",
      "epoch: 1 step: 1534, loss is 2.80088210105896\n",
      "epoch: 1 step: 1535, loss is 0.7061528563499451\n",
      "epoch: 1 step: 1536, loss is 0.35225290060043335\n",
      "epoch: 1 step: 1537, loss is 2.5379316806793213\n",
      "epoch: 1 step: 1538, loss is 1.6292823553085327\n",
      "epoch: 1 step: 1539, loss is 1.5952882766723633\n",
      "epoch: 1 step: 1540, loss is 1.7463408708572388\n",
      "epoch: 1 step: 1541, loss is 1.674102783203125\n",
      "epoch: 1 step: 1542, loss is 1.4883124828338623\n",
      "epoch: 1 step: 1543, loss is 0.9723376631736755\n",
      "epoch: 1 step: 1544, loss is 0.8419020175933838\n",
      "epoch: 1 step: 1545, loss is 1.4468305110931396\n",
      "epoch: 1 step: 1546, loss is 1.7852500677108765\n",
      "epoch: 1 step: 1547, loss is 1.5816004276275635\n",
      "epoch: 1 step: 1548, loss is 0.6520485877990723\n",
      "epoch: 1 step: 1549, loss is 0.8222780823707581\n",
      "epoch: 1 step: 1550, loss is 0.36088091135025024\n",
      "epoch: 1 step: 1551, loss is 1.6411476135253906\n",
      "epoch: 1 step: 1552, loss is 2.2891526222229004\n",
      "epoch: 1 step: 1553, loss is 0.9309546947479248\n",
      "epoch: 1 step: 1554, loss is 0.7180171012878418\n",
      "epoch: 1 step: 1555, loss is 1.917008638381958\n",
      "epoch: 1 step: 1556, loss is 0.7405900359153748\n",
      "epoch: 1 step: 1557, loss is 0.6834020018577576\n",
      "epoch: 1 step: 1558, loss is 0.469307005405426\n",
      "epoch: 1 step: 1559, loss is 0.42493152618408203\n",
      "epoch: 1 step: 1560, loss is 1.3808447122573853\n",
      "epoch: 1 step: 1561, loss is 2.2968242168426514\n",
      "epoch: 1 step: 1562, loss is 0.5138927102088928\n",
      "epoch: 1 step: 1563, loss is 0.6338997483253479\n",
      "epoch: 1 step: 1564, loss is 0.6313031315803528\n",
      "epoch: 1 step: 1565, loss is 2.327249526977539\n",
      "epoch: 1 step: 1566, loss is 0.43711885809898376\n",
      "epoch: 1 step: 1567, loss is 1.8685485124588013\n",
      "epoch: 1 step: 1568, loss is 2.169210433959961\n",
      "epoch: 1 step: 1569, loss is 0.6593519449234009\n",
      "epoch: 1 step: 1570, loss is 2.176171064376831\n",
      "epoch: 1 step: 1571, loss is 0.5374113917350769\n",
      "epoch: 1 step: 1572, loss is 1.4915709495544434\n",
      "epoch: 1 step: 1573, loss is 0.655317485332489\n",
      "epoch: 1 step: 1574, loss is 1.782501220703125\n",
      "epoch: 1 step: 1575, loss is 0.5372697114944458\n",
      "epoch: 1 step: 1576, loss is 0.3232748806476593\n",
      "epoch: 1 step: 1577, loss is 0.39393147826194763\n",
      "epoch: 1 step: 1578, loss is 2.647183895111084\n",
      "epoch: 1 step: 1579, loss is 0.5926151275634766\n",
      "epoch: 1 step: 1580, loss is 0.2729167938232422\n",
      "epoch: 1 step: 1581, loss is 0.19242197275161743\n",
      "epoch: 1 step: 1582, loss is 0.14930245280265808\n",
      "epoch: 1 step: 1583, loss is 0.17548377811908722\n",
      "epoch: 1 step: 1584, loss is 0.18159514665603638\n",
      "epoch: 1 step: 1585, loss is 0.11897759139537811\n",
      "epoch: 1 step: 1586, loss is 0.12440594285726547\n",
      "epoch: 1 step: 1587, loss is 0.7957082390785217\n",
      "epoch: 1 step: 1588, loss is 1.224123477935791\n",
      "epoch: 1 step: 1589, loss is 0.8131917715072632\n",
      "epoch: 1 step: 1590, loss is 0.09916913509368896\n",
      "epoch: 1 step: 1591, loss is 0.07090693712234497\n",
      "epoch: 1 step: 1592, loss is 0.058318112045526505\n",
      "epoch: 1 step: 1593, loss is 3.513062000274658\n",
      "epoch: 1 step: 1594, loss is 3.652904510498047\n",
      "epoch: 1 step: 1595, loss is 0.27578866481781006\n",
      "epoch: 1 step: 1596, loss is 0.2542952299118042\n",
      "epoch: 1 step: 1597, loss is 0.5490089058876038\n",
      "epoch: 1 step: 1598, loss is 2.2449891567230225\n",
      "epoch: 1 step: 1599, loss is 0.3198365569114685\n",
      "epoch: 1 step: 1600, loss is 1.7062305212020874\n",
      "epoch: 2 step: 1, loss is 0.6370810270309448\n",
      "epoch: 2 step: 2, loss is 2.36740779876709\n",
      "epoch: 2 step: 3, loss is 3.3482840061187744\n",
      "epoch: 2 step: 4, loss is 2.2133891582489014\n",
      "epoch: 2 step: 5, loss is 0.844499945640564\n",
      "epoch: 2 step: 6, loss is 2.1860666275024414\n",
      "epoch: 2 step: 7, loss is 0.6844104528427124\n",
      "epoch: 2 step: 8, loss is 0.6705438494682312\n",
      "epoch: 2 step: 9, loss is 0.4193776845932007\n",
      "epoch: 2 step: 10, loss is 0.7726414203643799\n",
      "epoch: 2 step: 11, loss is 2.5485568046569824\n",
      "epoch: 2 step: 12, loss is 1.8562771081924438\n",
      "epoch: 2 step: 13, loss is 0.6428993344306946\n",
      "epoch: 2 step: 14, loss is 0.5158184170722961\n",
      "epoch: 2 step: 15, loss is 0.3461875319480896\n",
      "epoch: 2 step: 16, loss is 1.941528081893921\n",
      "epoch: 2 step: 17, loss is 0.34253838658332825\n",
      "epoch: 2 step: 18, loss is 0.3971816897392273\n",
      "epoch: 2 step: 19, loss is 0.19275608658790588\n",
      "epoch: 2 step: 20, loss is 0.4479637145996094\n",
      "epoch: 2 step: 21, loss is 0.43606290221214294\n",
      "epoch: 2 step: 22, loss is 2.663187026977539\n",
      "epoch: 2 step: 23, loss is 0.2700645923614502\n",
      "epoch: 2 step: 24, loss is 3.919384002685547\n",
      "epoch: 2 step: 25, loss is 0.3223879635334015\n",
      "epoch: 2 step: 26, loss is 0.736687958240509\n",
      "epoch: 2 step: 27, loss is 0.15285581350326538\n",
      "epoch: 2 step: 28, loss is 0.3529917001724243\n",
      "epoch: 2 step: 29, loss is 3.475785732269287\n",
      "epoch: 2 step: 30, loss is 2.515723705291748\n",
      "epoch: 2 step: 31, loss is 0.4980003535747528\n",
      "epoch: 2 step: 32, loss is 0.32782065868377686\n",
      "epoch: 2 step: 33, loss is 0.4476986229419708\n",
      "epoch: 2 step: 34, loss is 0.22938813269138336\n",
      "epoch: 2 step: 35, loss is 0.26737868785858154\n",
      "epoch: 2 step: 36, loss is 0.3603059649467468\n",
      "epoch: 2 step: 37, loss is 0.2622207999229431\n",
      "epoch: 2 step: 38, loss is 0.6227424144744873\n",
      "epoch: 2 step: 39, loss is 1.6045501232147217\n",
      "epoch: 2 step: 40, loss is 1.9302706718444824\n",
      "epoch: 2 step: 41, loss is 2.187629222869873\n",
      "epoch: 2 step: 42, loss is 0.17618098855018616\n",
      "epoch: 2 step: 43, loss is 2.3604698181152344\n",
      "epoch: 2 step: 44, loss is 1.9574053287506104\n",
      "epoch: 2 step: 45, loss is 2.0039899349212646\n",
      "epoch: 2 step: 46, loss is 0.348100483417511\n",
      "epoch: 2 step: 47, loss is 3.0306711196899414\n",
      "epoch: 2 step: 48, loss is 0.7103505730628967\n",
      "epoch: 2 step: 49, loss is 0.31992658972740173\n",
      "epoch: 2 step: 50, loss is 2.593583106994629\n",
      "epoch: 2 step: 51, loss is 1.9665825366973877\n",
      "epoch: 2 step: 52, loss is 0.9083126187324524\n",
      "epoch: 2 step: 53, loss is 0.34160029888153076\n",
      "epoch: 2 step: 54, loss is 0.44728705286979675\n",
      "epoch: 2 step: 55, loss is 0.29223230481147766\n",
      "epoch: 2 step: 56, loss is 0.27908578515052795\n",
      "epoch: 2 step: 57, loss is 0.8364880084991455\n",
      "epoch: 2 step: 58, loss is 1.503430724143982\n",
      "epoch: 2 step: 59, loss is 0.4392874836921692\n",
      "epoch: 2 step: 60, loss is 2.7097108364105225\n",
      "epoch: 2 step: 61, loss is 0.406005859375\n",
      "epoch: 2 step: 62, loss is 0.4652074873447418\n",
      "epoch: 2 step: 63, loss is 2.1324660778045654\n",
      "epoch: 2 step: 64, loss is 1.597346544265747\n",
      "epoch: 2 step: 65, loss is 0.7104585766792297\n",
      "epoch: 2 step: 66, loss is 2.3871359825134277\n",
      "epoch: 2 step: 67, loss is 0.7671020030975342\n",
      "epoch: 2 step: 68, loss is 0.6750885248184204\n",
      "epoch: 2 step: 69, loss is 0.38020068407058716\n",
      "epoch: 2 step: 70, loss is 0.5319820046424866\n",
      "epoch: 2 step: 71, loss is 0.5693806409835815\n",
      "epoch: 2 step: 72, loss is 0.4245709180831909\n",
      "epoch: 2 step: 73, loss is 0.7210906744003296\n",
      "epoch: 2 step: 74, loss is 0.26638075709342957\n",
      "epoch: 2 step: 75, loss is 0.17965680360794067\n",
      "epoch: 2 step: 76, loss is 0.1617557853460312\n",
      "epoch: 2 step: 77, loss is 0.2523941993713379\n",
      "epoch: 2 step: 78, loss is 0.25159355998039246\n",
      "epoch: 2 step: 79, loss is 0.29495957493782043\n",
      "epoch: 2 step: 80, loss is 0.3018048405647278\n",
      "epoch: 2 step: 81, loss is 2.99849009513855\n",
      "epoch: 2 step: 82, loss is 0.23593579232692719\n",
      "epoch: 2 step: 83, loss is 2.0154120922088623\n",
      "epoch: 2 step: 84, loss is 0.26583853363990784\n",
      "epoch: 2 step: 85, loss is 0.36046043038368225\n",
      "epoch: 2 step: 86, loss is 0.11964848637580872\n",
      "epoch: 2 step: 87, loss is 0.15194563567638397\n",
      "epoch: 2 step: 88, loss is 1.4460994005203247\n",
      "epoch: 2 step: 89, loss is 0.06721719354391098\n",
      "epoch: 2 step: 90, loss is 0.09423815459012985\n",
      "epoch: 2 step: 91, loss is 0.15967074036598206\n",
      "epoch: 2 step: 92, loss is 3.895350933074951\n",
      "epoch: 2 step: 93, loss is 0.25083911418914795\n",
      "epoch: 2 step: 94, loss is 0.2183917611837387\n",
      "epoch: 2 step: 95, loss is 5.977470397949219\n",
      "epoch: 2 step: 96, loss is 2.753545045852661\n",
      "epoch: 2 step: 97, loss is 0.4641962945461273\n",
      "epoch: 2 step: 98, loss is 0.20627743005752563\n",
      "epoch: 2 step: 99, loss is 2.4664926528930664\n",
      "epoch: 2 step: 100, loss is 2.306305170059204\n",
      "epoch: 2 step: 101, loss is 1.916965126991272\n",
      "epoch: 2 step: 102, loss is 1.5589230060577393\n",
      "epoch: 2 step: 103, loss is 0.5792879462242126\n",
      "epoch: 2 step: 104, loss is 0.9059026837348938\n",
      "epoch: 2 step: 105, loss is 0.6491116285324097\n",
      "epoch: 2 step: 106, loss is 0.6492975950241089\n",
      "epoch: 2 step: 107, loss is 2.827252149581909\n",
      "epoch: 2 step: 108, loss is 0.37516894936561584\n",
      "epoch: 2 step: 109, loss is 2.596648693084717\n",
      "epoch: 2 step: 110, loss is 0.5550714135169983\n",
      "epoch: 2 step: 111, loss is 0.2282962054014206\n",
      "epoch: 2 step: 112, loss is 2.4358043670654297\n",
      "epoch: 2 step: 113, loss is 1.506685733795166\n",
      "epoch: 2 step: 114, loss is 0.716992974281311\n",
      "epoch: 2 step: 115, loss is 1.9242939949035645\n",
      "epoch: 2 step: 116, loss is 1.8467555046081543\n",
      "epoch: 2 step: 117, loss is 1.868424654006958\n",
      "epoch: 2 step: 118, loss is 1.1332590579986572\n",
      "epoch: 2 step: 119, loss is 1.874269723892212\n",
      "epoch: 2 step: 120, loss is 2.8512067794799805\n",
      "epoch: 2 step: 121, loss is 1.5263426303863525\n",
      "epoch: 2 step: 122, loss is 0.9504432678222656\n",
      "epoch: 2 step: 123, loss is 1.427620768547058\n",
      "epoch: 2 step: 124, loss is 0.9008011221885681\n",
      "epoch: 2 step: 125, loss is 2.386021375656128\n",
      "epoch: 2 step: 126, loss is 0.4862457513809204\n",
      "epoch: 2 step: 127, loss is 2.415976047515869\n",
      "epoch: 2 step: 128, loss is 0.45254820585250854\n",
      "epoch: 2 step: 129, loss is 0.9644395709037781\n",
      "epoch: 2 step: 130, loss is 2.14957332611084\n",
      "epoch: 2 step: 131, loss is 0.8689584732055664\n",
      "epoch: 2 step: 132, loss is 2.653069496154785\n",
      "epoch: 2 step: 133, loss is 0.6786142587661743\n",
      "epoch: 2 step: 134, loss is 0.8524489998817444\n",
      "epoch: 2 step: 135, loss is 1.437715768814087\n",
      "epoch: 2 step: 136, loss is 0.3520088791847229\n",
      "epoch: 2 step: 137, loss is 1.6873890161514282\n",
      "epoch: 2 step: 138, loss is 1.8439909219741821\n",
      "epoch: 2 step: 139, loss is 2.3174729347229004\n",
      "epoch: 2 step: 140, loss is 0.9249298572540283\n",
      "epoch: 2 step: 141, loss is 0.38910409808158875\n",
      "epoch: 2 step: 142, loss is 0.12365185469388962\n",
      "epoch: 2 step: 143, loss is 2.062685966491699\n",
      "epoch: 2 step: 144, loss is 0.5153828859329224\n",
      "epoch: 2 step: 145, loss is 0.18897710740566254\n",
      "epoch: 2 step: 146, loss is 0.878486692905426\n",
      "epoch: 2 step: 147, loss is 0.8678663969039917\n",
      "epoch: 2 step: 148, loss is 3.4103195667266846\n",
      "epoch: 2 step: 149, loss is 0.3375873863697052\n",
      "epoch: 2 step: 150, loss is 0.2241763174533844\n",
      "epoch: 2 step: 151, loss is 0.28215518593788147\n",
      "epoch: 2 step: 152, loss is 4.0187087059021\n",
      "epoch: 2 step: 153, loss is 0.8241876363754272\n",
      "epoch: 2 step: 154, loss is 1.598513126373291\n",
      "epoch: 2 step: 155, loss is 2.100966453552246\n",
      "epoch: 2 step: 156, loss is 1.7030839920043945\n",
      "epoch: 2 step: 157, loss is 0.6819818019866943\n",
      "epoch: 2 step: 158, loss is 0.937493622303009\n",
      "epoch: 2 step: 159, loss is 0.45720165967941284\n",
      "epoch: 2 step: 160, loss is 1.8905582427978516\n",
      "epoch: 2 step: 161, loss is 2.21736216545105\n",
      "epoch: 2 step: 162, loss is 0.8115469217300415\n",
      "epoch: 2 step: 163, loss is 0.5645591020584106\n",
      "epoch: 2 step: 164, loss is 0.3963598906993866\n",
      "epoch: 2 step: 165, loss is 0.28262048959732056\n",
      "epoch: 2 step: 166, loss is 0.4726378321647644\n",
      "epoch: 2 step: 167, loss is 2.6091456413269043\n",
      "epoch: 2 step: 168, loss is 4.081060886383057\n",
      "epoch: 2 step: 169, loss is 0.880597710609436\n",
      "epoch: 2 step: 170, loss is 0.5086588263511658\n",
      "epoch: 2 step: 171, loss is 0.5699730515480042\n",
      "epoch: 2 step: 172, loss is 1.9133833646774292\n",
      "epoch: 2 step: 173, loss is 0.266449898481369\n",
      "epoch: 2 step: 174, loss is 1.7687523365020752\n",
      "epoch: 2 step: 175, loss is 0.33105647563934326\n",
      "epoch: 2 step: 176, loss is 2.1610655784606934\n",
      "epoch: 2 step: 177, loss is 1.705465316772461\n",
      "epoch: 2 step: 178, loss is 0.8955841064453125\n",
      "epoch: 2 step: 179, loss is 0.8793328404426575\n",
      "epoch: 2 step: 180, loss is 2.1763710975646973\n",
      "epoch: 2 step: 181, loss is 3.1537041664123535\n",
      "epoch: 2 step: 182, loss is 0.8205167651176453\n",
      "epoch: 2 step: 183, loss is 0.6900609731674194\n",
      "epoch: 2 step: 184, loss is 2.1547188758850098\n",
      "epoch: 2 step: 185, loss is 0.8870499730110168\n",
      "epoch: 2 step: 186, loss is 0.7873783707618713\n",
      "epoch: 2 step: 187, loss is 1.3277173042297363\n",
      "epoch: 2 step: 188, loss is 0.5976085662841797\n",
      "epoch: 2 step: 189, loss is 0.5867148637771606\n",
      "epoch: 2 step: 190, loss is 1.3358287811279297\n",
      "epoch: 2 step: 191, loss is 2.76420521736145\n",
      "epoch: 2 step: 192, loss is 1.6554336547851562\n",
      "epoch: 2 step: 193, loss is 0.7388367056846619\n",
      "epoch: 2 step: 194, loss is 0.5918266773223877\n",
      "epoch: 2 step: 195, loss is 0.5635769367218018\n",
      "epoch: 2 step: 196, loss is 0.2289460003376007\n",
      "epoch: 2 step: 197, loss is 3.557267665863037\n",
      "epoch: 2 step: 198, loss is 2.4689114093780518\n",
      "epoch: 2 step: 199, loss is 0.7585919499397278\n",
      "epoch: 2 step: 200, loss is 0.4687756299972534\n",
      "epoch: 2 step: 201, loss is 2.498243808746338\n",
      "epoch: 2 step: 202, loss is 0.6893949508666992\n",
      "epoch: 2 step: 203, loss is 2.626459836959839\n",
      "epoch: 2 step: 204, loss is 0.8270235061645508\n",
      "epoch: 2 step: 205, loss is 2.3954408168792725\n",
      "epoch: 2 step: 206, loss is 0.7120734453201294\n",
      "epoch: 2 step: 207, loss is 0.7263484001159668\n",
      "epoch: 2 step: 208, loss is 0.6940481066703796\n",
      "epoch: 2 step: 209, loss is 0.6829537153244019\n",
      "epoch: 2 step: 210, loss is 1.6664726734161377\n",
      "epoch: 2 step: 211, loss is 2.2442984580993652\n",
      "epoch: 2 step: 212, loss is 2.2492101192474365\n",
      "epoch: 2 step: 213, loss is 0.49927884340286255\n",
      "epoch: 2 step: 214, loss is 1.858974575996399\n",
      "epoch: 2 step: 215, loss is 0.5436476469039917\n",
      "epoch: 2 step: 216, loss is 0.6943588256835938\n",
      "epoch: 2 step: 217, loss is 0.5914083123207092\n",
      "epoch: 2 step: 218, loss is 0.66731196641922\n",
      "epoch: 2 step: 219, loss is 0.34840166568756104\n",
      "epoch: 2 step: 220, loss is 1.5781433582305908\n",
      "epoch: 2 step: 221, loss is 0.46512728929519653\n",
      "epoch: 2 step: 222, loss is 0.5391706824302673\n",
      "epoch: 2 step: 223, loss is 2.74539852142334\n",
      "epoch: 2 step: 224, loss is 0.927385687828064\n",
      "epoch: 2 step: 225, loss is 1.7568886280059814\n",
      "epoch: 2 step: 226, loss is 3.4398109912872314\n",
      "epoch: 2 step: 227, loss is 0.6795307993888855\n",
      "epoch: 2 step: 228, loss is 0.45768243074417114\n",
      "epoch: 2 step: 229, loss is 0.2340029925107956\n",
      "epoch: 2 step: 230, loss is 0.3058770000934601\n",
      "epoch: 2 step: 231, loss is 0.3020559847354889\n",
      "epoch: 2 step: 232, loss is 0.6248730421066284\n",
      "epoch: 2 step: 233, loss is 0.21562741696834564\n",
      "epoch: 2 step: 234, loss is 0.3431394696235657\n",
      "epoch: 2 step: 235, loss is 0.1371418982744217\n",
      "epoch: 2 step: 236, loss is 3.516279935836792\n",
      "epoch: 2 step: 237, loss is 3.0660672187805176\n",
      "epoch: 2 step: 238, loss is 2.398653507232666\n",
      "epoch: 2 step: 239, loss is 1.700831651687622\n",
      "epoch: 2 step: 240, loss is 1.9340509176254272\n",
      "epoch: 2 step: 241, loss is 0.38568589091300964\n",
      "epoch: 2 step: 242, loss is 0.7867181301116943\n",
      "epoch: 2 step: 243, loss is 0.7471331357955933\n",
      "epoch: 2 step: 244, loss is 0.6417661905288696\n",
      "epoch: 2 step: 245, loss is 0.47015777230262756\n",
      "epoch: 2 step: 246, loss is 1.873186469078064\n",
      "epoch: 2 step: 247, loss is 0.16284316778182983\n",
      "epoch: 2 step: 248, loss is 2.2405896186828613\n",
      "epoch: 2 step: 249, loss is 0.6119179129600525\n",
      "epoch: 2 step: 250, loss is 1.8747625350952148\n",
      "epoch: 2 step: 251, loss is 0.607009768486023\n",
      "epoch: 2 step: 252, loss is 4.279577732086182\n",
      "epoch: 2 step: 253, loss is 2.668233871459961\n",
      "epoch: 2 step: 254, loss is 0.7719958424568176\n",
      "epoch: 2 step: 255, loss is 0.5844539999961853\n",
      "epoch: 2 step: 256, loss is 0.6994232535362244\n",
      "epoch: 2 step: 257, loss is 2.3940978050231934\n",
      "epoch: 2 step: 258, loss is 0.5138071179389954\n",
      "epoch: 2 step: 259, loss is 2.0002188682556152\n",
      "epoch: 2 step: 260, loss is 2.422985315322876\n",
      "epoch: 2 step: 261, loss is 0.6495406031608582\n",
      "epoch: 2 step: 262, loss is 0.6177511215209961\n",
      "epoch: 2 step: 263, loss is 0.4723913073539734\n",
      "epoch: 2 step: 264, loss is 2.066131591796875\n",
      "epoch: 2 step: 265, loss is 0.49628308415412903\n",
      "epoch: 2 step: 266, loss is 1.7938296794891357\n",
      "epoch: 2 step: 267, loss is 2.493917942047119\n",
      "epoch: 2 step: 268, loss is 0.8901078701019287\n",
      "epoch: 2 step: 269, loss is 1.9718167781829834\n",
      "epoch: 2 step: 270, loss is 1.6275997161865234\n",
      "epoch: 2 step: 271, loss is 0.7009299397468567\n",
      "epoch: 2 step: 272, loss is 0.573621392250061\n",
      "epoch: 2 step: 273, loss is 0.7583356499671936\n",
      "epoch: 2 step: 274, loss is 2.2320709228515625\n",
      "epoch: 2 step: 275, loss is 1.9080395698547363\n",
      "epoch: 2 step: 276, loss is 0.5799904465675354\n",
      "epoch: 2 step: 277, loss is 0.4694264233112335\n",
      "epoch: 2 step: 278, loss is 0.4646829068660736\n",
      "epoch: 2 step: 279, loss is 2.4626810550689697\n",
      "epoch: 2 step: 280, loss is 0.7245132923126221\n",
      "epoch: 2 step: 281, loss is 0.34531375765800476\n",
      "epoch: 2 step: 282, loss is 2.1508054733276367\n",
      "epoch: 2 step: 283, loss is 0.3234914243221283\n",
      "epoch: 2 step: 284, loss is 0.4620436728000641\n",
      "epoch: 2 step: 285, loss is 0.33695635199546814\n",
      "epoch: 2 step: 286, loss is 2.5316245555877686\n",
      "epoch: 2 step: 287, loss is 0.7496243715286255\n",
      "epoch: 2 step: 288, loss is 2.517827033996582\n",
      "epoch: 2 step: 289, loss is 2.1914234161376953\n",
      "epoch: 2 step: 290, loss is 1.0717674493789673\n",
      "epoch: 2 step: 291, loss is 0.5318095088005066\n",
      "epoch: 2 step: 292, loss is 0.3639869689941406\n",
      "epoch: 2 step: 293, loss is 0.3725697100162506\n",
      "epoch: 2 step: 294, loss is 0.7266485095024109\n",
      "epoch: 2 step: 295, loss is 1.6612484455108643\n",
      "epoch: 2 step: 296, loss is 0.5359189510345459\n",
      "epoch: 2 step: 297, loss is 2.630679130554199\n",
      "epoch: 2 step: 298, loss is 0.5775561928749084\n",
      "epoch: 2 step: 299, loss is 2.0530247688293457\n",
      "epoch: 2 step: 300, loss is 0.3385038673877716\n",
      "epoch: 2 step: 301, loss is 0.24361425638198853\n",
      "epoch: 2 step: 302, loss is 3.0159103870391846\n",
      "epoch: 2 step: 303, loss is 0.6934582591056824\n",
      "epoch: 2 step: 304, loss is 0.522497832775116\n",
      "epoch: 2 step: 305, loss is 2.323601484298706\n",
      "epoch: 2 step: 306, loss is 0.7392680048942566\n",
      "epoch: 2 step: 307, loss is 2.0608673095703125\n",
      "epoch: 2 step: 308, loss is 1.7988548278808594\n",
      "epoch: 2 step: 309, loss is 0.6840113401412964\n",
      "epoch: 2 step: 310, loss is 2.095299243927002\n",
      "epoch: 2 step: 311, loss is 1.6562690734863281\n",
      "epoch: 2 step: 312, loss is 0.4460269808769226\n",
      "epoch: 2 step: 313, loss is 2.499178886413574\n",
      "epoch: 2 step: 314, loss is 0.8078010082244873\n",
      "epoch: 2 step: 315, loss is 0.4655984044075012\n",
      "epoch: 2 step: 316, loss is 1.7163101434707642\n",
      "epoch: 2 step: 317, loss is 1.7431092262268066\n",
      "epoch: 2 step: 318, loss is 0.5989986062049866\n",
      "epoch: 2 step: 319, loss is 2.736011266708374\n",
      "epoch: 2 step: 320, loss is 0.6535422801971436\n",
      "epoch: 2 step: 321, loss is 0.42377758026123047\n",
      "epoch: 2 step: 322, loss is 0.49581778049468994\n",
      "epoch: 2 step: 323, loss is 0.6077134013175964\n",
      "epoch: 2 step: 324, loss is 0.20072197914123535\n",
      "epoch: 2 step: 325, loss is 2.7597107887268066\n",
      "epoch: 2 step: 326, loss is 0.34101542830467224\n",
      "epoch: 2 step: 327, loss is 2.678873300552368\n",
      "epoch: 2 step: 328, loss is 0.6480944156646729\n",
      "epoch: 2 step: 329, loss is 2.291468620300293\n",
      "epoch: 2 step: 330, loss is 0.45529964566230774\n",
      "epoch: 2 step: 331, loss is 0.47640544176101685\n",
      "epoch: 2 step: 332, loss is 3.4859747886657715\n",
      "epoch: 2 step: 333, loss is 2.443417549133301\n",
      "epoch: 2 step: 334, loss is 1.1010664701461792\n",
      "epoch: 2 step: 335, loss is 0.6010873317718506\n",
      "epoch: 2 step: 336, loss is 2.3370730876922607\n",
      "epoch: 2 step: 337, loss is 1.614833116531372\n",
      "epoch: 2 step: 338, loss is 2.0109589099884033\n",
      "epoch: 2 step: 339, loss is 1.2268345355987549\n",
      "epoch: 2 step: 340, loss is 0.9659518003463745\n",
      "epoch: 2 step: 341, loss is 1.703815221786499\n",
      "epoch: 2 step: 342, loss is 0.8451777100563049\n",
      "epoch: 2 step: 343, loss is 2.0503063201904297\n",
      "epoch: 2 step: 344, loss is 1.413921594619751\n",
      "epoch: 2 step: 345, loss is 1.0028754472732544\n",
      "epoch: 2 step: 346, loss is 2.159226894378662\n",
      "epoch: 2 step: 347, loss is 1.6881749629974365\n",
      "epoch: 2 step: 348, loss is 1.9656507968902588\n",
      "epoch: 2 step: 349, loss is 0.534184455871582\n",
      "epoch: 2 step: 350, loss is 0.6224757432937622\n",
      "epoch: 2 step: 351, loss is 0.7421082854270935\n",
      "epoch: 2 step: 352, loss is 0.6560271978378296\n",
      "epoch: 2 step: 353, loss is 1.7481558322906494\n",
      "epoch: 2 step: 354, loss is 0.35712355375289917\n",
      "epoch: 2 step: 355, loss is 0.6028661131858826\n",
      "epoch: 2 step: 356, loss is 0.41740137338638306\n",
      "epoch: 2 step: 357, loss is 2.50362491607666\n",
      "epoch: 2 step: 358, loss is 0.7071515917778015\n",
      "epoch: 2 step: 359, loss is 0.2713652551174164\n",
      "epoch: 2 step: 360, loss is 0.48820286989212036\n",
      "epoch: 2 step: 361, loss is 3.2691457271575928\n",
      "epoch: 2 step: 362, loss is 0.5200916528701782\n",
      "epoch: 2 step: 363, loss is 2.449601650238037\n",
      "epoch: 2 step: 364, loss is 1.8537685871124268\n",
      "epoch: 2 step: 365, loss is 1.8163305521011353\n",
      "epoch: 2 step: 366, loss is 2.4676177501678467\n",
      "epoch: 2 step: 367, loss is 0.7092760801315308\n",
      "epoch: 2 step: 368, loss is 0.5920562148094177\n",
      "epoch: 2 step: 369, loss is 2.263554096221924\n",
      "epoch: 2 step: 370, loss is 1.1689929962158203\n",
      "epoch: 2 step: 371, loss is 0.756646990776062\n",
      "epoch: 2 step: 372, loss is 0.37739765644073486\n",
      "epoch: 2 step: 373, loss is 1.8761237859725952\n",
      "epoch: 2 step: 374, loss is 0.6193200945854187\n",
      "epoch: 2 step: 375, loss is 1.8160924911499023\n",
      "epoch: 2 step: 376, loss is 0.6692367196083069\n",
      "epoch: 2 step: 377, loss is 1.684086799621582\n",
      "epoch: 2 step: 378, loss is 2.044433832168579\n",
      "epoch: 2 step: 379, loss is 0.7544920444488525\n",
      "epoch: 2 step: 380, loss is 0.9689171314239502\n",
      "epoch: 2 step: 381, loss is 1.5972473621368408\n",
      "epoch: 2 step: 382, loss is 0.7756504416465759\n",
      "epoch: 2 step: 383, loss is 2.6678807735443115\n",
      "epoch: 2 step: 384, loss is 0.45010098814964294\n",
      "epoch: 2 step: 385, loss is 2.189378023147583\n",
      "epoch: 2 step: 386, loss is 0.5551247000694275\n",
      "epoch: 2 step: 387, loss is 0.44970905780792236\n",
      "epoch: 2 step: 388, loss is 0.37138649821281433\n",
      "epoch: 2 step: 389, loss is 1.7192187309265137\n",
      "epoch: 2 step: 390, loss is 2.744668960571289\n",
      "epoch: 2 step: 391, loss is 0.40358030796051025\n",
      "epoch: 2 step: 392, loss is 2.4727108478546143\n",
      "epoch: 2 step: 393, loss is 1.404559850692749\n",
      "epoch: 2 step: 394, loss is 0.5696074962615967\n",
      "epoch: 2 step: 395, loss is 2.028555393218994\n",
      "epoch: 2 step: 396, loss is 0.49892979860305786\n",
      "epoch: 2 step: 397, loss is 0.877788782119751\n",
      "epoch: 2 step: 398, loss is 1.86051344871521\n",
      "epoch: 2 step: 399, loss is 0.5016383528709412\n",
      "epoch: 2 step: 400, loss is 0.39193060994148254\n",
      "epoch: 2 step: 401, loss is 0.27320346236228943\n",
      "epoch: 2 step: 402, loss is 2.360527753829956\n",
      "epoch: 2 step: 403, loss is 0.27679136395454407\n",
      "epoch: 2 step: 404, loss is 0.41617539525032043\n",
      "epoch: 2 step: 405, loss is 0.39692941308021545\n",
      "epoch: 2 step: 406, loss is 2.6160049438476562\n",
      "epoch: 2 step: 407, loss is 1.4499180316925049\n",
      "epoch: 2 step: 408, loss is 2.204509735107422\n",
      "epoch: 2 step: 409, loss is 1.662543535232544\n",
      "epoch: 2 step: 410, loss is 0.796717643737793\n",
      "epoch: 2 step: 411, loss is 0.38872596621513367\n",
      "epoch: 2 step: 412, loss is 0.3571242392063141\n",
      "epoch: 2 step: 413, loss is 0.301764577627182\n",
      "epoch: 2 step: 414, loss is 3.0465095043182373\n",
      "epoch: 2 step: 415, loss is 2.052340030670166\n",
      "epoch: 2 step: 416, loss is 0.390326589345932\n",
      "epoch: 2 step: 417, loss is 0.4209034740924835\n",
      "epoch: 2 step: 418, loss is 0.16898362338542938\n",
      "epoch: 2 step: 419, loss is 0.1387224942445755\n",
      "epoch: 2 step: 420, loss is 1.786430835723877\n",
      "epoch: 2 step: 421, loss is 0.11809197813272476\n",
      "epoch: 2 step: 422, loss is 0.23937350511550903\n",
      "epoch: 2 step: 423, loss is 0.126938134431839\n",
      "epoch: 2 step: 424, loss is 0.11916988343000412\n",
      "epoch: 2 step: 425, loss is 3.418365478515625\n",
      "epoch: 2 step: 426, loss is 0.48768699169158936\n",
      "epoch: 2 step: 427, loss is 2.0715932846069336\n",
      "epoch: 2 step: 428, loss is 1.9037503004074097\n",
      "epoch: 2 step: 429, loss is 0.49799224734306335\n",
      "epoch: 2 step: 430, loss is 0.25767502188682556\n",
      "epoch: 2 step: 431, loss is 3.13259220123291\n",
      "epoch: 2 step: 432, loss is 1.2246943712234497\n",
      "epoch: 2 step: 433, loss is 1.6327306032180786\n",
      "epoch: 2 step: 434, loss is 2.4793550968170166\n",
      "epoch: 2 step: 435, loss is 0.5988461375236511\n",
      "epoch: 2 step: 436, loss is 1.5845109224319458\n",
      "epoch: 2 step: 437, loss is 2.1040711402893066\n",
      "epoch: 2 step: 438, loss is 1.8105672597885132\n",
      "epoch: 2 step: 439, loss is 0.7660963535308838\n",
      "epoch: 2 step: 440, loss is 0.3942124843597412\n",
      "epoch: 2 step: 441, loss is 2.06618332862854\n",
      "epoch: 2 step: 442, loss is 0.794750452041626\n",
      "epoch: 2 step: 443, loss is 2.8327317237854004\n",
      "epoch: 2 step: 444, loss is 2.02933406829834\n",
      "epoch: 2 step: 445, loss is 1.2044509649276733\n",
      "epoch: 2 step: 446, loss is 0.5321345925331116\n",
      "epoch: 2 step: 447, loss is 0.8163183331489563\n",
      "epoch: 2 step: 448, loss is 0.4428936839103699\n",
      "epoch: 2 step: 449, loss is 1.867004156112671\n",
      "epoch: 2 step: 450, loss is 0.5697330832481384\n",
      "epoch: 2 step: 451, loss is 0.3906536400318146\n",
      "epoch: 2 step: 452, loss is 1.0293468236923218\n",
      "epoch: 2 step: 453, loss is 1.845959186553955\n",
      "epoch: 2 step: 454, loss is 0.3850349187850952\n",
      "epoch: 2 step: 455, loss is 2.627584218978882\n",
      "epoch: 2 step: 456, loss is 0.3331570625305176\n",
      "epoch: 2 step: 457, loss is 1.7276544570922852\n",
      "epoch: 2 step: 458, loss is 2.6336252689361572\n",
      "epoch: 2 step: 459, loss is 0.2767985761165619\n",
      "epoch: 2 step: 460, loss is 0.6495317816734314\n",
      "epoch: 2 step: 461, loss is 1.7613186836242676\n",
      "epoch: 2 step: 462, loss is 1.1955418586730957\n",
      "epoch: 2 step: 463, loss is 2.232184886932373\n",
      "epoch: 2 step: 464, loss is 1.898202657699585\n",
      "epoch: 2 step: 465, loss is 0.5301820635795593\n",
      "epoch: 2 step: 466, loss is 0.3581424653530121\n",
      "epoch: 2 step: 467, loss is 0.8067841529846191\n",
      "epoch: 2 step: 468, loss is 1.0091032981872559\n",
      "epoch: 2 step: 469, loss is 1.990057110786438\n",
      "epoch: 2 step: 470, loss is 0.24162350594997406\n",
      "epoch: 2 step: 471, loss is 1.8138847351074219\n",
      "epoch: 2 step: 472, loss is 0.35760337114334106\n",
      "epoch: 2 step: 473, loss is 0.5290040373802185\n",
      "epoch: 2 step: 474, loss is 0.2737523913383484\n",
      "epoch: 2 step: 475, loss is 0.07585049420595169\n",
      "epoch: 2 step: 476, loss is 0.6078799366950989\n",
      "epoch: 2 step: 477, loss is 1.244728684425354\n",
      "epoch: 2 step: 478, loss is 2.702702283859253\n",
      "epoch: 2 step: 479, loss is 2.0716092586517334\n",
      "epoch: 2 step: 480, loss is 0.281183123588562\n",
      "epoch: 2 step: 481, loss is 0.2834317982196808\n",
      "epoch: 2 step: 482, loss is 0.4457162618637085\n",
      "epoch: 2 step: 483, loss is 0.2642648220062256\n",
      "epoch: 2 step: 484, loss is 0.20783716440200806\n",
      "epoch: 2 step: 485, loss is 2.189471483230591\n",
      "epoch: 2 step: 486, loss is 2.04803204536438\n",
      "epoch: 2 step: 487, loss is 0.4251556694507599\n",
      "epoch: 2 step: 488, loss is 1.2102738618850708\n",
      "epoch: 2 step: 489, loss is 1.894519329071045\n",
      "epoch: 2 step: 490, loss is 1.7289454936981201\n",
      "epoch: 2 step: 491, loss is 0.7543433904647827\n",
      "epoch: 2 step: 492, loss is 1.9706628322601318\n",
      "epoch: 2 step: 493, loss is 0.5375059247016907\n",
      "epoch: 2 step: 494, loss is 0.8300414085388184\n",
      "epoch: 2 step: 495, loss is 0.13999389111995697\n",
      "epoch: 2 step: 496, loss is 0.6489490270614624\n",
      "epoch: 2 step: 497, loss is 3.8804125785827637\n",
      "epoch: 2 step: 498, loss is 1.6456000804901123\n",
      "epoch: 2 step: 499, loss is 0.4356144368648529\n",
      "epoch: 2 step: 500, loss is 0.23115825653076172\n",
      "epoch: 2 step: 501, loss is 2.151142120361328\n",
      "epoch: 2 step: 502, loss is 0.3968242406845093\n",
      "epoch: 2 step: 503, loss is 0.8235010504722595\n",
      "epoch: 2 step: 504, loss is 0.49135586619377136\n",
      "epoch: 2 step: 505, loss is 0.40133872628211975\n",
      "epoch: 2 step: 506, loss is 0.0768711194396019\n",
      "epoch: 2 step: 507, loss is 0.4209491014480591\n",
      "epoch: 2 step: 508, loss is 0.2445169985294342\n",
      "epoch: 2 step: 509, loss is 0.2305944412946701\n",
      "epoch: 2 step: 510, loss is 0.16100053489208221\n",
      "epoch: 2 step: 511, loss is 0.30601462721824646\n",
      "epoch: 2 step: 512, loss is 3.3646974563598633\n",
      "epoch: 2 step: 513, loss is 0.5039008259773254\n",
      "epoch: 2 step: 514, loss is 0.4743359088897705\n",
      "epoch: 2 step: 515, loss is 0.415538489818573\n",
      "epoch: 2 step: 516, loss is 0.18498486280441284\n",
      "epoch: 2 step: 517, loss is 0.3423578441143036\n",
      "epoch: 2 step: 518, loss is 3.8893215656280518\n",
      "epoch: 2 step: 519, loss is 0.7342946529388428\n",
      "epoch: 2 step: 520, loss is 0.4815693795681\n",
      "epoch: 2 step: 521, loss is 0.2521831691265106\n",
      "epoch: 2 step: 522, loss is 0.132023885846138\n",
      "epoch: 2 step: 523, loss is 0.16557207703590393\n",
      "epoch: 2 step: 524, loss is 6.046694755554199\n",
      "epoch: 2 step: 525, loss is 1.5755115747451782\n",
      "epoch: 2 step: 526, loss is 2.4986143112182617\n",
      "epoch: 2 step: 527, loss is 0.398510217666626\n",
      "epoch: 2 step: 528, loss is 0.11383913457393646\n",
      "epoch: 2 step: 529, loss is 1.5946464538574219\n",
      "epoch: 2 step: 530, loss is 2.174506664276123\n",
      "epoch: 2 step: 531, loss is 0.4113689363002777\n",
      "epoch: 2 step: 532, loss is 0.30781763792037964\n",
      "epoch: 2 step: 533, loss is 1.3279504776000977\n",
      "epoch: 2 step: 534, loss is 0.35961246490478516\n",
      "epoch: 2 step: 535, loss is 0.330240935087204\n",
      "epoch: 2 step: 536, loss is 2.628241777420044\n",
      "epoch: 2 step: 537, loss is 2.7177014350891113\n",
      "epoch: 2 step: 538, loss is 0.7694709300994873\n",
      "epoch: 2 step: 539, loss is 0.5357114672660828\n",
      "epoch: 2 step: 540, loss is 0.5785315036773682\n",
      "epoch: 2 step: 541, loss is 0.46867865324020386\n",
      "epoch: 2 step: 542, loss is 0.289206326007843\n",
      "epoch: 2 step: 543, loss is 2.7452774047851562\n",
      "epoch: 2 step: 544, loss is 3.268303871154785\n",
      "epoch: 2 step: 545, loss is 0.9795067310333252\n",
      "epoch: 2 step: 546, loss is 0.5837945342063904\n",
      "epoch: 2 step: 547, loss is 1.546007752418518\n",
      "epoch: 2 step: 548, loss is 0.4870087206363678\n",
      "epoch: 2 step: 549, loss is 0.543328583240509\n",
      "epoch: 2 step: 550, loss is 1.8266985416412354\n",
      "epoch: 2 step: 551, loss is 0.3003900647163391\n",
      "epoch: 2 step: 552, loss is 2.131287097930908\n",
      "epoch: 2 step: 553, loss is 0.45340821146965027\n",
      "epoch: 2 step: 554, loss is 2.4597020149230957\n",
      "epoch: 2 step: 555, loss is 0.8553508520126343\n",
      "epoch: 2 step: 556, loss is 0.31916379928588867\n",
      "epoch: 2 step: 557, loss is 0.3492211103439331\n",
      "epoch: 2 step: 558, loss is 0.4753043055534363\n",
      "epoch: 2 step: 559, loss is 0.7787812352180481\n",
      "epoch: 2 step: 560, loss is 0.7198185324668884\n",
      "epoch: 2 step: 561, loss is 0.23511828482151031\n",
      "epoch: 2 step: 562, loss is 0.634860634803772\n",
      "epoch: 2 step: 563, loss is 3.528968572616577\n",
      "epoch: 2 step: 564, loss is 0.5499632358551025\n",
      "epoch: 2 step: 565, loss is 3.0936686992645264\n",
      "epoch: 2 step: 566, loss is 1.7969846725463867\n",
      "epoch: 2 step: 567, loss is 2.290616035461426\n",
      "epoch: 2 step: 568, loss is 1.7783775329589844\n",
      "epoch: 2 step: 569, loss is 1.6079634428024292\n",
      "epoch: 2 step: 570, loss is 0.40420252084732056\n",
      "epoch: 2 step: 571, loss is 0.632888674736023\n",
      "epoch: 2 step: 572, loss is 0.33584293723106384\n",
      "epoch: 2 step: 573, loss is 1.016018271446228\n",
      "epoch: 2 step: 574, loss is 0.20076753199100494\n",
      "epoch: 2 step: 575, loss is 0.13810810446739197\n",
      "epoch: 2 step: 576, loss is 2.2299084663391113\n",
      "epoch: 2 step: 577, loss is 0.469306617975235\n",
      "epoch: 2 step: 578, loss is 0.17502807080745697\n",
      "epoch: 2 step: 579, loss is 0.27901148796081543\n",
      "epoch: 2 step: 580, loss is 2.0925910472869873\n",
      "epoch: 2 step: 581, loss is 0.40916597843170166\n",
      "epoch: 2 step: 582, loss is 0.47300976514816284\n",
      "epoch: 2 step: 583, loss is 0.3085471987724304\n",
      "epoch: 2 step: 584, loss is 0.7585036158561707\n",
      "epoch: 2 step: 585, loss is 0.01923094131052494\n",
      "epoch: 2 step: 586, loss is 0.8470756411552429\n",
      "epoch: 2 step: 587, loss is 2.9534337520599365\n",
      "epoch: 2 step: 588, loss is 0.5362118482589722\n",
      "epoch: 2 step: 589, loss is 0.37973466515541077\n",
      "epoch: 2 step: 590, loss is 1.921814203262329\n",
      "epoch: 2 step: 591, loss is 1.6284725666046143\n",
      "epoch: 2 step: 592, loss is 0.3980727791786194\n",
      "epoch: 2 step: 593, loss is 0.6828819513320923\n",
      "epoch: 2 step: 594, loss is 1.9561917781829834\n",
      "epoch: 2 step: 595, loss is 0.39153000712394714\n",
      "epoch: 2 step: 596, loss is 0.7555214166641235\n",
      "epoch: 2 step: 597, loss is 0.22260324656963348\n",
      "epoch: 2 step: 598, loss is 3.905402660369873\n",
      "epoch: 2 step: 599, loss is 0.3970372676849365\n",
      "epoch: 2 step: 600, loss is 3.031503200531006\n",
      "epoch: 2 step: 601, loss is 2.2053327560424805\n",
      "epoch: 2 step: 602, loss is 0.6256134510040283\n",
      "epoch: 2 step: 603, loss is 2.1055352687835693\n",
      "epoch: 2 step: 604, loss is 0.3890712261199951\n",
      "epoch: 2 step: 605, loss is 1.8461805582046509\n",
      "epoch: 2 step: 606, loss is 0.7721521854400635\n",
      "epoch: 2 step: 607, loss is 0.41142186522483826\n",
      "epoch: 2 step: 608, loss is 0.5132269859313965\n",
      "epoch: 2 step: 609, loss is 1.6353163719177246\n",
      "epoch: 2 step: 610, loss is 0.46500375866889954\n",
      "epoch: 2 step: 611, loss is 1.7679840326309204\n",
      "epoch: 2 step: 612, loss is 0.4098667800426483\n",
      "epoch: 2 step: 613, loss is 0.8676806092262268\n",
      "epoch: 2 step: 614, loss is 0.74649578332901\n",
      "epoch: 2 step: 615, loss is 0.18232259154319763\n",
      "epoch: 2 step: 616, loss is 0.20494313538074493\n",
      "epoch: 2 step: 617, loss is 2.7162652015686035\n",
      "epoch: 2 step: 618, loss is 0.2107393592596054\n",
      "epoch: 2 step: 619, loss is 0.5455848574638367\n",
      "epoch: 2 step: 620, loss is 0.17918634414672852\n",
      "epoch: 2 step: 621, loss is 1.9118189811706543\n",
      "epoch: 2 step: 622, loss is 0.44254568219184875\n",
      "epoch: 2 step: 623, loss is 0.6458821892738342\n",
      "epoch: 2 step: 624, loss is 0.5271870493888855\n",
      "epoch: 2 step: 625, loss is 2.8871164321899414\n",
      "epoch: 2 step: 626, loss is 2.1264946460723877\n",
      "epoch: 2 step: 627, loss is 0.2587699294090271\n",
      "epoch: 2 step: 628, loss is 0.39227059483528137\n",
      "epoch: 2 step: 629, loss is 0.9703930020332336\n",
      "epoch: 2 step: 630, loss is 1.9229094982147217\n",
      "epoch: 2 step: 631, loss is 0.3099486827850342\n",
      "epoch: 2 step: 632, loss is 0.3226509690284729\n",
      "epoch: 2 step: 633, loss is 0.22462408244609833\n",
      "epoch: 2 step: 634, loss is 0.12384167313575745\n",
      "epoch: 2 step: 635, loss is 1.6050136089324951\n",
      "epoch: 2 step: 636, loss is 2.648235559463501\n",
      "epoch: 2 step: 637, loss is 0.4272884130477905\n",
      "epoch: 2 step: 638, loss is 1.7238421440124512\n",
      "epoch: 2 step: 639, loss is 2.5481414794921875\n",
      "epoch: 2 step: 640, loss is 0.4874435067176819\n",
      "epoch: 2 step: 641, loss is 0.34807345271110535\n",
      "epoch: 2 step: 642, loss is 4.220625400543213\n",
      "epoch: 2 step: 643, loss is 0.9859001040458679\n",
      "epoch: 2 step: 644, loss is 1.7026960849761963\n",
      "epoch: 2 step: 645, loss is 1.6419358253479004\n",
      "epoch: 2 step: 646, loss is 2.0323219299316406\n",
      "epoch: 2 step: 647, loss is 0.8956467509269714\n",
      "epoch: 2 step: 648, loss is 0.5877556204795837\n",
      "epoch: 2 step: 649, loss is 0.46688684821128845\n",
      "epoch: 2 step: 650, loss is 0.3869112432003021\n",
      "epoch: 2 step: 651, loss is 1.4942257404327393\n",
      "epoch: 2 step: 652, loss is 0.6452008485794067\n",
      "epoch: 2 step: 653, loss is 2.118121862411499\n",
      "epoch: 2 step: 654, loss is 0.5693865418434143\n",
      "epoch: 2 step: 655, loss is 3.295999050140381\n",
      "epoch: 2 step: 656, loss is 3.367744207382202\n",
      "epoch: 2 step: 657, loss is 0.9106102585792542\n",
      "epoch: 2 step: 658, loss is 0.8708820343017578\n",
      "epoch: 2 step: 659, loss is 0.7568034529685974\n",
      "epoch: 2 step: 660, loss is 0.6216716766357422\n",
      "epoch: 2 step: 661, loss is 3.4443540573120117\n",
      "epoch: 2 step: 662, loss is 0.509660005569458\n",
      "epoch: 2 step: 663, loss is 0.7838099002838135\n",
      "epoch: 2 step: 664, loss is 2.374516487121582\n",
      "epoch: 2 step: 665, loss is 0.9716958403587341\n",
      "epoch: 2 step: 666, loss is 0.5243634581565857\n",
      "epoch: 2 step: 667, loss is 2.0075974464416504\n",
      "epoch: 2 step: 668, loss is 0.6499419212341309\n",
      "epoch: 2 step: 669, loss is 1.4055891036987305\n",
      "epoch: 2 step: 670, loss is 2.856552839279175\n",
      "epoch: 2 step: 671, loss is 1.8423031568527222\n",
      "epoch: 2 step: 672, loss is 0.7012708783149719\n",
      "epoch: 2 step: 673, loss is 2.094813346862793\n",
      "epoch: 2 step: 674, loss is 2.2259767055511475\n",
      "epoch: 2 step: 675, loss is 2.108297109603882\n",
      "epoch: 2 step: 676, loss is 0.679935097694397\n",
      "epoch: 2 step: 677, loss is 1.6981050968170166\n",
      "epoch: 2 step: 678, loss is 0.589289665222168\n",
      "epoch: 2 step: 679, loss is 0.6147748231887817\n",
      "epoch: 2 step: 680, loss is 2.370976448059082\n",
      "epoch: 2 step: 681, loss is 0.6641190648078918\n",
      "epoch: 2 step: 682, loss is 0.9175076484680176\n",
      "epoch: 2 step: 683, loss is 0.623737096786499\n",
      "epoch: 2 step: 684, loss is 0.5002280473709106\n",
      "epoch: 2 step: 685, loss is 1.8351294994354248\n",
      "epoch: 2 step: 686, loss is 2.5993399620056152\n",
      "epoch: 2 step: 687, loss is 2.2780983448028564\n",
      "epoch: 2 step: 688, loss is 0.7470901608467102\n",
      "epoch: 2 step: 689, loss is 0.36657479405403137\n",
      "epoch: 2 step: 690, loss is 0.6714757084846497\n",
      "epoch: 2 step: 691, loss is 0.5212073922157288\n",
      "epoch: 2 step: 692, loss is 0.6112850308418274\n",
      "epoch: 2 step: 693, loss is 0.5378365516662598\n",
      "epoch: 2 step: 694, loss is 0.8204278349876404\n",
      "epoch: 2 step: 695, loss is 0.4926582872867584\n",
      "epoch: 2 step: 696, loss is 1.9604732990264893\n",
      "epoch: 2 step: 697, loss is 2.855097770690918\n",
      "epoch: 2 step: 698, loss is 1.6653823852539062\n",
      "epoch: 2 step: 699, loss is 2.0126633644104004\n",
      "epoch: 2 step: 700, loss is 0.6873155832290649\n",
      "epoch: 2 step: 701, loss is 1.6409109830856323\n",
      "epoch: 2 step: 702, loss is 0.2817849814891815\n",
      "epoch: 2 step: 703, loss is 1.830763339996338\n",
      "epoch: 2 step: 704, loss is 0.5560243725776672\n",
      "epoch: 2 step: 705, loss is 3.567014694213867\n",
      "epoch: 2 step: 706, loss is 0.7831409573554993\n",
      "epoch: 2 step: 707, loss is 1.202090859413147\n",
      "epoch: 2 step: 708, loss is 2.5412397384643555\n",
      "epoch: 2 step: 709, loss is 1.922147512435913\n",
      "epoch: 2 step: 710, loss is 0.7160922288894653\n",
      "epoch: 2 step: 711, loss is 2.1233413219451904\n",
      "epoch: 2 step: 712, loss is 0.5663286447525024\n",
      "epoch: 2 step: 713, loss is 0.26504477858543396\n",
      "epoch: 2 step: 714, loss is 2.062431812286377\n",
      "epoch: 2 step: 715, loss is 0.3547070324420929\n",
      "epoch: 2 step: 716, loss is 2.290942907333374\n",
      "epoch: 2 step: 717, loss is 0.6919307112693787\n",
      "epoch: 2 step: 718, loss is 0.7217491865158081\n",
      "epoch: 2 step: 719, loss is 0.11092320084571838\n",
      "epoch: 2 step: 720, loss is 3.6334850788116455\n",
      "epoch: 2 step: 721, loss is 2.6215882301330566\n",
      "epoch: 2 step: 722, loss is 1.8992631435394287\n",
      "epoch: 2 step: 723, loss is 1.7820274829864502\n",
      "epoch: 2 step: 724, loss is 2.191948652267456\n",
      "epoch: 2 step: 725, loss is 1.6601765155792236\n",
      "epoch: 2 step: 726, loss is 1.7698032855987549\n",
      "epoch: 2 step: 727, loss is 1.7644217014312744\n",
      "epoch: 2 step: 728, loss is 1.7769975662231445\n",
      "epoch: 2 step: 729, loss is 0.9787258505821228\n",
      "epoch: 2 step: 730, loss is 1.6870752573013306\n",
      "epoch: 2 step: 731, loss is 1.560157299041748\n",
      "epoch: 2 step: 732, loss is 1.8232660293579102\n",
      "epoch: 2 step: 733, loss is 1.6478941440582275\n",
      "epoch: 2 step: 734, loss is 1.1242271661758423\n",
      "epoch: 2 step: 735, loss is 0.9458537101745605\n",
      "epoch: 2 step: 736, loss is 2.1385061740875244\n",
      "epoch: 2 step: 737, loss is 1.0481863021850586\n",
      "epoch: 2 step: 738, loss is 1.88008713722229\n",
      "epoch: 2 step: 739, loss is 1.7553579807281494\n",
      "epoch: 2 step: 740, loss is 1.8156006336212158\n",
      "epoch: 2 step: 741, loss is 1.0355606079101562\n",
      "epoch: 2 step: 742, loss is 1.596596121788025\n",
      "epoch: 2 step: 743, loss is 1.6122475862503052\n",
      "epoch: 2 step: 744, loss is 1.9352737665176392\n",
      "epoch: 2 step: 745, loss is 0.9234187602996826\n",
      "epoch: 2 step: 746, loss is 1.959553837776184\n",
      "epoch: 2 step: 747, loss is 0.8261570334434509\n",
      "epoch: 2 step: 748, loss is 0.7775190472602844\n",
      "epoch: 2 step: 749, loss is 1.584433674812317\n",
      "epoch: 2 step: 750, loss is 1.206075668334961\n",
      "epoch: 2 step: 751, loss is 1.4183785915374756\n",
      "epoch: 2 step: 752, loss is 1.1702579259872437\n",
      "epoch: 2 step: 753, loss is 2.1986160278320312\n",
      "epoch: 2 step: 754, loss is 3.164241075515747\n",
      "epoch: 2 step: 755, loss is 0.9564908146858215\n",
      "epoch: 2 step: 756, loss is 0.8279306888580322\n",
      "epoch: 2 step: 757, loss is 3.0054824352264404\n",
      "epoch: 2 step: 758, loss is 0.7710891366004944\n",
      "epoch: 2 step: 759, loss is 1.0179569721221924\n",
      "epoch: 2 step: 760, loss is 0.8803781867027283\n",
      "epoch: 2 step: 761, loss is 1.0378497838974\n",
      "epoch: 2 step: 762, loss is 0.7206341028213501\n",
      "epoch: 2 step: 763, loss is 1.6531593799591064\n",
      "epoch: 2 step: 764, loss is 0.8506274223327637\n",
      "epoch: 2 step: 765, loss is 0.4839184582233429\n",
      "epoch: 2 step: 766, loss is 0.5214987993240356\n",
      "epoch: 2 step: 767, loss is 1.8659400939941406\n",
      "epoch: 2 step: 768, loss is 0.6748307943344116\n",
      "epoch: 2 step: 769, loss is 1.8117388486862183\n",
      "epoch: 2 step: 770, loss is 3.103127956390381\n",
      "epoch: 2 step: 771, loss is 1.6312047243118286\n",
      "epoch: 2 step: 772, loss is 1.9289960861206055\n",
      "epoch: 2 step: 773, loss is 0.8188354969024658\n",
      "epoch: 2 step: 774, loss is 2.0097579956054688\n",
      "epoch: 2 step: 775, loss is 0.5824480056762695\n",
      "epoch: 2 step: 776, loss is 0.4996768534183502\n",
      "epoch: 2 step: 777, loss is 0.6061540246009827\n",
      "epoch: 2 step: 778, loss is 0.8689708709716797\n",
      "epoch: 2 step: 779, loss is 0.35445138812065125\n",
      "epoch: 2 step: 780, loss is 1.7825837135314941\n",
      "epoch: 2 step: 781, loss is 0.6395038366317749\n",
      "epoch: 2 step: 782, loss is 0.30726003646850586\n",
      "epoch: 2 step: 783, loss is 1.7807025909423828\n",
      "epoch: 2 step: 784, loss is 1.8102924823760986\n",
      "epoch: 2 step: 785, loss is 0.5052828192710876\n",
      "epoch: 2 step: 786, loss is 0.37404459714889526\n",
      "epoch: 2 step: 787, loss is 2.950160026550293\n",
      "epoch: 2 step: 788, loss is 2.182680606842041\n",
      "epoch: 2 step: 789, loss is 0.5297423601150513\n",
      "epoch: 2 step: 790, loss is 2.2898993492126465\n",
      "epoch: 2 step: 791, loss is 0.9441689252853394\n",
      "epoch: 2 step: 792, loss is 0.36445537209510803\n",
      "epoch: 2 step: 793, loss is 1.8269636631011963\n",
      "epoch: 2 step: 794, loss is 0.7491615414619446\n",
      "epoch: 2 step: 795, loss is 1.7353111505508423\n",
      "epoch: 2 step: 796, loss is 0.4598839581012726\n",
      "epoch: 2 step: 797, loss is 0.6096532344818115\n",
      "epoch: 2 step: 798, loss is 2.607525587081909\n",
      "epoch: 2 step: 799, loss is 2.6128041744232178\n",
      "epoch: 2 step: 800, loss is 0.6059773564338684\n",
      "epoch: 2 step: 801, loss is 1.5695245265960693\n",
      "epoch: 2 step: 802, loss is 2.0219593048095703\n",
      "epoch: 2 step: 803, loss is 1.0841569900512695\n",
      "epoch: 2 step: 804, loss is 2.8272111415863037\n",
      "epoch: 2 step: 805, loss is 0.6957589983940125\n",
      "epoch: 2 step: 806, loss is 0.7571574449539185\n",
      "epoch: 2 step: 807, loss is 0.8780080676078796\n",
      "epoch: 2 step: 808, loss is 0.5549755692481995\n",
      "epoch: 2 step: 809, loss is 0.8268430233001709\n",
      "epoch: 2 step: 810, loss is 0.7134699821472168\n",
      "epoch: 2 step: 811, loss is 0.27632656693458557\n",
      "epoch: 2 step: 812, loss is 0.2145782709121704\n",
      "epoch: 2 step: 813, loss is 0.5686347484588623\n",
      "epoch: 2 step: 814, loss is 0.18578962981700897\n",
      "epoch: 2 step: 815, loss is 0.516951858997345\n",
      "epoch: 2 step: 816, loss is 2.65964674949646\n",
      "epoch: 2 step: 817, loss is 0.7257840037345886\n",
      "epoch: 2 step: 818, loss is 0.17597965896129608\n",
      "epoch: 2 step: 819, loss is 3.493203639984131\n",
      "epoch: 2 step: 820, loss is 0.6614086627960205\n",
      "epoch: 2 step: 821, loss is 0.40274208784103394\n",
      "epoch: 2 step: 822, loss is 1.914435863494873\n",
      "epoch: 2 step: 823, loss is 1.702927589416504\n",
      "epoch: 2 step: 824, loss is 0.6156445741653442\n",
      "epoch: 2 step: 825, loss is 0.48454758524894714\n",
      "epoch: 2 step: 826, loss is 2.895878791809082\n",
      "epoch: 2 step: 827, loss is 0.7173008918762207\n",
      "epoch: 2 step: 828, loss is 0.27023646235466003\n",
      "epoch: 2 step: 829, loss is 2.994296073913574\n",
      "epoch: 2 step: 830, loss is 0.2921208441257477\n",
      "epoch: 2 step: 831, loss is 1.6933989524841309\n",
      "epoch: 2 step: 832, loss is 1.8943150043487549\n",
      "epoch: 2 step: 833, loss is 0.5403879284858704\n",
      "epoch: 2 step: 834, loss is 0.3308235704898834\n",
      "epoch: 2 step: 835, loss is 0.1991559863090515\n",
      "epoch: 2 step: 836, loss is 0.8685036301612854\n",
      "epoch: 2 step: 837, loss is 2.6472392082214355\n",
      "epoch: 2 step: 838, loss is 0.5844541788101196\n",
      "epoch: 2 step: 839, loss is 2.006415367126465\n",
      "epoch: 2 step: 840, loss is 2.052133560180664\n",
      "epoch: 2 step: 841, loss is 0.6823708415031433\n",
      "epoch: 2 step: 842, loss is 4.227701663970947\n",
      "epoch: 2 step: 843, loss is 0.7579952478408813\n",
      "epoch: 2 step: 844, loss is 1.947460651397705\n",
      "epoch: 2 step: 845, loss is 0.5160753726959229\n",
      "epoch: 2 step: 846, loss is 2.986487865447998\n",
      "epoch: 2 step: 847, loss is 1.727618932723999\n",
      "epoch: 2 step: 848, loss is 0.8929605484008789\n",
      "epoch: 2 step: 849, loss is 0.7755179405212402\n",
      "epoch: 2 step: 850, loss is 0.7526953816413879\n",
      "epoch: 2 step: 851, loss is 0.5361169576644897\n",
      "epoch: 2 step: 852, loss is 0.7412568926811218\n",
      "epoch: 2 step: 853, loss is 1.587923288345337\n",
      "epoch: 2 step: 854, loss is 0.6944500207901001\n",
      "epoch: 2 step: 855, loss is 0.5624638795852661\n",
      "epoch: 2 step: 856, loss is 0.4958930015563965\n",
      "epoch: 2 step: 857, loss is 2.5330939292907715\n",
      "epoch: 2 step: 858, loss is 1.7781052589416504\n",
      "epoch: 2 step: 859, loss is 2.262826681137085\n",
      "epoch: 2 step: 860, loss is 0.8098578453063965\n",
      "epoch: 2 step: 861, loss is 0.6205036640167236\n",
      "epoch: 2 step: 862, loss is 0.5731695890426636\n",
      "epoch: 2 step: 863, loss is 2.542607307434082\n",
      "epoch: 2 step: 864, loss is 0.9617776274681091\n",
      "epoch: 2 step: 865, loss is 3.0688233375549316\n",
      "epoch: 2 step: 866, loss is 2.188838481903076\n",
      "epoch: 2 step: 867, loss is 0.6865555644035339\n",
      "epoch: 2 step: 868, loss is 0.2518453598022461\n",
      "epoch: 2 step: 869, loss is 2.266390800476074\n",
      "epoch: 2 step: 870, loss is 2.1576499938964844\n",
      "epoch: 2 step: 871, loss is 0.6910325884819031\n",
      "epoch: 2 step: 872, loss is 0.7185776829719543\n",
      "epoch: 2 step: 873, loss is 0.678948163986206\n",
      "epoch: 2 step: 874, loss is 0.48463642597198486\n",
      "epoch: 2 step: 875, loss is 0.5164021253585815\n",
      "epoch: 2 step: 876, loss is 0.3804287016391754\n",
      "epoch: 2 step: 877, loss is 0.23413421213626862\n",
      "epoch: 2 step: 878, loss is 0.16255858540534973\n",
      "epoch: 2 step: 879, loss is 1.7803549766540527\n",
      "epoch: 2 step: 880, loss is 0.2477116733789444\n",
      "epoch: 2 step: 881, loss is 3.526319742202759\n",
      "epoch: 2 step: 882, loss is 2.103902816772461\n",
      "epoch: 2 step: 883, loss is 2.217749834060669\n",
      "epoch: 2 step: 884, loss is 0.555906355381012\n",
      "epoch: 2 step: 885, loss is 2.60779070854187\n",
      "epoch: 2 step: 886, loss is 0.4952506124973297\n",
      "epoch: 2 step: 887, loss is 0.37673619389533997\n",
      "epoch: 2 step: 888, loss is 0.7688056230545044\n",
      "epoch: 2 step: 889, loss is 0.4695925712585449\n",
      "epoch: 2 step: 890, loss is 1.9690909385681152\n",
      "epoch: 2 step: 891, loss is 0.22150112688541412\n",
      "epoch: 2 step: 892, loss is 0.46455085277557373\n",
      "epoch: 2 step: 893, loss is 1.8668508529663086\n",
      "epoch: 2 step: 894, loss is 1.744047999382019\n",
      "epoch: 2 step: 895, loss is 2.703508138656616\n",
      "epoch: 2 step: 896, loss is 2.0437142848968506\n",
      "epoch: 2 step: 897, loss is 1.7919849157333374\n",
      "epoch: 2 step: 898, loss is 1.4338459968566895\n",
      "epoch: 2 step: 899, loss is 0.7364922165870667\n",
      "epoch: 2 step: 900, loss is 1.6201236248016357\n",
      "epoch: 2 step: 901, loss is 0.47252702713012695\n",
      "epoch: 2 step: 902, loss is 1.7199293375015259\n",
      "epoch: 2 step: 903, loss is 0.6445865035057068\n",
      "epoch: 2 step: 904, loss is 1.2622407674789429\n",
      "epoch: 2 step: 905, loss is 0.3850218653678894\n",
      "epoch: 2 step: 906, loss is 2.0460360050201416\n",
      "epoch: 2 step: 907, loss is 0.5782203078269958\n",
      "epoch: 2 step: 908, loss is 2.1589996814727783\n",
      "epoch: 2 step: 909, loss is 1.7777812480926514\n",
      "epoch: 2 step: 910, loss is 2.0408763885498047\n",
      "epoch: 2 step: 911, loss is 0.4884624779224396\n",
      "epoch: 2 step: 912, loss is 0.4266815781593323\n",
      "epoch: 2 step: 913, loss is 0.537578821182251\n",
      "epoch: 2 step: 914, loss is 0.9477511048316956\n",
      "epoch: 2 step: 915, loss is 1.632641077041626\n",
      "epoch: 2 step: 916, loss is 0.5022084712982178\n",
      "epoch: 2 step: 917, loss is 0.3358103036880493\n",
      "epoch: 2 step: 918, loss is 1.8432765007019043\n",
      "epoch: 2 step: 919, loss is 0.5727411508560181\n",
      "epoch: 2 step: 920, loss is 1.90358304977417\n",
      "epoch: 2 step: 921, loss is 0.6737514138221741\n",
      "epoch: 2 step: 922, loss is 2.280430316925049\n",
      "epoch: 2 step: 923, loss is 0.4286830425262451\n",
      "epoch: 2 step: 924, loss is 2.4883005619049072\n",
      "epoch: 2 step: 925, loss is 0.5139965415000916\n",
      "epoch: 2 step: 926, loss is 0.46592268347740173\n",
      "epoch: 2 step: 927, loss is 0.29331013560295105\n",
      "epoch: 2 step: 928, loss is 0.24548998475074768\n",
      "epoch: 2 step: 929, loss is 0.6478121876716614\n",
      "epoch: 2 step: 930, loss is 0.15043464303016663\n",
      "epoch: 2 step: 931, loss is 0.37577325105667114\n",
      "epoch: 2 step: 932, loss is 1.7131853103637695\n",
      "epoch: 2 step: 933, loss is 0.3156643211841583\n",
      "epoch: 2 step: 934, loss is 2.0698530673980713\n",
      "epoch: 2 step: 935, loss is 1.9484636783599854\n",
      "epoch: 2 step: 936, loss is 0.4039785861968994\n",
      "epoch: 2 step: 937, loss is 0.23030029237270355\n",
      "epoch: 2 step: 938, loss is 0.7673304677009583\n",
      "epoch: 2 step: 939, loss is 3.907089948654175\n",
      "epoch: 2 step: 940, loss is 2.432746171951294\n",
      "epoch: 2 step: 941, loss is 0.27909642457962036\n",
      "epoch: 2 step: 942, loss is 0.35408368706703186\n",
      "epoch: 2 step: 943, loss is 0.30228880047798157\n",
      "epoch: 2 step: 944, loss is 2.393709659576416\n",
      "epoch: 2 step: 945, loss is 0.9067818522453308\n",
      "epoch: 2 step: 946, loss is 1.9863632917404175\n",
      "epoch: 2 step: 947, loss is 3.158154249191284\n",
      "epoch: 2 step: 948, loss is 1.905726432800293\n",
      "epoch: 2 step: 949, loss is 0.4310252070426941\n",
      "epoch: 2 step: 950, loss is 0.5734506249427795\n",
      "epoch: 2 step: 951, loss is 0.5411810874938965\n",
      "epoch: 2 step: 952, loss is 0.356502890586853\n",
      "epoch: 2 step: 953, loss is 0.16653332114219666\n",
      "epoch: 2 step: 954, loss is 0.5059115290641785\n",
      "epoch: 2 step: 955, loss is 0.2623753249645233\n",
      "epoch: 2 step: 956, loss is 2.7364518642425537\n",
      "epoch: 2 step: 957, loss is 0.29126864671707153\n",
      "epoch: 2 step: 958, loss is 0.711874783039093\n",
      "epoch: 2 step: 959, loss is 2.45841383934021\n",
      "epoch: 2 step: 960, loss is 0.16622324287891388\n",
      "epoch: 2 step: 961, loss is 0.5035189390182495\n",
      "epoch: 2 step: 962, loss is 2.7906298637390137\n",
      "epoch: 2 step: 963, loss is 0.5592944025993347\n",
      "epoch: 2 step: 964, loss is 2.3611578941345215\n",
      "epoch: 2 step: 965, loss is 0.6368016600608826\n",
      "epoch: 2 step: 966, loss is 2.205078363418579\n",
      "epoch: 2 step: 967, loss is 0.3858797550201416\n",
      "epoch: 2 step: 968, loss is 0.3656270503997803\n",
      "epoch: 2 step: 969, loss is 0.34476348757743835\n",
      "epoch: 2 step: 970, loss is 3.8303050994873047\n",
      "epoch: 2 step: 971, loss is 0.6389204263687134\n",
      "epoch: 2 step: 972, loss is 1.8149189949035645\n",
      "epoch: 2 step: 973, loss is 1.838597297668457\n",
      "epoch: 2 step: 974, loss is 0.5398834943771362\n",
      "epoch: 2 step: 975, loss is 0.42069289088249207\n",
      "epoch: 2 step: 976, loss is 2.8206489086151123\n",
      "epoch: 2 step: 977, loss is 2.341883659362793\n",
      "epoch: 2 step: 978, loss is 0.8202322125434875\n",
      "epoch: 2 step: 979, loss is 0.4506470263004303\n",
      "epoch: 2 step: 980, loss is 0.664249837398529\n",
      "epoch: 2 step: 981, loss is 1.8391053676605225\n",
      "epoch: 2 step: 982, loss is 1.661508321762085\n",
      "epoch: 2 step: 983, loss is 0.8241701126098633\n",
      "epoch: 2 step: 984, loss is 0.5434353947639465\n",
      "epoch: 2 step: 985, loss is 0.4573670029640198\n",
      "epoch: 2 step: 986, loss is 1.8781075477600098\n",
      "epoch: 2 step: 987, loss is 0.4934519827365875\n",
      "epoch: 2 step: 988, loss is 0.44561970233917236\n",
      "epoch: 2 step: 989, loss is 2.2104434967041016\n",
      "epoch: 2 step: 990, loss is 1.2578799724578857\n",
      "epoch: 2 step: 991, loss is 0.3206515312194824\n",
      "epoch: 2 step: 992, loss is 2.4545087814331055\n",
      "epoch: 2 step: 993, loss is 1.9535529613494873\n",
      "epoch: 2 step: 994, loss is 0.8021402359008789\n",
      "epoch: 2 step: 995, loss is 2.5205094814300537\n",
      "epoch: 2 step: 996, loss is 0.6712461709976196\n",
      "epoch: 2 step: 997, loss is 0.8255089521408081\n",
      "epoch: 2 step: 998, loss is 0.34758028388023376\n",
      "epoch: 2 step: 999, loss is 0.5514242053031921\n",
      "epoch: 2 step: 1000, loss is 2.3671631813049316\n",
      "epoch: 2 step: 1001, loss is 0.883307695388794\n",
      "epoch: 2 step: 1002, loss is 0.5728501677513123\n",
      "epoch: 2 step: 1003, loss is 0.34253957867622375\n",
      "epoch: 2 step: 1004, loss is 2.3713362216949463\n",
      "epoch: 2 step: 1005, loss is 0.4015257656574249\n",
      "epoch: 2 step: 1006, loss is 0.6367461681365967\n",
      "epoch: 2 step: 1007, loss is 0.2303251028060913\n",
      "epoch: 2 step: 1008, loss is 0.5456318855285645\n",
      "epoch: 2 step: 1009, loss is 2.002690553665161\n",
      "epoch: 2 step: 1010, loss is 2.0531601905822754\n",
      "epoch: 2 step: 1011, loss is 2.298604726791382\n",
      "epoch: 2 step: 1012, loss is 1.4010450839996338\n",
      "epoch: 2 step: 1013, loss is 2.61779522895813\n",
      "epoch: 2 step: 1014, loss is 1.7263777256011963\n",
      "epoch: 2 step: 1015, loss is 2.2180683612823486\n",
      "epoch: 2 step: 1016, loss is 0.4745478332042694\n",
      "epoch: 2 step: 1017, loss is 2.500433921813965\n",
      "epoch: 2 step: 1018, loss is 1.7591423988342285\n",
      "epoch: 2 step: 1019, loss is 0.6075365543365479\n",
      "epoch: 2 step: 1020, loss is 0.7748682498931885\n",
      "epoch: 2 step: 1021, loss is 0.5745975971221924\n",
      "epoch: 2 step: 1022, loss is 0.779252827167511\n",
      "epoch: 2 step: 1023, loss is 0.6484135985374451\n",
      "epoch: 2 step: 1024, loss is 0.5019754767417908\n",
      "epoch: 2 step: 1025, loss is 1.8843984603881836\n",
      "epoch: 2 step: 1026, loss is 0.3160432279109955\n",
      "epoch: 2 step: 1027, loss is 0.23472960293293\n",
      "epoch: 2 step: 1028, loss is 0.21158388257026672\n",
      "epoch: 2 step: 1029, loss is 1.8541841506958008\n",
      "epoch: 2 step: 1030, loss is 0.2639538645744324\n",
      "epoch: 2 step: 1031, loss is 0.5597334504127502\n",
      "epoch: 2 step: 1032, loss is 1.668389916419983\n",
      "epoch: 2 step: 1033, loss is 0.7575792670249939\n",
      "epoch: 2 step: 1034, loss is 2.760868787765503\n",
      "epoch: 2 step: 1035, loss is 1.7602543830871582\n",
      "epoch: 2 step: 1036, loss is 0.4926278591156006\n",
      "epoch: 2 step: 1037, loss is 4.490068435668945\n",
      "epoch: 2 step: 1038, loss is 0.8823232054710388\n",
      "epoch: 2 step: 1039, loss is 0.8541303873062134\n",
      "epoch: 2 step: 1040, loss is 2.308108329772949\n",
      "epoch: 2 step: 1041, loss is 1.815244436264038\n",
      "epoch: 2 step: 1042, loss is 0.5734505653381348\n",
      "epoch: 2 step: 1043, loss is 0.600307822227478\n",
      "epoch: 2 step: 1044, loss is 0.7221158742904663\n",
      "epoch: 2 step: 1045, loss is 3.3543992042541504\n",
      "epoch: 2 step: 1046, loss is 3.558237314224243\n",
      "epoch: 2 step: 1047, loss is 0.7727872133255005\n",
      "epoch: 2 step: 1048, loss is 1.0055015087127686\n",
      "epoch: 2 step: 1049, loss is 0.4321807324886322\n",
      "epoch: 2 step: 1050, loss is 1.4486472606658936\n",
      "epoch: 2 step: 1051, loss is 0.7867835760116577\n",
      "epoch: 2 step: 1052, loss is 0.6798558831214905\n",
      "epoch: 2 step: 1053, loss is 2.1114001274108887\n",
      "epoch: 2 step: 1054, loss is 2.3006768226623535\n",
      "epoch: 2 step: 1055, loss is 0.3559587299823761\n",
      "epoch: 2 step: 1056, loss is 0.5194764733314514\n",
      "epoch: 2 step: 1057, loss is 1.8626618385314941\n",
      "epoch: 2 step: 1058, loss is 0.5085058212280273\n",
      "epoch: 2 step: 1059, loss is 0.3597453236579895\n",
      "epoch: 2 step: 1060, loss is 0.35486704111099243\n",
      "epoch: 2 step: 1061, loss is 0.534544050693512\n",
      "epoch: 2 step: 1062, loss is 1.8486711978912354\n",
      "epoch: 2 step: 1063, loss is 1.8845970630645752\n",
      "epoch: 2 step: 1064, loss is 0.3817303478717804\n",
      "epoch: 2 step: 1065, loss is 1.824745535850525\n",
      "epoch: 2 step: 1066, loss is 0.5606284141540527\n",
      "epoch: 2 step: 1067, loss is 0.3916543424129486\n",
      "epoch: 2 step: 1068, loss is 2.8646762371063232\n",
      "epoch: 2 step: 1069, loss is 0.5058727264404297\n",
      "epoch: 2 step: 1070, loss is 0.7320624589920044\n",
      "epoch: 2 step: 1071, loss is 2.112473487854004\n",
      "epoch: 2 step: 1072, loss is 2.2564592361450195\n",
      "epoch: 2 step: 1073, loss is 0.5431884527206421\n",
      "epoch: 2 step: 1074, loss is 1.9723906517028809\n",
      "epoch: 2 step: 1075, loss is 0.2075837105512619\n",
      "epoch: 2 step: 1076, loss is 0.858941376209259\n",
      "epoch: 2 step: 1077, loss is 0.47612977027893066\n",
      "epoch: 2 step: 1078, loss is 1.6055145263671875\n",
      "epoch: 2 step: 1079, loss is 2.1235437393188477\n",
      "epoch: 2 step: 1080, loss is 1.8672287464141846\n",
      "epoch: 2 step: 1081, loss is 0.6798855662345886\n",
      "epoch: 2 step: 1082, loss is 0.4509701132774353\n",
      "epoch: 2 step: 1083, loss is 0.7561854124069214\n",
      "epoch: 2 step: 1084, loss is 3.077133893966675\n",
      "epoch: 2 step: 1085, loss is 0.6671053767204285\n",
      "epoch: 2 step: 1086, loss is 0.6235326528549194\n",
      "epoch: 2 step: 1087, loss is 0.455252081155777\n",
      "epoch: 2 step: 1088, loss is 1.8357501029968262\n",
      "epoch: 2 step: 1089, loss is 0.6227433681488037\n",
      "epoch: 2 step: 1090, loss is 0.3523368537425995\n",
      "epoch: 2 step: 1091, loss is 0.6559337377548218\n",
      "epoch: 2 step: 1092, loss is 1.276986002922058\n",
      "epoch: 2 step: 1093, loss is 0.23255831003189087\n",
      "epoch: 2 step: 1094, loss is 1.9779621362686157\n",
      "epoch: 2 step: 1095, loss is 2.7036116123199463\n",
      "epoch: 2 step: 1096, loss is 0.4551433324813843\n",
      "epoch: 2 step: 1097, loss is 0.7944009304046631\n",
      "epoch: 2 step: 1098, loss is 0.26401373744010925\n",
      "epoch: 2 step: 1099, loss is 0.20515978336334229\n",
      "epoch: 2 step: 1100, loss is 2.498279094696045\n",
      "epoch: 2 step: 1101, loss is 1.7689146995544434\n",
      "epoch: 2 step: 1102, loss is 1.4058263301849365\n",
      "epoch: 2 step: 1103, loss is 1.113308072090149\n",
      "epoch: 2 step: 1104, loss is 1.7861384153366089\n",
      "epoch: 2 step: 1105, loss is 0.8005223274230957\n",
      "epoch: 2 step: 1106, loss is 0.644906759262085\n",
      "epoch: 2 step: 1107, loss is 0.5512884259223938\n",
      "epoch: 2 step: 1108, loss is 1.9347368478775024\n",
      "epoch: 2 step: 1109, loss is 0.43799254298210144\n",
      "epoch: 2 step: 1110, loss is 0.3403749167919159\n",
      "epoch: 2 step: 1111, loss is 0.266645222902298\n",
      "epoch: 2 step: 1112, loss is 0.36120203137397766\n",
      "epoch: 2 step: 1113, loss is 0.8370769619941711\n",
      "epoch: 2 step: 1114, loss is 2.314803123474121\n",
      "epoch: 2 step: 1115, loss is 0.285970538854599\n",
      "epoch: 2 step: 1116, loss is 0.2943688929080963\n",
      "epoch: 2 step: 1117, loss is 0.6913434267044067\n",
      "epoch: 2 step: 1118, loss is 0.2955857515335083\n",
      "epoch: 2 step: 1119, loss is 4.789536476135254\n",
      "epoch: 2 step: 1120, loss is 0.5339590311050415\n",
      "epoch: 2 step: 1121, loss is 0.3850148022174835\n",
      "epoch: 2 step: 1122, loss is 0.2365696281194687\n",
      "epoch: 2 step: 1123, loss is 1.3622952699661255\n",
      "epoch: 2 step: 1124, loss is 0.23283903300762177\n",
      "epoch: 2 step: 1125, loss is 0.3300894498825073\n",
      "epoch: 2 step: 1126, loss is 0.3803569972515106\n",
      "epoch: 2 step: 1127, loss is 2.866820812225342\n",
      "epoch: 2 step: 1128, loss is 0.19414277374744415\n",
      "epoch: 2 step: 1129, loss is 0.24462004005908966\n",
      "epoch: 2 step: 1130, loss is 0.1592724323272705\n",
      "epoch: 2 step: 1131, loss is 0.11637495458126068\n",
      "epoch: 2 step: 1132, loss is 0.12837472558021545\n",
      "epoch: 2 step: 1133, loss is 3.123706579208374\n",
      "epoch: 2 step: 1134, loss is 0.4329763948917389\n",
      "epoch: 2 step: 1135, loss is 0.7119934558868408\n",
      "epoch: 2 step: 1136, loss is 0.9404586553573608\n",
      "epoch: 2 step: 1137, loss is 3.787031888961792\n",
      "epoch: 2 step: 1138, loss is 4.343789100646973\n",
      "epoch: 2 step: 1139, loss is 0.20426686108112335\n",
      "epoch: 2 step: 1140, loss is 0.33008164167404175\n",
      "epoch: 2 step: 1141, loss is 0.26378729939460754\n",
      "epoch: 2 step: 1142, loss is 2.3100497722625732\n",
      "epoch: 2 step: 1143, loss is 2.8161399364471436\n",
      "epoch: 2 step: 1144, loss is 0.4616268277168274\n",
      "epoch: 2 step: 1145, loss is 2.1372461318969727\n",
      "epoch: 2 step: 1146, loss is 0.7480953931808472\n",
      "epoch: 2 step: 1147, loss is 1.2525932788848877\n",
      "epoch: 2 step: 1148, loss is 2.658015251159668\n",
      "epoch: 2 step: 1149, loss is 1.8879241943359375\n",
      "epoch: 2 step: 1150, loss is 1.4760609865188599\n",
      "epoch: 2 step: 1151, loss is 0.4552377164363861\n",
      "epoch: 2 step: 1152, loss is 0.29387345910072327\n",
      "epoch: 2 step: 1153, loss is 3.094348907470703\n",
      "epoch: 2 step: 1154, loss is 0.8829478621482849\n",
      "epoch: 2 step: 1155, loss is 2.072052001953125\n",
      "epoch: 2 step: 1156, loss is 0.3454872667789459\n",
      "epoch: 2 step: 1157, loss is 2.3048417568206787\n",
      "epoch: 2 step: 1158, loss is 2.2121100425720215\n",
      "epoch: 2 step: 1159, loss is 1.9454221725463867\n",
      "epoch: 2 step: 1160, loss is 2.1534671783447266\n",
      "epoch: 2 step: 1161, loss is 1.451430320739746\n",
      "epoch: 2 step: 1162, loss is 1.7685284614562988\n",
      "epoch: 2 step: 1163, loss is 0.6132555603981018\n",
      "epoch: 2 step: 1164, loss is 1.090538740158081\n",
      "epoch: 2 step: 1165, loss is 1.2253350019454956\n",
      "epoch: 2 step: 1166, loss is 2.2068636417388916\n",
      "epoch: 2 step: 1167, loss is 0.45700037479400635\n",
      "epoch: 2 step: 1168, loss is 2.265507936477661\n",
      "epoch: 2 step: 1169, loss is 1.0831273794174194\n",
      "epoch: 2 step: 1170, loss is 1.557473063468933\n",
      "epoch: 2 step: 1171, loss is 2.215845823287964\n",
      "epoch: 2 step: 1172, loss is 0.839686393737793\n",
      "epoch: 2 step: 1173, loss is 0.6309417486190796\n",
      "epoch: 2 step: 1174, loss is 0.8322529196739197\n",
      "epoch: 2 step: 1175, loss is 2.518587589263916\n",
      "epoch: 2 step: 1176, loss is 1.8706178665161133\n",
      "epoch: 2 step: 1177, loss is 1.6814453601837158\n",
      "epoch: 2 step: 1178, loss is 0.5476452708244324\n",
      "epoch: 2 step: 1179, loss is 0.43317878246307373\n",
      "epoch: 2 step: 1180, loss is 3.375631332397461\n",
      "epoch: 2 step: 1181, loss is 1.292858600616455\n",
      "epoch: 2 step: 1182, loss is 0.7080104351043701\n",
      "epoch: 2 step: 1183, loss is 1.3552476167678833\n",
      "epoch: 2 step: 1184, loss is 0.9975723624229431\n",
      "epoch: 2 step: 1185, loss is 0.4423713684082031\n",
      "epoch: 2 step: 1186, loss is 0.9183866381645203\n",
      "epoch: 2 step: 1187, loss is 0.7919368743896484\n",
      "epoch: 2 step: 1188, loss is 0.23776394128799438\n",
      "epoch: 2 step: 1189, loss is 1.5350263118743896\n",
      "epoch: 2 step: 1190, loss is 2.1446967124938965\n",
      "epoch: 2 step: 1191, loss is 0.4353771209716797\n",
      "epoch: 2 step: 1192, loss is 0.7440058588981628\n",
      "epoch: 2 step: 1193, loss is 0.6922787427902222\n",
      "epoch: 2 step: 1194, loss is 0.37635302543640137\n",
      "epoch: 2 step: 1195, loss is 0.5734929442405701\n",
      "epoch: 2 step: 1196, loss is 2.829235553741455\n",
      "epoch: 2 step: 1197, loss is 0.3696919083595276\n",
      "epoch: 2 step: 1198, loss is 0.10920385271310806\n",
      "epoch: 2 step: 1199, loss is 0.5688469409942627\n",
      "epoch: 2 step: 1200, loss is 2.407792091369629\n",
      "epoch: 2 step: 1201, loss is 0.4579910337924957\n",
      "epoch: 2 step: 1202, loss is 0.11436612159013748\n",
      "epoch: 2 step: 1203, loss is 0.21061672270298004\n",
      "epoch: 2 step: 1204, loss is 2.707853078842163\n",
      "epoch: 2 step: 1205, loss is 1.940834641456604\n",
      "epoch: 2 step: 1206, loss is 0.6024054884910583\n",
      "epoch: 2 step: 1207, loss is 0.11570589989423752\n",
      "epoch: 2 step: 1208, loss is 0.18408195674419403\n",
      "epoch: 2 step: 1209, loss is 0.6592662334442139\n",
      "epoch: 2 step: 1210, loss is 0.7391254305839539\n",
      "epoch: 2 step: 1211, loss is 0.7981925010681152\n",
      "epoch: 2 step: 1212, loss is 0.40541788935661316\n",
      "epoch: 2 step: 1213, loss is 3.408573865890503\n",
      "epoch: 2 step: 1214, loss is 0.1972501426935196\n",
      "epoch: 2 step: 1215, loss is 0.43521180748939514\n",
      "epoch: 2 step: 1216, loss is 0.205033540725708\n",
      "epoch: 2 step: 1217, loss is 1.207927942276001\n",
      "epoch: 2 step: 1218, loss is 0.6209210753440857\n",
      "epoch: 2 step: 1219, loss is 0.422414630651474\n",
      "epoch: 2 step: 1220, loss is 2.2390074729919434\n",
      "epoch: 2 step: 1221, loss is 0.1115155965089798\n",
      "epoch: 2 step: 1222, loss is 0.09460922330617905\n",
      "epoch: 2 step: 1223, loss is 0.19924107193946838\n",
      "epoch: 2 step: 1224, loss is 2.417128562927246\n",
      "epoch: 2 step: 1225, loss is 0.4481722116470337\n",
      "epoch: 2 step: 1226, loss is 0.11219854652881622\n",
      "epoch: 2 step: 1227, loss is 0.3858731985092163\n",
      "epoch: 2 step: 1228, loss is 2.316316843032837\n",
      "epoch: 2 step: 1229, loss is 0.4202612638473511\n",
      "epoch: 2 step: 1230, loss is 2.2613065242767334\n",
      "epoch: 2 step: 1231, loss is 0.4243990480899811\n",
      "epoch: 2 step: 1232, loss is 0.17108973860740662\n",
      "epoch: 2 step: 1233, loss is 0.13228657841682434\n",
      "epoch: 2 step: 1234, loss is 0.28368327021598816\n",
      "epoch: 2 step: 1235, loss is 0.10980955511331558\n",
      "epoch: 2 step: 1236, loss is 0.14223799109458923\n",
      "epoch: 2 step: 1237, loss is 2.683182954788208\n",
      "epoch: 2 step: 1238, loss is 0.056361034512519836\n",
      "epoch: 2 step: 1239, loss is 0.5555464625358582\n",
      "epoch: 2 step: 1240, loss is 0.31356820464134216\n",
      "epoch: 2 step: 1241, loss is 0.275247722864151\n",
      "epoch: 2 step: 1242, loss is 0.01204703189432621\n",
      "epoch: 2 step: 1243, loss is 0.16772933304309845\n",
      "epoch: 2 step: 1244, loss is 0.048738233745098114\n",
      "epoch: 2 step: 1245, loss is 0.020361099392175674\n",
      "epoch: 2 step: 1246, loss is 0.5384928584098816\n",
      "epoch: 2 step: 1247, loss is 0.2757284939289093\n",
      "epoch: 2 step: 1248, loss is 0.012114047072827816\n",
      "epoch: 2 step: 1249, loss is 3.39916729927063\n",
      "epoch: 2 step: 1250, loss is 3.136075258255005\n",
      "epoch: 2 step: 1251, loss is 2.2732183933258057\n",
      "epoch: 2 step: 1252, loss is 0.8923395276069641\n",
      "epoch: 2 step: 1253, loss is 0.3921178877353668\n",
      "epoch: 2 step: 1254, loss is 3.740755319595337\n",
      "epoch: 2 step: 1255, loss is 0.47891080379486084\n",
      "epoch: 2 step: 1256, loss is 0.25403809547424316\n",
      "epoch: 2 step: 1257, loss is 0.1480063647031784\n",
      "epoch: 2 step: 1258, loss is 2.565363645553589\n",
      "epoch: 2 step: 1259, loss is 2.7711472511291504\n",
      "epoch: 2 step: 1260, loss is 0.23403525352478027\n",
      "epoch: 2 step: 1261, loss is 0.205660879611969\n",
      "epoch: 2 step: 1262, loss is 0.27964502573013306\n",
      "epoch: 2 step: 1263, loss is 1.620208501815796\n",
      "epoch: 2 step: 1264, loss is 0.34232306480407715\n",
      "epoch: 2 step: 1265, loss is 0.13496172428131104\n",
      "epoch: 2 step: 1266, loss is 0.36256900429725647\n",
      "epoch: 2 step: 1267, loss is 0.09774430841207504\n",
      "epoch: 2 step: 1268, loss is 2.9606359004974365\n",
      "epoch: 2 step: 1269, loss is 0.4355623126029968\n",
      "epoch: 2 step: 1270, loss is 0.06241368502378464\n",
      "epoch: 2 step: 1271, loss is 0.5482431650161743\n",
      "epoch: 2 step: 1272, loss is 2.2223095893859863\n",
      "epoch: 2 step: 1273, loss is 0.15778519213199615\n",
      "epoch: 2 step: 1274, loss is 1.823761224746704\n",
      "epoch: 2 step: 1275, loss is 0.41309046745300293\n",
      "epoch: 2 step: 1276, loss is 0.5794512033462524\n",
      "epoch: 2 step: 1277, loss is 0.28654858469963074\n",
      "epoch: 2 step: 1278, loss is 4.0283074378967285\n",
      "epoch: 2 step: 1279, loss is 0.2732086479663849\n",
      "epoch: 2 step: 1280, loss is 0.43815168738365173\n",
      "epoch: 2 step: 1281, loss is 0.17448003590106964\n",
      "epoch: 2 step: 1282, loss is 0.20530997216701508\n",
      "epoch: 2 step: 1283, loss is 2.323995590209961\n",
      "epoch: 2 step: 1284, loss is 0.48433446884155273\n",
      "epoch: 2 step: 1285, loss is 0.606691837310791\n",
      "epoch: 2 step: 1286, loss is 1.6453735828399658\n",
      "epoch: 2 step: 1287, loss is 0.09188302606344223\n",
      "epoch: 2 step: 1288, loss is 2.0174784660339355\n",
      "epoch: 2 step: 1289, loss is 0.4842112958431244\n",
      "epoch: 2 step: 1290, loss is 0.10556996613740921\n",
      "epoch: 2 step: 1291, loss is 0.18113137781620026\n",
      "epoch: 2 step: 1292, loss is 1.8508415222167969\n",
      "epoch: 2 step: 1293, loss is 0.3169628083705902\n",
      "epoch: 2 step: 1294, loss is 0.14185377955436707\n",
      "epoch: 2 step: 1295, loss is 0.13225838541984558\n",
      "epoch: 2 step: 1296, loss is 2.105421781539917\n",
      "epoch: 2 step: 1297, loss is 4.006439208984375\n",
      "epoch: 2 step: 1298, loss is 0.7533628940582275\n",
      "epoch: 2 step: 1299, loss is 0.4756423234939575\n",
      "epoch: 2 step: 1300, loss is 0.37306761741638184\n",
      "epoch: 2 step: 1301, loss is 0.07797373831272125\n",
      "epoch: 2 step: 1302, loss is 0.48707515001296997\n",
      "epoch: 2 step: 1303, loss is 0.1705852895975113\n",
      "epoch: 2 step: 1304, loss is 0.33873847126960754\n",
      "epoch: 2 step: 1305, loss is 0.07822985202074051\n",
      "epoch: 2 step: 1306, loss is 0.2830187678337097\n",
      "epoch: 2 step: 1307, loss is 3.0026657581329346\n",
      "epoch: 2 step: 1308, loss is 0.11632709205150604\n",
      "epoch: 2 step: 1309, loss is 0.38703519105911255\n",
      "epoch: 2 step: 1310, loss is 0.1197216734290123\n",
      "epoch: 2 step: 1311, loss is 0.18179455399513245\n",
      "epoch: 2 step: 1312, loss is 0.44819051027297974\n",
      "epoch: 2 step: 1313, loss is 0.15824994444847107\n",
      "epoch: 2 step: 1314, loss is 4.206709861755371\n",
      "epoch: 2 step: 1315, loss is 0.2847234606742859\n",
      "epoch: 2 step: 1316, loss is 0.3157452642917633\n",
      "epoch: 2 step: 1317, loss is 2.0679609775543213\n",
      "epoch: 2 step: 1318, loss is 3.363091230392456\n",
      "epoch: 2 step: 1319, loss is 0.14316654205322266\n",
      "epoch: 2 step: 1320, loss is 0.1585833579301834\n",
      "epoch: 2 step: 1321, loss is 0.5267431735992432\n",
      "epoch: 2 step: 1322, loss is 0.46909523010253906\n",
      "epoch: 2 step: 1323, loss is 1.630908727645874\n",
      "epoch: 2 step: 1324, loss is 0.1526685655117035\n",
      "epoch: 2 step: 1325, loss is 0.2131800651550293\n",
      "epoch: 2 step: 1326, loss is 2.8749351501464844\n",
      "epoch: 2 step: 1327, loss is 1.7502965927124023\n",
      "epoch: 2 step: 1328, loss is 0.40234091877937317\n",
      "epoch: 2 step: 1329, loss is 0.12090536206960678\n",
      "epoch: 2 step: 1330, loss is 0.06036384031176567\n",
      "epoch: 2 step: 1331, loss is 3.202599048614502\n",
      "epoch: 2 step: 1332, loss is 2.9467575550079346\n",
      "epoch: 2 step: 1333, loss is 0.3340831398963928\n",
      "epoch: 2 step: 1334, loss is 1.8681628704071045\n",
      "epoch: 2 step: 1335, loss is 3.4849936962127686\n",
      "epoch: 2 step: 1336, loss is 0.2803458869457245\n",
      "epoch: 2 step: 1337, loss is 2.4497950077056885\n",
      "epoch: 2 step: 1338, loss is 1.8317773342132568\n",
      "epoch: 2 step: 1339, loss is 2.4696245193481445\n",
      "epoch: 2 step: 1340, loss is 0.8983148336410522\n",
      "epoch: 2 step: 1341, loss is 0.6002799272537231\n",
      "epoch: 2 step: 1342, loss is 0.962945282459259\n",
      "epoch: 2 step: 1343, loss is 0.416170209646225\n",
      "epoch: 2 step: 1344, loss is 1.7378183603286743\n",
      "epoch: 2 step: 1345, loss is 2.705887794494629\n",
      "epoch: 2 step: 1346, loss is 1.9453375339508057\n",
      "epoch: 2 step: 1347, loss is 2.0939512252807617\n",
      "epoch: 2 step: 1348, loss is 4.483443260192871\n",
      "epoch: 2 step: 1349, loss is 1.0809334516525269\n",
      "epoch: 2 step: 1350, loss is 0.5735228657722473\n",
      "epoch: 2 step: 1351, loss is 2.7745859622955322\n",
      "epoch: 2 step: 1352, loss is 0.6224275231361389\n",
      "epoch: 2 step: 1353, loss is 0.9805371761322021\n",
      "epoch: 2 step: 1354, loss is 0.9392495155334473\n",
      "epoch: 2 step: 1355, loss is 0.9886215329170227\n",
      "epoch: 2 step: 1356, loss is 0.834578275680542\n",
      "epoch: 2 step: 1357, loss is 0.7572031617164612\n",
      "epoch: 2 step: 1358, loss is 0.6172041893005371\n",
      "epoch: 2 step: 1359, loss is 0.6431513428688049\n",
      "epoch: 2 step: 1360, loss is 0.21733514964580536\n",
      "epoch: 2 step: 1361, loss is 2.1118853092193604\n",
      "epoch: 2 step: 1362, loss is 0.3300861716270447\n",
      "epoch: 2 step: 1363, loss is 0.572562038898468\n",
      "epoch: 2 step: 1364, loss is 0.49222636222839355\n",
      "epoch: 2 step: 1365, loss is 1.7627265453338623\n",
      "epoch: 2 step: 1366, loss is 2.292337656021118\n",
      "epoch: 2 step: 1367, loss is 0.17351830005645752\n",
      "epoch: 2 step: 1368, loss is 0.17882035672664642\n",
      "epoch: 2 step: 1369, loss is 3.1280055046081543\n",
      "epoch: 2 step: 1370, loss is 0.37294021248817444\n",
      "epoch: 2 step: 1371, loss is 0.9812660217285156\n",
      "epoch: 2 step: 1372, loss is 0.09162048995494843\n",
      "epoch: 2 step: 1373, loss is 0.23490718007087708\n",
      "epoch: 2 step: 1374, loss is 0.12911677360534668\n",
      "epoch: 2 step: 1375, loss is 0.3090800642967224\n",
      "epoch: 2 step: 1376, loss is 2.3529725074768066\n",
      "epoch: 2 step: 1377, loss is 0.3354012370109558\n",
      "epoch: 2 step: 1378, loss is 0.07271096855401993\n",
      "epoch: 2 step: 1379, loss is 1.7571332454681396\n",
      "epoch: 2 step: 1380, loss is 0.5062427520751953\n",
      "epoch: 2 step: 1381, loss is 2.194932222366333\n",
      "epoch: 2 step: 1382, loss is 0.1559760421514511\n",
      "epoch: 2 step: 1383, loss is 3.089531898498535\n",
      "epoch: 2 step: 1384, loss is 0.4342899024486542\n",
      "epoch: 2 step: 1385, loss is 1.7469907999038696\n",
      "epoch: 2 step: 1386, loss is 1.7588987350463867\n",
      "epoch: 2 step: 1387, loss is 1.0554527044296265\n",
      "epoch: 2 step: 1388, loss is 0.48311179876327515\n",
      "epoch: 2 step: 1389, loss is 0.2357904016971588\n",
      "epoch: 2 step: 1390, loss is 0.24188271164894104\n",
      "epoch: 2 step: 1391, loss is 2.1036782264709473\n",
      "epoch: 2 step: 1392, loss is 0.1155148521065712\n",
      "epoch: 2 step: 1393, loss is 0.6621991395950317\n",
      "epoch: 2 step: 1394, loss is 0.4407421350479126\n",
      "epoch: 2 step: 1395, loss is 0.2817363440990448\n",
      "epoch: 2 step: 1396, loss is 0.17538464069366455\n",
      "epoch: 2 step: 1397, loss is 0.222219780087471\n",
      "epoch: 2 step: 1398, loss is 0.32332268357276917\n",
      "epoch: 2 step: 1399, loss is 0.6096338033676147\n",
      "epoch: 2 step: 1400, loss is 3.579683542251587\n",
      "epoch: 2 step: 1401, loss is 4.595552921295166\n",
      "epoch: 2 step: 1402, loss is 0.9989548325538635\n",
      "epoch: 2 step: 1403, loss is 2.090259552001953\n",
      "epoch: 2 step: 1404, loss is 0.36407384276390076\n",
      "epoch: 2 step: 1405, loss is 1.9707813262939453\n",
      "epoch: 2 step: 1406, loss is 1.934536099433899\n",
      "epoch: 2 step: 1407, loss is 1.8943042755126953\n",
      "epoch: 2 step: 1408, loss is 1.7141387462615967\n",
      "epoch: 2 step: 1409, loss is 0.46007686853408813\n",
      "epoch: 2 step: 1410, loss is 1.657881498336792\n",
      "epoch: 2 step: 1411, loss is 1.6052721738815308\n",
      "epoch: 2 step: 1412, loss is 1.7840561866760254\n",
      "epoch: 2 step: 1413, loss is 1.1823573112487793\n",
      "epoch: 2 step: 1414, loss is 1.2129464149475098\n",
      "epoch: 2 step: 1415, loss is 1.5947582721710205\n",
      "epoch: 2 step: 1416, loss is 1.5507405996322632\n",
      "epoch: 2 step: 1417, loss is 1.6829783916473389\n",
      "epoch: 2 step: 1418, loss is 2.08618426322937\n",
      "epoch: 2 step: 1419, loss is 1.0336562395095825\n",
      "epoch: 2 step: 1420, loss is 0.964425802230835\n",
      "epoch: 2 step: 1421, loss is 1.0985995531082153\n",
      "epoch: 2 step: 1422, loss is 1.7306418418884277\n",
      "epoch: 2 step: 1423, loss is 0.7591381072998047\n",
      "epoch: 2 step: 1424, loss is 1.8626307249069214\n",
      "epoch: 2 step: 1425, loss is 0.8936251997947693\n",
      "epoch: 2 step: 1426, loss is 0.5710839033126831\n",
      "epoch: 2 step: 1427, loss is 1.6049877405166626\n",
      "epoch: 2 step: 1428, loss is 2.1102168560028076\n",
      "epoch: 2 step: 1429, loss is 0.5740000009536743\n",
      "epoch: 2 step: 1430, loss is 0.27202308177948\n",
      "epoch: 2 step: 1431, loss is 2.374934673309326\n",
      "epoch: 2 step: 1432, loss is 0.5776631832122803\n",
      "epoch: 2 step: 1433, loss is 0.36295515298843384\n",
      "epoch: 2 step: 1434, loss is 2.6799304485321045\n",
      "epoch: 2 step: 1435, loss is 2.4033079147338867\n",
      "epoch: 2 step: 1436, loss is 2.2584853172302246\n",
      "epoch: 2 step: 1437, loss is 2.4123589992523193\n",
      "epoch: 2 step: 1438, loss is 0.517431914806366\n",
      "epoch: 2 step: 1439, loss is 0.8499643206596375\n",
      "epoch: 2 step: 1440, loss is 0.22897881269454956\n",
      "epoch: 2 step: 1441, loss is 0.4620067775249481\n",
      "epoch: 2 step: 1442, loss is 1.628793478012085\n",
      "epoch: 2 step: 1443, loss is 1.9456472396850586\n",
      "epoch: 2 step: 1444, loss is 0.5226333141326904\n",
      "epoch: 2 step: 1445, loss is 0.6046433448791504\n",
      "epoch: 2 step: 1446, loss is 0.30485400557518005\n",
      "epoch: 2 step: 1447, loss is 0.9702754616737366\n",
      "epoch: 2 step: 1448, loss is 0.5140568614006042\n",
      "epoch: 2 step: 1449, loss is 0.2816981077194214\n",
      "epoch: 2 step: 1450, loss is 1.641951322555542\n",
      "epoch: 2 step: 1451, loss is 3.2220096588134766\n",
      "epoch: 2 step: 1452, loss is 3.23825740814209\n",
      "epoch: 2 step: 1453, loss is 1.5829219818115234\n",
      "epoch: 2 step: 1454, loss is 0.9986377358436584\n",
      "epoch: 2 step: 1455, loss is 0.667253851890564\n",
      "epoch: 2 step: 1456, loss is 2.2749791145324707\n",
      "epoch: 2 step: 1457, loss is 2.1434640884399414\n",
      "epoch: 2 step: 1458, loss is 0.5419088006019592\n",
      "epoch: 2 step: 1459, loss is 2.221281051635742\n",
      "epoch: 2 step: 1460, loss is 1.713140606880188\n",
      "epoch: 2 step: 1461, loss is 1.8882031440734863\n",
      "epoch: 2 step: 1462, loss is 2.061849594116211\n",
      "epoch: 2 step: 1463, loss is 2.015418291091919\n",
      "epoch: 2 step: 1464, loss is 1.9208979606628418\n",
      "epoch: 2 step: 1465, loss is 1.0733635425567627\n",
      "epoch: 2 step: 1466, loss is 1.756486177444458\n",
      "epoch: 2 step: 1467, loss is 1.7668769359588623\n",
      "epoch: 2 step: 1468, loss is 1.87001371383667\n",
      "epoch: 2 step: 1469, loss is 2.4303901195526123\n",
      "epoch: 2 step: 1470, loss is 0.9689263105392456\n",
      "epoch: 2 step: 1471, loss is 1.0222944021224976\n",
      "epoch: 2 step: 1472, loss is 1.18831467628479\n",
      "epoch: 2 step: 1473, loss is 0.7126418948173523\n",
      "epoch: 2 step: 1474, loss is 0.6821208596229553\n",
      "epoch: 2 step: 1475, loss is 0.640338122844696\n",
      "epoch: 2 step: 1476, loss is 1.8017675876617432\n",
      "epoch: 2 step: 1477, loss is 2.6093738079071045\n",
      "epoch: 2 step: 1478, loss is 2.205113410949707\n",
      "epoch: 2 step: 1479, loss is 1.8986494541168213\n",
      "epoch: 2 step: 1480, loss is 1.0503621101379395\n",
      "epoch: 2 step: 1481, loss is 1.8480393886566162\n",
      "epoch: 2 step: 1482, loss is 0.9066226482391357\n",
      "epoch: 2 step: 1483, loss is 0.9509482979774475\n",
      "epoch: 2 step: 1484, loss is 0.9076419472694397\n",
      "epoch: 2 step: 1485, loss is 0.9719724059104919\n",
      "epoch: 2 step: 1486, loss is 0.6242992281913757\n",
      "epoch: 2 step: 1487, loss is 0.5079888105392456\n",
      "epoch: 2 step: 1488, loss is 1.0193415880203247\n",
      "epoch: 2 step: 1489, loss is 2.637934684753418\n",
      "epoch: 2 step: 1490, loss is 0.615489661693573\n",
      "epoch: 2 step: 1491, loss is 0.30603763461112976\n",
      "epoch: 2 step: 1492, loss is 1.2089427709579468\n",
      "epoch: 2 step: 1493, loss is 0.3831959366798401\n",
      "epoch: 2 step: 1494, loss is 0.4762358069419861\n",
      "epoch: 2 step: 1495, loss is 2.375972270965576\n",
      "epoch: 2 step: 1496, loss is 0.647198498249054\n",
      "epoch: 2 step: 1497, loss is 0.6500636339187622\n",
      "epoch: 2 step: 1498, loss is 0.31194037199020386\n",
      "epoch: 2 step: 1499, loss is 0.38526371121406555\n",
      "epoch: 2 step: 1500, loss is 0.6438441872596741\n",
      "epoch: 2 step: 1501, loss is 0.45331594347953796\n",
      "epoch: 2 step: 1502, loss is 0.13039655983448029\n",
      "epoch: 2 step: 1503, loss is 0.5629869103431702\n",
      "epoch: 2 step: 1504, loss is 0.07339245826005936\n",
      "epoch: 2 step: 1505, loss is 0.08760743588209152\n",
      "epoch: 2 step: 1506, loss is 0.08679796755313873\n",
      "epoch: 2 step: 1507, loss is 2.2044942378997803\n",
      "epoch: 2 step: 1508, loss is 0.8511024117469788\n",
      "epoch: 2 step: 1509, loss is 0.3292871117591858\n",
      "epoch: 2 step: 1510, loss is 2.0498247146606445\n",
      "epoch: 2 step: 1511, loss is 0.33644208312034607\n",
      "epoch: 2 step: 1512, loss is 0.27733659744262695\n",
      "epoch: 2 step: 1513, loss is 0.45173412561416626\n",
      "epoch: 2 step: 1514, loss is 3.873948335647583\n",
      "epoch: 2 step: 1515, loss is 0.12749026715755463\n",
      "epoch: 2 step: 1516, loss is 5.004800319671631\n",
      "epoch: 2 step: 1517, loss is 0.21770860254764557\n",
      "epoch: 2 step: 1518, loss is 0.35582244396209717\n",
      "epoch: 2 step: 1519, loss is 2.716282367706299\n",
      "epoch: 2 step: 1520, loss is 0.49508941173553467\n",
      "epoch: 2 step: 1521, loss is 0.1832008808851242\n",
      "epoch: 2 step: 1522, loss is 1.0827834606170654\n",
      "epoch: 2 step: 1523, loss is 0.44649627804756165\n",
      "epoch: 2 step: 1524, loss is 2.2098679542541504\n",
      "epoch: 2 step: 1525, loss is 0.3433944582939148\n",
      "epoch: 2 step: 1526, loss is 0.16895754635334015\n",
      "epoch: 2 step: 1527, loss is 0.22083662450313568\n",
      "epoch: 2 step: 1528, loss is 2.4695122241973877\n",
      "epoch: 2 step: 1529, loss is 2.10548996925354\n",
      "epoch: 2 step: 1530, loss is 0.24851207435131073\n",
      "epoch: 2 step: 1531, loss is 1.9047307968139648\n",
      "epoch: 2 step: 1532, loss is 2.469994306564331\n",
      "epoch: 2 step: 1533, loss is 0.37081921100616455\n",
      "epoch: 2 step: 1534, loss is 0.9052184224128723\n",
      "epoch: 2 step: 1535, loss is 0.7222222685813904\n",
      "epoch: 2 step: 1536, loss is 0.2836513817310333\n",
      "epoch: 2 step: 1537, loss is 0.2494296282529831\n",
      "epoch: 2 step: 1538, loss is 0.39166900515556335\n",
      "epoch: 2 step: 1539, loss is 0.1685117483139038\n",
      "epoch: 2 step: 1540, loss is 2.0640358924865723\n",
      "epoch: 2 step: 1541, loss is 0.4090423583984375\n",
      "epoch: 2 step: 1542, loss is 2.289893388748169\n",
      "epoch: 2 step: 1543, loss is 0.7084944248199463\n",
      "epoch: 2 step: 1544, loss is 0.4192424714565277\n",
      "epoch: 2 step: 1545, loss is 0.3033817410469055\n",
      "epoch: 2 step: 1546, loss is 0.09134688228368759\n",
      "epoch: 2 step: 1547, loss is 0.41465872526168823\n",
      "epoch: 2 step: 1548, loss is 2.5994980335235596\n",
      "epoch: 2 step: 1549, loss is 0.5493229627609253\n",
      "epoch: 2 step: 1550, loss is 1.0129681825637817\n",
      "epoch: 2 step: 1551, loss is 2.7276411056518555\n",
      "epoch: 2 step: 1552, loss is 0.3860601484775543\n",
      "epoch: 2 step: 1553, loss is 2.801166534423828\n",
      "epoch: 2 step: 1554, loss is 0.20207488536834717\n",
      "epoch: 2 step: 1555, loss is 0.44759073853492737\n",
      "epoch: 2 step: 1556, loss is 0.6168516874313354\n",
      "epoch: 2 step: 1557, loss is 1.9553537368774414\n",
      "epoch: 2 step: 1558, loss is 1.942535400390625\n",
      "epoch: 2 step: 1559, loss is 2.3168411254882812\n",
      "epoch: 2 step: 1560, loss is 0.8636457920074463\n",
      "epoch: 2 step: 1561, loss is 0.7245720028877258\n",
      "epoch: 2 step: 1562, loss is 1.394668698310852\n",
      "epoch: 2 step: 1563, loss is 2.517256736755371\n",
      "epoch: 2 step: 1564, loss is 4.527160167694092\n",
      "epoch: 2 step: 1565, loss is 0.6492787003517151\n",
      "epoch: 2 step: 1566, loss is 1.6542166471481323\n",
      "epoch: 2 step: 1567, loss is 0.5571919679641724\n",
      "epoch: 2 step: 1568, loss is 1.5556315183639526\n",
      "epoch: 2 step: 1569, loss is 2.677147626876831\n",
      "epoch: 2 step: 1570, loss is 0.9340052604675293\n",
      "epoch: 2 step: 1571, loss is 1.965994119644165\n",
      "epoch: 2 step: 1572, loss is 0.708758533000946\n",
      "epoch: 2 step: 1573, loss is 1.9671345949172974\n",
      "epoch: 2 step: 1574, loss is 0.7248739004135132\n",
      "epoch: 2 step: 1575, loss is 0.40981876850128174\n",
      "epoch: 2 step: 1576, loss is 2.370513916015625\n",
      "epoch: 2 step: 1577, loss is 1.7747563123703003\n",
      "epoch: 2 step: 1578, loss is 2.2130627632141113\n",
      "epoch: 2 step: 1579, loss is 1.7643187046051025\n",
      "epoch: 2 step: 1580, loss is 1.9018104076385498\n",
      "epoch: 2 step: 1581, loss is 0.5776423811912537\n",
      "epoch: 2 step: 1582, loss is 1.1482529640197754\n",
      "epoch: 2 step: 1583, loss is 0.551973283290863\n",
      "epoch: 2 step: 1584, loss is 0.48536938428878784\n",
      "epoch: 2 step: 1585, loss is 0.31019487977027893\n",
      "epoch: 2 step: 1586, loss is 0.7874429225921631\n",
      "epoch: 2 step: 1587, loss is 0.8199243545532227\n",
      "epoch: 2 step: 1588, loss is 1.9146270751953125\n",
      "epoch: 2 step: 1589, loss is 0.4404137134552002\n",
      "epoch: 2 step: 1590, loss is 1.8421803712844849\n",
      "epoch: 2 step: 1591, loss is 0.22043775022029877\n",
      "epoch: 2 step: 1592, loss is 0.37014374136924744\n",
      "epoch: 2 step: 1593, loss is 2.270113706588745\n",
      "epoch: 2 step: 1594, loss is 0.19498935341835022\n",
      "epoch: 2 step: 1595, loss is 3.677312135696411\n",
      "epoch: 2 step: 1596, loss is 1.934727668762207\n",
      "epoch: 2 step: 1597, loss is 0.6538670659065247\n",
      "epoch: 2 step: 1598, loss is 2.610811233520508\n",
      "epoch: 2 step: 1599, loss is 2.1712803840637207\n",
      "epoch: 2 step: 1600, loss is 0.48457491397857666\n",
      "epoch: 3 step: 1, loss is 2.0275278091430664\n",
      "epoch: 3 step: 2, loss is 1.7145354747772217\n",
      "epoch: 3 step: 3, loss is 2.0794711112976074\n",
      "epoch: 3 step: 4, loss is 0.42703676223754883\n",
      "epoch: 3 step: 5, loss is 0.6190752387046814\n",
      "epoch: 3 step: 6, loss is 0.9300392270088196\n",
      "epoch: 3 step: 7, loss is 0.7874397039413452\n",
      "epoch: 3 step: 8, loss is 0.2533043920993805\n",
      "epoch: 3 step: 9, loss is 2.364405393600464\n",
      "epoch: 3 step: 10, loss is 2.5206527709960938\n",
      "epoch: 3 step: 11, loss is 0.39747855067253113\n",
      "epoch: 3 step: 12, loss is 0.4297485053539276\n",
      "epoch: 3 step: 13, loss is 0.7026334404945374\n",
      "epoch: 3 step: 14, loss is 2.118361473083496\n",
      "epoch: 3 step: 15, loss is 1.9580070972442627\n",
      "epoch: 3 step: 16, loss is 0.6133293509483337\n",
      "epoch: 3 step: 17, loss is 0.3182355761528015\n",
      "epoch: 3 step: 18, loss is 0.31947025656700134\n",
      "epoch: 3 step: 19, loss is 0.42077991366386414\n",
      "epoch: 3 step: 20, loss is 0.2165738046169281\n",
      "epoch: 3 step: 21, loss is 2.021419048309326\n",
      "epoch: 3 step: 22, loss is 1.2559852600097656\n",
      "epoch: 3 step: 23, loss is 1.9247429370880127\n",
      "epoch: 3 step: 24, loss is 2.3037142753601074\n",
      "epoch: 3 step: 25, loss is 1.8449594974517822\n",
      "epoch: 3 step: 26, loss is 0.8240346908569336\n",
      "epoch: 3 step: 27, loss is 2.0327625274658203\n",
      "epoch: 3 step: 28, loss is 0.5240502953529358\n",
      "epoch: 3 step: 29, loss is 2.214158296585083\n",
      "epoch: 3 step: 30, loss is 0.28890952467918396\n",
      "epoch: 3 step: 31, loss is 0.9280129075050354\n",
      "epoch: 3 step: 32, loss is 0.403577595949173\n",
      "epoch: 3 step: 33, loss is 1.5894814729690552\n",
      "epoch: 3 step: 34, loss is 0.34319156408309937\n",
      "epoch: 3 step: 35, loss is 1.8632025718688965\n",
      "epoch: 3 step: 36, loss is 2.1066055297851562\n",
      "epoch: 3 step: 37, loss is 0.29491519927978516\n",
      "epoch: 3 step: 38, loss is 2.1908063888549805\n",
      "epoch: 3 step: 39, loss is 0.4675455093383789\n",
      "epoch: 3 step: 40, loss is 0.3333349823951721\n",
      "epoch: 3 step: 41, loss is 3.340200424194336\n",
      "epoch: 3 step: 42, loss is 2.4698729515075684\n",
      "epoch: 3 step: 43, loss is 0.3510185182094574\n",
      "epoch: 3 step: 44, loss is 2.067412853240967\n",
      "epoch: 3 step: 45, loss is 2.314119338989258\n",
      "epoch: 3 step: 46, loss is 1.1479852199554443\n",
      "epoch: 3 step: 47, loss is 1.9380409717559814\n",
      "epoch: 3 step: 48, loss is 1.0911731719970703\n",
      "epoch: 3 step: 49, loss is 1.028346061706543\n",
      "epoch: 3 step: 50, loss is 0.7423068881034851\n",
      "epoch: 3 step: 51, loss is 1.907590627670288\n",
      "epoch: 3 step: 52, loss is 1.3498075008392334\n",
      "epoch: 3 step: 53, loss is 0.25328803062438965\n",
      "epoch: 3 step: 54, loss is 0.7952303886413574\n",
      "epoch: 3 step: 55, loss is 1.98945951461792\n",
      "epoch: 3 step: 56, loss is 0.30918148159980774\n",
      "epoch: 3 step: 57, loss is 0.8780694007873535\n",
      "epoch: 3 step: 58, loss is 1.1199212074279785\n",
      "epoch: 3 step: 59, loss is 0.49635934829711914\n",
      "epoch: 3 step: 60, loss is 0.48672470450401306\n",
      "epoch: 3 step: 61, loss is 0.08985550701618195\n",
      "epoch: 3 step: 62, loss is 0.7265028953552246\n",
      "epoch: 3 step: 63, loss is 0.4832678437232971\n",
      "epoch: 3 step: 64, loss is 0.3572540879249573\n",
      "epoch: 3 step: 65, loss is 0.3680790662765503\n",
      "epoch: 3 step: 66, loss is 0.39306750893592834\n",
      "epoch: 3 step: 67, loss is 0.14412705600261688\n",
      "epoch: 3 step: 68, loss is 0.05717715620994568\n",
      "epoch: 3 step: 69, loss is 0.02937253564596176\n",
      "epoch: 3 step: 70, loss is 3.457477569580078\n",
      "epoch: 3 step: 71, loss is 0.21572473645210266\n",
      "epoch: 3 step: 72, loss is 0.963439404964447\n",
      "epoch: 3 step: 73, loss is 1.779581069946289\n",
      "epoch: 3 step: 74, loss is 0.37600260972976685\n",
      "epoch: 3 step: 75, loss is 0.12660133838653564\n",
      "epoch: 3 step: 76, loss is 2.2219555377960205\n",
      "epoch: 3 step: 77, loss is 0.3334414064884186\n",
      "epoch: 3 step: 78, loss is 0.5278754830360413\n",
      "epoch: 3 step: 79, loss is 0.07114655524492264\n",
      "epoch: 3 step: 80, loss is 0.026602648198604584\n",
      "epoch: 3 step: 81, loss is 4.022202014923096\n",
      "epoch: 3 step: 82, loss is 4.357561111450195\n",
      "epoch: 3 step: 83, loss is 2.199212074279785\n",
      "epoch: 3 step: 84, loss is 0.8789445161819458\n",
      "epoch: 3 step: 85, loss is 2.1442365646362305\n",
      "epoch: 3 step: 86, loss is 1.8077898025512695\n",
      "epoch: 3 step: 87, loss is 0.5134614706039429\n",
      "epoch: 3 step: 88, loss is 0.866716206073761\n",
      "epoch: 3 step: 89, loss is 2.358383893966675\n",
      "epoch: 3 step: 90, loss is 0.3114301860332489\n",
      "epoch: 3 step: 91, loss is 1.8189353942871094\n",
      "epoch: 3 step: 92, loss is 0.7880699634552002\n",
      "epoch: 3 step: 93, loss is 0.3400307595729828\n",
      "epoch: 3 step: 94, loss is 0.9031833410263062\n",
      "epoch: 3 step: 95, loss is 1.74744713306427\n",
      "epoch: 3 step: 96, loss is 2.0777153968811035\n",
      "epoch: 3 step: 97, loss is 1.5353569984436035\n",
      "epoch: 3 step: 98, loss is 0.6437525153160095\n",
      "epoch: 3 step: 99, loss is 0.2352095991373062\n",
      "epoch: 3 step: 100, loss is 1.954345941543579\n",
      "epoch: 3 step: 101, loss is 0.2001313716173172\n",
      "epoch: 3 step: 102, loss is 2.1293654441833496\n",
      "epoch: 3 step: 103, loss is 0.7979941368103027\n",
      "epoch: 3 step: 104, loss is 0.6145013570785522\n",
      "epoch: 3 step: 105, loss is 2.1145265102386475\n",
      "epoch: 3 step: 106, loss is 0.4426423907279968\n",
      "epoch: 3 step: 107, loss is 1.8379924297332764\n",
      "epoch: 3 step: 108, loss is 2.50662899017334\n",
      "epoch: 3 step: 109, loss is 0.5447943210601807\n",
      "epoch: 3 step: 110, loss is 0.7134400606155396\n",
      "epoch: 3 step: 111, loss is 2.0867395401000977\n",
      "epoch: 3 step: 112, loss is 2.2120189666748047\n",
      "epoch: 3 step: 113, loss is 2.0035312175750732\n",
      "epoch: 3 step: 114, loss is 0.8553358912467957\n",
      "epoch: 3 step: 115, loss is 2.0677614212036133\n",
      "epoch: 3 step: 116, loss is 0.5484185218811035\n",
      "epoch: 3 step: 117, loss is 0.41765666007995605\n",
      "epoch: 3 step: 118, loss is 1.6222023963928223\n",
      "epoch: 3 step: 119, loss is 0.4084484279155731\n",
      "epoch: 3 step: 120, loss is 2.5008912086486816\n",
      "epoch: 3 step: 121, loss is 0.6043519973754883\n",
      "epoch: 3 step: 122, loss is 2.1041035652160645\n",
      "epoch: 3 step: 123, loss is 0.6850744485855103\n",
      "epoch: 3 step: 124, loss is 2.2656311988830566\n",
      "epoch: 3 step: 125, loss is 0.6580657958984375\n",
      "epoch: 3 step: 126, loss is 0.698562502861023\n",
      "epoch: 3 step: 127, loss is 0.27272531390190125\n",
      "epoch: 3 step: 128, loss is 1.9908367395401\n",
      "epoch: 3 step: 129, loss is 2.6149063110351562\n",
      "epoch: 3 step: 130, loss is 1.819760799407959\n",
      "epoch: 3 step: 131, loss is 1.7158310413360596\n",
      "epoch: 3 step: 132, loss is 0.4220336377620697\n",
      "epoch: 3 step: 133, loss is 1.6444528102874756\n",
      "epoch: 3 step: 134, loss is 2.226200819015503\n",
      "epoch: 3 step: 135, loss is 1.8178822994232178\n",
      "epoch: 3 step: 136, loss is 1.9229921102523804\n",
      "epoch: 3 step: 137, loss is 0.7573832869529724\n",
      "epoch: 3 step: 138, loss is 1.1549638509750366\n",
      "epoch: 3 step: 139, loss is 3.1144399642944336\n",
      "epoch: 3 step: 140, loss is 0.4893559515476227\n",
      "epoch: 3 step: 141, loss is 1.9553568363189697\n",
      "epoch: 3 step: 142, loss is 0.45897820591926575\n",
      "epoch: 3 step: 143, loss is 0.9764578342437744\n",
      "epoch: 3 step: 144, loss is 0.6798054575920105\n",
      "epoch: 3 step: 145, loss is 0.8845644593238831\n",
      "epoch: 3 step: 146, loss is 1.00357985496521\n",
      "epoch: 3 step: 147, loss is 2.712714672088623\n",
      "epoch: 3 step: 148, loss is 0.48619481921195984\n",
      "epoch: 3 step: 149, loss is 1.8407654762268066\n",
      "epoch: 3 step: 150, loss is 1.8647900819778442\n",
      "epoch: 3 step: 151, loss is 1.8198260068893433\n",
      "epoch: 3 step: 152, loss is 1.992957592010498\n",
      "epoch: 3 step: 153, loss is 1.0998612642288208\n",
      "epoch: 3 step: 154, loss is 0.5654187798500061\n",
      "epoch: 3 step: 155, loss is 0.5306394696235657\n",
      "epoch: 3 step: 156, loss is 0.698846161365509\n",
      "epoch: 3 step: 157, loss is 2.26985502243042\n",
      "epoch: 3 step: 158, loss is 2.017008066177368\n",
      "epoch: 3 step: 159, loss is 0.9745633006095886\n",
      "epoch: 3 step: 160, loss is 0.8549730181694031\n",
      "epoch: 3 step: 161, loss is 0.6881247162818909\n",
      "epoch: 3 step: 162, loss is 0.2739628851413727\n",
      "epoch: 3 step: 163, loss is 0.840198814868927\n",
      "epoch: 3 step: 164, loss is 0.9175403118133545\n",
      "epoch: 3 step: 165, loss is 4.032403469085693\n",
      "epoch: 3 step: 166, loss is 0.626405656337738\n",
      "epoch: 3 step: 167, loss is 2.2951834201812744\n",
      "epoch: 3 step: 168, loss is 2.2883992195129395\n",
      "epoch: 3 step: 169, loss is 1.938720703125\n",
      "epoch: 3 step: 170, loss is 2.274383544921875\n",
      "epoch: 3 step: 171, loss is 1.88627290725708\n",
      "epoch: 3 step: 172, loss is 2.443264961242676\n",
      "epoch: 3 step: 173, loss is 2.1024718284606934\n",
      "epoch: 3 step: 174, loss is 1.6697179079055786\n",
      "epoch: 3 step: 175, loss is 1.594928503036499\n",
      "epoch: 3 step: 176, loss is 0.7160899043083191\n",
      "epoch: 3 step: 177, loss is 0.5379539132118225\n",
      "epoch: 3 step: 178, loss is 0.6093189716339111\n",
      "epoch: 3 step: 179, loss is 2.0399560928344727\n",
      "epoch: 3 step: 180, loss is 1.189168930053711\n",
      "epoch: 3 step: 181, loss is 0.8429186344146729\n",
      "epoch: 3 step: 182, loss is 1.705517053604126\n",
      "epoch: 3 step: 183, loss is 2.1659438610076904\n",
      "epoch: 3 step: 184, loss is 1.7627692222595215\n",
      "epoch: 3 step: 185, loss is 0.541575014591217\n",
      "epoch: 3 step: 186, loss is 1.9663941860198975\n",
      "epoch: 3 step: 187, loss is 0.5474492907524109\n",
      "epoch: 3 step: 188, loss is 0.9468709230422974\n",
      "epoch: 3 step: 189, loss is 0.27661970257759094\n",
      "epoch: 3 step: 190, loss is 0.9881146550178528\n",
      "epoch: 3 step: 191, loss is 0.49407055974006653\n",
      "epoch: 3 step: 192, loss is 0.5531103014945984\n",
      "epoch: 3 step: 193, loss is 0.3378291726112366\n",
      "epoch: 3 step: 194, loss is 2.2206554412841797\n",
      "epoch: 3 step: 195, loss is 0.7827650904655457\n",
      "epoch: 3 step: 196, loss is 0.7813102602958679\n",
      "epoch: 3 step: 197, loss is 0.24455012381076813\n",
      "epoch: 3 step: 198, loss is 0.11941248923540115\n",
      "epoch: 3 step: 199, loss is 1.0239109992980957\n",
      "epoch: 3 step: 200, loss is 2.1946234703063965\n",
      "epoch: 3 step: 201, loss is 1.9678070545196533\n",
      "epoch: 3 step: 202, loss is 1.0896166563034058\n",
      "epoch: 3 step: 203, loss is 0.32770487666130066\n",
      "epoch: 3 step: 204, loss is 0.23528195917606354\n",
      "epoch: 3 step: 205, loss is 0.20249564945697784\n",
      "epoch: 3 step: 206, loss is 2.5725317001342773\n",
      "epoch: 3 step: 207, loss is 0.5134733319282532\n",
      "epoch: 3 step: 208, loss is 0.12146717309951782\n",
      "epoch: 3 step: 209, loss is 1.8654899597167969\n",
      "epoch: 3 step: 210, loss is 0.3524230122566223\n",
      "epoch: 3 step: 211, loss is 0.12190394103527069\n",
      "epoch: 3 step: 212, loss is 0.21065090596675873\n",
      "epoch: 3 step: 213, loss is 0.20547811686992645\n",
      "epoch: 3 step: 214, loss is 2.7622268199920654\n",
      "epoch: 3 step: 215, loss is 0.14649906754493713\n",
      "epoch: 3 step: 216, loss is 0.21049465239048004\n",
      "epoch: 3 step: 217, loss is 0.33692407608032227\n",
      "epoch: 3 step: 218, loss is 5.739481449127197\n",
      "epoch: 3 step: 219, loss is 0.6648017168045044\n",
      "epoch: 3 step: 220, loss is 2.3106844425201416\n",
      "epoch: 3 step: 221, loss is 1.7662220001220703\n",
      "epoch: 3 step: 222, loss is 2.2311079502105713\n",
      "epoch: 3 step: 223, loss is 0.6252530217170715\n",
      "epoch: 3 step: 224, loss is 1.7217530012130737\n",
      "epoch: 3 step: 225, loss is 1.733039379119873\n",
      "epoch: 3 step: 226, loss is 1.3868852853775024\n",
      "epoch: 3 step: 227, loss is 0.24033838510513306\n",
      "epoch: 3 step: 228, loss is 2.179636001586914\n",
      "epoch: 3 step: 229, loss is 0.4280228614807129\n",
      "epoch: 3 step: 230, loss is 0.4565911889076233\n",
      "epoch: 3 step: 231, loss is 1.7154899835586548\n",
      "epoch: 3 step: 232, loss is 1.0964785814285278\n",
      "epoch: 3 step: 233, loss is 0.9128240346908569\n",
      "epoch: 3 step: 234, loss is 0.3049260675907135\n",
      "epoch: 3 step: 235, loss is 0.23802264034748077\n",
      "epoch: 3 step: 236, loss is 0.5040596723556519\n",
      "epoch: 3 step: 237, loss is 1.8385848999023438\n",
      "epoch: 3 step: 238, loss is 2.0548694133758545\n",
      "epoch: 3 step: 239, loss is 1.6216397285461426\n",
      "epoch: 3 step: 240, loss is 0.30787548422813416\n",
      "epoch: 3 step: 241, loss is 0.8726871609687805\n",
      "epoch: 3 step: 242, loss is 0.45129847526550293\n",
      "epoch: 3 step: 243, loss is 0.6637517213821411\n",
      "epoch: 3 step: 244, loss is 1.0220341682434082\n",
      "epoch: 3 step: 245, loss is 0.37229281663894653\n",
      "epoch: 3 step: 246, loss is 3.5332448482513428\n",
      "epoch: 3 step: 247, loss is 0.22489239275455475\n",
      "epoch: 3 step: 248, loss is 2.244943857192993\n",
      "epoch: 3 step: 249, loss is 1.9779325723648071\n",
      "epoch: 3 step: 250, loss is 2.3391592502593994\n",
      "epoch: 3 step: 251, loss is 0.5190844535827637\n",
      "epoch: 3 step: 252, loss is 0.545396625995636\n",
      "epoch: 3 step: 253, loss is 0.11413706839084625\n",
      "epoch: 3 step: 254, loss is 0.6014836430549622\n",
      "epoch: 3 step: 255, loss is 0.24444249272346497\n",
      "epoch: 3 step: 256, loss is 3.2258620262145996\n",
      "epoch: 3 step: 257, loss is 2.097012519836426\n",
      "epoch: 3 step: 258, loss is 0.1339525431394577\n",
      "epoch: 3 step: 259, loss is 2.7717082500457764\n",
      "epoch: 3 step: 260, loss is 1.6186443567276\n",
      "epoch: 3 step: 261, loss is 0.6070995330810547\n",
      "epoch: 3 step: 262, loss is 1.1285535097122192\n",
      "epoch: 3 step: 263, loss is 0.3644515872001648\n",
      "epoch: 3 step: 264, loss is 0.4475199282169342\n",
      "epoch: 3 step: 265, loss is 2.0542821884155273\n",
      "epoch: 3 step: 266, loss is 0.3380107879638672\n",
      "epoch: 3 step: 267, loss is 1.7840747833251953\n",
      "epoch: 3 step: 268, loss is 1.7401095628738403\n",
      "epoch: 3 step: 269, loss is 1.9523324966430664\n",
      "epoch: 3 step: 270, loss is 0.46268415451049805\n",
      "epoch: 3 step: 271, loss is 0.7808724641799927\n",
      "epoch: 3 step: 272, loss is 0.9145715832710266\n",
      "epoch: 3 step: 273, loss is 2.3892617225646973\n",
      "epoch: 3 step: 274, loss is 2.160764217376709\n",
      "epoch: 3 step: 275, loss is 0.33143720030784607\n",
      "epoch: 3 step: 276, loss is 0.12101680040359497\n",
      "epoch: 3 step: 277, loss is 1.7186943292617798\n",
      "epoch: 3 step: 278, loss is 0.8773418068885803\n",
      "epoch: 3 step: 279, loss is 0.22881239652633667\n",
      "epoch: 3 step: 280, loss is 0.6701414585113525\n",
      "epoch: 3 step: 281, loss is 0.4278334081172943\n",
      "epoch: 3 step: 282, loss is 0.5699509382247925\n",
      "epoch: 3 step: 283, loss is 0.8092347383499146\n",
      "epoch: 3 step: 284, loss is 4.29741907119751\n",
      "epoch: 3 step: 285, loss is 0.5350204706192017\n",
      "epoch: 3 step: 286, loss is 0.27018579840660095\n",
      "epoch: 3 step: 287, loss is 0.39431077241897583\n",
      "epoch: 3 step: 288, loss is 0.41732922196388245\n",
      "epoch: 3 step: 289, loss is 0.1559383124113083\n",
      "epoch: 3 step: 290, loss is 1.916162371635437\n",
      "epoch: 3 step: 291, loss is 2.120842695236206\n",
      "epoch: 3 step: 292, loss is 2.2423441410064697\n",
      "epoch: 3 step: 293, loss is 2.395688772201538\n",
      "epoch: 3 step: 294, loss is 0.6851630210876465\n",
      "epoch: 3 step: 295, loss is 1.957047939300537\n",
      "epoch: 3 step: 296, loss is 2.8218111991882324\n",
      "epoch: 3 step: 297, loss is 2.1125235557556152\n",
      "epoch: 3 step: 298, loss is 0.5414314270019531\n",
      "epoch: 3 step: 299, loss is 0.35394755005836487\n",
      "epoch: 3 step: 300, loss is 0.20004305243492126\n",
      "epoch: 3 step: 301, loss is 0.5715716481208801\n",
      "epoch: 3 step: 302, loss is 0.7556086778640747\n",
      "epoch: 3 step: 303, loss is 0.22797471284866333\n",
      "epoch: 3 step: 304, loss is 0.49480751156806946\n",
      "epoch: 3 step: 305, loss is 0.38071003556251526\n",
      "epoch: 3 step: 306, loss is 2.934211254119873\n",
      "epoch: 3 step: 307, loss is 0.0763440951704979\n",
      "epoch: 3 step: 308, loss is 0.06116167828440666\n",
      "epoch: 3 step: 309, loss is 0.2216547131538391\n",
      "epoch: 3 step: 310, loss is 2.2620303630828857\n",
      "epoch: 3 step: 311, loss is 0.5605419278144836\n",
      "epoch: 3 step: 312, loss is 2.0914206504821777\n",
      "epoch: 3 step: 313, loss is 0.1627356857061386\n",
      "epoch: 3 step: 314, loss is 2.3449840545654297\n",
      "epoch: 3 step: 315, loss is 2.21694278717041\n",
      "epoch: 3 step: 316, loss is 2.1545088291168213\n",
      "epoch: 3 step: 317, loss is 2.213188409805298\n",
      "epoch: 3 step: 318, loss is 0.9161194562911987\n",
      "epoch: 3 step: 319, loss is 0.34639671444892883\n",
      "epoch: 3 step: 320, loss is 1.8969753980636597\n",
      "epoch: 3 step: 321, loss is 0.5615119338035583\n",
      "epoch: 3 step: 322, loss is 2.1721439361572266\n",
      "epoch: 3 step: 323, loss is 2.0536558628082275\n",
      "epoch: 3 step: 324, loss is 1.4594533443450928\n",
      "epoch: 3 step: 325, loss is 1.0641682147979736\n",
      "epoch: 3 step: 326, loss is 0.60631263256073\n",
      "epoch: 3 step: 327, loss is 1.8836270570755005\n",
      "epoch: 3 step: 328, loss is 2.800962448120117\n",
      "epoch: 3 step: 329, loss is 1.810307502746582\n",
      "epoch: 3 step: 330, loss is 1.9913322925567627\n",
      "epoch: 3 step: 331, loss is 1.6148459911346436\n",
      "epoch: 3 step: 332, loss is 0.8123375773429871\n",
      "epoch: 3 step: 333, loss is 0.9355774521827698\n",
      "epoch: 3 step: 334, loss is 0.8255444765090942\n",
      "epoch: 3 step: 335, loss is 0.9796913862228394\n",
      "epoch: 3 step: 336, loss is 0.7434356212615967\n",
      "epoch: 3 step: 337, loss is 0.4543476402759552\n",
      "epoch: 3 step: 338, loss is 0.3683837950229645\n",
      "epoch: 3 step: 339, loss is 0.4936971962451935\n",
      "epoch: 3 step: 340, loss is 0.6055513620376587\n",
      "epoch: 3 step: 341, loss is 2.552503824234009\n",
      "epoch: 3 step: 342, loss is 0.8981905579566956\n",
      "epoch: 3 step: 343, loss is 0.384494811296463\n",
      "epoch: 3 step: 344, loss is 0.2245013266801834\n",
      "epoch: 3 step: 345, loss is 2.767366647720337\n",
      "epoch: 3 step: 346, loss is 0.4931267499923706\n",
      "epoch: 3 step: 347, loss is 2.247257709503174\n",
      "epoch: 3 step: 348, loss is 0.5166935920715332\n",
      "epoch: 3 step: 349, loss is 2.682180881500244\n",
      "epoch: 3 step: 350, loss is 1.6861876249313354\n",
      "epoch: 3 step: 351, loss is 1.0002206563949585\n",
      "epoch: 3 step: 352, loss is 0.4094782769680023\n",
      "epoch: 3 step: 353, loss is 0.7478131651878357\n",
      "epoch: 3 step: 354, loss is 2.1645619869232178\n",
      "epoch: 3 step: 355, loss is 0.701805055141449\n",
      "epoch: 3 step: 356, loss is 2.189929485321045\n",
      "epoch: 3 step: 357, loss is 0.42644843459129333\n",
      "epoch: 3 step: 358, loss is 2.7522356510162354\n",
      "epoch: 3 step: 359, loss is 1.0583750009536743\n",
      "epoch: 3 step: 360, loss is 0.37807175517082214\n",
      "epoch: 3 step: 361, loss is 0.6944888234138489\n",
      "epoch: 3 step: 362, loss is 2.091677188873291\n",
      "epoch: 3 step: 363, loss is 0.7013013958930969\n",
      "epoch: 3 step: 364, loss is 0.5068592429161072\n",
      "epoch: 3 step: 365, loss is 0.3224402964115143\n",
      "epoch: 3 step: 366, loss is 2.017557382583618\n",
      "epoch: 3 step: 367, loss is 1.6366920471191406\n",
      "epoch: 3 step: 368, loss is 0.40853914618492126\n",
      "epoch: 3 step: 369, loss is 0.42578041553497314\n",
      "epoch: 3 step: 370, loss is 2.008871555328369\n",
      "epoch: 3 step: 371, loss is 3.358380079269409\n",
      "epoch: 3 step: 372, loss is 0.5770961046218872\n",
      "epoch: 3 step: 373, loss is 3.1509456634521484\n",
      "epoch: 3 step: 374, loss is 1.202573537826538\n",
      "epoch: 3 step: 375, loss is 0.40703046321868896\n",
      "epoch: 3 step: 376, loss is 0.5685207843780518\n",
      "epoch: 3 step: 377, loss is 1.8449716567993164\n",
      "epoch: 3 step: 378, loss is 1.9772155284881592\n",
      "epoch: 3 step: 379, loss is 2.4281861782073975\n",
      "epoch: 3 step: 380, loss is 0.9785634875297546\n",
      "epoch: 3 step: 381, loss is 0.8695064783096313\n",
      "epoch: 3 step: 382, loss is 0.6670171618461609\n",
      "epoch: 3 step: 383, loss is 2.0381455421447754\n",
      "epoch: 3 step: 384, loss is 2.789271354675293\n",
      "epoch: 3 step: 385, loss is 1.663209080696106\n",
      "epoch: 3 step: 386, loss is 0.8154228329658508\n",
      "epoch: 3 step: 387, loss is 2.270324468612671\n",
      "epoch: 3 step: 388, loss is 0.8437526822090149\n",
      "epoch: 3 step: 389, loss is 2.0124051570892334\n",
      "epoch: 3 step: 390, loss is 0.7298085689544678\n",
      "epoch: 3 step: 391, loss is 1.7368669509887695\n",
      "epoch: 3 step: 392, loss is 1.498355507850647\n",
      "epoch: 3 step: 393, loss is 1.7411340475082397\n",
      "epoch: 3 step: 394, loss is 0.6313408017158508\n",
      "epoch: 3 step: 395, loss is 0.9464586973190308\n",
      "epoch: 3 step: 396, loss is 0.8509535789489746\n",
      "epoch: 3 step: 397, loss is 0.5782912373542786\n",
      "epoch: 3 step: 398, loss is 1.6871521472930908\n",
      "epoch: 3 step: 399, loss is 0.8180970549583435\n",
      "epoch: 3 step: 400, loss is 0.69733065366745\n",
      "epoch: 3 step: 401, loss is 2.265843391418457\n",
      "epoch: 3 step: 402, loss is 0.5907970666885376\n",
      "epoch: 3 step: 403, loss is 0.5707815885543823\n",
      "epoch: 3 step: 404, loss is 0.8249651193618774\n",
      "epoch: 3 step: 405, loss is 1.862418532371521\n",
      "epoch: 3 step: 406, loss is 0.44257959723472595\n",
      "epoch: 3 step: 407, loss is 0.3989167809486389\n",
      "epoch: 3 step: 408, loss is 1.7901725769042969\n",
      "epoch: 3 step: 409, loss is 0.34788650274276733\n",
      "epoch: 3 step: 410, loss is 3.216032028198242\n",
      "epoch: 3 step: 411, loss is 0.8366625308990479\n",
      "epoch: 3 step: 412, loss is 0.42299696803092957\n",
      "epoch: 3 step: 413, loss is 1.8800718784332275\n",
      "epoch: 3 step: 414, loss is 1.6769304275512695\n",
      "epoch: 3 step: 415, loss is 0.6340218782424927\n",
      "epoch: 3 step: 416, loss is 0.4170714318752289\n",
      "epoch: 3 step: 417, loss is 2.4674923419952393\n",
      "epoch: 3 step: 418, loss is 0.49022558331489563\n",
      "epoch: 3 step: 419, loss is 0.21619868278503418\n",
      "epoch: 3 step: 420, loss is 1.683428406715393\n",
      "epoch: 3 step: 421, loss is 0.2843564450740814\n",
      "epoch: 3 step: 422, loss is 0.2724417448043823\n",
      "epoch: 3 step: 423, loss is 1.6966352462768555\n",
      "epoch: 3 step: 424, loss is 0.36138004064559937\n",
      "epoch: 3 step: 425, loss is 1.980675458908081\n",
      "epoch: 3 step: 426, loss is 3.8189902305603027\n",
      "epoch: 3 step: 427, loss is 0.34134161472320557\n",
      "epoch: 3 step: 428, loss is 0.6643450856208801\n",
      "epoch: 3 step: 429, loss is 1.7746849060058594\n",
      "epoch: 3 step: 430, loss is 0.5023572444915771\n",
      "epoch: 3 step: 431, loss is 1.8055416345596313\n",
      "epoch: 3 step: 432, loss is 0.19538527727127075\n",
      "epoch: 3 step: 433, loss is 2.079925060272217\n",
      "epoch: 3 step: 434, loss is 1.9038975238800049\n",
      "epoch: 3 step: 435, loss is 0.7486175894737244\n",
      "epoch: 3 step: 436, loss is 1.152530550956726\n",
      "epoch: 3 step: 437, loss is 1.7827510833740234\n",
      "epoch: 3 step: 438, loss is 1.677894115447998\n",
      "epoch: 3 step: 439, loss is 0.4597541391849518\n",
      "epoch: 3 step: 440, loss is 2.357276678085327\n",
      "epoch: 3 step: 441, loss is 0.572659432888031\n",
      "epoch: 3 step: 442, loss is 1.9752812385559082\n",
      "epoch: 3 step: 443, loss is 1.9305692911148071\n",
      "epoch: 3 step: 444, loss is 0.385153591632843\n",
      "epoch: 3 step: 445, loss is 0.7103988528251648\n",
      "epoch: 3 step: 446, loss is 0.7138529419898987\n",
      "epoch: 3 step: 447, loss is 0.525183379650116\n",
      "epoch: 3 step: 448, loss is 0.7451582551002502\n",
      "epoch: 3 step: 449, loss is 0.3765780031681061\n",
      "epoch: 3 step: 450, loss is 0.36645811796188354\n",
      "epoch: 3 step: 451, loss is 2.146453380584717\n",
      "epoch: 3 step: 452, loss is 2.099552631378174\n",
      "epoch: 3 step: 453, loss is 0.6531997323036194\n",
      "epoch: 3 step: 454, loss is 2.392892360687256\n",
      "epoch: 3 step: 455, loss is 0.3849696218967438\n",
      "epoch: 3 step: 456, loss is 1.6128032207489014\n",
      "epoch: 3 step: 457, loss is 0.5648805499076843\n",
      "epoch: 3 step: 458, loss is 1.6207616329193115\n",
      "epoch: 3 step: 459, loss is 0.21148720383644104\n",
      "epoch: 3 step: 460, loss is 1.699265480041504\n",
      "epoch: 3 step: 461, loss is 2.399726629257202\n",
      "epoch: 3 step: 462, loss is 1.0588310956954956\n",
      "epoch: 3 step: 463, loss is 0.4029558002948761\n",
      "epoch: 3 step: 464, loss is 0.4395444393157959\n",
      "epoch: 3 step: 465, loss is 2.0889759063720703\n",
      "epoch: 3 step: 466, loss is 2.502382516860962\n",
      "epoch: 3 step: 467, loss is 0.5376436710357666\n",
      "epoch: 3 step: 468, loss is 2.746213912963867\n",
      "epoch: 3 step: 469, loss is 0.5584710240364075\n",
      "epoch: 3 step: 470, loss is 0.9467490315437317\n",
      "epoch: 3 step: 471, loss is 0.3798910677433014\n",
      "epoch: 3 step: 472, loss is 1.678076148033142\n",
      "epoch: 3 step: 473, loss is 1.639763593673706\n",
      "epoch: 3 step: 474, loss is 0.5042176246643066\n",
      "epoch: 3 step: 475, loss is 0.3403637111186981\n",
      "epoch: 3 step: 476, loss is 0.5256444215774536\n",
      "epoch: 3 step: 477, loss is 0.7926356196403503\n",
      "epoch: 3 step: 478, loss is 1.8679202795028687\n",
      "epoch: 3 step: 479, loss is 0.6245936155319214\n",
      "epoch: 3 step: 480, loss is 0.7709887027740479\n",
      "epoch: 3 step: 481, loss is 0.6203426122665405\n",
      "epoch: 3 step: 482, loss is 0.15439452230930328\n",
      "epoch: 3 step: 483, loss is 0.4813750982284546\n",
      "epoch: 3 step: 484, loss is 0.2148561179637909\n",
      "epoch: 3 step: 485, loss is 0.16582761704921722\n",
      "epoch: 3 step: 486, loss is 2.0162839889526367\n",
      "epoch: 3 step: 487, loss is 1.5913197994232178\n",
      "epoch: 3 step: 488, loss is 2.6367688179016113\n",
      "epoch: 3 step: 489, loss is 2.487189769744873\n",
      "epoch: 3 step: 490, loss is 0.6688125133514404\n",
      "epoch: 3 step: 491, loss is 0.5541062951087952\n",
      "epoch: 3 step: 492, loss is 1.9782475233078003\n",
      "epoch: 3 step: 493, loss is 3.0964152812957764\n",
      "epoch: 3 step: 494, loss is 0.6141206622123718\n",
      "epoch: 3 step: 495, loss is 2.1785664558410645\n",
      "epoch: 3 step: 496, loss is 1.7268869876861572\n",
      "epoch: 3 step: 497, loss is 0.7878523468971252\n",
      "epoch: 3 step: 498, loss is 0.39952701330184937\n",
      "epoch: 3 step: 499, loss is 1.9352948665618896\n",
      "epoch: 3 step: 500, loss is 0.30051884055137634\n",
      "epoch: 3 step: 501, loss is 0.38390225172042847\n",
      "epoch: 3 step: 502, loss is 0.4988803565502167\n",
      "epoch: 3 step: 503, loss is 0.3068777918815613\n",
      "epoch: 3 step: 504, loss is 0.15339617431163788\n",
      "epoch: 3 step: 505, loss is 1.68046236038208\n",
      "epoch: 3 step: 506, loss is 0.04688902571797371\n",
      "epoch: 3 step: 507, loss is 2.2425947189331055\n",
      "epoch: 3 step: 508, loss is 0.2939664125442505\n",
      "epoch: 3 step: 509, loss is 1.7417893409729004\n",
      "epoch: 3 step: 510, loss is 1.945828914642334\n",
      "epoch: 3 step: 511, loss is 0.5664031505584717\n",
      "epoch: 3 step: 512, loss is 0.20100487768650055\n",
      "epoch: 3 step: 513, loss is 0.615472674369812\n",
      "epoch: 3 step: 514, loss is 0.5516179203987122\n",
      "epoch: 3 step: 515, loss is 0.21098487079143524\n",
      "epoch: 3 step: 516, loss is 0.12145228683948517\n",
      "epoch: 3 step: 517, loss is 2.155212163925171\n",
      "epoch: 3 step: 518, loss is 0.21856383979320526\n",
      "epoch: 3 step: 519, loss is 0.4253785014152527\n",
      "epoch: 3 step: 520, loss is 3.932645320892334\n",
      "epoch: 3 step: 521, loss is 2.7989108562469482\n",
      "epoch: 3 step: 522, loss is 0.16987662017345428\n",
      "epoch: 3 step: 523, loss is 0.396007776260376\n",
      "epoch: 3 step: 524, loss is 1.5841957330703735\n",
      "epoch: 3 step: 525, loss is 0.34558922052383423\n",
      "epoch: 3 step: 526, loss is 2.322249412536621\n",
      "epoch: 3 step: 527, loss is 0.3129771649837494\n",
      "epoch: 3 step: 528, loss is 2.2722725868225098\n",
      "epoch: 3 step: 529, loss is 0.62537682056427\n",
      "epoch: 3 step: 530, loss is 0.8056690692901611\n",
      "epoch: 3 step: 531, loss is 0.42206138372421265\n",
      "epoch: 3 step: 532, loss is 0.29706650972366333\n",
      "epoch: 3 step: 533, loss is 0.65547776222229\n",
      "epoch: 3 step: 534, loss is 0.3036210238933563\n",
      "epoch: 3 step: 535, loss is 0.2017534226179123\n",
      "epoch: 3 step: 536, loss is 0.21452680230140686\n",
      "epoch: 3 step: 537, loss is 0.07687829434871674\n",
      "epoch: 3 step: 538, loss is 0.05842021480202675\n",
      "epoch: 3 step: 539, loss is 1.8157212734222412\n",
      "epoch: 3 step: 540, loss is 0.334160715341568\n",
      "epoch: 3 step: 541, loss is 0.4690554141998291\n",
      "epoch: 3 step: 542, loss is 2.9222724437713623\n",
      "epoch: 3 step: 543, loss is 1.3899353742599487\n",
      "epoch: 3 step: 544, loss is 0.2679097652435303\n",
      "epoch: 3 step: 545, loss is 0.09233714640140533\n",
      "epoch: 3 step: 546, loss is 0.3333638608455658\n",
      "epoch: 3 step: 547, loss is 2.3056323528289795\n",
      "epoch: 3 step: 548, loss is 3.0833895206451416\n",
      "epoch: 3 step: 549, loss is 0.5169099569320679\n",
      "epoch: 3 step: 550, loss is 0.22804313898086548\n",
      "epoch: 3 step: 551, loss is 0.46996766328811646\n",
      "epoch: 3 step: 552, loss is 2.7815101146698\n",
      "epoch: 3 step: 553, loss is 0.4118167757987976\n",
      "epoch: 3 step: 554, loss is 0.49070098996162415\n",
      "epoch: 3 step: 555, loss is 0.3430171310901642\n",
      "epoch: 3 step: 556, loss is 2.1800315380096436\n",
      "epoch: 3 step: 557, loss is 0.2656470835208893\n",
      "epoch: 3 step: 558, loss is 4.040129661560059\n",
      "epoch: 3 step: 559, loss is 4.186792850494385\n",
      "epoch: 3 step: 560, loss is 2.5615603923797607\n",
      "epoch: 3 step: 561, loss is 1.561851143836975\n",
      "epoch: 3 step: 562, loss is 1.921924114227295\n",
      "epoch: 3 step: 563, loss is 1.0038940906524658\n",
      "epoch: 3 step: 564, loss is 1.1606706380844116\n",
      "epoch: 3 step: 565, loss is 0.9764742851257324\n",
      "epoch: 3 step: 566, loss is 2.226959228515625\n",
      "epoch: 3 step: 567, loss is 0.8626612424850464\n",
      "epoch: 3 step: 568, loss is 0.4997844696044922\n",
      "epoch: 3 step: 569, loss is 0.6332368850708008\n",
      "epoch: 3 step: 570, loss is 2.225770950317383\n",
      "epoch: 3 step: 571, loss is 1.848926305770874\n",
      "epoch: 3 step: 572, loss is 0.5979940295219421\n",
      "epoch: 3 step: 573, loss is 1.8740086555480957\n",
      "epoch: 3 step: 574, loss is 1.7577378749847412\n",
      "epoch: 3 step: 575, loss is 0.37439823150634766\n",
      "epoch: 3 step: 576, loss is 2.6816797256469727\n",
      "epoch: 3 step: 577, loss is 0.616931676864624\n",
      "epoch: 3 step: 578, loss is 2.694662570953369\n",
      "epoch: 3 step: 579, loss is 1.1154147386550903\n",
      "epoch: 3 step: 580, loss is 2.043348550796509\n",
      "epoch: 3 step: 581, loss is 0.3989381194114685\n",
      "epoch: 3 step: 582, loss is 2.2444581985473633\n",
      "epoch: 3 step: 583, loss is 1.1313815116882324\n",
      "epoch: 3 step: 584, loss is 0.8288295269012451\n",
      "epoch: 3 step: 585, loss is 2.139244318008423\n",
      "epoch: 3 step: 586, loss is 0.9896273612976074\n",
      "epoch: 3 step: 587, loss is 1.1970345973968506\n",
      "epoch: 3 step: 588, loss is 0.7904263138771057\n",
      "epoch: 3 step: 589, loss is 1.5654065608978271\n",
      "epoch: 3 step: 590, loss is 2.4336721897125244\n",
      "epoch: 3 step: 591, loss is 0.7673920392990112\n",
      "epoch: 3 step: 592, loss is 1.6490081548690796\n",
      "epoch: 3 step: 593, loss is 1.7923557758331299\n",
      "epoch: 3 step: 594, loss is 0.8759270310401917\n",
      "epoch: 3 step: 595, loss is 0.4633283317089081\n",
      "epoch: 3 step: 596, loss is 0.42878031730651855\n",
      "epoch: 3 step: 597, loss is 0.5828908681869507\n",
      "epoch: 3 step: 598, loss is 0.3295872211456299\n",
      "epoch: 3 step: 599, loss is 0.348488986492157\n",
      "epoch: 3 step: 600, loss is 1.5406434535980225\n",
      "epoch: 3 step: 601, loss is 2.6467344760894775\n",
      "epoch: 3 step: 602, loss is 0.26161715388298035\n",
      "epoch: 3 step: 603, loss is 2.2515852451324463\n",
      "epoch: 3 step: 604, loss is 0.6829925775527954\n",
      "epoch: 3 step: 605, loss is 2.4160399436950684\n",
      "epoch: 3 step: 606, loss is 1.1459168195724487\n",
      "epoch: 3 step: 607, loss is 2.029730796813965\n",
      "epoch: 3 step: 608, loss is 0.34937024116516113\n",
      "epoch: 3 step: 609, loss is 2.2834384441375732\n",
      "epoch: 3 step: 610, loss is 1.7287694215774536\n",
      "epoch: 3 step: 611, loss is 0.44204938411712646\n",
      "epoch: 3 step: 612, loss is 0.8961066603660583\n",
      "epoch: 3 step: 613, loss is 1.6968797445297241\n",
      "epoch: 3 step: 614, loss is 0.24924521148204803\n",
      "epoch: 3 step: 615, loss is 2.037238121032715\n",
      "epoch: 3 step: 616, loss is 2.937190532684326\n",
      "epoch: 3 step: 617, loss is 0.2712596356868744\n",
      "epoch: 3 step: 618, loss is 3.340447425842285\n",
      "epoch: 3 step: 619, loss is 0.6440152525901794\n",
      "epoch: 3 step: 620, loss is 1.050313949584961\n",
      "epoch: 3 step: 621, loss is 0.5867244005203247\n",
      "epoch: 3 step: 622, loss is 1.4788587093353271\n",
      "epoch: 3 step: 623, loss is 1.6685101985931396\n",
      "epoch: 3 step: 624, loss is 0.7361416220664978\n",
      "epoch: 3 step: 625, loss is 1.7861835956573486\n",
      "epoch: 3 step: 626, loss is 1.538292646408081\n",
      "epoch: 3 step: 627, loss is 1.800729751586914\n",
      "epoch: 3 step: 628, loss is 0.9438105821609497\n",
      "epoch: 3 step: 629, loss is 0.7210960388183594\n",
      "epoch: 3 step: 630, loss is 0.7722731828689575\n",
      "epoch: 3 step: 631, loss is 0.7434049844741821\n",
      "epoch: 3 step: 632, loss is 0.8122312426567078\n",
      "epoch: 3 step: 633, loss is 0.6820307374000549\n",
      "epoch: 3 step: 634, loss is 0.3673536479473114\n",
      "epoch: 3 step: 635, loss is 0.4309433102607727\n",
      "epoch: 3 step: 636, loss is 0.3944399952888489\n",
      "epoch: 3 step: 637, loss is 0.34171754121780396\n",
      "epoch: 3 step: 638, loss is 0.464626282453537\n",
      "epoch: 3 step: 639, loss is 0.13571566343307495\n",
      "epoch: 3 step: 640, loss is 2.4834351539611816\n",
      "epoch: 3 step: 641, loss is 1.7221516370773315\n",
      "epoch: 3 step: 642, loss is 1.6198395490646362\n",
      "epoch: 3 step: 643, loss is 1.9686036109924316\n",
      "epoch: 3 step: 644, loss is 0.41715750098228455\n",
      "epoch: 3 step: 645, loss is 2.4602110385894775\n",
      "epoch: 3 step: 646, loss is 0.23628899455070496\n",
      "epoch: 3 step: 647, loss is 0.35849595069885254\n",
      "epoch: 3 step: 648, loss is 1.3144638538360596\n",
      "epoch: 3 step: 649, loss is 2.0742568969726562\n",
      "epoch: 3 step: 650, loss is 1.2782330513000488\n",
      "epoch: 3 step: 651, loss is 3.0104050636291504\n",
      "epoch: 3 step: 652, loss is 1.8562664985656738\n",
      "epoch: 3 step: 653, loss is 0.322248637676239\n",
      "epoch: 3 step: 654, loss is 3.0217859745025635\n",
      "epoch: 3 step: 655, loss is 1.728539228439331\n",
      "epoch: 3 step: 656, loss is 1.1777740716934204\n",
      "epoch: 3 step: 657, loss is 0.34673380851745605\n",
      "epoch: 3 step: 658, loss is 2.025047540664673\n",
      "epoch: 3 step: 659, loss is 0.8355928659439087\n",
      "epoch: 3 step: 660, loss is 1.7234292030334473\n",
      "epoch: 3 step: 661, loss is 0.8402453064918518\n",
      "epoch: 3 step: 662, loss is 1.9385749101638794\n",
      "epoch: 3 step: 663, loss is 0.7926570773124695\n",
      "epoch: 3 step: 664, loss is 0.5194188356399536\n",
      "epoch: 3 step: 665, loss is 0.2585059702396393\n",
      "epoch: 3 step: 666, loss is 0.23543015122413635\n",
      "epoch: 3 step: 667, loss is 0.32423946261405945\n",
      "epoch: 3 step: 668, loss is 0.8721696138381958\n",
      "epoch: 3 step: 669, loss is 0.2290419489145279\n",
      "epoch: 3 step: 670, loss is 4.175298690795898\n",
      "epoch: 3 step: 671, loss is 0.4126964509487152\n",
      "epoch: 3 step: 672, loss is 0.6062768697738647\n",
      "epoch: 3 step: 673, loss is 0.6650786399841309\n",
      "epoch: 3 step: 674, loss is 0.4802532196044922\n",
      "epoch: 3 step: 675, loss is 2.981336832046509\n",
      "epoch: 3 step: 676, loss is 0.34438323974609375\n",
      "epoch: 3 step: 677, loss is 0.12864844501018524\n",
      "epoch: 3 step: 678, loss is 0.20593053102493286\n",
      "epoch: 3 step: 679, loss is 0.6246237754821777\n",
      "epoch: 3 step: 680, loss is 0.5129286050796509\n",
      "epoch: 3 step: 681, loss is 0.43092411756515503\n",
      "epoch: 3 step: 682, loss is 0.13923300802707672\n",
      "epoch: 3 step: 683, loss is 2.583258628845215\n",
      "epoch: 3 step: 684, loss is 0.17195746302604675\n",
      "epoch: 3 step: 685, loss is 0.03520927205681801\n",
      "epoch: 3 step: 686, loss is 3.449810028076172\n",
      "epoch: 3 step: 687, loss is 2.2961678504943848\n",
      "epoch: 3 step: 688, loss is 1.6730382442474365\n",
      "epoch: 3 step: 689, loss is 2.334726333618164\n",
      "epoch: 3 step: 690, loss is 2.5012102127075195\n",
      "epoch: 3 step: 691, loss is 0.7986325025558472\n",
      "epoch: 3 step: 692, loss is 0.5023943185806274\n",
      "epoch: 3 step: 693, loss is 0.4942471981048584\n",
      "epoch: 3 step: 694, loss is 0.3291979730129242\n",
      "epoch: 3 step: 695, loss is 0.36728015542030334\n",
      "epoch: 3 step: 696, loss is 2.387550115585327\n",
      "epoch: 3 step: 697, loss is 0.6171462535858154\n",
      "epoch: 3 step: 698, loss is 0.5289830565452576\n",
      "epoch: 3 step: 699, loss is 2.1854708194732666\n",
      "epoch: 3 step: 700, loss is 0.19248510897159576\n",
      "epoch: 3 step: 701, loss is 0.487201064825058\n",
      "epoch: 3 step: 702, loss is 2.7750308513641357\n",
      "epoch: 3 step: 703, loss is 0.5087867379188538\n",
      "epoch: 3 step: 704, loss is 0.9433429837226868\n",
      "epoch: 3 step: 705, loss is 0.1527254581451416\n",
      "epoch: 3 step: 706, loss is 0.5287271738052368\n",
      "epoch: 3 step: 707, loss is 4.514370441436768\n",
      "epoch: 3 step: 708, loss is 1.792479157447815\n",
      "epoch: 3 step: 709, loss is 1.9235738515853882\n",
      "epoch: 3 step: 710, loss is 0.9805724620819092\n",
      "epoch: 3 step: 711, loss is 1.5046089887619019\n",
      "epoch: 3 step: 712, loss is 3.0306007862091064\n",
      "epoch: 3 step: 713, loss is 0.3490421772003174\n",
      "epoch: 3 step: 714, loss is 0.9406948685646057\n",
      "epoch: 3 step: 715, loss is 1.9684975147247314\n",
      "epoch: 3 step: 716, loss is 2.733957290649414\n",
      "epoch: 3 step: 717, loss is 1.2778539657592773\n",
      "epoch: 3 step: 718, loss is 1.0449564456939697\n",
      "epoch: 3 step: 719, loss is 1.672561526298523\n",
      "epoch: 3 step: 720, loss is 1.7642135620117188\n",
      "epoch: 3 step: 721, loss is 0.3851965665817261\n",
      "epoch: 3 step: 722, loss is 1.0766242742538452\n",
      "epoch: 3 step: 723, loss is 0.40644046664237976\n",
      "epoch: 3 step: 724, loss is 3.54215407371521\n",
      "epoch: 3 step: 725, loss is 0.5335592031478882\n",
      "epoch: 3 step: 726, loss is 2.7620668411254883\n",
      "epoch: 3 step: 727, loss is 1.8050462007522583\n",
      "epoch: 3 step: 728, loss is 0.4972997307777405\n",
      "epoch: 3 step: 729, loss is 0.5508260726928711\n",
      "epoch: 3 step: 730, loss is 1.231674313545227\n",
      "epoch: 3 step: 731, loss is 0.8370989561080933\n",
      "epoch: 3 step: 732, loss is 0.17604804039001465\n",
      "epoch: 3 step: 733, loss is 4.1648736000061035\n",
      "epoch: 3 step: 734, loss is 0.8999533653259277\n",
      "epoch: 3 step: 735, loss is 1.9053676128387451\n",
      "epoch: 3 step: 736, loss is 0.9080134630203247\n",
      "epoch: 3 step: 737, loss is 0.6500291228294373\n",
      "epoch: 3 step: 738, loss is 0.8774589896202087\n",
      "epoch: 3 step: 739, loss is 2.0935397148132324\n",
      "epoch: 3 step: 740, loss is 1.832381248474121\n",
      "epoch: 3 step: 741, loss is 0.6013796925544739\n",
      "epoch: 3 step: 742, loss is 1.775541067123413\n",
      "epoch: 3 step: 743, loss is 0.5885134339332581\n",
      "epoch: 3 step: 744, loss is 2.267538070678711\n",
      "epoch: 3 step: 745, loss is 0.6719200611114502\n",
      "epoch: 3 step: 746, loss is 0.6158128976821899\n",
      "epoch: 3 step: 747, loss is 0.8381263613700867\n",
      "epoch: 3 step: 748, loss is 0.5768647193908691\n",
      "epoch: 3 step: 749, loss is 1.912926197052002\n",
      "epoch: 3 step: 750, loss is 0.6281018257141113\n",
      "epoch: 3 step: 751, loss is 0.3334662616252899\n",
      "epoch: 3 step: 752, loss is 0.3865148723125458\n",
      "epoch: 3 step: 753, loss is 0.5663038492202759\n",
      "epoch: 3 step: 754, loss is 0.32852068543434143\n",
      "epoch: 3 step: 755, loss is 0.9496493339538574\n",
      "epoch: 3 step: 756, loss is 0.7004726529121399\n",
      "epoch: 3 step: 757, loss is 1.7092790603637695\n",
      "epoch: 3 step: 758, loss is 0.2789546549320221\n",
      "epoch: 3 step: 759, loss is 0.21701164543628693\n",
      "epoch: 3 step: 760, loss is 0.6995523571968079\n",
      "epoch: 3 step: 761, loss is 0.26376891136169434\n",
      "epoch: 3 step: 762, loss is 0.6970325112342834\n",
      "epoch: 3 step: 763, loss is 0.3529546856880188\n",
      "epoch: 3 step: 764, loss is 3.8570494651794434\n",
      "epoch: 3 step: 765, loss is 2.979074001312256\n",
      "epoch: 3 step: 766, loss is 0.4230343699455261\n",
      "epoch: 3 step: 767, loss is 0.19431093335151672\n",
      "epoch: 3 step: 768, loss is 0.3603394031524658\n",
      "epoch: 3 step: 769, loss is 0.8550484776496887\n",
      "epoch: 3 step: 770, loss is 0.20045091211795807\n",
      "epoch: 3 step: 771, loss is 0.4774430990219116\n",
      "epoch: 3 step: 772, loss is 1.780278205871582\n",
      "epoch: 3 step: 773, loss is 0.4818779230117798\n",
      "epoch: 3 step: 774, loss is 0.40574830770492554\n",
      "epoch: 3 step: 775, loss is 2.9877591133117676\n",
      "epoch: 3 step: 776, loss is 0.13523469865322113\n",
      "epoch: 3 step: 777, loss is 0.1440296173095703\n",
      "epoch: 3 step: 778, loss is 2.652059555053711\n",
      "epoch: 3 step: 779, loss is 0.24938103556632996\n",
      "epoch: 3 step: 780, loss is 3.2432377338409424\n",
      "epoch: 3 step: 781, loss is 0.27363207936286926\n",
      "epoch: 3 step: 782, loss is 0.8599919676780701\n",
      "epoch: 3 step: 783, loss is 0.46080589294433594\n",
      "epoch: 3 step: 784, loss is 2.501157283782959\n",
      "epoch: 3 step: 785, loss is 1.9298312664031982\n",
      "epoch: 3 step: 786, loss is 0.6498254537582397\n",
      "epoch: 3 step: 787, loss is 0.3077599108219147\n",
      "epoch: 3 step: 788, loss is 0.2701495587825775\n",
      "epoch: 3 step: 789, loss is 2.3003714084625244\n",
      "epoch: 3 step: 790, loss is 0.8872844576835632\n",
      "epoch: 3 step: 791, loss is 2.3725674152374268\n",
      "epoch: 3 step: 792, loss is 0.6881018877029419\n",
      "epoch: 3 step: 793, loss is 0.5937322974205017\n",
      "epoch: 3 step: 794, loss is 1.7474439144134521\n",
      "epoch: 3 step: 795, loss is 0.5336485505104065\n",
      "epoch: 3 step: 796, loss is 0.37516748905181885\n",
      "epoch: 3 step: 797, loss is 2.254354476928711\n",
      "epoch: 3 step: 798, loss is 0.25400933623313904\n",
      "epoch: 3 step: 799, loss is 0.20312856137752533\n",
      "epoch: 3 step: 800, loss is 0.24514643847942352\n",
      "epoch: 3 step: 801, loss is 0.15937326848506927\n",
      "epoch: 3 step: 802, loss is 0.33934324979782104\n",
      "epoch: 3 step: 803, loss is 0.1949896514415741\n",
      "epoch: 3 step: 804, loss is 0.03812931478023529\n",
      "epoch: 3 step: 805, loss is 2.742112159729004\n",
      "epoch: 3 step: 806, loss is 0.23883908987045288\n",
      "epoch: 3 step: 807, loss is 3.4638547897338867\n",
      "epoch: 3 step: 808, loss is 0.4226345717906952\n",
      "epoch: 3 step: 809, loss is 0.18871359527111053\n",
      "epoch: 3 step: 810, loss is 0.39910227060317993\n",
      "epoch: 3 step: 811, loss is 0.23331154882907867\n",
      "epoch: 3 step: 812, loss is 0.14717058837413788\n",
      "epoch: 3 step: 813, loss is 0.12644441425800323\n",
      "epoch: 3 step: 814, loss is 0.2156689167022705\n",
      "epoch: 3 step: 815, loss is 3.73038911819458\n",
      "epoch: 3 step: 816, loss is 0.21034938097000122\n",
      "epoch: 3 step: 817, loss is 0.2716333866119385\n",
      "epoch: 3 step: 818, loss is 0.15532919764518738\n",
      "epoch: 3 step: 819, loss is 0.27942174673080444\n",
      "epoch: 3 step: 820, loss is 0.13391698896884918\n",
      "epoch: 3 step: 821, loss is 0.0607709176838398\n",
      "epoch: 3 step: 822, loss is 0.18270547688007355\n",
      "epoch: 3 step: 823, loss is 0.30979418754577637\n",
      "epoch: 3 step: 824, loss is 0.1322813630104065\n",
      "epoch: 3 step: 825, loss is 2.8171608448028564\n",
      "epoch: 3 step: 826, loss is 2.1401541233062744\n",
      "epoch: 3 step: 827, loss is 0.18707388639450073\n",
      "epoch: 3 step: 828, loss is 2.2945101261138916\n",
      "epoch: 3 step: 829, loss is 2.935335874557495\n",
      "epoch: 3 step: 830, loss is 0.40337884426116943\n",
      "epoch: 3 step: 831, loss is 0.4417286217212677\n",
      "epoch: 3 step: 832, loss is 0.871186375617981\n",
      "epoch: 3 step: 833, loss is 0.2631787359714508\n",
      "epoch: 3 step: 834, loss is 3.3922934532165527\n",
      "epoch: 3 step: 835, loss is 2.3706459999084473\n",
      "epoch: 3 step: 836, loss is 1.6838059425354004\n",
      "epoch: 3 step: 837, loss is 0.6069707274436951\n",
      "epoch: 3 step: 838, loss is 2.0876312255859375\n",
      "epoch: 3 step: 839, loss is 1.8886439800262451\n",
      "epoch: 3 step: 840, loss is 2.384582042694092\n",
      "epoch: 3 step: 841, loss is 0.37493735551834106\n",
      "epoch: 3 step: 842, loss is 0.2112635374069214\n",
      "epoch: 3 step: 843, loss is 0.3989378809928894\n",
      "epoch: 3 step: 844, loss is 0.20650804042816162\n",
      "epoch: 3 step: 845, loss is 0.6173878312110901\n",
      "epoch: 3 step: 846, loss is 0.25185954570770264\n",
      "epoch: 3 step: 847, loss is 0.5012226104736328\n",
      "epoch: 3 step: 848, loss is 1.91971755027771\n",
      "epoch: 3 step: 849, loss is 2.0452752113342285\n",
      "epoch: 3 step: 850, loss is 0.20493894815444946\n",
      "epoch: 3 step: 851, loss is 0.9466648697853088\n",
      "epoch: 3 step: 852, loss is 0.10267464071512222\n",
      "epoch: 3 step: 853, loss is 0.5393272638320923\n",
      "epoch: 3 step: 854, loss is 2.1450445652008057\n",
      "epoch: 3 step: 855, loss is 3.907984495162964\n",
      "epoch: 3 step: 856, loss is 1.7565991878509521\n",
      "epoch: 3 step: 857, loss is 2.4588675498962402\n",
      "epoch: 3 step: 858, loss is 0.7834426164627075\n",
      "epoch: 3 step: 859, loss is 0.41302454471588135\n",
      "epoch: 3 step: 860, loss is 1.8306076526641846\n",
      "epoch: 3 step: 861, loss is 2.086029291152954\n",
      "epoch: 3 step: 862, loss is 1.5188112258911133\n",
      "epoch: 3 step: 863, loss is 0.7703431248664856\n",
      "epoch: 3 step: 864, loss is 0.5652914047241211\n",
      "epoch: 3 step: 865, loss is 0.5145304203033447\n",
      "epoch: 3 step: 866, loss is 1.4943643808364868\n",
      "epoch: 3 step: 867, loss is 1.8035204410552979\n",
      "epoch: 3 step: 868, loss is 1.703437328338623\n",
      "epoch: 3 step: 869, loss is 1.5118646621704102\n",
      "epoch: 3 step: 870, loss is 0.6876673698425293\n",
      "epoch: 3 step: 871, loss is 0.9753526449203491\n",
      "epoch: 3 step: 872, loss is 0.4564688503742218\n",
      "epoch: 3 step: 873, loss is 2.3176097869873047\n",
      "epoch: 3 step: 874, loss is 0.5470858812332153\n",
      "epoch: 3 step: 875, loss is 1.709261417388916\n",
      "epoch: 3 step: 876, loss is 0.5991132259368896\n",
      "epoch: 3 step: 877, loss is 0.6946011781692505\n",
      "epoch: 3 step: 878, loss is 1.0117242336273193\n",
      "epoch: 3 step: 879, loss is 1.8042021989822388\n",
      "epoch: 3 step: 880, loss is 0.2834620475769043\n",
      "epoch: 3 step: 881, loss is 0.4823591113090515\n",
      "epoch: 3 step: 882, loss is 0.33590343594551086\n",
      "epoch: 3 step: 883, loss is 0.6474211812019348\n",
      "epoch: 3 step: 884, loss is 2.309412717819214\n",
      "epoch: 3 step: 885, loss is 1.6684013605117798\n",
      "epoch: 3 step: 886, loss is 3.1611459255218506\n",
      "epoch: 3 step: 887, loss is 1.8195017576217651\n",
      "epoch: 3 step: 888, loss is 0.5379045009613037\n",
      "epoch: 3 step: 889, loss is 0.9069899916648865\n",
      "epoch: 3 step: 890, loss is 0.6716085076332092\n",
      "epoch: 3 step: 891, loss is 0.32877591252326965\n",
      "epoch: 3 step: 892, loss is 1.7873196601867676\n",
      "epoch: 3 step: 893, loss is 0.8453574180603027\n",
      "epoch: 3 step: 894, loss is 3.386965036392212\n",
      "epoch: 3 step: 895, loss is 0.33697012066841125\n",
      "epoch: 3 step: 896, loss is 0.863288402557373\n",
      "epoch: 3 step: 897, loss is 3.2669506072998047\n",
      "epoch: 3 step: 898, loss is 0.34824901819229126\n",
      "epoch: 3 step: 899, loss is 0.9635415077209473\n",
      "epoch: 3 step: 900, loss is 1.9622538089752197\n",
      "epoch: 3 step: 901, loss is 0.4675029218196869\n",
      "epoch: 3 step: 902, loss is 2.456803321838379\n",
      "epoch: 3 step: 903, loss is 1.0522806644439697\n",
      "epoch: 3 step: 904, loss is 2.0269887447357178\n",
      "epoch: 3 step: 905, loss is 0.8819094300270081\n",
      "epoch: 3 step: 906, loss is 1.831404447555542\n",
      "epoch: 3 step: 907, loss is 0.6398113369941711\n",
      "epoch: 3 step: 908, loss is 0.3408714830875397\n",
      "epoch: 3 step: 909, loss is 2.019768714904785\n",
      "epoch: 3 step: 910, loss is 0.8140667080879211\n",
      "epoch: 3 step: 911, loss is 0.6177276372909546\n",
      "epoch: 3 step: 912, loss is 0.7719436287879944\n",
      "epoch: 3 step: 913, loss is 0.3605853021144867\n",
      "epoch: 3 step: 914, loss is 0.24010756611824036\n",
      "epoch: 3 step: 915, loss is 0.17284388840198517\n",
      "epoch: 3 step: 916, loss is 2.116360902786255\n",
      "epoch: 3 step: 917, loss is 0.12293262779712677\n",
      "epoch: 3 step: 918, loss is 1.6851990222930908\n",
      "epoch: 3 step: 919, loss is 1.5337406396865845\n",
      "epoch: 3 step: 920, loss is 0.12106294929981232\n",
      "epoch: 3 step: 921, loss is 1.0608084201812744\n",
      "epoch: 3 step: 922, loss is 0.1632077693939209\n",
      "epoch: 3 step: 923, loss is 3.1560680866241455\n",
      "epoch: 3 step: 924, loss is 0.49844616651535034\n",
      "epoch: 3 step: 925, loss is 0.3493730127811432\n",
      "epoch: 3 step: 926, loss is 0.17875954508781433\n",
      "epoch: 3 step: 927, loss is 0.2928526997566223\n",
      "epoch: 3 step: 928, loss is 0.0849277675151825\n",
      "epoch: 3 step: 929, loss is 3.1128997802734375\n",
      "epoch: 3 step: 930, loss is 2.0250957012176514\n",
      "epoch: 3 step: 931, loss is 0.6963260769844055\n",
      "epoch: 3 step: 932, loss is 2.3899433612823486\n",
      "epoch: 3 step: 933, loss is 2.264434337615967\n",
      "epoch: 3 step: 934, loss is 0.6752445101737976\n",
      "epoch: 3 step: 935, loss is 0.4181833863258362\n",
      "epoch: 3 step: 936, loss is 0.6171175241470337\n",
      "epoch: 3 step: 937, loss is 0.2611998915672302\n",
      "epoch: 3 step: 938, loss is 0.7332280874252319\n",
      "epoch: 3 step: 939, loss is 2.504368782043457\n",
      "epoch: 3 step: 940, loss is 0.35949182510375977\n",
      "epoch: 3 step: 941, loss is 1.8747248649597168\n",
      "epoch: 3 step: 942, loss is 0.6013232469558716\n",
      "epoch: 3 step: 943, loss is 2.417982578277588\n",
      "epoch: 3 step: 944, loss is 0.38191473484039307\n",
      "epoch: 3 step: 945, loss is 1.8708868026733398\n",
      "epoch: 3 step: 946, loss is 2.4851999282836914\n",
      "epoch: 3 step: 947, loss is 1.0810922384262085\n",
      "epoch: 3 step: 948, loss is 2.3530476093292236\n",
      "epoch: 3 step: 949, loss is 2.4096598625183105\n",
      "epoch: 3 step: 950, loss is 0.6109728217124939\n",
      "epoch: 3 step: 951, loss is 2.219560384750366\n",
      "epoch: 3 step: 952, loss is 0.7198083400726318\n",
      "epoch: 3 step: 953, loss is 0.8172248601913452\n",
      "epoch: 3 step: 954, loss is 1.814652919769287\n",
      "epoch: 3 step: 955, loss is 0.764112114906311\n",
      "epoch: 3 step: 956, loss is 0.8805999755859375\n",
      "epoch: 3 step: 957, loss is 0.6803364157676697\n",
      "epoch: 3 step: 958, loss is 0.5521441102027893\n",
      "epoch: 3 step: 959, loss is 0.5558687448501587\n",
      "epoch: 3 step: 960, loss is 0.47442376613616943\n",
      "epoch: 3 step: 961, loss is 1.979570984840393\n",
      "epoch: 3 step: 962, loss is 2.098391056060791\n",
      "epoch: 3 step: 963, loss is 0.9292976260185242\n",
      "epoch: 3 step: 964, loss is 0.3146314024925232\n",
      "epoch: 3 step: 965, loss is 1.8524503707885742\n",
      "epoch: 3 step: 966, loss is 2.706268548965454\n",
      "epoch: 3 step: 967, loss is 2.338191509246826\n",
      "epoch: 3 step: 968, loss is 0.8926818370819092\n",
      "epoch: 3 step: 969, loss is 0.8704286217689514\n",
      "epoch: 3 step: 970, loss is 2.0440895557403564\n",
      "epoch: 3 step: 971, loss is 2.1599202156066895\n",
      "epoch: 3 step: 972, loss is 0.6336145997047424\n",
      "epoch: 3 step: 973, loss is 2.5088305473327637\n",
      "epoch: 3 step: 974, loss is 0.7831609845161438\n",
      "epoch: 3 step: 975, loss is 0.5128672122955322\n",
      "epoch: 3 step: 976, loss is 2.21490740776062\n",
      "epoch: 3 step: 977, loss is 0.8805356025695801\n",
      "epoch: 3 step: 978, loss is 0.3520112931728363\n",
      "epoch: 3 step: 979, loss is 2.142711877822876\n",
      "epoch: 3 step: 980, loss is 0.7373459339141846\n",
      "epoch: 3 step: 981, loss is 2.0546250343322754\n",
      "epoch: 3 step: 982, loss is 1.766045331954956\n",
      "epoch: 3 step: 983, loss is 1.939659595489502\n",
      "epoch: 3 step: 984, loss is 0.8315194249153137\n",
      "epoch: 3 step: 985, loss is 2.008183717727661\n",
      "epoch: 3 step: 986, loss is 0.6662408709526062\n",
      "epoch: 3 step: 987, loss is 1.8159843683242798\n",
      "epoch: 3 step: 988, loss is 2.4458117485046387\n",
      "epoch: 3 step: 989, loss is 0.6638360023498535\n",
      "epoch: 3 step: 990, loss is 0.5473366975784302\n",
      "epoch: 3 step: 991, loss is 0.738507866859436\n",
      "epoch: 3 step: 992, loss is 0.4414614140987396\n",
      "epoch: 3 step: 993, loss is 0.37865233421325684\n",
      "epoch: 3 step: 994, loss is 0.43810877203941345\n",
      "epoch: 3 step: 995, loss is 0.5035238265991211\n",
      "epoch: 3 step: 996, loss is 0.40986257791519165\n",
      "epoch: 3 step: 997, loss is 3.8111603260040283\n",
      "epoch: 3 step: 998, loss is 2.233579158782959\n",
      "epoch: 3 step: 999, loss is 0.7830749154090881\n",
      "epoch: 3 step: 1000, loss is 0.6198412179946899\n",
      "epoch: 3 step: 1001, loss is 0.8973586559295654\n",
      "epoch: 3 step: 1002, loss is 2.411065101623535\n",
      "epoch: 3 step: 1003, loss is 0.6907245516777039\n",
      "epoch: 3 step: 1004, loss is 1.9009673595428467\n",
      "epoch: 3 step: 1005, loss is 2.428028106689453\n",
      "epoch: 3 step: 1006, loss is 0.2115669995546341\n",
      "epoch: 3 step: 1007, loss is 0.5842663049697876\n",
      "epoch: 3 step: 1008, loss is 1.7869460582733154\n",
      "epoch: 3 step: 1009, loss is 1.361678957939148\n",
      "epoch: 3 step: 1010, loss is 0.6506702303886414\n",
      "epoch: 3 step: 1011, loss is 0.5364475250244141\n",
      "epoch: 3 step: 1012, loss is 0.2757596969604492\n",
      "epoch: 3 step: 1013, loss is 0.3009641468524933\n",
      "epoch: 3 step: 1014, loss is 0.15262916684150696\n",
      "epoch: 3 step: 1015, loss is 1.8835985660552979\n",
      "epoch: 3 step: 1016, loss is 2.249969005584717\n",
      "epoch: 3 step: 1017, loss is 0.7609695196151733\n",
      "epoch: 3 step: 1018, loss is 0.2339562028646469\n",
      "epoch: 3 step: 1019, loss is 0.20288130640983582\n",
      "epoch: 3 step: 1020, loss is 0.39528536796569824\n",
      "epoch: 3 step: 1021, loss is 0.6356635093688965\n",
      "epoch: 3 step: 1022, loss is 0.45820245146751404\n",
      "epoch: 3 step: 1023, loss is 0.5992162823677063\n",
      "epoch: 3 step: 1024, loss is 0.32080602645874023\n",
      "epoch: 3 step: 1025, loss is 0.38777077198028564\n",
      "epoch: 3 step: 1026, loss is 0.15319061279296875\n",
      "epoch: 3 step: 1027, loss is 2.1627345085144043\n",
      "epoch: 3 step: 1028, loss is 0.3586103916168213\n",
      "epoch: 3 step: 1029, loss is 2.615586042404175\n",
      "epoch: 3 step: 1030, loss is 0.40773195028305054\n",
      "epoch: 3 step: 1031, loss is 0.33339598774909973\n",
      "epoch: 3 step: 1032, loss is 0.2178414911031723\n",
      "epoch: 3 step: 1033, loss is 2.326549530029297\n",
      "epoch: 3 step: 1034, loss is 0.19219045341014862\n",
      "epoch: 3 step: 1035, loss is 1.7132010459899902\n",
      "epoch: 3 step: 1036, loss is 0.4870091676712036\n",
      "epoch: 3 step: 1037, loss is 1.7722657918930054\n",
      "epoch: 3 step: 1038, loss is 2.709041118621826\n",
      "epoch: 3 step: 1039, loss is 1.7802672386169434\n",
      "epoch: 3 step: 1040, loss is 0.3985340893268585\n",
      "epoch: 3 step: 1041, loss is 0.44478076696395874\n",
      "epoch: 3 step: 1042, loss is 0.19114704430103302\n",
      "epoch: 3 step: 1043, loss is 2.362548351287842\n",
      "epoch: 3 step: 1044, loss is 0.5500519275665283\n",
      "epoch: 3 step: 1045, loss is 2.1722607612609863\n",
      "epoch: 3 step: 1046, loss is 3.9761781692504883\n",
      "epoch: 3 step: 1047, loss is 0.4409516155719757\n",
      "epoch: 3 step: 1048, loss is 0.13227717578411102\n",
      "epoch: 3 step: 1049, loss is 2.096280097961426\n",
      "epoch: 3 step: 1050, loss is 0.29798194766044617\n",
      "epoch: 3 step: 1051, loss is 2.2883167266845703\n",
      "epoch: 3 step: 1052, loss is 0.5835190415382385\n",
      "epoch: 3 step: 1053, loss is 0.2775515019893646\n",
      "epoch: 3 step: 1054, loss is 1.9600732326507568\n",
      "epoch: 3 step: 1055, loss is 0.20222602784633636\n",
      "epoch: 3 step: 1056, loss is 0.0755331963300705\n",
      "epoch: 3 step: 1057, loss is 0.4879738390445709\n",
      "epoch: 3 step: 1058, loss is 2.1102135181427\n",
      "epoch: 3 step: 1059, loss is 0.5626160502433777\n",
      "epoch: 3 step: 1060, loss is 3.26474928855896\n",
      "epoch: 3 step: 1061, loss is 0.4164386987686157\n",
      "epoch: 3 step: 1062, loss is 0.31656211614608765\n",
      "epoch: 3 step: 1063, loss is 0.7587185502052307\n",
      "epoch: 3 step: 1064, loss is 2.477823257446289\n",
      "epoch: 3 step: 1065, loss is 0.1806904822587967\n",
      "epoch: 3 step: 1066, loss is 0.30477410554885864\n",
      "epoch: 3 step: 1067, loss is 0.3027537167072296\n",
      "epoch: 3 step: 1068, loss is 0.07922988384962082\n",
      "epoch: 3 step: 1069, loss is 0.10356079041957855\n",
      "epoch: 3 step: 1070, loss is 2.6337172985076904\n",
      "epoch: 3 step: 1071, loss is 2.9005939960479736\n",
      "epoch: 3 step: 1072, loss is 0.5344191193580627\n",
      "epoch: 3 step: 1073, loss is 1.8541536331176758\n",
      "epoch: 3 step: 1074, loss is 0.5398837924003601\n",
      "epoch: 3 step: 1075, loss is 0.45514804124832153\n",
      "epoch: 3 step: 1076, loss is 0.24528655409812927\n",
      "epoch: 3 step: 1077, loss is 0.4182405173778534\n",
      "epoch: 3 step: 1078, loss is 0.2926512360572815\n",
      "epoch: 3 step: 1079, loss is 0.08645941317081451\n",
      "epoch: 3 step: 1080, loss is 0.39128023386001587\n",
      "epoch: 3 step: 1081, loss is 0.10304399579763412\n",
      "epoch: 3 step: 1082, loss is 1.9912059307098389\n",
      "epoch: 3 step: 1083, loss is 0.07006705552339554\n",
      "epoch: 3 step: 1084, loss is 0.0264605563133955\n",
      "epoch: 3 step: 1085, loss is 1.8589122295379639\n",
      "epoch: 3 step: 1086, loss is 4.542840003967285\n",
      "epoch: 3 step: 1087, loss is 2.5882585048675537\n",
      "epoch: 3 step: 1088, loss is 0.6971586346626282\n",
      "epoch: 3 step: 1089, loss is 0.8667113780975342\n",
      "epoch: 3 step: 1090, loss is 0.26132041215896606\n",
      "epoch: 3 step: 1091, loss is 1.8372083902359009\n",
      "epoch: 3 step: 1092, loss is 0.197351336479187\n",
      "epoch: 3 step: 1093, loss is 0.38366642594337463\n",
      "epoch: 3 step: 1094, loss is 1.7026811838150024\n",
      "epoch: 3 step: 1095, loss is 2.575949192047119\n",
      "epoch: 3 step: 1096, loss is 0.4025334417819977\n",
      "epoch: 3 step: 1097, loss is 0.2948792278766632\n",
      "epoch: 3 step: 1098, loss is 1.9202631711959839\n",
      "epoch: 3 step: 1099, loss is 0.15821462869644165\n",
      "epoch: 3 step: 1100, loss is 1.9507840871810913\n",
      "epoch: 3 step: 1101, loss is 2.2497076988220215\n",
      "epoch: 3 step: 1102, loss is 0.37112531065940857\n",
      "epoch: 3 step: 1103, loss is 1.9895555973052979\n",
      "epoch: 3 step: 1104, loss is 1.0717413425445557\n",
      "epoch: 3 step: 1105, loss is 0.1507345736026764\n",
      "epoch: 3 step: 1106, loss is 1.789226770401001\n",
      "epoch: 3 step: 1107, loss is 0.26909226179122925\n",
      "epoch: 3 step: 1108, loss is 3.077462673187256\n",
      "epoch: 3 step: 1109, loss is 1.904105305671692\n",
      "epoch: 3 step: 1110, loss is 0.3081643283367157\n",
      "epoch: 3 step: 1111, loss is 0.17227761447429657\n",
      "epoch: 3 step: 1112, loss is 2.4162073135375977\n",
      "epoch: 3 step: 1113, loss is 0.5137909650802612\n",
      "epoch: 3 step: 1114, loss is 0.5938065648078918\n",
      "epoch: 3 step: 1115, loss is 0.3016524314880371\n",
      "epoch: 3 step: 1116, loss is 5.1682844161987305\n",
      "epoch: 3 step: 1117, loss is 1.673771619796753\n",
      "epoch: 3 step: 1118, loss is 2.8640716075897217\n",
      "epoch: 3 step: 1119, loss is 1.0072985887527466\n",
      "epoch: 3 step: 1120, loss is 1.1517250537872314\n",
      "epoch: 3 step: 1121, loss is 0.8234581351280212\n",
      "epoch: 3 step: 1122, loss is 0.5016470551490784\n",
      "epoch: 3 step: 1123, loss is 0.4986264109611511\n",
      "epoch: 3 step: 1124, loss is 1.9220097064971924\n",
      "epoch: 3 step: 1125, loss is 2.192692518234253\n",
      "epoch: 3 step: 1126, loss is 0.6643994450569153\n",
      "epoch: 3 step: 1127, loss is 0.5939408540725708\n",
      "epoch: 3 step: 1128, loss is 2.662700891494751\n",
      "epoch: 3 step: 1129, loss is 0.84520024061203\n",
      "epoch: 3 step: 1130, loss is 0.9215619564056396\n",
      "epoch: 3 step: 1131, loss is 2.715738296508789\n",
      "epoch: 3 step: 1132, loss is 1.9306941032409668\n",
      "epoch: 3 step: 1133, loss is 0.3884851932525635\n",
      "epoch: 3 step: 1134, loss is 0.6710138320922852\n",
      "epoch: 3 step: 1135, loss is 0.4619084596633911\n",
      "epoch: 3 step: 1136, loss is 0.16292297840118408\n",
      "epoch: 3 step: 1137, loss is 2.106271505355835\n",
      "epoch: 3 step: 1138, loss is 0.6234686970710754\n",
      "epoch: 3 step: 1139, loss is 0.31326261162757874\n",
      "epoch: 3 step: 1140, loss is 0.4268399775028229\n",
      "epoch: 3 step: 1141, loss is 0.7437481880187988\n",
      "epoch: 3 step: 1142, loss is 1.9135937690734863\n",
      "epoch: 3 step: 1143, loss is 0.46406814455986023\n",
      "epoch: 3 step: 1144, loss is 2.3692078590393066\n",
      "epoch: 3 step: 1145, loss is 2.9765803813934326\n",
      "epoch: 3 step: 1146, loss is 1.8842049837112427\n",
      "epoch: 3 step: 1147, loss is 0.4731268882751465\n",
      "epoch: 3 step: 1148, loss is 0.5537233948707581\n",
      "epoch: 3 step: 1149, loss is 1.993987798690796\n",
      "epoch: 3 step: 1150, loss is 0.7873957753181458\n",
      "epoch: 3 step: 1151, loss is 0.8201550245285034\n",
      "epoch: 3 step: 1152, loss is 2.2505240440368652\n",
      "epoch: 3 step: 1153, loss is 2.2454447746276855\n",
      "epoch: 3 step: 1154, loss is 1.9554435014724731\n",
      "epoch: 3 step: 1155, loss is 0.5272181630134583\n",
      "epoch: 3 step: 1156, loss is 0.3778294622898102\n",
      "epoch: 3 step: 1157, loss is 0.4113369286060333\n",
      "epoch: 3 step: 1158, loss is 1.664260745048523\n",
      "epoch: 3 step: 1159, loss is 3.1167125701904297\n",
      "epoch: 3 step: 1160, loss is 0.6075868010520935\n",
      "epoch: 3 step: 1161, loss is 0.14905929565429688\n",
      "epoch: 3 step: 1162, loss is 0.33606019616127014\n",
      "epoch: 3 step: 1163, loss is 0.5987551212310791\n",
      "epoch: 3 step: 1164, loss is 1.8067803382873535\n",
      "epoch: 3 step: 1165, loss is 0.2572459578514099\n",
      "epoch: 3 step: 1166, loss is 0.8268546462059021\n",
      "epoch: 3 step: 1167, loss is 0.394208163022995\n",
      "epoch: 3 step: 1168, loss is 0.4386729598045349\n",
      "epoch: 3 step: 1169, loss is 0.18030323088169098\n",
      "epoch: 3 step: 1170, loss is 1.275022029876709\n",
      "epoch: 3 step: 1171, loss is 0.15552717447280884\n",
      "epoch: 3 step: 1172, loss is 0.2738983631134033\n",
      "epoch: 3 step: 1173, loss is 0.037744373083114624\n",
      "epoch: 3 step: 1174, loss is 0.21668285131454468\n",
      "epoch: 3 step: 1175, loss is 0.44532662630081177\n",
      "epoch: 3 step: 1176, loss is 0.056324414908885956\n",
      "epoch: 3 step: 1177, loss is 2.423128366470337\n",
      "epoch: 3 step: 1178, loss is 0.26815348863601685\n",
      "epoch: 3 step: 1179, loss is 2.1021974086761475\n",
      "epoch: 3 step: 1180, loss is 3.314107656478882\n",
      "epoch: 3 step: 1181, loss is 0.7967748045921326\n",
      "epoch: 3 step: 1182, loss is 2.394300937652588\n",
      "epoch: 3 step: 1183, loss is 0.3595602214336395\n",
      "epoch: 3 step: 1184, loss is 0.24727998673915863\n",
      "epoch: 3 step: 1185, loss is 2.715285062789917\n",
      "epoch: 3 step: 1186, loss is 3.795693874359131\n",
      "epoch: 3 step: 1187, loss is 0.44675421714782715\n",
      "epoch: 3 step: 1188, loss is 2.129584312438965\n",
      "epoch: 3 step: 1189, loss is 1.8375598192214966\n",
      "epoch: 3 step: 1190, loss is 0.6429668664932251\n",
      "epoch: 3 step: 1191, loss is 1.2586219310760498\n",
      "epoch: 3 step: 1192, loss is 0.3962191343307495\n",
      "epoch: 3 step: 1193, loss is 1.6468652486801147\n",
      "epoch: 3 step: 1194, loss is 0.3991561532020569\n",
      "epoch: 3 step: 1195, loss is 0.19629213213920593\n",
      "epoch: 3 step: 1196, loss is 2.7180871963500977\n",
      "epoch: 3 step: 1197, loss is 0.582902193069458\n",
      "epoch: 3 step: 1198, loss is 0.5259267091751099\n",
      "epoch: 3 step: 1199, loss is 0.37887832522392273\n",
      "epoch: 3 step: 1200, loss is 1.0067037343978882\n",
      "epoch: 3 step: 1201, loss is 0.2541821599006653\n",
      "epoch: 3 step: 1202, loss is 2.3510823249816895\n",
      "epoch: 3 step: 1203, loss is 2.326763391494751\n",
      "epoch: 3 step: 1204, loss is 0.4571976065635681\n",
      "epoch: 3 step: 1205, loss is 0.386684775352478\n",
      "epoch: 3 step: 1206, loss is 0.7627883553504944\n",
      "epoch: 3 step: 1207, loss is 0.5464229583740234\n",
      "epoch: 3 step: 1208, loss is 3.060122013092041\n",
      "epoch: 3 step: 1209, loss is 2.229304313659668\n",
      "epoch: 3 step: 1210, loss is 2.0254037380218506\n",
      "epoch: 3 step: 1211, loss is 1.9739291667938232\n",
      "epoch: 3 step: 1212, loss is 0.8467300534248352\n",
      "epoch: 3 step: 1213, loss is 0.47964227199554443\n",
      "epoch: 3 step: 1214, loss is 0.4097067713737488\n",
      "epoch: 3 step: 1215, loss is 0.31943681836128235\n",
      "epoch: 3 step: 1216, loss is 1.9537208080291748\n",
      "epoch: 3 step: 1217, loss is 2.2376585006713867\n",
      "epoch: 3 step: 1218, loss is 0.4085839092731476\n",
      "epoch: 3 step: 1219, loss is 0.5331754684448242\n",
      "epoch: 3 step: 1220, loss is 0.35075798630714417\n",
      "epoch: 3 step: 1221, loss is 0.4388837516307831\n",
      "epoch: 3 step: 1222, loss is 0.4913521409034729\n",
      "epoch: 3 step: 1223, loss is 0.5281394720077515\n",
      "epoch: 3 step: 1224, loss is 3.4061248302459717\n",
      "epoch: 3 step: 1225, loss is 3.366426706314087\n",
      "epoch: 3 step: 1226, loss is 1.034157633781433\n",
      "epoch: 3 step: 1227, loss is 0.3714960217475891\n",
      "epoch: 3 step: 1228, loss is 0.7501630783081055\n",
      "epoch: 3 step: 1229, loss is 0.6048214435577393\n",
      "epoch: 3 step: 1230, loss is 0.3782518208026886\n",
      "epoch: 3 step: 1231, loss is 0.14748631417751312\n",
      "epoch: 3 step: 1232, loss is 0.43677783012390137\n",
      "epoch: 3 step: 1233, loss is 2.175405502319336\n",
      "epoch: 3 step: 1234, loss is 2.519763946533203\n",
      "epoch: 3 step: 1235, loss is 0.8540750741958618\n",
      "epoch: 3 step: 1236, loss is 2.2656664848327637\n",
      "epoch: 3 step: 1237, loss is 2.4209933280944824\n",
      "epoch: 3 step: 1238, loss is 0.6222330927848816\n",
      "epoch: 3 step: 1239, loss is 2.2978498935699463\n",
      "epoch: 3 step: 1240, loss is 0.8229875564575195\n",
      "epoch: 3 step: 1241, loss is 2.5229084491729736\n",
      "epoch: 3 step: 1242, loss is 1.6921052932739258\n",
      "epoch: 3 step: 1243, loss is 1.154873251914978\n",
      "epoch: 3 step: 1244, loss is 0.7334423661231995\n",
      "epoch: 3 step: 1245, loss is 0.5508027076721191\n",
      "epoch: 3 step: 1246, loss is 0.697402834892273\n",
      "epoch: 3 step: 1247, loss is 2.0667824745178223\n",
      "epoch: 3 step: 1248, loss is 0.641912043094635\n",
      "epoch: 3 step: 1249, loss is 0.8395313620567322\n",
      "epoch: 3 step: 1250, loss is 1.9077703952789307\n",
      "epoch: 3 step: 1251, loss is 1.7355384826660156\n",
      "epoch: 3 step: 1252, loss is 2.0227861404418945\n",
      "epoch: 3 step: 1253, loss is 0.4407367408275604\n",
      "epoch: 3 step: 1254, loss is 1.9227678775787354\n",
      "epoch: 3 step: 1255, loss is 2.216080904006958\n",
      "epoch: 3 step: 1256, loss is 0.6990298628807068\n",
      "epoch: 3 step: 1257, loss is 0.7483296990394592\n",
      "epoch: 3 step: 1258, loss is 0.5320658683776855\n",
      "epoch: 3 step: 1259, loss is 1.7622543573379517\n",
      "epoch: 3 step: 1260, loss is 0.48720479011535645\n",
      "epoch: 3 step: 1261, loss is 2.3705031871795654\n",
      "epoch: 3 step: 1262, loss is 2.3107993602752686\n",
      "epoch: 3 step: 1263, loss is 0.5645399689674377\n",
      "epoch: 3 step: 1264, loss is 0.5587629675865173\n",
      "epoch: 3 step: 1265, loss is 1.649143099784851\n",
      "epoch: 3 step: 1266, loss is 0.23748721182346344\n",
      "epoch: 3 step: 1267, loss is 2.287554979324341\n",
      "epoch: 3 step: 1268, loss is 1.0796071290969849\n",
      "epoch: 3 step: 1269, loss is 0.8914517760276794\n",
      "epoch: 3 step: 1270, loss is 0.5291053652763367\n",
      "epoch: 3 step: 1271, loss is 0.4787064492702484\n",
      "epoch: 3 step: 1272, loss is 2.2108702659606934\n",
      "epoch: 3 step: 1273, loss is 1.703775405883789\n",
      "epoch: 3 step: 1274, loss is 0.6151695847511292\n",
      "epoch: 3 step: 1275, loss is 0.47825661301612854\n",
      "epoch: 3 step: 1276, loss is 0.4010176360607147\n",
      "epoch: 3 step: 1277, loss is 1.7822177410125732\n",
      "epoch: 3 step: 1278, loss is 0.37632086873054504\n",
      "epoch: 3 step: 1279, loss is 0.40407606959342957\n",
      "epoch: 3 step: 1280, loss is 0.12308705598115921\n",
      "epoch: 3 step: 1281, loss is 3.495697021484375\n",
      "epoch: 3 step: 1282, loss is 1.7497286796569824\n",
      "epoch: 3 step: 1283, loss is 0.44935527443885803\n",
      "epoch: 3 step: 1284, loss is 0.8521084189414978\n",
      "epoch: 3 step: 1285, loss is 1.9146630764007568\n",
      "epoch: 3 step: 1286, loss is 0.611352264881134\n",
      "epoch: 3 step: 1287, loss is 2.036757469177246\n",
      "epoch: 3 step: 1288, loss is 2.2204809188842773\n",
      "epoch: 3 step: 1289, loss is 1.8138573169708252\n",
      "epoch: 3 step: 1290, loss is 0.6144681572914124\n",
      "epoch: 3 step: 1291, loss is 0.1660163551568985\n",
      "epoch: 3 step: 1292, loss is 0.15130580961704254\n",
      "epoch: 3 step: 1293, loss is 0.15908759832382202\n",
      "epoch: 3 step: 1294, loss is 0.5523266196250916\n",
      "epoch: 3 step: 1295, loss is 0.5283597707748413\n",
      "epoch: 3 step: 1296, loss is 3.642301082611084\n",
      "epoch: 3 step: 1297, loss is 0.5792567133903503\n",
      "epoch: 3 step: 1298, loss is 0.23831404745578766\n",
      "epoch: 3 step: 1299, loss is 0.44213443994522095\n",
      "epoch: 3 step: 1300, loss is 2.0549890995025635\n",
      "epoch: 3 step: 1301, loss is 0.3547324538230896\n",
      "epoch: 3 step: 1302, loss is 2.0323233604431152\n",
      "epoch: 3 step: 1303, loss is 2.054216146469116\n",
      "epoch: 3 step: 1304, loss is 0.36077529191970825\n",
      "epoch: 3 step: 1305, loss is 0.35655471682548523\n",
      "epoch: 3 step: 1306, loss is 0.28507140278816223\n",
      "epoch: 3 step: 1307, loss is 0.18599869310855865\n",
      "epoch: 3 step: 1308, loss is 0.2956498861312866\n",
      "epoch: 3 step: 1309, loss is 1.902369499206543\n",
      "epoch: 3 step: 1310, loss is 0.25815343856811523\n",
      "epoch: 3 step: 1311, loss is 0.271403044462204\n",
      "epoch: 3 step: 1312, loss is 2.013052463531494\n",
      "epoch: 3 step: 1313, loss is 0.25086796283721924\n",
      "epoch: 3 step: 1314, loss is 2.1578586101531982\n",
      "epoch: 3 step: 1315, loss is 0.22455133497714996\n",
      "epoch: 3 step: 1316, loss is 0.25724974274635315\n",
      "epoch: 3 step: 1317, loss is 1.905173420906067\n",
      "epoch: 3 step: 1318, loss is 1.0551910400390625\n",
      "epoch: 3 step: 1319, loss is 0.20365314185619354\n",
      "epoch: 3 step: 1320, loss is 0.24547263979911804\n",
      "epoch: 3 step: 1321, loss is 4.601935863494873\n",
      "epoch: 3 step: 1322, loss is 0.783492922782898\n",
      "epoch: 3 step: 1323, loss is 2.7128632068634033\n",
      "epoch: 3 step: 1324, loss is 0.25999006628990173\n",
      "epoch: 3 step: 1325, loss is 0.3282743990421295\n",
      "epoch: 3 step: 1326, loss is 2.445188045501709\n",
      "epoch: 3 step: 1327, loss is 2.183783531188965\n",
      "epoch: 3 step: 1328, loss is 1.1649729013442993\n",
      "epoch: 3 step: 1329, loss is 2.216805934906006\n",
      "epoch: 3 step: 1330, loss is 0.6550121307373047\n",
      "epoch: 3 step: 1331, loss is 1.9556844234466553\n",
      "epoch: 3 step: 1332, loss is 0.6666383147239685\n",
      "epoch: 3 step: 1333, loss is 1.7297369241714478\n",
      "epoch: 3 step: 1334, loss is 0.2916722297668457\n",
      "epoch: 3 step: 1335, loss is 0.7899406552314758\n",
      "epoch: 3 step: 1336, loss is 2.3046998977661133\n",
      "epoch: 3 step: 1337, loss is 1.8751178979873657\n",
      "epoch: 3 step: 1338, loss is 1.8092701435089111\n",
      "epoch: 3 step: 1339, loss is 2.2587480545043945\n",
      "epoch: 3 step: 1340, loss is 1.634759545326233\n",
      "epoch: 3 step: 1341, loss is 0.9372996687889099\n",
      "epoch: 3 step: 1342, loss is 0.32011762261390686\n",
      "epoch: 3 step: 1343, loss is 2.283912181854248\n",
      "epoch: 3 step: 1344, loss is 0.7373360395431519\n",
      "epoch: 3 step: 1345, loss is 1.6283018589019775\n",
      "epoch: 3 step: 1346, loss is 0.6277392506599426\n",
      "epoch: 3 step: 1347, loss is 0.5259278416633606\n",
      "epoch: 3 step: 1348, loss is 0.36814063787460327\n",
      "epoch: 3 step: 1349, loss is 0.4044274389743805\n",
      "epoch: 3 step: 1350, loss is 0.12825489044189453\n",
      "epoch: 3 step: 1351, loss is 1.7653306722640991\n",
      "epoch: 3 step: 1352, loss is 0.3128270208835602\n",
      "epoch: 3 step: 1353, loss is 2.5867557525634766\n",
      "epoch: 3 step: 1354, loss is 0.8333337306976318\n",
      "epoch: 3 step: 1355, loss is 0.5480725765228271\n",
      "epoch: 3 step: 1356, loss is 0.5883240699768066\n",
      "epoch: 3 step: 1357, loss is 2.066582202911377\n",
      "epoch: 3 step: 1358, loss is 1.3818795680999756\n",
      "epoch: 3 step: 1359, loss is 2.327113389968872\n",
      "epoch: 3 step: 1360, loss is 0.5768312215805054\n",
      "epoch: 3 step: 1361, loss is 0.2520589530467987\n",
      "epoch: 3 step: 1362, loss is 0.2876321077346802\n",
      "epoch: 3 step: 1363, loss is 2.020444393157959\n",
      "epoch: 3 step: 1364, loss is 1.6512413024902344\n",
      "epoch: 3 step: 1365, loss is 0.3736830949783325\n",
      "epoch: 3 step: 1366, loss is 0.14962470531463623\n",
      "epoch: 3 step: 1367, loss is 0.44714251160621643\n",
      "epoch: 3 step: 1368, loss is 0.2943050265312195\n",
      "epoch: 3 step: 1369, loss is 0.46488887071609497\n",
      "epoch: 3 step: 1370, loss is 0.2862265706062317\n",
      "epoch: 3 step: 1371, loss is 0.11550561338663101\n",
      "epoch: 3 step: 1372, loss is 0.688555121421814\n",
      "epoch: 3 step: 1373, loss is 0.1700441688299179\n",
      "epoch: 3 step: 1374, loss is 0.23440875113010406\n",
      "epoch: 3 step: 1375, loss is 6.929434776306152\n",
      "epoch: 3 step: 1376, loss is 0.7631218433380127\n",
      "epoch: 3 step: 1377, loss is 2.7525413036346436\n",
      "epoch: 3 step: 1378, loss is 2.1690144538879395\n",
      "epoch: 3 step: 1379, loss is 1.9341034889221191\n",
      "epoch: 3 step: 1380, loss is 1.7157469987869263\n",
      "epoch: 3 step: 1381, loss is 0.6534335017204285\n",
      "epoch: 3 step: 1382, loss is 0.4698304831981659\n",
      "epoch: 3 step: 1383, loss is 0.8053789734840393\n",
      "epoch: 3 step: 1384, loss is 0.1825227439403534\n",
      "epoch: 3 step: 1385, loss is 0.5258656144142151\n",
      "epoch: 3 step: 1386, loss is 2.480161428451538\n",
      "epoch: 3 step: 1387, loss is 3.3899428844451904\n",
      "epoch: 3 step: 1388, loss is 1.7422451972961426\n",
      "epoch: 3 step: 1389, loss is 1.8922245502471924\n",
      "epoch: 3 step: 1390, loss is 1.959606409072876\n",
      "epoch: 3 step: 1391, loss is 0.7096573710441589\n",
      "epoch: 3 step: 1392, loss is 1.9482307434082031\n",
      "epoch: 3 step: 1393, loss is 0.6728664636611938\n",
      "epoch: 3 step: 1394, loss is 1.6585865020751953\n",
      "epoch: 3 step: 1395, loss is 1.7582659721374512\n",
      "epoch: 3 step: 1396, loss is 0.7512760162353516\n",
      "epoch: 3 step: 1397, loss is 0.5300668478012085\n",
      "epoch: 3 step: 1398, loss is 0.6747144460678101\n",
      "epoch: 3 step: 1399, loss is 0.34168559312820435\n",
      "epoch: 3 step: 1400, loss is 0.6091505885124207\n",
      "epoch: 3 step: 1401, loss is 0.5467373728752136\n",
      "epoch: 3 step: 1402, loss is 0.19584032893180847\n",
      "epoch: 3 step: 1403, loss is 0.26862406730651855\n",
      "epoch: 3 step: 1404, loss is 2.791023015975952\n",
      "epoch: 3 step: 1405, loss is 0.6531220078468323\n",
      "epoch: 3 step: 1406, loss is 2.5204102993011475\n",
      "epoch: 3 step: 1407, loss is 0.37944287061691284\n",
      "epoch: 3 step: 1408, loss is 2.6157827377319336\n",
      "epoch: 3 step: 1409, loss is 1.8928442001342773\n",
      "epoch: 3 step: 1410, loss is 2.0469741821289062\n",
      "epoch: 3 step: 1411, loss is 0.3243178129196167\n",
      "epoch: 3 step: 1412, loss is 0.33972084522247314\n",
      "epoch: 3 step: 1413, loss is 0.4725562334060669\n",
      "epoch: 3 step: 1414, loss is 0.38015151023864746\n",
      "epoch: 3 step: 1415, loss is 2.3571343421936035\n",
      "epoch: 3 step: 1416, loss is 0.24765191972255707\n",
      "epoch: 3 step: 1417, loss is 1.6961785554885864\n",
      "epoch: 3 step: 1418, loss is 0.8639343976974487\n",
      "epoch: 3 step: 1419, loss is 2.056874990463257\n",
      "epoch: 3 step: 1420, loss is 0.46555888652801514\n",
      "epoch: 3 step: 1421, loss is 0.3580703139305115\n",
      "epoch: 3 step: 1422, loss is 0.9302149415016174\n",
      "epoch: 3 step: 1423, loss is 2.1234419345855713\n",
      "epoch: 3 step: 1424, loss is 0.9653173685073853\n",
      "epoch: 3 step: 1425, loss is 5.324446678161621\n",
      "epoch: 3 step: 1426, loss is 0.28356125950813293\n",
      "epoch: 3 step: 1427, loss is 2.6497933864593506\n",
      "epoch: 3 step: 1428, loss is 1.9209516048431396\n",
      "epoch: 3 step: 1429, loss is 4.473146438598633\n",
      "epoch: 3 step: 1430, loss is 1.8172991275787354\n",
      "epoch: 3 step: 1431, loss is 1.8061326742172241\n",
      "epoch: 3 step: 1432, loss is 0.8295917510986328\n",
      "epoch: 3 step: 1433, loss is 0.8683772683143616\n",
      "epoch: 3 step: 1434, loss is 0.9472721219062805\n",
      "epoch: 3 step: 1435, loss is 0.3931374251842499\n",
      "epoch: 3 step: 1436, loss is 1.7666504383087158\n",
      "epoch: 3 step: 1437, loss is 0.5164231657981873\n",
      "epoch: 3 step: 1438, loss is 0.6200372576713562\n",
      "epoch: 3 step: 1439, loss is 0.8973272442817688\n",
      "epoch: 3 step: 1440, loss is 2.3596463203430176\n",
      "epoch: 3 step: 1441, loss is 1.5499736070632935\n",
      "epoch: 3 step: 1442, loss is 0.9107469320297241\n",
      "epoch: 3 step: 1443, loss is 2.330294609069824\n",
      "epoch: 3 step: 1444, loss is 2.0792367458343506\n",
      "epoch: 3 step: 1445, loss is 1.9599878787994385\n",
      "epoch: 3 step: 1446, loss is 1.0095257759094238\n",
      "epoch: 3 step: 1447, loss is 1.7643603086471558\n",
      "epoch: 3 step: 1448, loss is 0.5245225429534912\n",
      "epoch: 3 step: 1449, loss is 0.45537570118904114\n",
      "epoch: 3 step: 1450, loss is 0.9425035715103149\n",
      "epoch: 3 step: 1451, loss is 0.23258210718631744\n",
      "epoch: 3 step: 1452, loss is 0.4298118054866791\n",
      "epoch: 3 step: 1453, loss is 2.000246286392212\n",
      "epoch: 3 step: 1454, loss is 0.4290542006492615\n",
      "epoch: 3 step: 1455, loss is 1.891161561012268\n",
      "epoch: 3 step: 1456, loss is 0.3731563687324524\n",
      "epoch: 3 step: 1457, loss is 0.7864887118339539\n",
      "epoch: 3 step: 1458, loss is 1.7745699882507324\n",
      "epoch: 3 step: 1459, loss is 1.1197025775909424\n",
      "epoch: 3 step: 1460, loss is 0.3390081524848938\n",
      "epoch: 3 step: 1461, loss is 0.7181040644645691\n",
      "epoch: 3 step: 1462, loss is 1.779437780380249\n",
      "epoch: 3 step: 1463, loss is 0.587273359298706\n",
      "epoch: 3 step: 1464, loss is 0.5067212581634521\n",
      "epoch: 3 step: 1465, loss is 2.0957751274108887\n",
      "epoch: 3 step: 1466, loss is 0.48720991611480713\n",
      "epoch: 3 step: 1467, loss is 1.9223483800888062\n",
      "epoch: 3 step: 1468, loss is 0.14520788192749023\n",
      "epoch: 3 step: 1469, loss is 2.1762542724609375\n",
      "epoch: 3 step: 1470, loss is 0.6078881025314331\n",
      "epoch: 3 step: 1471, loss is 2.0225722789764404\n",
      "epoch: 3 step: 1472, loss is 2.3696022033691406\n",
      "epoch: 3 step: 1473, loss is 0.6281874179840088\n",
      "epoch: 3 step: 1474, loss is 0.2808621823787689\n",
      "epoch: 3 step: 1475, loss is 0.5058518648147583\n",
      "epoch: 3 step: 1476, loss is 1.1500829458236694\n",
      "epoch: 3 step: 1477, loss is 2.469492197036743\n",
      "epoch: 3 step: 1478, loss is 2.121760129928589\n",
      "epoch: 3 step: 1479, loss is 0.35470837354660034\n",
      "epoch: 3 step: 1480, loss is 0.26109015941619873\n",
      "epoch: 3 step: 1481, loss is 2.2242345809936523\n",
      "epoch: 3 step: 1482, loss is 1.9865918159484863\n",
      "epoch: 3 step: 1483, loss is 0.6504793763160706\n",
      "epoch: 3 step: 1484, loss is 1.6574091911315918\n",
      "epoch: 3 step: 1485, loss is 3.071823835372925\n",
      "epoch: 3 step: 1486, loss is 2.501821994781494\n",
      "epoch: 3 step: 1487, loss is 0.6984697580337524\n",
      "epoch: 3 step: 1488, loss is 0.30532512068748474\n",
      "epoch: 3 step: 1489, loss is 0.8386627435684204\n",
      "epoch: 3 step: 1490, loss is 1.6623578071594238\n",
      "epoch: 3 step: 1491, loss is 1.8729491233825684\n",
      "epoch: 3 step: 1492, loss is 2.537459135055542\n",
      "epoch: 3 step: 1493, loss is 1.8434507846832275\n",
      "epoch: 3 step: 1494, loss is 1.016998291015625\n",
      "epoch: 3 step: 1495, loss is 2.0789151191711426\n",
      "epoch: 3 step: 1496, loss is 0.5399653315544128\n",
      "epoch: 3 step: 1497, loss is 1.8471283912658691\n",
      "epoch: 3 step: 1498, loss is 0.45810240507125854\n",
      "epoch: 3 step: 1499, loss is 0.30819499492645264\n",
      "epoch: 3 step: 1500, loss is 0.5027756094932556\n",
      "epoch: 3 step: 1501, loss is 0.6000416874885559\n",
      "epoch: 3 step: 1502, loss is 1.193449854850769\n",
      "epoch: 3 step: 1503, loss is 0.6202777028083801\n",
      "epoch: 3 step: 1504, loss is 1.6868774890899658\n",
      "epoch: 3 step: 1505, loss is 2.0352213382720947\n",
      "epoch: 3 step: 1506, loss is 0.35728877782821655\n",
      "epoch: 3 step: 1507, loss is 0.4975452721118927\n",
      "epoch: 3 step: 1508, loss is 0.1422899067401886\n",
      "epoch: 3 step: 1509, loss is 0.15766820311546326\n",
      "epoch: 3 step: 1510, loss is 2.519786834716797\n",
      "epoch: 3 step: 1511, loss is 0.40184733271598816\n",
      "epoch: 3 step: 1512, loss is 2.249142646789551\n",
      "epoch: 3 step: 1513, loss is 0.3828238546848297\n",
      "epoch: 3 step: 1514, loss is 1.6787972450256348\n",
      "epoch: 3 step: 1515, loss is 0.5002532005310059\n",
      "epoch: 3 step: 1516, loss is 0.7147771716117859\n",
      "epoch: 3 step: 1517, loss is 0.1885465681552887\n",
      "epoch: 3 step: 1518, loss is 0.06930199265480042\n",
      "epoch: 3 step: 1519, loss is 2.2196884155273438\n",
      "epoch: 3 step: 1520, loss is 0.1970541924238205\n",
      "epoch: 3 step: 1521, loss is 1.8579585552215576\n",
      "epoch: 3 step: 1522, loss is 2.126055955886841\n",
      "epoch: 3 step: 1523, loss is 2.418490409851074\n",
      "epoch: 3 step: 1524, loss is 2.2708661556243896\n",
      "epoch: 3 step: 1525, loss is 1.0023144483566284\n",
      "epoch: 3 step: 1526, loss is 1.3988935947418213\n",
      "epoch: 3 step: 1527, loss is 0.7519797682762146\n",
      "epoch: 3 step: 1528, loss is 0.8676561713218689\n",
      "epoch: 3 step: 1529, loss is 0.5089126825332642\n",
      "epoch: 3 step: 1530, loss is 0.8294048309326172\n",
      "epoch: 3 step: 1531, loss is 1.7843818664550781\n",
      "epoch: 3 step: 1532, loss is 0.3383176624774933\n",
      "epoch: 3 step: 1533, loss is 0.6581400036811829\n",
      "epoch: 3 step: 1534, loss is 0.3474595248699188\n",
      "epoch: 3 step: 1535, loss is 0.5690915584564209\n",
      "epoch: 3 step: 1536, loss is 0.3424830436706543\n",
      "epoch: 3 step: 1537, loss is 0.4819326400756836\n",
      "epoch: 3 step: 1538, loss is 0.17806263267993927\n",
      "epoch: 3 step: 1539, loss is 0.1560407131910324\n",
      "epoch: 3 step: 1540, loss is 0.20919352769851685\n",
      "epoch: 3 step: 1541, loss is 0.27958256006240845\n",
      "epoch: 3 step: 1542, loss is 4.021545886993408\n",
      "epoch: 3 step: 1543, loss is 0.6784203052520752\n",
      "epoch: 3 step: 1544, loss is 2.232733726501465\n",
      "epoch: 3 step: 1545, loss is 0.4860711991786957\n",
      "epoch: 3 step: 1546, loss is 2.449657917022705\n",
      "epoch: 3 step: 1547, loss is 0.6023849844932556\n",
      "epoch: 3 step: 1548, loss is 0.6627350449562073\n",
      "epoch: 3 step: 1549, loss is 0.4159983992576599\n",
      "epoch: 3 step: 1550, loss is 0.7018648982048035\n",
      "epoch: 3 step: 1551, loss is 1.627784013748169\n",
      "epoch: 3 step: 1552, loss is 1.7445486783981323\n",
      "epoch: 3 step: 1553, loss is 3.1534719467163086\n",
      "epoch: 3 step: 1554, loss is 2.174484968185425\n",
      "epoch: 3 step: 1555, loss is 2.6482460498809814\n",
      "epoch: 3 step: 1556, loss is 1.043675184249878\n",
      "epoch: 3 step: 1557, loss is 0.9528408646583557\n",
      "epoch: 3 step: 1558, loss is 1.8605389595031738\n",
      "epoch: 3 step: 1559, loss is 0.4530751407146454\n",
      "epoch: 3 step: 1560, loss is 0.4070706069469452\n",
      "epoch: 3 step: 1561, loss is 2.221095085144043\n",
      "epoch: 3 step: 1562, loss is 1.7828359603881836\n",
      "epoch: 3 step: 1563, loss is 3.0352065563201904\n",
      "epoch: 3 step: 1564, loss is 1.8815205097198486\n",
      "epoch: 3 step: 1565, loss is 0.949880838394165\n",
      "epoch: 3 step: 1566, loss is 0.613455057144165\n",
      "epoch: 3 step: 1567, loss is 1.6727409362792969\n",
      "epoch: 3 step: 1568, loss is 0.8310900926589966\n",
      "epoch: 3 step: 1569, loss is 0.3236280381679535\n",
      "epoch: 3 step: 1570, loss is 0.6212425231933594\n",
      "epoch: 3 step: 1571, loss is 2.3503549098968506\n",
      "epoch: 3 step: 1572, loss is 0.5049625635147095\n",
      "epoch: 3 step: 1573, loss is 0.4111456274986267\n",
      "epoch: 3 step: 1574, loss is 0.4881238341331482\n",
      "epoch: 3 step: 1575, loss is 2.6308093070983887\n",
      "epoch: 3 step: 1576, loss is 0.34595373272895813\n",
      "epoch: 3 step: 1577, loss is 0.6358664035797119\n",
      "epoch: 3 step: 1578, loss is 1.9655344486236572\n",
      "epoch: 3 step: 1579, loss is 2.0519943237304688\n",
      "epoch: 3 step: 1580, loss is 2.3757927417755127\n",
      "epoch: 3 step: 1581, loss is 1.8928641080856323\n",
      "epoch: 3 step: 1582, loss is 1.6551405191421509\n",
      "epoch: 3 step: 1583, loss is 1.7516340017318726\n",
      "epoch: 3 step: 1584, loss is 0.4787304699420929\n",
      "epoch: 3 step: 1585, loss is 3.475480556488037\n",
      "epoch: 3 step: 1586, loss is 1.943579912185669\n",
      "epoch: 3 step: 1587, loss is 2.390247106552124\n",
      "epoch: 3 step: 1588, loss is 0.9169716835021973\n",
      "epoch: 3 step: 1589, loss is 0.9757481217384338\n",
      "epoch: 3 step: 1590, loss is 0.5146623849868774\n",
      "epoch: 3 step: 1591, loss is 1.3805187940597534\n",
      "epoch: 3 step: 1592, loss is 0.6089156866073608\n",
      "epoch: 3 step: 1593, loss is 0.6001823544502258\n",
      "epoch: 3 step: 1594, loss is 0.6338163614273071\n",
      "epoch: 3 step: 1595, loss is 0.7683815360069275\n",
      "epoch: 3 step: 1596, loss is 1.4747462272644043\n",
      "epoch: 3 step: 1597, loss is 0.7648457884788513\n",
      "epoch: 3 step: 1598, loss is 0.6156302094459534\n",
      "epoch: 3 step: 1599, loss is 0.28766539692878723\n",
      "epoch: 3 step: 1600, loss is 2.027188777923584\n",
      "epoch: 4 step: 1, loss is 1.6256787776947021\n",
      "epoch: 4 step: 2, loss is 1.312723159790039\n",
      "epoch: 4 step: 3, loss is 0.7899352312088013\n",
      "epoch: 4 step: 4, loss is 1.814367651939392\n",
      "epoch: 4 step: 5, loss is 0.47099006175994873\n",
      "epoch: 4 step: 6, loss is 1.6355109214782715\n",
      "epoch: 4 step: 7, loss is 2.1663730144500732\n",
      "epoch: 4 step: 8, loss is 0.8750384449958801\n",
      "epoch: 4 step: 9, loss is 0.40725910663604736\n",
      "epoch: 4 step: 10, loss is 0.10916463285684586\n",
      "epoch: 4 step: 11, loss is 1.8843019008636475\n",
      "epoch: 4 step: 12, loss is 0.8447237014770508\n",
      "epoch: 4 step: 13, loss is 0.39684218168258667\n",
      "epoch: 4 step: 14, loss is 2.736077308654785\n",
      "epoch: 4 step: 15, loss is 0.2388204038143158\n",
      "epoch: 4 step: 16, loss is 2.070352792739868\n",
      "epoch: 4 step: 17, loss is 0.15782195329666138\n",
      "epoch: 4 step: 18, loss is 3.15800142288208\n",
      "epoch: 4 step: 19, loss is 0.32501891255378723\n",
      "epoch: 4 step: 20, loss is 0.34350690245628357\n",
      "epoch: 4 step: 21, loss is 2.2079391479492188\n",
      "epoch: 4 step: 22, loss is 0.1665278673171997\n",
      "epoch: 4 step: 23, loss is 2.5454111099243164\n",
      "epoch: 4 step: 24, loss is 0.2239963412284851\n",
      "epoch: 4 step: 25, loss is 1.0061211585998535\n",
      "epoch: 4 step: 26, loss is 1.0322028398513794\n",
      "epoch: 4 step: 27, loss is 0.1993931382894516\n",
      "epoch: 4 step: 28, loss is 4.5392303466796875\n",
      "epoch: 4 step: 29, loss is 2.1387271881103516\n",
      "epoch: 4 step: 30, loss is 2.496335029602051\n",
      "epoch: 4 step: 31, loss is 1.1283538341522217\n",
      "epoch: 4 step: 32, loss is 2.006814956665039\n",
      "epoch: 4 step: 33, loss is 0.7383072972297668\n",
      "epoch: 4 step: 34, loss is 1.8025634288787842\n",
      "epoch: 4 step: 35, loss is 0.7563810348510742\n",
      "epoch: 4 step: 36, loss is 0.6806176900863647\n",
      "epoch: 4 step: 37, loss is 0.7866098880767822\n",
      "epoch: 4 step: 38, loss is 1.0508226156234741\n",
      "epoch: 4 step: 39, loss is 3.126859188079834\n",
      "epoch: 4 step: 40, loss is 1.971224308013916\n",
      "epoch: 4 step: 41, loss is 0.7021986842155457\n",
      "epoch: 4 step: 42, loss is 2.6561012268066406\n",
      "epoch: 4 step: 43, loss is 1.646838903427124\n",
      "epoch: 4 step: 44, loss is 1.0685310363769531\n",
      "epoch: 4 step: 45, loss is 0.5598816871643066\n",
      "epoch: 4 step: 46, loss is 2.2269999980926514\n",
      "epoch: 4 step: 47, loss is 0.4161795675754547\n",
      "epoch: 4 step: 48, loss is 0.5670055747032166\n",
      "epoch: 4 step: 49, loss is 0.35495632886886597\n",
      "epoch: 4 step: 50, loss is 2.0035645961761475\n",
      "epoch: 4 step: 51, loss is 1.6959742307662964\n",
      "epoch: 4 step: 52, loss is 2.0060739517211914\n",
      "epoch: 4 step: 53, loss is 0.36689746379852295\n",
      "epoch: 4 step: 54, loss is 3.318248748779297\n",
      "epoch: 4 step: 55, loss is 1.8280657529830933\n",
      "epoch: 4 step: 56, loss is 1.2392048835754395\n",
      "epoch: 4 step: 57, loss is 1.9974720478057861\n",
      "epoch: 4 step: 58, loss is 0.5123983025550842\n",
      "epoch: 4 step: 59, loss is 0.37459322810173035\n",
      "epoch: 4 step: 60, loss is 0.30396053194999695\n",
      "epoch: 4 step: 61, loss is 1.0740195512771606\n",
      "epoch: 4 step: 62, loss is 1.2413806915283203\n",
      "epoch: 4 step: 63, loss is 0.30248525738716125\n",
      "epoch: 4 step: 64, loss is 2.4133200645446777\n",
      "epoch: 4 step: 65, loss is 0.3062077462673187\n",
      "epoch: 4 step: 66, loss is 0.2329045832157135\n",
      "epoch: 4 step: 67, loss is 1.9530978202819824\n",
      "epoch: 4 step: 68, loss is 0.24464525282382965\n",
      "epoch: 4 step: 69, loss is 3.423118829727173\n",
      "epoch: 4 step: 70, loss is 0.5387104749679565\n",
      "epoch: 4 step: 71, loss is 2.006256580352783\n",
      "epoch: 4 step: 72, loss is 0.9690772294998169\n",
      "epoch: 4 step: 73, loss is 2.284538507461548\n",
      "epoch: 4 step: 74, loss is 0.810922384262085\n",
      "epoch: 4 step: 75, loss is 0.4873095154762268\n",
      "epoch: 4 step: 76, loss is 0.4555431306362152\n",
      "epoch: 4 step: 77, loss is 0.44947826862335205\n",
      "epoch: 4 step: 78, loss is 0.8166016936302185\n",
      "epoch: 4 step: 79, loss is 3.087763786315918\n",
      "epoch: 4 step: 80, loss is 1.1381027698516846\n",
      "epoch: 4 step: 81, loss is 0.843925952911377\n",
      "epoch: 4 step: 82, loss is 2.572207450866699\n",
      "epoch: 4 step: 83, loss is 0.50801020860672\n",
      "epoch: 4 step: 84, loss is 0.7871841788291931\n",
      "epoch: 4 step: 85, loss is 0.8412865400314331\n",
      "epoch: 4 step: 86, loss is 0.4568982422351837\n",
      "epoch: 4 step: 87, loss is 0.6606078147888184\n",
      "epoch: 4 step: 88, loss is 0.1801271289587021\n",
      "epoch: 4 step: 89, loss is 0.35875844955444336\n",
      "epoch: 4 step: 90, loss is 0.2947971224784851\n",
      "epoch: 4 step: 91, loss is 1.7867345809936523\n",
      "epoch: 4 step: 92, loss is 2.011566400527954\n",
      "epoch: 4 step: 93, loss is 2.1733386516571045\n",
      "epoch: 4 step: 94, loss is 0.6446322202682495\n",
      "epoch: 4 step: 95, loss is 2.6501994132995605\n",
      "epoch: 4 step: 96, loss is 0.21396546065807343\n",
      "epoch: 4 step: 97, loss is 0.26666539907455444\n",
      "epoch: 4 step: 98, loss is 2.513864278793335\n",
      "epoch: 4 step: 99, loss is 0.9818462133407593\n",
      "epoch: 4 step: 100, loss is 1.8133540153503418\n",
      "epoch: 4 step: 101, loss is 0.4138887822628021\n",
      "epoch: 4 step: 102, loss is 0.36069026589393616\n",
      "epoch: 4 step: 103, loss is 0.31795406341552734\n",
      "epoch: 4 step: 104, loss is 0.25531110167503357\n",
      "epoch: 4 step: 105, loss is 1.3702646493911743\n",
      "epoch: 4 step: 106, loss is 0.5113060474395752\n",
      "epoch: 4 step: 107, loss is 0.5846925973892212\n",
      "epoch: 4 step: 108, loss is 0.6048980951309204\n",
      "epoch: 4 step: 109, loss is 3.0495128631591797\n",
      "epoch: 4 step: 110, loss is 0.7992087602615356\n",
      "epoch: 4 step: 111, loss is 0.25116363167762756\n",
      "epoch: 4 step: 112, loss is 1.9440832138061523\n",
      "epoch: 4 step: 113, loss is 0.23262612521648407\n",
      "epoch: 4 step: 114, loss is 0.6502455472946167\n",
      "epoch: 4 step: 115, loss is 0.15570838749408722\n",
      "epoch: 4 step: 116, loss is 2.9088473320007324\n",
      "epoch: 4 step: 117, loss is 3.833296537399292\n",
      "epoch: 4 step: 118, loss is 0.6703794002532959\n",
      "epoch: 4 step: 119, loss is 1.952539324760437\n",
      "epoch: 4 step: 120, loss is 0.5001668930053711\n",
      "epoch: 4 step: 121, loss is 2.0063364505767822\n",
      "epoch: 4 step: 122, loss is 1.9585999250411987\n",
      "epoch: 4 step: 123, loss is 0.6225287914276123\n",
      "epoch: 4 step: 124, loss is 0.3245113790035248\n",
      "epoch: 4 step: 125, loss is 0.6410283446311951\n",
      "epoch: 4 step: 126, loss is 2.554795742034912\n",
      "epoch: 4 step: 127, loss is 1.4754869937896729\n",
      "epoch: 4 step: 128, loss is 0.557942271232605\n",
      "epoch: 4 step: 129, loss is 2.281179428100586\n",
      "epoch: 4 step: 130, loss is 0.6937770247459412\n",
      "epoch: 4 step: 131, loss is 0.433447927236557\n",
      "epoch: 4 step: 132, loss is 2.3492493629455566\n",
      "epoch: 4 step: 133, loss is 1.8628512620925903\n",
      "epoch: 4 step: 134, loss is 2.2319412231445312\n",
      "epoch: 4 step: 135, loss is 1.8752756118774414\n",
      "epoch: 4 step: 136, loss is 0.8646361827850342\n",
      "epoch: 4 step: 137, loss is 0.5349282026290894\n",
      "epoch: 4 step: 138, loss is 0.593532383441925\n",
      "epoch: 4 step: 139, loss is 0.34575456380844116\n",
      "epoch: 4 step: 140, loss is 0.2390904724597931\n",
      "epoch: 4 step: 141, loss is 0.35977861285209656\n",
      "epoch: 4 step: 142, loss is 2.2332770824432373\n",
      "epoch: 4 step: 143, loss is 1.8149263858795166\n",
      "epoch: 4 step: 144, loss is 0.3073214888572693\n",
      "epoch: 4 step: 145, loss is 0.3452518880367279\n",
      "epoch: 4 step: 146, loss is 1.6596460342407227\n",
      "epoch: 4 step: 147, loss is 2.3063271045684814\n",
      "epoch: 4 step: 148, loss is 1.1172268390655518\n",
      "epoch: 4 step: 149, loss is 0.4238446056842804\n",
      "epoch: 4 step: 150, loss is 0.543502926826477\n",
      "epoch: 4 step: 151, loss is 0.7407108545303345\n",
      "epoch: 4 step: 152, loss is 1.9834721088409424\n",
      "epoch: 4 step: 153, loss is 0.29588159918785095\n",
      "epoch: 4 step: 154, loss is 1.3619379997253418\n",
      "epoch: 4 step: 155, loss is 0.4258561134338379\n",
      "epoch: 4 step: 156, loss is 0.494468629360199\n",
      "epoch: 4 step: 157, loss is 2.0748209953308105\n",
      "epoch: 4 step: 158, loss is 0.06880957633256912\n",
      "epoch: 4 step: 159, loss is 0.16757166385650635\n",
      "epoch: 4 step: 160, loss is 0.6918326616287231\n",
      "epoch: 4 step: 161, loss is 0.336532324552536\n",
      "epoch: 4 step: 162, loss is 2.013016700744629\n",
      "epoch: 4 step: 163, loss is 1.8170135021209717\n",
      "epoch: 4 step: 164, loss is 0.20215396583080292\n",
      "epoch: 4 step: 165, loss is 3.2257814407348633\n",
      "epoch: 4 step: 166, loss is 0.8083153367042542\n",
      "epoch: 4 step: 167, loss is 0.25895363092422485\n",
      "epoch: 4 step: 168, loss is 3.041992425918579\n",
      "epoch: 4 step: 169, loss is 0.34845399856567383\n",
      "epoch: 4 step: 170, loss is 1.8741101026535034\n",
      "epoch: 4 step: 171, loss is 2.251586675643921\n",
      "epoch: 4 step: 172, loss is 0.931348443031311\n",
      "epoch: 4 step: 173, loss is 0.377811074256897\n",
      "epoch: 4 step: 174, loss is 1.7900121212005615\n",
      "epoch: 4 step: 175, loss is 0.2170265167951584\n",
      "epoch: 4 step: 176, loss is 0.9987471103668213\n",
      "epoch: 4 step: 177, loss is 0.44346603751182556\n",
      "epoch: 4 step: 178, loss is 0.5255141258239746\n",
      "epoch: 4 step: 179, loss is 0.5781753659248352\n",
      "epoch: 4 step: 180, loss is 0.229561448097229\n",
      "epoch: 4 step: 181, loss is 0.35034945607185364\n",
      "epoch: 4 step: 182, loss is 2.929682493209839\n",
      "epoch: 4 step: 183, loss is 0.45719245076179504\n",
      "epoch: 4 step: 184, loss is 0.31945666670799255\n",
      "epoch: 4 step: 185, loss is 3.144853115081787\n",
      "epoch: 4 step: 186, loss is 0.48146510124206543\n",
      "epoch: 4 step: 187, loss is 0.19070550799369812\n",
      "epoch: 4 step: 188, loss is 0.3222406208515167\n",
      "epoch: 4 step: 189, loss is 1.8975379467010498\n",
      "epoch: 4 step: 190, loss is 2.05556058883667\n",
      "epoch: 4 step: 191, loss is 0.5178534388542175\n",
      "epoch: 4 step: 192, loss is 1.845707654953003\n",
      "epoch: 4 step: 193, loss is 2.6788697242736816\n",
      "epoch: 4 step: 194, loss is 2.487131118774414\n",
      "epoch: 4 step: 195, loss is 0.6550720930099487\n",
      "epoch: 4 step: 196, loss is 0.373930424451828\n",
      "epoch: 4 step: 197, loss is 1.5531119108200073\n",
      "epoch: 4 step: 198, loss is 0.2973822355270386\n",
      "epoch: 4 step: 199, loss is 0.6098533272743225\n",
      "epoch: 4 step: 200, loss is 1.7865285873413086\n",
      "epoch: 4 step: 201, loss is 0.6632391214370728\n",
      "epoch: 4 step: 202, loss is 2.216564178466797\n",
      "epoch: 4 step: 203, loss is 2.0114974975585938\n",
      "epoch: 4 step: 204, loss is 1.7479199171066284\n",
      "epoch: 4 step: 205, loss is 0.7190583348274231\n",
      "epoch: 4 step: 206, loss is 0.43619468808174133\n",
      "epoch: 4 step: 207, loss is 0.3554307520389557\n",
      "epoch: 4 step: 208, loss is 0.5889294743537903\n",
      "epoch: 4 step: 209, loss is 2.828251600265503\n",
      "epoch: 4 step: 210, loss is 1.635391354560852\n",
      "epoch: 4 step: 211, loss is 0.49942585825920105\n",
      "epoch: 4 step: 212, loss is 2.2665765285491943\n",
      "epoch: 4 step: 213, loss is 1.4296283721923828\n",
      "epoch: 4 step: 214, loss is 0.9559401273727417\n",
      "epoch: 4 step: 215, loss is 0.33152449131011963\n",
      "epoch: 4 step: 216, loss is 0.5179517865180969\n",
      "epoch: 4 step: 217, loss is 0.5454979538917542\n",
      "epoch: 4 step: 218, loss is 2.0742945671081543\n",
      "epoch: 4 step: 219, loss is 0.6213408708572388\n",
      "epoch: 4 step: 220, loss is 2.7957770824432373\n",
      "epoch: 4 step: 221, loss is 1.777154564857483\n",
      "epoch: 4 step: 222, loss is 2.6257364749908447\n",
      "epoch: 4 step: 223, loss is 2.3245129585266113\n",
      "epoch: 4 step: 224, loss is 0.7503084540367126\n",
      "epoch: 4 step: 225, loss is 0.8282848000526428\n",
      "epoch: 4 step: 226, loss is 0.6213142275810242\n",
      "epoch: 4 step: 227, loss is 2.508286237716675\n",
      "epoch: 4 step: 228, loss is 0.6633772850036621\n",
      "epoch: 4 step: 229, loss is 1.7016043663024902\n",
      "epoch: 4 step: 230, loss is 0.7467145919799805\n",
      "epoch: 4 step: 231, loss is 0.31997108459472656\n",
      "epoch: 4 step: 232, loss is 0.684180736541748\n",
      "epoch: 4 step: 233, loss is 1.8039448261260986\n",
      "epoch: 4 step: 234, loss is 0.5683937072753906\n",
      "epoch: 4 step: 235, loss is 0.39127469062805176\n",
      "epoch: 4 step: 236, loss is 0.32387349009513855\n",
      "epoch: 4 step: 237, loss is 0.5153242349624634\n",
      "epoch: 4 step: 238, loss is 2.2623558044433594\n",
      "epoch: 4 step: 239, loss is 1.0044541358947754\n",
      "epoch: 4 step: 240, loss is 2.570945978164673\n",
      "epoch: 4 step: 241, loss is 0.38058939576148987\n",
      "epoch: 4 step: 242, loss is 0.2892070412635803\n",
      "epoch: 4 step: 243, loss is 0.213157519698143\n",
      "epoch: 4 step: 244, loss is 0.5235264301300049\n",
      "epoch: 4 step: 245, loss is 0.9228518009185791\n",
      "epoch: 4 step: 246, loss is 2.7123358249664307\n",
      "epoch: 4 step: 247, loss is 0.3153633773326874\n",
      "epoch: 4 step: 248, loss is 0.5382496118545532\n",
      "epoch: 4 step: 249, loss is 0.3296433687210083\n",
      "epoch: 4 step: 250, loss is 3.6621646881103516\n",
      "epoch: 4 step: 251, loss is 2.9606523513793945\n",
      "epoch: 4 step: 252, loss is 0.32763126492500305\n",
      "epoch: 4 step: 253, loss is 2.091909408569336\n",
      "epoch: 4 step: 254, loss is 1.6699390411376953\n",
      "epoch: 4 step: 255, loss is 0.38704442977905273\n",
      "epoch: 4 step: 256, loss is 2.3643202781677246\n",
      "epoch: 4 step: 257, loss is 2.2306482791900635\n",
      "epoch: 4 step: 258, loss is 3.105433464050293\n",
      "epoch: 4 step: 259, loss is 0.6320061087608337\n",
      "epoch: 4 step: 260, loss is 0.79584139585495\n",
      "epoch: 4 step: 261, loss is 1.6930021047592163\n",
      "epoch: 4 step: 262, loss is 0.4585171639919281\n",
      "epoch: 4 step: 263, loss is 1.1421974897384644\n",
      "epoch: 4 step: 264, loss is 1.7136476039886475\n",
      "epoch: 4 step: 265, loss is 1.6832952499389648\n",
      "epoch: 4 step: 266, loss is 0.3656008243560791\n",
      "epoch: 4 step: 267, loss is 1.8057329654693604\n",
      "epoch: 4 step: 268, loss is 0.42442166805267334\n",
      "epoch: 4 step: 269, loss is 1.9029548168182373\n",
      "epoch: 4 step: 270, loss is 1.594299077987671\n",
      "epoch: 4 step: 271, loss is 0.64924556016922\n",
      "epoch: 4 step: 272, loss is 0.917506217956543\n",
      "epoch: 4 step: 273, loss is 0.3793591856956482\n",
      "epoch: 4 step: 274, loss is 0.33336496353149414\n",
      "epoch: 4 step: 275, loss is 0.6817749738693237\n",
      "epoch: 4 step: 276, loss is 0.23536646366119385\n",
      "epoch: 4 step: 277, loss is 0.6444151401519775\n",
      "epoch: 4 step: 278, loss is 0.3450409471988678\n",
      "epoch: 4 step: 279, loss is 0.6267729997634888\n",
      "epoch: 4 step: 280, loss is 0.6760838627815247\n",
      "epoch: 4 step: 281, loss is 2.132777214050293\n",
      "epoch: 4 step: 282, loss is 0.7012619972229004\n",
      "epoch: 4 step: 283, loss is 3.713822841644287\n",
      "epoch: 4 step: 284, loss is 0.2169388085603714\n",
      "epoch: 4 step: 285, loss is 0.33679479360580444\n",
      "epoch: 4 step: 286, loss is 0.5046136379241943\n",
      "epoch: 4 step: 287, loss is 3.567727565765381\n",
      "epoch: 4 step: 288, loss is 0.1943625658750534\n",
      "epoch: 4 step: 289, loss is 3.7654199600219727\n",
      "epoch: 4 step: 290, loss is 0.5920618176460266\n",
      "epoch: 4 step: 291, loss is 1.8711971044540405\n",
      "epoch: 4 step: 292, loss is 0.7515290379524231\n",
      "epoch: 4 step: 293, loss is 0.5625746250152588\n",
      "epoch: 4 step: 294, loss is 2.27488374710083\n",
      "epoch: 4 step: 295, loss is 0.46226564049720764\n",
      "epoch: 4 step: 296, loss is 0.40132221579551697\n",
      "epoch: 4 step: 297, loss is 2.499617099761963\n",
      "epoch: 4 step: 298, loss is 2.478480100631714\n",
      "epoch: 4 step: 299, loss is 2.1481893062591553\n",
      "epoch: 4 step: 300, loss is 0.537287712097168\n",
      "epoch: 4 step: 301, loss is 0.4578859210014343\n",
      "epoch: 4 step: 302, loss is 0.6711395382881165\n",
      "epoch: 4 step: 303, loss is 1.7343358993530273\n",
      "epoch: 4 step: 304, loss is 0.409962922334671\n",
      "epoch: 4 step: 305, loss is 0.4512943923473358\n",
      "epoch: 4 step: 306, loss is 2.408973455429077\n",
      "epoch: 4 step: 307, loss is 0.5911239385604858\n",
      "epoch: 4 step: 308, loss is 1.7245945930480957\n",
      "epoch: 4 step: 309, loss is 0.4112519919872284\n",
      "epoch: 4 step: 310, loss is 0.5247403383255005\n",
      "epoch: 4 step: 311, loss is 0.4452578127384186\n",
      "epoch: 4 step: 312, loss is 0.46239304542541504\n",
      "epoch: 4 step: 313, loss is 0.39410069584846497\n",
      "epoch: 4 step: 314, loss is 0.4447757303714752\n",
      "epoch: 4 step: 315, loss is 2.6059751510620117\n",
      "epoch: 4 step: 316, loss is 2.2341840267181396\n",
      "epoch: 4 step: 317, loss is 0.7458029985427856\n",
      "epoch: 4 step: 318, loss is 0.973727822303772\n",
      "epoch: 4 step: 319, loss is 2.85906982421875\n",
      "epoch: 4 step: 320, loss is 1.7558526992797852\n",
      "epoch: 4 step: 321, loss is 2.56880259513855\n",
      "epoch: 4 step: 322, loss is 0.8946444988250732\n",
      "epoch: 4 step: 323, loss is 1.6192874908447266\n",
      "epoch: 4 step: 324, loss is 0.7216250896453857\n",
      "epoch: 4 step: 325, loss is 0.7509664297103882\n",
      "epoch: 4 step: 326, loss is 2.1681039333343506\n",
      "epoch: 4 step: 327, loss is 0.47976386547088623\n",
      "epoch: 4 step: 328, loss is 1.7673001289367676\n",
      "epoch: 4 step: 329, loss is 1.882145643234253\n",
      "epoch: 4 step: 330, loss is 1.7569594383239746\n",
      "epoch: 4 step: 331, loss is 1.8643335103988647\n",
      "epoch: 4 step: 332, loss is 0.5727443099021912\n",
      "epoch: 4 step: 333, loss is 0.5759782791137695\n",
      "epoch: 4 step: 334, loss is 3.160269260406494\n",
      "epoch: 4 step: 335, loss is 0.9798244833946228\n",
      "epoch: 4 step: 336, loss is 1.5993565320968628\n",
      "epoch: 4 step: 337, loss is 0.6100361347198486\n",
      "epoch: 4 step: 338, loss is 0.42330023646354675\n",
      "epoch: 4 step: 339, loss is 1.8496934175491333\n",
      "epoch: 4 step: 340, loss is 3.510117292404175\n",
      "epoch: 4 step: 341, loss is 1.0485355854034424\n",
      "epoch: 4 step: 342, loss is 1.7810120582580566\n",
      "epoch: 4 step: 343, loss is 0.8982636332511902\n",
      "epoch: 4 step: 344, loss is 0.41350430250167847\n",
      "epoch: 4 step: 345, loss is 0.4059949815273285\n",
      "epoch: 4 step: 346, loss is 0.4051021635532379\n",
      "epoch: 4 step: 347, loss is 0.7355852127075195\n",
      "epoch: 4 step: 348, loss is 0.39786267280578613\n",
      "epoch: 4 step: 349, loss is 1.868842601776123\n",
      "epoch: 4 step: 350, loss is 1.8247637748718262\n",
      "epoch: 4 step: 351, loss is 1.1237303018569946\n",
      "epoch: 4 step: 352, loss is 0.722945511341095\n",
      "epoch: 4 step: 353, loss is 0.7123453617095947\n",
      "epoch: 4 step: 354, loss is 1.9376246929168701\n",
      "epoch: 4 step: 355, loss is 1.6174910068511963\n",
      "epoch: 4 step: 356, loss is 1.8106439113616943\n",
      "epoch: 4 step: 357, loss is 0.5710221529006958\n",
      "epoch: 4 step: 358, loss is 0.3163311183452606\n",
      "epoch: 4 step: 359, loss is 1.7792375087738037\n",
      "epoch: 4 step: 360, loss is 0.1791563481092453\n",
      "epoch: 4 step: 361, loss is 3.022451162338257\n",
      "epoch: 4 step: 362, loss is 0.460398405790329\n",
      "epoch: 4 step: 363, loss is 0.6804570555686951\n",
      "epoch: 4 step: 364, loss is 2.2548372745513916\n",
      "epoch: 4 step: 365, loss is 2.019719123840332\n",
      "epoch: 4 step: 366, loss is 1.1248552799224854\n",
      "epoch: 4 step: 367, loss is 0.487202525138855\n",
      "epoch: 4 step: 368, loss is 0.5105778574943542\n",
      "epoch: 4 step: 369, loss is 0.7188665270805359\n",
      "epoch: 4 step: 370, loss is 1.949906587600708\n",
      "epoch: 4 step: 371, loss is 0.8108022212982178\n",
      "epoch: 4 step: 372, loss is 0.34382638335227966\n",
      "epoch: 4 step: 373, loss is 2.2217800617218018\n",
      "epoch: 4 step: 374, loss is 1.8994970321655273\n",
      "epoch: 4 step: 375, loss is 0.6347456574440002\n",
      "epoch: 4 step: 376, loss is 2.0348870754241943\n",
      "epoch: 4 step: 377, loss is 0.8757910132408142\n",
      "epoch: 4 step: 378, loss is 0.4784506559371948\n",
      "epoch: 4 step: 379, loss is 0.4304737150669098\n",
      "epoch: 4 step: 380, loss is 1.8003500699996948\n",
      "epoch: 4 step: 381, loss is 1.8978317975997925\n",
      "epoch: 4 step: 382, loss is 0.4599277675151825\n",
      "epoch: 4 step: 383, loss is 0.31759339570999146\n",
      "epoch: 4 step: 384, loss is 0.34063518047332764\n",
      "epoch: 4 step: 385, loss is 1.9275844097137451\n",
      "epoch: 4 step: 386, loss is 0.36670881509780884\n",
      "epoch: 4 step: 387, loss is 0.23644645512104034\n",
      "epoch: 4 step: 388, loss is 1.9708609580993652\n",
      "epoch: 4 step: 389, loss is 0.29167675971984863\n",
      "epoch: 4 step: 390, loss is 0.3114296793937683\n",
      "epoch: 4 step: 391, loss is 0.49910351634025574\n",
      "epoch: 4 step: 392, loss is 0.6818923354148865\n",
      "epoch: 4 step: 393, loss is 2.034048557281494\n",
      "epoch: 4 step: 394, loss is 0.602051854133606\n",
      "epoch: 4 step: 395, loss is 1.7905430793762207\n",
      "epoch: 4 step: 396, loss is 2.6980605125427246\n",
      "epoch: 4 step: 397, loss is 0.7136278748512268\n",
      "epoch: 4 step: 398, loss is 2.333251714706421\n",
      "epoch: 4 step: 399, loss is 0.40804600715637207\n",
      "epoch: 4 step: 400, loss is 0.37473979592323303\n",
      "epoch: 4 step: 401, loss is 0.4490554928779602\n",
      "epoch: 4 step: 402, loss is 0.3891635537147522\n",
      "epoch: 4 step: 403, loss is 2.5311484336853027\n",
      "epoch: 4 step: 404, loss is 3.2540359497070312\n",
      "epoch: 4 step: 405, loss is 0.6316434741020203\n",
      "epoch: 4 step: 406, loss is 0.327923983335495\n",
      "epoch: 4 step: 407, loss is 0.4833506941795349\n",
      "epoch: 4 step: 408, loss is 1.923452377319336\n",
      "epoch: 4 step: 409, loss is 0.37133294343948364\n",
      "epoch: 4 step: 410, loss is 2.4496054649353027\n",
      "epoch: 4 step: 411, loss is 0.6586165428161621\n",
      "epoch: 4 step: 412, loss is 0.433479905128479\n",
      "epoch: 4 step: 413, loss is 0.4432021379470825\n",
      "epoch: 4 step: 414, loss is 0.2898756265640259\n",
      "epoch: 4 step: 415, loss is 0.22603406012058258\n",
      "epoch: 4 step: 416, loss is 0.18099670112133026\n",
      "epoch: 4 step: 417, loss is 0.19143128395080566\n",
      "epoch: 4 step: 418, loss is 0.22890694439411163\n",
      "epoch: 4 step: 419, loss is 0.2747289836406708\n",
      "epoch: 4 step: 420, loss is 0.24495089054107666\n",
      "epoch: 4 step: 421, loss is 2.3940460681915283\n",
      "epoch: 4 step: 422, loss is 2.5889596939086914\n",
      "epoch: 4 step: 423, loss is 0.5340957641601562\n",
      "epoch: 4 step: 424, loss is 2.233884572982788\n",
      "epoch: 4 step: 425, loss is 0.8772777318954468\n",
      "epoch: 4 step: 426, loss is 0.3773581087589264\n",
      "epoch: 4 step: 427, loss is 0.2816982865333557\n",
      "epoch: 4 step: 428, loss is 2.409824848175049\n",
      "epoch: 4 step: 429, loss is 0.36534351110458374\n",
      "epoch: 4 step: 430, loss is 0.6991905570030212\n",
      "epoch: 4 step: 431, loss is 0.17233259975910187\n",
      "epoch: 4 step: 432, loss is 0.30867600440979004\n",
      "epoch: 4 step: 433, loss is 0.7846684455871582\n",
      "epoch: 4 step: 434, loss is 0.261076956987381\n",
      "epoch: 4 step: 435, loss is 0.12519501149654388\n",
      "epoch: 4 step: 436, loss is 4.903335094451904\n",
      "epoch: 4 step: 437, loss is 2.645509719848633\n",
      "epoch: 4 step: 438, loss is 0.31432822346687317\n",
      "epoch: 4 step: 439, loss is 0.4679059684276581\n",
      "epoch: 4 step: 440, loss is 1.8931891918182373\n",
      "epoch: 4 step: 441, loss is 0.4372255504131317\n",
      "epoch: 4 step: 442, loss is 2.2707509994506836\n",
      "epoch: 4 step: 443, loss is 0.47636011242866516\n",
      "epoch: 4 step: 444, loss is 0.3645899295806885\n",
      "epoch: 4 step: 445, loss is 0.12186077982187271\n",
      "epoch: 4 step: 446, loss is 0.1535586416721344\n",
      "epoch: 4 step: 447, loss is 0.20318926870822906\n",
      "epoch: 4 step: 448, loss is 1.9237509965896606\n",
      "epoch: 4 step: 449, loss is 0.5018869042396545\n",
      "epoch: 4 step: 450, loss is 0.6450672745704651\n",
      "epoch: 4 step: 451, loss is 2.082761287689209\n",
      "epoch: 4 step: 452, loss is 0.6802272796630859\n",
      "epoch: 4 step: 453, loss is 0.3222408890724182\n",
      "epoch: 4 step: 454, loss is 0.4602002501487732\n",
      "epoch: 4 step: 455, loss is 0.8896764516830444\n",
      "epoch: 4 step: 456, loss is 0.24503719806671143\n",
      "epoch: 4 step: 457, loss is 0.15217335522174835\n",
      "epoch: 4 step: 458, loss is 0.5712965726852417\n",
      "epoch: 4 step: 459, loss is 0.22420795261859894\n",
      "epoch: 4 step: 460, loss is 0.22006043791770935\n",
      "epoch: 4 step: 461, loss is 0.19001805782318115\n",
      "epoch: 4 step: 462, loss is 0.20052212476730347\n",
      "epoch: 4 step: 463, loss is 2.7151124477386475\n",
      "epoch: 4 step: 464, loss is 0.48068469762802124\n",
      "epoch: 4 step: 465, loss is 0.5341807007789612\n",
      "epoch: 4 step: 466, loss is 0.08071892708539963\n",
      "epoch: 4 step: 467, loss is 2.631432294845581\n",
      "epoch: 4 step: 468, loss is 0.35381317138671875\n",
      "epoch: 4 step: 469, loss is 0.22243854403495789\n",
      "epoch: 4 step: 470, loss is 0.2506222128868103\n",
      "epoch: 4 step: 471, loss is 2.680166244506836\n",
      "epoch: 4 step: 472, loss is 3.091308355331421\n",
      "epoch: 4 step: 473, loss is 0.18600472807884216\n",
      "epoch: 4 step: 474, loss is 1.7524076700210571\n",
      "epoch: 4 step: 475, loss is 1.0309247970581055\n",
      "epoch: 4 step: 476, loss is 0.48182979226112366\n",
      "epoch: 4 step: 477, loss is 0.16226907074451447\n",
      "epoch: 4 step: 478, loss is 3.623368740081787\n",
      "epoch: 4 step: 479, loss is 0.22962068021297455\n",
      "epoch: 4 step: 480, loss is 0.5123222470283508\n",
      "epoch: 4 step: 481, loss is 0.4765174984931946\n",
      "epoch: 4 step: 482, loss is 0.1555081009864807\n",
      "epoch: 4 step: 483, loss is 0.1016201600432396\n",
      "epoch: 4 step: 484, loss is 0.13152608275413513\n",
      "epoch: 4 step: 485, loss is 3.348314046859741\n",
      "epoch: 4 step: 486, loss is 0.6313545107841492\n",
      "epoch: 4 step: 487, loss is 0.1274850219488144\n",
      "epoch: 4 step: 488, loss is 0.5578002333641052\n",
      "epoch: 4 step: 489, loss is 0.287619411945343\n",
      "epoch: 4 step: 490, loss is 1.8495585918426514\n",
      "epoch: 4 step: 491, loss is 0.49829429388046265\n",
      "epoch: 4 step: 492, loss is 0.25600293278694153\n",
      "epoch: 4 step: 493, loss is 0.0949532687664032\n",
      "epoch: 4 step: 494, loss is 2.912048578262329\n",
      "epoch: 4 step: 495, loss is 0.3375851809978485\n",
      "epoch: 4 step: 496, loss is 2.884016513824463\n",
      "epoch: 4 step: 497, loss is 3.3945975303649902\n",
      "epoch: 4 step: 498, loss is 0.47095850110054016\n",
      "epoch: 4 step: 499, loss is 1.8332126140594482\n",
      "epoch: 4 step: 500, loss is 0.5143052935600281\n",
      "epoch: 4 step: 501, loss is 0.27943626046180725\n",
      "epoch: 4 step: 502, loss is 2.0950186252593994\n",
      "epoch: 4 step: 503, loss is 2.1907496452331543\n",
      "epoch: 4 step: 504, loss is 0.4440590441226959\n",
      "epoch: 4 step: 505, loss is 0.3899971842765808\n",
      "epoch: 4 step: 506, loss is 0.4254557192325592\n",
      "epoch: 4 step: 507, loss is 3.1692776679992676\n",
      "epoch: 4 step: 508, loss is 0.34081146121025085\n",
      "epoch: 4 step: 509, loss is 2.125236749649048\n",
      "epoch: 4 step: 510, loss is 0.4284197688102722\n",
      "epoch: 4 step: 511, loss is 0.3821176588535309\n",
      "epoch: 4 step: 512, loss is 0.34390050172805786\n",
      "epoch: 4 step: 513, loss is 0.16189044713974\n",
      "epoch: 4 step: 514, loss is 1.613584041595459\n",
      "epoch: 4 step: 515, loss is 1.6993091106414795\n",
      "epoch: 4 step: 516, loss is 0.22102147340774536\n",
      "epoch: 4 step: 517, loss is 2.215641975402832\n",
      "epoch: 4 step: 518, loss is 0.5874190330505371\n",
      "epoch: 4 step: 519, loss is 0.3303627669811249\n",
      "epoch: 4 step: 520, loss is 0.15526847541332245\n",
      "epoch: 4 step: 521, loss is 5.098062515258789\n",
      "epoch: 4 step: 522, loss is 1.0098432302474976\n",
      "epoch: 4 step: 523, loss is 0.44836121797561646\n",
      "epoch: 4 step: 524, loss is 2.365792751312256\n",
      "epoch: 4 step: 525, loss is 2.0179412364959717\n",
      "epoch: 4 step: 526, loss is 0.6867873668670654\n",
      "epoch: 4 step: 527, loss is 0.6655188798904419\n",
      "epoch: 4 step: 528, loss is 0.52781081199646\n",
      "epoch: 4 step: 529, loss is 1.0618879795074463\n",
      "epoch: 4 step: 530, loss is 2.634922504425049\n",
      "epoch: 4 step: 531, loss is 2.1562771797180176\n",
      "epoch: 4 step: 532, loss is 0.846156120300293\n",
      "epoch: 4 step: 533, loss is 1.0006568431854248\n",
      "epoch: 4 step: 534, loss is 0.3273424208164215\n",
      "epoch: 4 step: 535, loss is 0.27713122963905334\n",
      "epoch: 4 step: 536, loss is 1.106765866279602\n",
      "epoch: 4 step: 537, loss is 0.3816474974155426\n",
      "epoch: 4 step: 538, loss is 0.24917516112327576\n",
      "epoch: 4 step: 539, loss is 2.8176827430725098\n",
      "epoch: 4 step: 540, loss is 0.2079169601202011\n",
      "epoch: 4 step: 541, loss is 1.7421473264694214\n",
      "epoch: 4 step: 542, loss is 0.42404940724372864\n",
      "epoch: 4 step: 543, loss is 1.565544843673706\n",
      "epoch: 4 step: 544, loss is 0.6912405490875244\n",
      "epoch: 4 step: 545, loss is 3.20686411857605\n",
      "epoch: 4 step: 546, loss is 0.8531712889671326\n",
      "epoch: 4 step: 547, loss is 0.4310673475265503\n",
      "epoch: 4 step: 548, loss is 0.42917171120643616\n",
      "epoch: 4 step: 549, loss is 1.884886622428894\n",
      "epoch: 4 step: 550, loss is 2.6235101222991943\n",
      "epoch: 4 step: 551, loss is 0.5045161247253418\n",
      "epoch: 4 step: 552, loss is 2.111077070236206\n",
      "epoch: 4 step: 553, loss is 0.40960872173309326\n",
      "epoch: 4 step: 554, loss is 0.5866376161575317\n",
      "epoch: 4 step: 555, loss is 0.24011553823947906\n",
      "epoch: 4 step: 556, loss is 2.097672462463379\n",
      "epoch: 4 step: 557, loss is 1.9726431369781494\n",
      "epoch: 4 step: 558, loss is 1.6882028579711914\n",
      "epoch: 4 step: 559, loss is 0.31230053305625916\n",
      "epoch: 4 step: 560, loss is 2.9357266426086426\n",
      "epoch: 4 step: 561, loss is 0.7426565885543823\n",
      "epoch: 4 step: 562, loss is 0.3984062671661377\n",
      "epoch: 4 step: 563, loss is 0.6221678853034973\n",
      "epoch: 4 step: 564, loss is 1.7212865352630615\n",
      "epoch: 4 step: 565, loss is 0.49656710028648376\n",
      "epoch: 4 step: 566, loss is 1.7040694952011108\n",
      "epoch: 4 step: 567, loss is 2.147517442703247\n",
      "epoch: 4 step: 568, loss is 0.5330476760864258\n",
      "epoch: 4 step: 569, loss is 1.7509419918060303\n",
      "epoch: 4 step: 570, loss is 0.3936667740345001\n",
      "epoch: 4 step: 571, loss is 1.074376106262207\n",
      "epoch: 4 step: 572, loss is 0.7250288724899292\n",
      "epoch: 4 step: 573, loss is 1.8391388654708862\n",
      "epoch: 4 step: 574, loss is 0.37220439314842224\n",
      "epoch: 4 step: 575, loss is 0.2561030387878418\n",
      "epoch: 4 step: 576, loss is 0.2161855250597\n",
      "epoch: 4 step: 577, loss is 0.12257487326860428\n",
      "epoch: 4 step: 578, loss is 0.4071289896965027\n",
      "epoch: 4 step: 579, loss is 0.47721049189567566\n",
      "epoch: 4 step: 580, loss is 0.8956246376037598\n",
      "epoch: 4 step: 581, loss is 2.662283420562744\n",
      "epoch: 4 step: 582, loss is 0.23666861653327942\n",
      "epoch: 4 step: 583, loss is 0.11554086953401566\n",
      "epoch: 4 step: 584, loss is 0.5350227355957031\n",
      "epoch: 4 step: 585, loss is 0.2656949758529663\n",
      "epoch: 4 step: 586, loss is 0.13180239498615265\n",
      "epoch: 4 step: 587, loss is 1.8229776620864868\n",
      "epoch: 4 step: 588, loss is 2.454401731491089\n",
      "epoch: 4 step: 589, loss is 0.4467439353466034\n",
      "epoch: 4 step: 590, loss is 0.13156935572624207\n",
      "epoch: 4 step: 591, loss is 1.8447781801223755\n",
      "epoch: 4 step: 592, loss is 2.054176092147827\n",
      "epoch: 4 step: 593, loss is 0.1474798321723938\n",
      "epoch: 4 step: 594, loss is 0.18158899247646332\n",
      "epoch: 4 step: 595, loss is 0.2928040623664856\n",
      "epoch: 4 step: 596, loss is 0.21556369960308075\n",
      "epoch: 4 step: 597, loss is 1.9415141344070435\n",
      "epoch: 4 step: 598, loss is 0.3097264766693115\n",
      "epoch: 4 step: 599, loss is 2.6757960319519043\n",
      "epoch: 4 step: 600, loss is 0.1085457056760788\n",
      "epoch: 4 step: 601, loss is 0.2454662024974823\n",
      "epoch: 4 step: 602, loss is 0.6262010931968689\n",
      "epoch: 4 step: 603, loss is 0.039563801139593124\n",
      "epoch: 4 step: 604, loss is 3.4385132789611816\n",
      "epoch: 4 step: 605, loss is 4.410919189453125\n",
      "epoch: 4 step: 606, loss is 2.3972532749176025\n",
      "epoch: 4 step: 607, loss is 1.5745232105255127\n",
      "epoch: 4 step: 608, loss is 0.7925208806991577\n",
      "epoch: 4 step: 609, loss is 0.5309484004974365\n",
      "epoch: 4 step: 610, loss is 2.0718655586242676\n",
      "epoch: 4 step: 611, loss is 0.77082359790802\n",
      "epoch: 4 step: 612, loss is 0.7666248083114624\n",
      "epoch: 4 step: 613, loss is 0.8235965967178345\n",
      "epoch: 4 step: 614, loss is 0.34381648898124695\n",
      "epoch: 4 step: 615, loss is 0.2775421738624573\n",
      "epoch: 4 step: 616, loss is 1.8386552333831787\n",
      "epoch: 4 step: 617, loss is 1.7634354829788208\n",
      "epoch: 4 step: 618, loss is 2.1178903579711914\n",
      "epoch: 4 step: 619, loss is 1.9287288188934326\n",
      "epoch: 4 step: 620, loss is 0.5870000123977661\n",
      "epoch: 4 step: 621, loss is 0.40899747610092163\n",
      "epoch: 4 step: 622, loss is 1.9218841791152954\n",
      "epoch: 4 step: 623, loss is 0.5995393991470337\n",
      "epoch: 4 step: 624, loss is 0.4774813950061798\n",
      "epoch: 4 step: 625, loss is 0.33568572998046875\n",
      "epoch: 4 step: 626, loss is 0.5394972562789917\n",
      "epoch: 4 step: 627, loss is 2.3689701557159424\n",
      "epoch: 4 step: 628, loss is 0.740237832069397\n",
      "epoch: 4 step: 629, loss is 0.2045864462852478\n",
      "epoch: 4 step: 630, loss is 0.49765506386756897\n",
      "epoch: 4 step: 631, loss is 0.5982834100723267\n",
      "epoch: 4 step: 632, loss is 3.0815391540527344\n",
      "epoch: 4 step: 633, loss is 1.9640370607376099\n",
      "epoch: 4 step: 634, loss is 0.6333903074264526\n",
      "epoch: 4 step: 635, loss is 0.19602760672569275\n",
      "epoch: 4 step: 636, loss is 0.7022987008094788\n",
      "epoch: 4 step: 637, loss is 1.9452033042907715\n",
      "epoch: 4 step: 638, loss is 1.847287654876709\n",
      "epoch: 4 step: 639, loss is 2.8091201782226562\n",
      "epoch: 4 step: 640, loss is 0.24974578619003296\n",
      "epoch: 4 step: 641, loss is 0.26872122287750244\n",
      "epoch: 4 step: 642, loss is 1.012421727180481\n",
      "epoch: 4 step: 643, loss is 1.0045775175094604\n",
      "epoch: 4 step: 644, loss is 0.5850077271461487\n",
      "epoch: 4 step: 645, loss is 0.17396016418933868\n",
      "epoch: 4 step: 646, loss is 0.3604344129562378\n",
      "epoch: 4 step: 647, loss is 0.25387832522392273\n",
      "epoch: 4 step: 648, loss is 0.22647784650325775\n",
      "epoch: 4 step: 649, loss is 2.9099314212799072\n",
      "epoch: 4 step: 650, loss is 0.4569075405597687\n",
      "epoch: 4 step: 651, loss is 2.072000503540039\n",
      "epoch: 4 step: 652, loss is 0.12360571324825287\n",
      "epoch: 4 step: 653, loss is 0.15616554021835327\n",
      "epoch: 4 step: 654, loss is 1.9482650756835938\n",
      "epoch: 4 step: 655, loss is 0.08559966832399368\n",
      "epoch: 4 step: 656, loss is 3.152388095855713\n",
      "epoch: 4 step: 657, loss is 0.2056427299976349\n",
      "epoch: 4 step: 658, loss is 1.7981435060501099\n",
      "epoch: 4 step: 659, loss is 0.19219498336315155\n",
      "epoch: 4 step: 660, loss is 0.2222592979669571\n",
      "epoch: 4 step: 661, loss is 0.17965231835842133\n",
      "epoch: 4 step: 662, loss is 2.344515800476074\n",
      "epoch: 4 step: 663, loss is 2.0851593017578125\n",
      "epoch: 4 step: 664, loss is 0.14016155898571014\n",
      "epoch: 4 step: 665, loss is 1.705728530883789\n",
      "epoch: 4 step: 666, loss is 2.121351718902588\n",
      "epoch: 4 step: 667, loss is 0.6090289354324341\n",
      "epoch: 4 step: 668, loss is 0.6892820596694946\n",
      "epoch: 4 step: 669, loss is 1.0177280902862549\n",
      "epoch: 4 step: 670, loss is 2.505721092224121\n",
      "epoch: 4 step: 671, loss is 0.6086625456809998\n",
      "epoch: 4 step: 672, loss is 0.2797929048538208\n",
      "epoch: 4 step: 673, loss is 2.2890477180480957\n",
      "epoch: 4 step: 674, loss is 1.5993791818618774\n",
      "epoch: 4 step: 675, loss is 0.17616349458694458\n",
      "epoch: 4 step: 676, loss is 0.5998802185058594\n",
      "epoch: 4 step: 677, loss is 0.3633486330509186\n",
      "epoch: 4 step: 678, loss is 0.32282310724258423\n",
      "epoch: 4 step: 679, loss is 0.08975601941347122\n",
      "epoch: 4 step: 680, loss is 0.08638527989387512\n",
      "epoch: 4 step: 681, loss is 2.891068696975708\n",
      "epoch: 4 step: 682, loss is 0.11313772201538086\n",
      "epoch: 4 step: 683, loss is 0.17228342592716217\n",
      "epoch: 4 step: 684, loss is 0.44336795806884766\n",
      "epoch: 4 step: 685, loss is 0.13021259009838104\n",
      "epoch: 4 step: 686, loss is 3.5167880058288574\n",
      "epoch: 4 step: 687, loss is 1.8160796165466309\n",
      "epoch: 4 step: 688, loss is 1.8732669353485107\n",
      "epoch: 4 step: 689, loss is 2.02866530418396\n",
      "epoch: 4 step: 690, loss is 1.9380204677581787\n",
      "epoch: 4 step: 691, loss is 2.498941421508789\n",
      "epoch: 4 step: 692, loss is 0.40398040413856506\n",
      "epoch: 4 step: 693, loss is 0.44165533781051636\n",
      "epoch: 4 step: 694, loss is 1.7356038093566895\n",
      "epoch: 4 step: 695, loss is 0.46374639868736267\n",
      "epoch: 4 step: 696, loss is 0.6788719892501831\n",
      "epoch: 4 step: 697, loss is 0.4933807849884033\n",
      "epoch: 4 step: 698, loss is 1.3575488328933716\n",
      "epoch: 4 step: 699, loss is 2.0920352935791016\n",
      "epoch: 4 step: 700, loss is 1.7064881324768066\n",
      "epoch: 4 step: 701, loss is 0.6019330024719238\n",
      "epoch: 4 step: 702, loss is 2.821408987045288\n",
      "epoch: 4 step: 703, loss is 2.317152261734009\n",
      "epoch: 4 step: 704, loss is 1.61275053024292\n",
      "epoch: 4 step: 705, loss is 1.163037896156311\n",
      "epoch: 4 step: 706, loss is 0.921565592288971\n",
      "epoch: 4 step: 707, loss is 0.2884092628955841\n",
      "epoch: 4 step: 708, loss is 0.7891655564308167\n",
      "epoch: 4 step: 709, loss is 1.6958448886871338\n",
      "epoch: 4 step: 710, loss is 2.280038833618164\n",
      "epoch: 4 step: 711, loss is 0.9556976556777954\n",
      "epoch: 4 step: 712, loss is 0.4527966380119324\n",
      "epoch: 4 step: 713, loss is 0.34626948833465576\n",
      "epoch: 4 step: 714, loss is 2.5937609672546387\n",
      "epoch: 4 step: 715, loss is 0.42725062370300293\n",
      "epoch: 4 step: 716, loss is 2.2984402179718018\n",
      "epoch: 4 step: 717, loss is 0.70541912317276\n",
      "epoch: 4 step: 718, loss is 1.8910629749298096\n",
      "epoch: 4 step: 719, loss is 0.25181108713150024\n",
      "epoch: 4 step: 720, loss is 0.37871411442756653\n",
      "epoch: 4 step: 721, loss is 1.779740810394287\n",
      "epoch: 4 step: 722, loss is 2.310476779937744\n",
      "epoch: 4 step: 723, loss is 0.9710652828216553\n",
      "epoch: 4 step: 724, loss is 0.7326489686965942\n",
      "epoch: 4 step: 725, loss is 2.0373642444610596\n",
      "epoch: 4 step: 726, loss is 0.47263389825820923\n",
      "epoch: 4 step: 727, loss is 1.8970975875854492\n",
      "epoch: 4 step: 728, loss is 2.0886921882629395\n",
      "epoch: 4 step: 729, loss is 0.6961462497711182\n",
      "epoch: 4 step: 730, loss is 0.4817560017108917\n",
      "epoch: 4 step: 731, loss is 0.4889146089553833\n",
      "epoch: 4 step: 732, loss is 1.7003910541534424\n",
      "epoch: 4 step: 733, loss is 0.6462030410766602\n",
      "epoch: 4 step: 734, loss is 2.054136276245117\n",
      "epoch: 4 step: 735, loss is 2.0861988067626953\n",
      "epoch: 4 step: 736, loss is 0.7422077059745789\n",
      "epoch: 4 step: 737, loss is 0.7051696181297302\n",
      "epoch: 4 step: 738, loss is 0.46596989035606384\n",
      "epoch: 4 step: 739, loss is 1.857755422592163\n",
      "epoch: 4 step: 740, loss is 0.21427302062511444\n",
      "epoch: 4 step: 741, loss is 0.6026975512504578\n",
      "epoch: 4 step: 742, loss is 0.7299522161483765\n",
      "epoch: 4 step: 743, loss is 0.4033445119857788\n",
      "epoch: 4 step: 744, loss is 0.43420350551605225\n",
      "epoch: 4 step: 745, loss is 0.42503878474235535\n",
      "epoch: 4 step: 746, loss is 2.5225961208343506\n",
      "epoch: 4 step: 747, loss is 0.19965453445911407\n",
      "epoch: 4 step: 748, loss is 0.7158623337745667\n",
      "epoch: 4 step: 749, loss is 0.1450570523738861\n",
      "epoch: 4 step: 750, loss is 0.45868635177612305\n",
      "epoch: 4 step: 751, loss is 0.3714110851287842\n",
      "epoch: 4 step: 752, loss is 0.09295564889907837\n",
      "epoch: 4 step: 753, loss is 0.22270609438419342\n",
      "epoch: 4 step: 754, loss is 0.16991806030273438\n",
      "epoch: 4 step: 755, loss is 0.48408934473991394\n",
      "epoch: 4 step: 756, loss is 0.25974977016448975\n",
      "epoch: 4 step: 757, loss is 0.15931807458400726\n",
      "epoch: 4 step: 758, loss is 0.2528455853462219\n",
      "epoch: 4 step: 759, loss is 0.06842245906591415\n",
      "epoch: 4 step: 760, loss is 2.2435202598571777\n",
      "epoch: 4 step: 761, loss is 0.6656443476676941\n",
      "epoch: 4 step: 762, loss is 0.0792306512594223\n",
      "epoch: 4 step: 763, loss is 3.2811503410339355\n",
      "epoch: 4 step: 764, loss is 0.1503564864397049\n",
      "epoch: 4 step: 765, loss is 0.16809114813804626\n",
      "epoch: 4 step: 766, loss is 2.2226805686950684\n",
      "epoch: 4 step: 767, loss is 2.638524293899536\n",
      "epoch: 4 step: 768, loss is 0.7751327753067017\n",
      "epoch: 4 step: 769, loss is 0.4860715866088867\n",
      "epoch: 4 step: 770, loss is 0.7200251221656799\n",
      "epoch: 4 step: 771, loss is 0.12934598326683044\n",
      "epoch: 4 step: 772, loss is 0.17794090509414673\n",
      "epoch: 4 step: 773, loss is 0.22354421019554138\n",
      "epoch: 4 step: 774, loss is 0.099868543446064\n",
      "epoch: 4 step: 775, loss is 0.9325974583625793\n",
      "epoch: 4 step: 776, loss is 2.5333614349365234\n",
      "epoch: 4 step: 777, loss is 5.141091346740723\n",
      "epoch: 4 step: 778, loss is 0.38100555539131165\n",
      "epoch: 4 step: 779, loss is 4.135032653808594\n",
      "epoch: 4 step: 780, loss is 0.2663988173007965\n",
      "epoch: 4 step: 781, loss is 0.48740601539611816\n",
      "epoch: 4 step: 782, loss is 1.3532248735427856\n",
      "epoch: 4 step: 783, loss is 0.131612628698349\n",
      "epoch: 4 step: 784, loss is 1.9420021772384644\n",
      "epoch: 4 step: 785, loss is 2.28078031539917\n",
      "epoch: 4 step: 786, loss is 1.0139981508255005\n",
      "epoch: 4 step: 787, loss is 2.5791685581207275\n",
      "epoch: 4 step: 788, loss is 2.034597396850586\n",
      "epoch: 4 step: 789, loss is 1.894361972808838\n",
      "epoch: 4 step: 790, loss is 0.4360559582710266\n",
      "epoch: 4 step: 791, loss is 2.0616440773010254\n",
      "epoch: 4 step: 792, loss is 2.0250649452209473\n",
      "epoch: 4 step: 793, loss is 1.023482322692871\n",
      "epoch: 4 step: 794, loss is 1.5716662406921387\n",
      "epoch: 4 step: 795, loss is 2.0486838817596436\n",
      "epoch: 4 step: 796, loss is 0.7340112328529358\n",
      "epoch: 4 step: 797, loss is 0.7064439058303833\n",
      "epoch: 4 step: 798, loss is 1.8139020204544067\n",
      "epoch: 4 step: 799, loss is 1.7524387836456299\n",
      "epoch: 4 step: 800, loss is 1.629643440246582\n",
      "epoch: 4 step: 801, loss is 0.8248509168624878\n",
      "epoch: 4 step: 802, loss is 0.7376117706298828\n",
      "epoch: 4 step: 803, loss is 1.6849157810211182\n",
      "epoch: 4 step: 804, loss is 0.39224207401275635\n",
      "epoch: 4 step: 805, loss is 0.8560354113578796\n",
      "epoch: 4 step: 806, loss is 0.21651889383792877\n",
      "epoch: 4 step: 807, loss is 1.6431701183319092\n",
      "epoch: 4 step: 808, loss is 2.1011295318603516\n",
      "epoch: 4 step: 809, loss is 1.8023571968078613\n",
      "epoch: 4 step: 810, loss is 1.8769232034683228\n",
      "epoch: 4 step: 811, loss is 1.2303842306137085\n",
      "epoch: 4 step: 812, loss is 1.7835946083068848\n",
      "epoch: 4 step: 813, loss is 0.740598738193512\n",
      "epoch: 4 step: 814, loss is 3.5985686779022217\n",
      "epoch: 4 step: 815, loss is 0.8228087425231934\n",
      "epoch: 4 step: 816, loss is 0.4687877297401428\n",
      "epoch: 4 step: 817, loss is 0.6972718834877014\n",
      "epoch: 4 step: 818, loss is 0.5089056491851807\n",
      "epoch: 4 step: 819, loss is 0.3435855507850647\n",
      "epoch: 4 step: 820, loss is 0.5998636484146118\n",
      "epoch: 4 step: 821, loss is 0.21595242619514465\n",
      "epoch: 4 step: 822, loss is 0.556313693523407\n",
      "epoch: 4 step: 823, loss is 1.923614501953125\n",
      "epoch: 4 step: 824, loss is 2.8741488456726074\n",
      "epoch: 4 step: 825, loss is 0.42934080958366394\n",
      "epoch: 4 step: 826, loss is 1.6041357517242432\n",
      "epoch: 4 step: 827, loss is 0.45593371987342834\n",
      "epoch: 4 step: 828, loss is 2.0578346252441406\n",
      "epoch: 4 step: 829, loss is 0.11788485944271088\n",
      "epoch: 4 step: 830, loss is 0.44220513105392456\n",
      "epoch: 4 step: 831, loss is 0.6052106618881226\n",
      "epoch: 4 step: 832, loss is 0.5921711325645447\n",
      "epoch: 4 step: 833, loss is 1.8549156188964844\n",
      "epoch: 4 step: 834, loss is 0.33546558022499084\n",
      "epoch: 4 step: 835, loss is 0.4892025589942932\n",
      "epoch: 4 step: 836, loss is 0.1700180321931839\n",
      "epoch: 4 step: 837, loss is 0.18025615811347961\n",
      "epoch: 4 step: 838, loss is 0.1902499794960022\n",
      "epoch: 4 step: 839, loss is 0.2529059648513794\n",
      "epoch: 4 step: 840, loss is 1.6488696336746216\n",
      "epoch: 4 step: 841, loss is 2.167994260787964\n",
      "epoch: 4 step: 842, loss is 0.2620590925216675\n",
      "epoch: 4 step: 843, loss is 0.07642228901386261\n",
      "epoch: 4 step: 844, loss is 0.08218807727098465\n",
      "epoch: 4 step: 845, loss is 1.638286828994751\n",
      "epoch: 4 step: 846, loss is 0.7004511952400208\n",
      "epoch: 4 step: 847, loss is 0.04344790056347847\n",
      "epoch: 4 step: 848, loss is 0.053125035017728806\n",
      "epoch: 4 step: 849, loss is 2.82081937789917\n",
      "epoch: 4 step: 850, loss is 0.49654293060302734\n",
      "epoch: 4 step: 851, loss is 0.4157314598560333\n",
      "epoch: 4 step: 852, loss is 4.273838520050049\n",
      "epoch: 4 step: 853, loss is 1.6569417715072632\n",
      "epoch: 4 step: 854, loss is 0.5048912167549133\n",
      "epoch: 4 step: 855, loss is 0.1786695122718811\n",
      "epoch: 4 step: 856, loss is 2.9637715816497803\n",
      "epoch: 4 step: 857, loss is 0.7938193082809448\n",
      "epoch: 4 step: 858, loss is 0.526172399520874\n",
      "epoch: 4 step: 859, loss is 0.5300306677818298\n",
      "epoch: 4 step: 860, loss is 0.6154173612594604\n",
      "epoch: 4 step: 861, loss is 0.41878703236579895\n",
      "epoch: 4 step: 862, loss is 2.14199161529541\n",
      "epoch: 4 step: 863, loss is 0.2230280488729477\n",
      "epoch: 4 step: 864, loss is 0.2497026026248932\n",
      "epoch: 4 step: 865, loss is 5.4483489990234375\n",
      "epoch: 4 step: 866, loss is 2.66930890083313\n",
      "epoch: 4 step: 867, loss is 1.6318563222885132\n",
      "epoch: 4 step: 868, loss is 0.17192895710468292\n",
      "epoch: 4 step: 869, loss is 1.5906741619110107\n",
      "epoch: 4 step: 870, loss is 0.8308438062667847\n",
      "epoch: 4 step: 871, loss is 0.5587907433509827\n",
      "epoch: 4 step: 872, loss is 0.5275781154632568\n",
      "epoch: 4 step: 873, loss is 2.3751704692840576\n",
      "epoch: 4 step: 874, loss is 1.6315659284591675\n",
      "epoch: 4 step: 875, loss is 0.314559668302536\n",
      "epoch: 4 step: 876, loss is 0.606904923915863\n",
      "epoch: 4 step: 877, loss is 0.5683292150497437\n",
      "epoch: 4 step: 878, loss is 3.2947885990142822\n",
      "epoch: 4 step: 879, loss is 1.7687268257141113\n",
      "epoch: 4 step: 880, loss is 1.6973565816879272\n",
      "epoch: 4 step: 881, loss is 0.684982419013977\n",
      "epoch: 4 step: 882, loss is 0.8142967224121094\n",
      "epoch: 4 step: 883, loss is 2.1972124576568604\n",
      "epoch: 4 step: 884, loss is 0.3807563781738281\n",
      "epoch: 4 step: 885, loss is 1.7180712223052979\n",
      "epoch: 4 step: 886, loss is 1.660120964050293\n",
      "epoch: 4 step: 887, loss is 2.1888201236724854\n",
      "epoch: 4 step: 888, loss is 0.6752129197120667\n",
      "epoch: 4 step: 889, loss is 2.9626991748809814\n",
      "epoch: 4 step: 890, loss is 0.7165775895118713\n",
      "epoch: 4 step: 891, loss is 0.8659741282463074\n",
      "epoch: 4 step: 892, loss is 0.28814539313316345\n",
      "epoch: 4 step: 893, loss is 1.7074440717697144\n",
      "epoch: 4 step: 894, loss is 0.6391434073448181\n",
      "epoch: 4 step: 895, loss is 2.3275809288024902\n",
      "epoch: 4 step: 896, loss is 1.751875638961792\n",
      "epoch: 4 step: 897, loss is 0.865451991558075\n",
      "epoch: 4 step: 898, loss is 0.5139395594596863\n",
      "epoch: 4 step: 899, loss is 0.5423062443733215\n",
      "epoch: 4 step: 900, loss is 1.59584379196167\n",
      "epoch: 4 step: 901, loss is 2.4869978427886963\n",
      "epoch: 4 step: 902, loss is 1.8863554000854492\n",
      "epoch: 4 step: 903, loss is 0.9149097204208374\n",
      "epoch: 4 step: 904, loss is 0.23066116869449615\n",
      "epoch: 4 step: 905, loss is 1.647470235824585\n",
      "epoch: 4 step: 906, loss is 0.7377241849899292\n",
      "epoch: 4 step: 907, loss is 0.3242000639438629\n",
      "epoch: 4 step: 908, loss is 0.3468744456768036\n",
      "epoch: 4 step: 909, loss is 2.2751410007476807\n",
      "epoch: 4 step: 910, loss is 0.6158464550971985\n",
      "epoch: 4 step: 911, loss is 2.2861709594726562\n",
      "epoch: 4 step: 912, loss is 1.7095632553100586\n",
      "epoch: 4 step: 913, loss is 2.1851072311401367\n",
      "epoch: 4 step: 914, loss is 1.2710446119308472\n",
      "epoch: 4 step: 915, loss is 0.4888637959957123\n",
      "epoch: 4 step: 916, loss is 1.5955208539962769\n",
      "epoch: 4 step: 917, loss is 0.2843441665172577\n",
      "epoch: 4 step: 918, loss is 0.9020493030548096\n",
      "epoch: 4 step: 919, loss is 0.18982166051864624\n",
      "epoch: 4 step: 920, loss is 0.460493803024292\n",
      "epoch: 4 step: 921, loss is 3.3721933364868164\n",
      "epoch: 4 step: 922, loss is 0.1803370714187622\n",
      "epoch: 4 step: 923, loss is 0.3528972268104553\n",
      "epoch: 4 step: 924, loss is 0.1504950374364853\n",
      "epoch: 4 step: 925, loss is 0.41894856095314026\n",
      "epoch: 4 step: 926, loss is 0.11202686280012131\n",
      "epoch: 4 step: 927, loss is 0.16730104386806488\n",
      "epoch: 4 step: 928, loss is 1.7835347652435303\n",
      "epoch: 4 step: 929, loss is 0.567324161529541\n",
      "epoch: 4 step: 930, loss is 2.219693422317505\n",
      "epoch: 4 step: 931, loss is 0.24378840625286102\n",
      "epoch: 4 step: 932, loss is 0.4602937698364258\n",
      "epoch: 4 step: 933, loss is 0.8955082893371582\n",
      "epoch: 4 step: 934, loss is 2.034327507019043\n",
      "epoch: 4 step: 935, loss is 0.25588902831077576\n",
      "epoch: 4 step: 936, loss is 0.141693115234375\n",
      "epoch: 4 step: 937, loss is 2.9992384910583496\n",
      "epoch: 4 step: 938, loss is 0.5220770239830017\n",
      "epoch: 4 step: 939, loss is 1.826912522315979\n",
      "epoch: 4 step: 940, loss is 1.9629285335540771\n",
      "epoch: 4 step: 941, loss is 0.47446945309638977\n",
      "epoch: 4 step: 942, loss is 0.8093603849411011\n",
      "epoch: 4 step: 943, loss is 0.36092203855514526\n",
      "epoch: 4 step: 944, loss is 0.8122799396514893\n",
      "epoch: 4 step: 945, loss is 0.5577282309532166\n",
      "epoch: 4 step: 946, loss is 2.615701198577881\n",
      "epoch: 4 step: 947, loss is 1.872869610786438\n",
      "epoch: 4 step: 948, loss is 2.0839056968688965\n",
      "epoch: 4 step: 949, loss is 0.9954596757888794\n",
      "epoch: 4 step: 950, loss is 1.591646432876587\n",
      "epoch: 4 step: 951, loss is 2.5125231742858887\n",
      "epoch: 4 step: 952, loss is 0.3524291515350342\n",
      "epoch: 4 step: 953, loss is 0.43544507026672363\n",
      "epoch: 4 step: 954, loss is 0.2568974196910858\n",
      "epoch: 4 step: 955, loss is 2.0830891132354736\n",
      "epoch: 4 step: 956, loss is 0.8060820698738098\n",
      "epoch: 4 step: 957, loss is 2.3318774700164795\n",
      "epoch: 4 step: 958, loss is 0.3277547061443329\n",
      "epoch: 4 step: 959, loss is 1.6208336353302002\n",
      "epoch: 4 step: 960, loss is 0.3733454644680023\n",
      "epoch: 4 step: 961, loss is 0.21133697032928467\n",
      "epoch: 4 step: 962, loss is 0.4548409581184387\n",
      "epoch: 4 step: 963, loss is 1.9933048486709595\n",
      "epoch: 4 step: 964, loss is 0.5817636251449585\n",
      "epoch: 4 step: 965, loss is 0.28760939836502075\n",
      "epoch: 4 step: 966, loss is 0.6727706789970398\n",
      "epoch: 4 step: 967, loss is 0.6469135880470276\n",
      "epoch: 4 step: 968, loss is 0.552166223526001\n",
      "epoch: 4 step: 969, loss is 1.9477136135101318\n",
      "epoch: 4 step: 970, loss is 0.2574189603328705\n",
      "epoch: 4 step: 971, loss is 0.3825334310531616\n",
      "epoch: 4 step: 972, loss is 1.9059326648712158\n",
      "epoch: 4 step: 973, loss is 0.06941443681716919\n",
      "epoch: 4 step: 974, loss is 0.35401248931884766\n",
      "epoch: 4 step: 975, loss is 0.11481248587369919\n",
      "epoch: 4 step: 976, loss is 0.323721706867218\n",
      "epoch: 4 step: 977, loss is 0.10272359102964401\n",
      "epoch: 4 step: 978, loss is 0.4200771450996399\n",
      "epoch: 4 step: 979, loss is 2.68107008934021\n",
      "epoch: 4 step: 980, loss is 0.06760711222887039\n",
      "epoch: 4 step: 981, loss is 1.6942224502563477\n",
      "epoch: 4 step: 982, loss is 0.5194523334503174\n",
      "epoch: 4 step: 983, loss is 1.3350880146026611\n",
      "epoch: 4 step: 984, loss is 0.244850754737854\n",
      "epoch: 4 step: 985, loss is 0.08391883969306946\n",
      "epoch: 4 step: 986, loss is 0.08404017239809036\n",
      "epoch: 4 step: 987, loss is 3.732004165649414\n",
      "epoch: 4 step: 988, loss is 0.10369814187288284\n",
      "epoch: 4 step: 989, loss is 0.08925241976976395\n",
      "epoch: 4 step: 990, loss is 0.285017728805542\n",
      "epoch: 4 step: 991, loss is 0.10739856958389282\n",
      "epoch: 4 step: 992, loss is 6.330358028411865\n",
      "epoch: 4 step: 993, loss is 1.813468337059021\n",
      "epoch: 4 step: 994, loss is 0.8350841403007507\n",
      "epoch: 4 step: 995, loss is 0.4637967050075531\n",
      "epoch: 4 step: 996, loss is 0.192240908741951\n",
      "epoch: 4 step: 997, loss is 0.07212651520967484\n",
      "epoch: 4 step: 998, loss is 0.3482636511325836\n",
      "epoch: 4 step: 999, loss is 0.16058163344860077\n",
      "epoch: 4 step: 1000, loss is 2.6720874309539795\n",
      "epoch: 4 step: 1001, loss is 0.2777027487754822\n",
      "epoch: 4 step: 1002, loss is 3.71514892578125\n",
      "epoch: 4 step: 1003, loss is 0.35394546389579773\n",
      "epoch: 4 step: 1004, loss is 1.7018563747406006\n",
      "epoch: 4 step: 1005, loss is 1.6493875980377197\n",
      "epoch: 4 step: 1006, loss is 0.28673097491264343\n",
      "epoch: 4 step: 1007, loss is 1.7798027992248535\n",
      "epoch: 4 step: 1008, loss is 0.39561811089515686\n",
      "epoch: 4 step: 1009, loss is 2.282697916030884\n",
      "epoch: 4 step: 1010, loss is 1.7691714763641357\n",
      "epoch: 4 step: 1011, loss is 0.4556272625923157\n",
      "epoch: 4 step: 1012, loss is 2.219857692718506\n",
      "epoch: 4 step: 1013, loss is 0.29042938351631165\n",
      "epoch: 4 step: 1014, loss is 0.551786482334137\n",
      "epoch: 4 step: 1015, loss is 2.5822043418884277\n",
      "epoch: 4 step: 1016, loss is 0.18237881362438202\n",
      "epoch: 4 step: 1017, loss is 0.27305668592453003\n",
      "epoch: 4 step: 1018, loss is 1.8366882801055908\n",
      "epoch: 4 step: 1019, loss is 1.7397921085357666\n",
      "epoch: 4 step: 1020, loss is 0.16332420706748962\n",
      "epoch: 4 step: 1021, loss is 0.21087858080863953\n",
      "epoch: 4 step: 1022, loss is 2.489199161529541\n",
      "epoch: 4 step: 1023, loss is 0.4222448170185089\n",
      "epoch: 4 step: 1024, loss is 0.8518717288970947\n",
      "epoch: 4 step: 1025, loss is 0.21155792474746704\n",
      "epoch: 4 step: 1026, loss is 0.308527410030365\n",
      "epoch: 4 step: 1027, loss is 0.09087838232517242\n",
      "epoch: 4 step: 1028, loss is 1.5908668041229248\n",
      "epoch: 4 step: 1029, loss is 0.05134247988462448\n",
      "epoch: 4 step: 1030, loss is 1.921984314918518\n",
      "epoch: 4 step: 1031, loss is 0.5184721946716309\n",
      "epoch: 4 step: 1032, loss is 2.8749451637268066\n",
      "epoch: 4 step: 1033, loss is 0.16718748211860657\n",
      "epoch: 4 step: 1034, loss is 2.659090518951416\n",
      "epoch: 4 step: 1035, loss is 0.3204963207244873\n",
      "epoch: 4 step: 1036, loss is 0.1888386458158493\n",
      "epoch: 4 step: 1037, loss is 2.7448620796203613\n",
      "epoch: 4 step: 1038, loss is 1.6027895212173462\n",
      "epoch: 4 step: 1039, loss is 1.9621832370758057\n",
      "epoch: 4 step: 1040, loss is 0.3687552809715271\n",
      "epoch: 4 step: 1041, loss is 0.794661819934845\n",
      "epoch: 4 step: 1042, loss is 1.1159788370132446\n",
      "epoch: 4 step: 1043, loss is 0.34403640031814575\n",
      "epoch: 4 step: 1044, loss is 0.14444932341575623\n",
      "epoch: 4 step: 1045, loss is 0.17356258630752563\n",
      "epoch: 4 step: 1046, loss is 0.2921585142612457\n",
      "epoch: 4 step: 1047, loss is 0.6096510887145996\n",
      "epoch: 4 step: 1048, loss is 0.696453332901001\n",
      "epoch: 4 step: 1049, loss is 2.7504794597625732\n",
      "epoch: 4 step: 1050, loss is 0.6253791451454163\n",
      "epoch: 4 step: 1051, loss is 0.26628968119621277\n",
      "epoch: 4 step: 1052, loss is 0.8981333374977112\n",
      "epoch: 4 step: 1053, loss is 0.5811017155647278\n",
      "epoch: 4 step: 1054, loss is 1.9738725423812866\n",
      "epoch: 4 step: 1055, loss is 0.46935680508613586\n",
      "epoch: 4 step: 1056, loss is 0.8228028416633606\n",
      "epoch: 4 step: 1057, loss is 1.7597861289978027\n",
      "epoch: 4 step: 1058, loss is 0.11382169276475906\n",
      "epoch: 4 step: 1059, loss is 3.721526861190796\n",
      "epoch: 4 step: 1060, loss is 3.0223467350006104\n",
      "epoch: 4 step: 1061, loss is 0.1288345903158188\n",
      "epoch: 4 step: 1062, loss is 2.7593977451324463\n",
      "epoch: 4 step: 1063, loss is 0.6067026257514954\n",
      "epoch: 4 step: 1064, loss is 0.4953053891658783\n",
      "epoch: 4 step: 1065, loss is 2.0525269508361816\n",
      "epoch: 4 step: 1066, loss is 0.5517029762268066\n",
      "epoch: 4 step: 1067, loss is 0.9584683775901794\n",
      "epoch: 4 step: 1068, loss is 0.4419732987880707\n",
      "epoch: 4 step: 1069, loss is 2.305227756500244\n",
      "epoch: 4 step: 1070, loss is 2.067396402359009\n",
      "epoch: 4 step: 1071, loss is 0.20904788374900818\n",
      "epoch: 4 step: 1072, loss is 0.8203989863395691\n",
      "epoch: 4 step: 1073, loss is 1.874976634979248\n",
      "epoch: 4 step: 1074, loss is 1.0315556526184082\n",
      "epoch: 4 step: 1075, loss is 0.45231086015701294\n",
      "epoch: 4 step: 1076, loss is 1.974576711654663\n",
      "epoch: 4 step: 1077, loss is 1.905334711074829\n",
      "epoch: 4 step: 1078, loss is 0.22222578525543213\n",
      "epoch: 4 step: 1079, loss is 2.051943302154541\n",
      "epoch: 4 step: 1080, loss is 2.125694513320923\n",
      "epoch: 4 step: 1081, loss is 1.6880849599838257\n",
      "epoch: 4 step: 1082, loss is 2.070230007171631\n",
      "epoch: 4 step: 1083, loss is 1.6600937843322754\n",
      "epoch: 4 step: 1084, loss is 0.7957534193992615\n",
      "epoch: 4 step: 1085, loss is 0.1816791445016861\n",
      "epoch: 4 step: 1086, loss is 1.5249099731445312\n",
      "epoch: 4 step: 1087, loss is 1.1962652206420898\n",
      "epoch: 4 step: 1088, loss is 0.3580757975578308\n",
      "epoch: 4 step: 1089, loss is 1.583723783493042\n",
      "epoch: 4 step: 1090, loss is 0.9279609322547913\n",
      "epoch: 4 step: 1091, loss is 1.6194599866867065\n",
      "epoch: 4 step: 1092, loss is 0.4551551342010498\n",
      "epoch: 4 step: 1093, loss is 0.7051082253456116\n",
      "epoch: 4 step: 1094, loss is 0.3326950967311859\n",
      "epoch: 4 step: 1095, loss is 0.47186991572380066\n",
      "epoch: 4 step: 1096, loss is 0.6119523048400879\n",
      "epoch: 4 step: 1097, loss is 3.0496530532836914\n",
      "epoch: 4 step: 1098, loss is 0.34407079219818115\n",
      "epoch: 4 step: 1099, loss is 0.37293314933776855\n",
      "epoch: 4 step: 1100, loss is 0.39583805203437805\n",
      "epoch: 4 step: 1101, loss is 0.5562905669212341\n",
      "epoch: 4 step: 1102, loss is 0.09011546522378922\n",
      "epoch: 4 step: 1103, loss is 0.30261746048927307\n",
      "epoch: 4 step: 1104, loss is 1.0143392086029053\n",
      "epoch: 4 step: 1105, loss is 1.7115089893341064\n",
      "epoch: 4 step: 1106, loss is 2.985276937484741\n",
      "epoch: 4 step: 1107, loss is 2.06272554397583\n",
      "epoch: 4 step: 1108, loss is 1.7306305170059204\n",
      "epoch: 4 step: 1109, loss is 0.23441261053085327\n",
      "epoch: 4 step: 1110, loss is 5.038395881652832\n",
      "epoch: 4 step: 1111, loss is 0.6106765866279602\n",
      "epoch: 4 step: 1112, loss is 0.6280676126480103\n",
      "epoch: 4 step: 1113, loss is 2.0183050632476807\n",
      "epoch: 4 step: 1114, loss is 0.5646528005599976\n",
      "epoch: 4 step: 1115, loss is 0.7230956554412842\n",
      "epoch: 4 step: 1116, loss is 1.6185495853424072\n",
      "epoch: 4 step: 1117, loss is 0.6589409112930298\n",
      "epoch: 4 step: 1118, loss is 0.7977911233901978\n",
      "epoch: 4 step: 1119, loss is 0.2671816051006317\n",
      "epoch: 4 step: 1120, loss is 2.8664441108703613\n",
      "epoch: 4 step: 1121, loss is 0.6981953382492065\n",
      "epoch: 4 step: 1122, loss is 1.7172948122024536\n",
      "epoch: 4 step: 1123, loss is 0.5926306843757629\n",
      "epoch: 4 step: 1124, loss is 0.4196303188800812\n",
      "epoch: 4 step: 1125, loss is 0.4095418453216553\n",
      "epoch: 4 step: 1126, loss is 3.4601945877075195\n",
      "epoch: 4 step: 1127, loss is 0.46496841311454773\n",
      "epoch: 4 step: 1128, loss is 2.3759090900421143\n",
      "epoch: 4 step: 1129, loss is 0.15734702348709106\n",
      "epoch: 4 step: 1130, loss is 0.609723687171936\n",
      "epoch: 4 step: 1131, loss is 1.846348762512207\n",
      "epoch: 4 step: 1132, loss is 1.9702653884887695\n",
      "epoch: 4 step: 1133, loss is 0.35398170351982117\n",
      "epoch: 4 step: 1134, loss is 0.6859646439552307\n",
      "epoch: 4 step: 1135, loss is 1.7881863117218018\n",
      "epoch: 4 step: 1136, loss is 0.3494676649570465\n",
      "epoch: 4 step: 1137, loss is 2.8704721927642822\n",
      "epoch: 4 step: 1138, loss is 0.4481752812862396\n",
      "epoch: 4 step: 1139, loss is 2.1994142532348633\n",
      "epoch: 4 step: 1140, loss is 2.4394586086273193\n",
      "epoch: 4 step: 1141, loss is 1.2681535482406616\n",
      "epoch: 4 step: 1142, loss is 0.5017182230949402\n",
      "epoch: 4 step: 1143, loss is 0.6846862435340881\n",
      "epoch: 4 step: 1144, loss is 1.802844762802124\n",
      "epoch: 4 step: 1145, loss is 0.6063922047615051\n",
      "epoch: 4 step: 1146, loss is 0.43762150406837463\n",
      "epoch: 4 step: 1147, loss is 0.1673213094472885\n",
      "epoch: 4 step: 1148, loss is 2.9613637924194336\n",
      "epoch: 4 step: 1149, loss is 1.7936090230941772\n",
      "epoch: 4 step: 1150, loss is 0.6918354630470276\n",
      "epoch: 4 step: 1151, loss is 0.27259090542793274\n",
      "epoch: 4 step: 1152, loss is 3.1263339519500732\n",
      "epoch: 4 step: 1153, loss is 0.36205777525901794\n",
      "epoch: 4 step: 1154, loss is 1.9061073064804077\n",
      "epoch: 4 step: 1155, loss is 0.2789369821548462\n",
      "epoch: 4 step: 1156, loss is 1.9446991682052612\n",
      "epoch: 4 step: 1157, loss is 2.1576619148254395\n",
      "epoch: 4 step: 1158, loss is 2.0705618858337402\n",
      "epoch: 4 step: 1159, loss is 0.5652968883514404\n",
      "epoch: 4 step: 1160, loss is 0.40613824129104614\n",
      "epoch: 4 step: 1161, loss is 0.2868465185165405\n",
      "epoch: 4 step: 1162, loss is 1.1943438053131104\n",
      "epoch: 4 step: 1163, loss is 0.3122377395629883\n",
      "epoch: 4 step: 1164, loss is 0.3088230788707733\n",
      "epoch: 4 step: 1165, loss is 0.6729483604431152\n",
      "epoch: 4 step: 1166, loss is 0.27673983573913574\n",
      "epoch: 4 step: 1167, loss is 0.3554539084434509\n",
      "epoch: 4 step: 1168, loss is 0.15563717484474182\n",
      "epoch: 4 step: 1169, loss is 1.679152250289917\n",
      "epoch: 4 step: 1170, loss is 2.2191691398620605\n",
      "epoch: 4 step: 1171, loss is 1.913766860961914\n",
      "epoch: 4 step: 1172, loss is 2.0945639610290527\n",
      "epoch: 4 step: 1173, loss is 2.505352020263672\n",
      "epoch: 4 step: 1174, loss is 0.5573634505271912\n",
      "epoch: 4 step: 1175, loss is 2.2187180519104004\n",
      "epoch: 4 step: 1176, loss is 0.46821874380111694\n",
      "epoch: 4 step: 1177, loss is 0.7371421456336975\n",
      "epoch: 4 step: 1178, loss is 0.4857490658760071\n",
      "epoch: 4 step: 1179, loss is 0.7840733528137207\n",
      "epoch: 4 step: 1180, loss is 0.3602412939071655\n",
      "epoch: 4 step: 1181, loss is 0.4285239279270172\n",
      "epoch: 4 step: 1182, loss is 1.8024505376815796\n",
      "epoch: 4 step: 1183, loss is 0.21704867482185364\n",
      "epoch: 4 step: 1184, loss is 0.5416182279586792\n",
      "epoch: 4 step: 1185, loss is 3.480808973312378\n",
      "epoch: 4 step: 1186, loss is 0.409960001707077\n",
      "epoch: 4 step: 1187, loss is 0.42799195647239685\n",
      "epoch: 4 step: 1188, loss is 0.3654267191886902\n",
      "epoch: 4 step: 1189, loss is 0.71462482213974\n",
      "epoch: 4 step: 1190, loss is 2.3638200759887695\n",
      "epoch: 4 step: 1191, loss is 0.23908625543117523\n",
      "epoch: 4 step: 1192, loss is 0.12026268988847733\n",
      "epoch: 4 step: 1193, loss is 2.256657123565674\n",
      "epoch: 4 step: 1194, loss is 0.6626602411270142\n",
      "epoch: 4 step: 1195, loss is 0.25888746976852417\n",
      "epoch: 4 step: 1196, loss is 0.3990548253059387\n",
      "epoch: 4 step: 1197, loss is 0.10942880809307098\n",
      "epoch: 4 step: 1198, loss is 2.3594157695770264\n",
      "epoch: 4 step: 1199, loss is 0.17143598198890686\n",
      "epoch: 4 step: 1200, loss is 2.5942625999450684\n",
      "epoch: 4 step: 1201, loss is 0.15950855612754822\n",
      "epoch: 4 step: 1202, loss is 1.9023739099502563\n",
      "epoch: 4 step: 1203, loss is 0.4664519727230072\n",
      "epoch: 4 step: 1204, loss is 0.3728165626525879\n",
      "epoch: 4 step: 1205, loss is 0.14903146028518677\n",
      "epoch: 4 step: 1206, loss is 0.44007760286331177\n",
      "epoch: 4 step: 1207, loss is 0.09720350801944733\n",
      "epoch: 4 step: 1208, loss is 0.08120749145746231\n",
      "epoch: 4 step: 1209, loss is 0.22288192808628082\n",
      "epoch: 4 step: 1210, loss is 0.23595979809761047\n",
      "epoch: 4 step: 1211, loss is 3.076838970184326\n",
      "epoch: 4 step: 1212, loss is 1.6651345491409302\n",
      "epoch: 4 step: 1213, loss is 0.2904244661331177\n",
      "epoch: 4 step: 1214, loss is 1.202871561050415\n",
      "epoch: 4 step: 1215, loss is 0.7022119164466858\n",
      "epoch: 4 step: 1216, loss is 0.08442534506320953\n",
      "epoch: 4 step: 1217, loss is 0.513462483882904\n",
      "epoch: 4 step: 1218, loss is 0.29744642972946167\n",
      "epoch: 4 step: 1219, loss is 0.03887571394443512\n",
      "epoch: 4 step: 1220, loss is 0.11073935031890869\n",
      "epoch: 4 step: 1221, loss is 2.543369770050049\n",
      "epoch: 4 step: 1222, loss is 0.03176148608326912\n",
      "epoch: 4 step: 1223, loss is 0.15465334057807922\n",
      "epoch: 4 step: 1224, loss is 2.742851972579956\n",
      "epoch: 4 step: 1225, loss is 0.09034256637096405\n",
      "epoch: 4 step: 1226, loss is 1.8096578121185303\n",
      "epoch: 4 step: 1227, loss is 1.8100671768188477\n",
      "epoch: 4 step: 1228, loss is 0.6057079434394836\n",
      "epoch: 4 step: 1229, loss is 2.5806665420532227\n",
      "epoch: 4 step: 1230, loss is 0.3260522782802582\n",
      "epoch: 4 step: 1231, loss is 2.7037699222564697\n",
      "epoch: 4 step: 1232, loss is 0.3180336654186249\n",
      "epoch: 4 step: 1233, loss is 0.2859385907649994\n",
      "epoch: 4 step: 1234, loss is 2.351266384124756\n",
      "epoch: 4 step: 1235, loss is 0.534305214881897\n",
      "epoch: 4 step: 1236, loss is 1.9533708095550537\n",
      "epoch: 4 step: 1237, loss is 1.7917197942733765\n",
      "epoch: 4 step: 1238, loss is 1.7088642120361328\n",
      "epoch: 4 step: 1239, loss is 1.8340493440628052\n",
      "epoch: 4 step: 1240, loss is 0.6020691394805908\n",
      "epoch: 4 step: 1241, loss is 0.3752245008945465\n",
      "epoch: 4 step: 1242, loss is 3.540794610977173\n",
      "epoch: 4 step: 1243, loss is 1.6301900148391724\n",
      "epoch: 4 step: 1244, loss is 1.7146716117858887\n",
      "epoch: 4 step: 1245, loss is 0.3089543879032135\n",
      "epoch: 4 step: 1246, loss is 0.3266875743865967\n",
      "epoch: 4 step: 1247, loss is 2.051642417907715\n",
      "epoch: 4 step: 1248, loss is 1.7677812576293945\n",
      "epoch: 4 step: 1249, loss is 0.5233131051063538\n",
      "epoch: 4 step: 1250, loss is 2.080573797225952\n",
      "epoch: 4 step: 1251, loss is 0.22246716916561127\n",
      "epoch: 4 step: 1252, loss is 0.49877968430519104\n",
      "epoch: 4 step: 1253, loss is 1.5027364492416382\n",
      "epoch: 4 step: 1254, loss is 0.35836926102638245\n",
      "epoch: 4 step: 1255, loss is 0.5569686889648438\n",
      "epoch: 4 step: 1256, loss is 0.1549883633852005\n",
      "epoch: 4 step: 1257, loss is 1.651289463043213\n",
      "epoch: 4 step: 1258, loss is 0.8132203221321106\n",
      "epoch: 4 step: 1259, loss is 2.041090965270996\n",
      "epoch: 4 step: 1260, loss is 0.2540785074234009\n",
      "epoch: 4 step: 1261, loss is 0.21668313443660736\n",
      "epoch: 4 step: 1262, loss is 0.45764440298080444\n",
      "epoch: 4 step: 1263, loss is 0.5621964931488037\n",
      "epoch: 4 step: 1264, loss is 3.370060920715332\n",
      "epoch: 4 step: 1265, loss is 0.04624670743942261\n",
      "epoch: 4 step: 1266, loss is 3.1025023460388184\n",
      "epoch: 4 step: 1267, loss is 2.1525988578796387\n",
      "epoch: 4 step: 1268, loss is 0.3427509665489197\n",
      "epoch: 4 step: 1269, loss is 1.7957683801651\n",
      "epoch: 4 step: 1270, loss is 1.9943010807037354\n",
      "epoch: 4 step: 1271, loss is 2.097576141357422\n",
      "epoch: 4 step: 1272, loss is 0.5881925225257874\n",
      "epoch: 4 step: 1273, loss is 0.9234642386436462\n",
      "epoch: 4 step: 1274, loss is 0.53905189037323\n",
      "epoch: 4 step: 1275, loss is 0.07318484783172607\n",
      "epoch: 4 step: 1276, loss is 0.847971498966217\n",
      "epoch: 4 step: 1277, loss is 0.21073877811431885\n",
      "epoch: 4 step: 1278, loss is 0.1711001843214035\n",
      "epoch: 4 step: 1279, loss is 0.45110905170440674\n",
      "epoch: 4 step: 1280, loss is 2.4052159786224365\n",
      "epoch: 4 step: 1281, loss is 0.08967220783233643\n",
      "epoch: 4 step: 1282, loss is 1.5576269626617432\n",
      "epoch: 4 step: 1283, loss is 3.079688787460327\n",
      "epoch: 4 step: 1284, loss is 0.30476102232933044\n",
      "epoch: 4 step: 1285, loss is 0.8456459641456604\n",
      "epoch: 4 step: 1286, loss is 0.07399499416351318\n",
      "epoch: 4 step: 1287, loss is 0.10528609901666641\n",
      "epoch: 4 step: 1288, loss is 0.04481414332985878\n",
      "epoch: 4 step: 1289, loss is 0.15981371700763702\n",
      "epoch: 4 step: 1290, loss is 3.25923490524292\n",
      "epoch: 4 step: 1291, loss is 2.5058107376098633\n",
      "epoch: 4 step: 1292, loss is 0.5908446311950684\n",
      "epoch: 4 step: 1293, loss is 1.9537036418914795\n",
      "epoch: 4 step: 1294, loss is 0.4106275737285614\n",
      "epoch: 4 step: 1295, loss is 0.5367193818092346\n",
      "epoch: 4 step: 1296, loss is 0.27110984921455383\n",
      "epoch: 4 step: 1297, loss is 0.1326892077922821\n",
      "epoch: 4 step: 1298, loss is 0.020697329193353653\n",
      "epoch: 4 step: 1299, loss is 0.07609301805496216\n",
      "epoch: 4 step: 1300, loss is 3.303631067276001\n",
      "epoch: 4 step: 1301, loss is 0.296293169260025\n",
      "epoch: 4 step: 1302, loss is 0.2312709242105484\n",
      "epoch: 4 step: 1303, loss is 1.8886581659317017\n",
      "epoch: 4 step: 1304, loss is 0.18213193118572235\n",
      "epoch: 4 step: 1305, loss is 0.3186857998371124\n",
      "epoch: 4 step: 1306, loss is 1.8635356426239014\n",
      "epoch: 4 step: 1307, loss is 0.20469039678573608\n",
      "epoch: 4 step: 1308, loss is 2.2111916542053223\n",
      "epoch: 4 step: 1309, loss is 0.17174173891544342\n",
      "epoch: 4 step: 1310, loss is 0.34188446402549744\n",
      "epoch: 4 step: 1311, loss is 1.745980978012085\n",
      "epoch: 4 step: 1312, loss is 0.22295518219470978\n",
      "epoch: 4 step: 1313, loss is 1.9540235996246338\n",
      "epoch: 4 step: 1314, loss is 0.07334969937801361\n",
      "epoch: 4 step: 1315, loss is 1.8931509256362915\n",
      "epoch: 4 step: 1316, loss is 0.3531166613101959\n",
      "epoch: 4 step: 1317, loss is 0.11348354071378708\n",
      "epoch: 4 step: 1318, loss is 3.68037486076355\n",
      "epoch: 4 step: 1319, loss is 1.021620512008667\n",
      "epoch: 4 step: 1320, loss is 1.7220759391784668\n",
      "epoch: 4 step: 1321, loss is 0.5693245530128479\n",
      "epoch: 4 step: 1322, loss is 0.8203125\n",
      "epoch: 4 step: 1323, loss is 2.3737058639526367\n",
      "epoch: 4 step: 1324, loss is 2.4597954750061035\n",
      "epoch: 4 step: 1325, loss is 0.6530847549438477\n",
      "epoch: 4 step: 1326, loss is 2.0864083766937256\n",
      "epoch: 4 step: 1327, loss is 0.3975001871585846\n",
      "epoch: 4 step: 1328, loss is 2.018230438232422\n",
      "epoch: 4 step: 1329, loss is 0.34266018867492676\n",
      "epoch: 4 step: 1330, loss is 0.3237559497356415\n",
      "epoch: 4 step: 1331, loss is 2.334857225418091\n",
      "epoch: 4 step: 1332, loss is 2.715399742126465\n",
      "epoch: 4 step: 1333, loss is 0.8175003528594971\n",
      "epoch: 4 step: 1334, loss is 1.6394004821777344\n",
      "epoch: 4 step: 1335, loss is 2.2438759803771973\n",
      "epoch: 4 step: 1336, loss is 1.7029846906661987\n",
      "epoch: 4 step: 1337, loss is 1.826859951019287\n",
      "epoch: 4 step: 1338, loss is 1.3525536060333252\n",
      "epoch: 4 step: 1339, loss is 1.3517709970474243\n",
      "epoch: 4 step: 1340, loss is 1.716928482055664\n",
      "epoch: 4 step: 1341, loss is 0.845668375492096\n",
      "epoch: 4 step: 1342, loss is 0.8682717084884644\n",
      "epoch: 4 step: 1343, loss is 2.1042158603668213\n",
      "epoch: 4 step: 1344, loss is 2.1266987323760986\n",
      "epoch: 4 step: 1345, loss is 0.6610015630722046\n",
      "epoch: 4 step: 1346, loss is 0.9204659461975098\n",
      "epoch: 4 step: 1347, loss is 1.6008410453796387\n",
      "epoch: 4 step: 1348, loss is 1.351157784461975\n",
      "epoch: 4 step: 1349, loss is 0.6186704635620117\n",
      "epoch: 4 step: 1350, loss is 0.5203124284744263\n",
      "epoch: 4 step: 1351, loss is 1.7364870309829712\n",
      "epoch: 4 step: 1352, loss is 0.6992061734199524\n",
      "epoch: 4 step: 1353, loss is 0.5093212127685547\n",
      "epoch: 4 step: 1354, loss is 0.8898228406906128\n",
      "epoch: 4 step: 1355, loss is 0.548222541809082\n",
      "epoch: 4 step: 1356, loss is 0.4706633985042572\n",
      "epoch: 4 step: 1357, loss is 1.6658997535705566\n",
      "epoch: 4 step: 1358, loss is 0.4259749948978424\n",
      "epoch: 4 step: 1359, loss is 0.17614330351352692\n",
      "epoch: 4 step: 1360, loss is 0.3400159776210785\n",
      "epoch: 4 step: 1361, loss is 2.03194260597229\n",
      "epoch: 4 step: 1362, loss is 2.0402276515960693\n",
      "epoch: 4 step: 1363, loss is 0.6158171892166138\n",
      "epoch: 4 step: 1364, loss is 0.6836866140365601\n",
      "epoch: 4 step: 1365, loss is 1.6694318056106567\n",
      "epoch: 4 step: 1366, loss is 0.389741450548172\n",
      "epoch: 4 step: 1367, loss is 0.1628178507089615\n",
      "epoch: 4 step: 1368, loss is 1.7322173118591309\n",
      "epoch: 4 step: 1369, loss is 2.173130512237549\n",
      "epoch: 4 step: 1370, loss is 0.35613343119621277\n",
      "epoch: 4 step: 1371, loss is 1.6447120904922485\n",
      "epoch: 4 step: 1372, loss is 0.3159882128238678\n",
      "epoch: 4 step: 1373, loss is 0.8270382285118103\n",
      "epoch: 4 step: 1374, loss is 0.07479353994131088\n",
      "epoch: 4 step: 1375, loss is 3.5166146755218506\n",
      "epoch: 4 step: 1376, loss is 0.6830651760101318\n",
      "epoch: 4 step: 1377, loss is 0.5874542593955994\n",
      "epoch: 4 step: 1378, loss is 1.7365245819091797\n",
      "epoch: 4 step: 1379, loss is 0.5787594318389893\n",
      "epoch: 4 step: 1380, loss is 0.13711830973625183\n",
      "epoch: 4 step: 1381, loss is 0.07745590060949326\n",
      "epoch: 4 step: 1382, loss is 0.0894327461719513\n",
      "epoch: 4 step: 1383, loss is 0.16617700457572937\n",
      "epoch: 4 step: 1384, loss is 0.09740111231803894\n",
      "epoch: 4 step: 1385, loss is 2.8838205337524414\n",
      "epoch: 4 step: 1386, loss is 0.8747220635414124\n",
      "epoch: 4 step: 1387, loss is 2.0068893432617188\n",
      "epoch: 4 step: 1388, loss is 1.6853547096252441\n",
      "epoch: 4 step: 1389, loss is 0.15801902115345\n",
      "epoch: 4 step: 1390, loss is 1.2217153310775757\n",
      "epoch: 4 step: 1391, loss is 0.17843249440193176\n",
      "epoch: 4 step: 1392, loss is 0.07671865820884705\n",
      "epoch: 4 step: 1393, loss is 2.3725390434265137\n",
      "epoch: 4 step: 1394, loss is 1.7601022720336914\n",
      "epoch: 4 step: 1395, loss is 0.6570630669593811\n",
      "epoch: 4 step: 1396, loss is 0.3168250024318695\n",
      "epoch: 4 step: 1397, loss is 0.7923349738121033\n",
      "epoch: 4 step: 1398, loss is 0.2300688475370407\n",
      "epoch: 4 step: 1399, loss is 1.551630973815918\n",
      "epoch: 4 step: 1400, loss is 0.8437894582748413\n",
      "epoch: 4 step: 1401, loss is 0.052709296345710754\n",
      "epoch: 4 step: 1402, loss is 0.12272914499044418\n",
      "epoch: 4 step: 1403, loss is 3.5194551944732666\n",
      "epoch: 4 step: 1404, loss is 2.080141067504883\n",
      "epoch: 4 step: 1405, loss is 2.383474826812744\n",
      "epoch: 4 step: 1406, loss is 0.3779223561286926\n",
      "epoch: 4 step: 1407, loss is 0.251912921667099\n",
      "epoch: 4 step: 1408, loss is 1.9212636947631836\n",
      "epoch: 4 step: 1409, loss is 2.0471277236938477\n",
      "epoch: 4 step: 1410, loss is 0.3976968228816986\n",
      "epoch: 4 step: 1411, loss is 0.38868314027786255\n",
      "epoch: 4 step: 1412, loss is 1.8172390460968018\n",
      "epoch: 4 step: 1413, loss is 0.14875483512878418\n",
      "epoch: 4 step: 1414, loss is 1.9300918579101562\n",
      "epoch: 4 step: 1415, loss is 1.039613127708435\n",
      "epoch: 4 step: 1416, loss is 2.3281939029693604\n",
      "epoch: 4 step: 1417, loss is 2.7436466217041016\n",
      "epoch: 4 step: 1418, loss is 0.3054733872413635\n",
      "epoch: 4 step: 1419, loss is 2.734541654586792\n",
      "epoch: 4 step: 1420, loss is 0.39578768610954285\n",
      "epoch: 4 step: 1421, loss is 0.35090622305870056\n",
      "epoch: 4 step: 1422, loss is 1.3233120441436768\n",
      "epoch: 4 step: 1423, loss is 1.6478195190429688\n",
      "epoch: 4 step: 1424, loss is 0.9175326228141785\n",
      "epoch: 4 step: 1425, loss is 1.6498727798461914\n",
      "epoch: 4 step: 1426, loss is 0.3560742139816284\n",
      "epoch: 4 step: 1427, loss is 0.27929580211639404\n",
      "epoch: 4 step: 1428, loss is 3.237762451171875\n",
      "epoch: 4 step: 1429, loss is 1.819651484489441\n",
      "epoch: 4 step: 1430, loss is 1.81107759475708\n",
      "epoch: 4 step: 1431, loss is 0.6259213089942932\n",
      "epoch: 4 step: 1432, loss is 0.747736394405365\n",
      "epoch: 4 step: 1433, loss is 1.224653959274292\n",
      "epoch: 4 step: 1434, loss is 0.5330951809883118\n",
      "epoch: 4 step: 1435, loss is 2.082578659057617\n",
      "epoch: 4 step: 1436, loss is 2.1952123641967773\n",
      "epoch: 4 step: 1437, loss is 2.756146192550659\n",
      "epoch: 4 step: 1438, loss is 1.9413650035858154\n",
      "epoch: 4 step: 1439, loss is 0.4035916030406952\n",
      "epoch: 4 step: 1440, loss is 1.7544606924057007\n",
      "epoch: 4 step: 1441, loss is 2.0431466102600098\n",
      "epoch: 4 step: 1442, loss is 0.22301393747329712\n",
      "epoch: 4 step: 1443, loss is 0.24312014877796173\n",
      "epoch: 4 step: 1444, loss is 2.6403446197509766\n",
      "epoch: 4 step: 1445, loss is 0.6162943840026855\n",
      "epoch: 4 step: 1446, loss is 0.6075574159622192\n",
      "epoch: 4 step: 1447, loss is 0.2636629343032837\n",
      "epoch: 4 step: 1448, loss is 0.35782337188720703\n",
      "epoch: 4 step: 1449, loss is 0.08509649336338043\n",
      "epoch: 4 step: 1450, loss is 1.8100743293762207\n",
      "epoch: 4 step: 1451, loss is 1.8952324390411377\n",
      "epoch: 4 step: 1452, loss is 0.8160266876220703\n",
      "epoch: 4 step: 1453, loss is 0.9818035364151001\n",
      "epoch: 4 step: 1454, loss is 1.8442668914794922\n",
      "epoch: 4 step: 1455, loss is 3.4668502807617188\n",
      "epoch: 4 step: 1456, loss is 0.7397314310073853\n",
      "epoch: 4 step: 1457, loss is 0.24164476990699768\n",
      "epoch: 4 step: 1458, loss is 1.7082232236862183\n",
      "epoch: 4 step: 1459, loss is 0.484124094247818\n",
      "epoch: 4 step: 1460, loss is 1.7643393278121948\n",
      "epoch: 4 step: 1461, loss is 2.055659294128418\n",
      "epoch: 4 step: 1462, loss is 1.869239091873169\n",
      "epoch: 4 step: 1463, loss is 1.0328048467636108\n",
      "epoch: 4 step: 1464, loss is 0.9935764074325562\n",
      "epoch: 4 step: 1465, loss is 1.728966236114502\n",
      "epoch: 4 step: 1466, loss is 1.76006281375885\n",
      "epoch: 4 step: 1467, loss is 0.31251442432403564\n",
      "epoch: 4 step: 1468, loss is 2.081050157546997\n",
      "epoch: 4 step: 1469, loss is 0.3508261442184448\n",
      "epoch: 4 step: 1470, loss is 0.4913691282272339\n",
      "epoch: 4 step: 1471, loss is 2.5320005416870117\n",
      "epoch: 4 step: 1472, loss is 0.237931489944458\n",
      "epoch: 4 step: 1473, loss is 0.27827566862106323\n",
      "epoch: 4 step: 1474, loss is 0.07513672858476639\n",
      "epoch: 4 step: 1475, loss is 1.5681697130203247\n",
      "epoch: 4 step: 1476, loss is 0.30770137906074524\n",
      "epoch: 4 step: 1477, loss is 0.10428162664175034\n",
      "epoch: 4 step: 1478, loss is 0.12657508254051208\n",
      "epoch: 4 step: 1479, loss is 0.15741026401519775\n",
      "epoch: 4 step: 1480, loss is 2.409459114074707\n",
      "epoch: 4 step: 1481, loss is 0.5566906332969666\n",
      "epoch: 4 step: 1482, loss is 0.09181136637926102\n",
      "epoch: 4 step: 1483, loss is 0.25250867009162903\n",
      "epoch: 4 step: 1484, loss is 0.43677839636802673\n",
      "epoch: 4 step: 1485, loss is 0.045926474034786224\n",
      "epoch: 4 step: 1486, loss is 0.28528642654418945\n",
      "epoch: 4 step: 1487, loss is 2.9873147010803223\n",
      "epoch: 4 step: 1488, loss is 3.028318166732788\n",
      "epoch: 4 step: 1489, loss is 0.24011459946632385\n",
      "epoch: 4 step: 1490, loss is 0.5084181427955627\n",
      "epoch: 4 step: 1491, loss is 0.29618892073631287\n",
      "epoch: 4 step: 1492, loss is 0.5663734078407288\n",
      "epoch: 4 step: 1493, loss is 0.4519897401332855\n",
      "epoch: 4 step: 1494, loss is 0.5664886832237244\n",
      "epoch: 4 step: 1495, loss is 2.7854278087615967\n",
      "epoch: 4 step: 1496, loss is 0.6573864817619324\n",
      "epoch: 4 step: 1497, loss is 0.35950955748558044\n",
      "epoch: 4 step: 1498, loss is 0.060730304569005966\n",
      "epoch: 4 step: 1499, loss is 0.09945841133594513\n",
      "epoch: 4 step: 1500, loss is 0.10547160357236862\n",
      "epoch: 4 step: 1501, loss is 0.4803590476512909\n",
      "epoch: 4 step: 1502, loss is 0.0732181966304779\n",
      "epoch: 4 step: 1503, loss is 0.6238073706626892\n",
      "epoch: 4 step: 1504, loss is 0.23176488280296326\n",
      "epoch: 4 step: 1505, loss is 0.05863754823803902\n",
      "epoch: 4 step: 1506, loss is 0.6825213432312012\n",
      "epoch: 4 step: 1507, loss is 0.0476650595664978\n",
      "epoch: 4 step: 1508, loss is 2.1451799869537354\n",
      "epoch: 4 step: 1509, loss is 1.9067835807800293\n",
      "epoch: 4 step: 1510, loss is 0.010952829383313656\n",
      "epoch: 4 step: 1511, loss is 0.0916103720664978\n",
      "epoch: 4 step: 1512, loss is 0.06351165473461151\n",
      "epoch: 4 step: 1513, loss is 2.488767147064209\n",
      "epoch: 4 step: 1514, loss is 0.20298358798027039\n",
      "epoch: 4 step: 1515, loss is 3.5034494400024414\n",
      "epoch: 4 step: 1516, loss is 0.42683660984039307\n",
      "epoch: 4 step: 1517, loss is 0.3644285500049591\n",
      "epoch: 4 step: 1518, loss is 1.8060863018035889\n",
      "epoch: 4 step: 1519, loss is 1.8055461645126343\n",
      "epoch: 4 step: 1520, loss is 1.5180126428604126\n",
      "epoch: 4 step: 1521, loss is 0.5208410024642944\n",
      "epoch: 4 step: 1522, loss is 0.3707945942878723\n",
      "epoch: 4 step: 1523, loss is 0.4543763995170593\n",
      "epoch: 4 step: 1524, loss is 2.391455888748169\n",
      "epoch: 4 step: 1525, loss is 1.589195966720581\n",
      "epoch: 4 step: 1526, loss is 2.6222681999206543\n",
      "epoch: 4 step: 1527, loss is 0.8216612339019775\n",
      "epoch: 4 step: 1528, loss is 0.7211357951164246\n",
      "epoch: 4 step: 1529, loss is 1.5842645168304443\n",
      "epoch: 4 step: 1530, loss is 0.5839868783950806\n",
      "epoch: 4 step: 1531, loss is 2.5714001655578613\n",
      "epoch: 4 step: 1532, loss is 0.6030239462852478\n",
      "epoch: 4 step: 1533, loss is 0.4764767289161682\n",
      "epoch: 4 step: 1534, loss is 0.7718034386634827\n",
      "epoch: 4 step: 1535, loss is 2.5819265842437744\n",
      "epoch: 4 step: 1536, loss is 0.35046297311782837\n",
      "epoch: 4 step: 1537, loss is 3.3945372104644775\n",
      "epoch: 4 step: 1538, loss is 1.4595844745635986\n",
      "epoch: 4 step: 1539, loss is 0.28698787093162537\n",
      "epoch: 4 step: 1540, loss is 1.8993234634399414\n",
      "epoch: 4 step: 1541, loss is 1.4385712146759033\n",
      "epoch: 4 step: 1542, loss is 0.5446690320968628\n",
      "epoch: 4 step: 1543, loss is 0.32393935322761536\n",
      "epoch: 4 step: 1544, loss is 0.23861242830753326\n",
      "epoch: 4 step: 1545, loss is 2.339463233947754\n",
      "epoch: 4 step: 1546, loss is 1.6122283935546875\n",
      "epoch: 4 step: 1547, loss is 0.21221646666526794\n",
      "epoch: 4 step: 1548, loss is 0.5164182782173157\n",
      "epoch: 4 step: 1549, loss is 0.7848337888717651\n",
      "epoch: 4 step: 1550, loss is 1.6897997856140137\n",
      "epoch: 4 step: 1551, loss is 0.10591326653957367\n",
      "epoch: 4 step: 1552, loss is 0.796933114528656\n",
      "epoch: 4 step: 1553, loss is 2.1653828620910645\n",
      "epoch: 4 step: 1554, loss is 0.38314464688301086\n",
      "epoch: 4 step: 1555, loss is 1.7831082344055176\n",
      "epoch: 4 step: 1556, loss is 0.2795678675174713\n",
      "epoch: 4 step: 1557, loss is 0.40943601727485657\n",
      "epoch: 4 step: 1558, loss is 1.7895183563232422\n",
      "epoch: 4 step: 1559, loss is 2.4055042266845703\n",
      "epoch: 4 step: 1560, loss is 0.2065000981092453\n",
      "epoch: 4 step: 1561, loss is 1.7239595651626587\n",
      "epoch: 4 step: 1562, loss is 1.879915714263916\n",
      "epoch: 4 step: 1563, loss is 1.991844654083252\n",
      "epoch: 4 step: 1564, loss is 0.6392661929130554\n",
      "epoch: 4 step: 1565, loss is 3.9224302768707275\n",
      "epoch: 4 step: 1566, loss is 1.6814943552017212\n",
      "epoch: 4 step: 1567, loss is 2.339055061340332\n",
      "epoch: 4 step: 1568, loss is 1.7075858116149902\n",
      "epoch: 4 step: 1569, loss is 1.9330260753631592\n",
      "epoch: 4 step: 1570, loss is 2.0611674785614014\n",
      "epoch: 4 step: 1571, loss is 3.1398589611053467\n",
      "epoch: 4 step: 1572, loss is 0.752414882183075\n",
      "epoch: 4 step: 1573, loss is 0.9399997591972351\n",
      "epoch: 4 step: 1574, loss is 1.164371371269226\n",
      "epoch: 4 step: 1575, loss is 0.8545483946800232\n",
      "epoch: 4 step: 1576, loss is 1.9018948078155518\n",
      "epoch: 4 step: 1577, loss is 1.649074673652649\n",
      "epoch: 4 step: 1578, loss is 1.7332841157913208\n",
      "epoch: 4 step: 1579, loss is 1.6169564723968506\n",
      "epoch: 4 step: 1580, loss is 2.311361789703369\n",
      "epoch: 4 step: 1581, loss is 1.3367568254470825\n",
      "epoch: 4 step: 1582, loss is 1.2344459295272827\n",
      "epoch: 4 step: 1583, loss is 1.6914551258087158\n",
      "epoch: 4 step: 1584, loss is 1.8121964931488037\n",
      "epoch: 4 step: 1585, loss is 0.5350487232208252\n",
      "epoch: 4 step: 1586, loss is 0.3953169882297516\n",
      "epoch: 4 step: 1587, loss is 1.8553454875946045\n",
      "epoch: 4 step: 1588, loss is 1.6402531862258911\n",
      "epoch: 4 step: 1589, loss is 0.52360600233078\n",
      "epoch: 4 step: 1590, loss is 1.148016333580017\n",
      "epoch: 4 step: 1591, loss is 1.3522263765335083\n",
      "epoch: 4 step: 1592, loss is 1.6295139789581299\n",
      "epoch: 4 step: 1593, loss is 1.7826639413833618\n",
      "epoch: 4 step: 1594, loss is 0.5513957142829895\n",
      "epoch: 4 step: 1595, loss is 1.6924781799316406\n",
      "epoch: 4 step: 1596, loss is 0.6354488730430603\n",
      "epoch: 4 step: 1597, loss is 0.5006558299064636\n",
      "epoch: 4 step: 1598, loss is 0.38553890585899353\n",
      "epoch: 4 step: 1599, loss is 1.0539841651916504\n",
      "epoch: 4 step: 1600, loss is 1.9934515953063965\n",
      "epoch: 5 step: 1, loss is 0.7333278059959412\n",
      "epoch: 5 step: 2, loss is 0.08252358436584473\n",
      "epoch: 5 step: 3, loss is 2.052546977996826\n",
      "epoch: 5 step: 4, loss is 0.20835037529468536\n",
      "epoch: 5 step: 5, loss is 0.29242444038391113\n",
      "epoch: 5 step: 6, loss is 0.2175338864326477\n",
      "epoch: 5 step: 7, loss is 3.745784044265747\n",
      "epoch: 5 step: 8, loss is 0.4184304475784302\n",
      "epoch: 5 step: 9, loss is 0.3572475016117096\n",
      "epoch: 5 step: 10, loss is 0.9260690212249756\n",
      "epoch: 5 step: 11, loss is 2.508321523666382\n",
      "epoch: 5 step: 12, loss is 0.347121924161911\n",
      "epoch: 5 step: 13, loss is 1.822779893875122\n",
      "epoch: 5 step: 14, loss is 0.2986309826374054\n",
      "epoch: 5 step: 15, loss is 2.1032981872558594\n",
      "epoch: 5 step: 16, loss is 0.9946017265319824\n",
      "epoch: 5 step: 17, loss is 0.1676144152879715\n",
      "epoch: 5 step: 18, loss is 2.371225595474243\n",
      "epoch: 5 step: 19, loss is 1.8951083421707153\n",
      "epoch: 5 step: 20, loss is 1.6809356212615967\n",
      "epoch: 5 step: 21, loss is 0.283051460981369\n",
      "epoch: 5 step: 22, loss is 0.053393587470054626\n",
      "epoch: 5 step: 23, loss is 1.8143699169158936\n",
      "epoch: 5 step: 24, loss is 0.33253875374794006\n",
      "epoch: 5 step: 25, loss is 0.3978522717952728\n",
      "epoch: 5 step: 26, loss is 0.21181096136569977\n",
      "epoch: 5 step: 27, loss is 3.486776351928711\n",
      "epoch: 5 step: 28, loss is 0.32794830203056335\n",
      "epoch: 5 step: 29, loss is 0.3009854853153229\n",
      "epoch: 5 step: 30, loss is 2.4233741760253906\n",
      "epoch: 5 step: 31, loss is 1.7119969129562378\n",
      "epoch: 5 step: 32, loss is 1.9792377948760986\n",
      "epoch: 5 step: 33, loss is 1.719353437423706\n",
      "epoch: 5 step: 34, loss is 1.353448510169983\n",
      "epoch: 5 step: 35, loss is 1.1661401987075806\n",
      "epoch: 5 step: 36, loss is 0.31653448939323425\n",
      "epoch: 5 step: 37, loss is 0.9305413961410522\n",
      "epoch: 5 step: 38, loss is 1.220821738243103\n",
      "epoch: 5 step: 39, loss is 0.49656933546066284\n",
      "epoch: 5 step: 40, loss is 2.084965467453003\n",
      "epoch: 5 step: 41, loss is 0.5782719254493713\n",
      "epoch: 5 step: 42, loss is 0.2792391777038574\n",
      "epoch: 5 step: 43, loss is 0.9175758361816406\n",
      "epoch: 5 step: 44, loss is 2.964804172515869\n",
      "epoch: 5 step: 45, loss is 0.5538538694381714\n",
      "epoch: 5 step: 46, loss is 2.546433448791504\n",
      "epoch: 5 step: 47, loss is 0.9391078352928162\n",
      "epoch: 5 step: 48, loss is 0.7729477882385254\n",
      "epoch: 5 step: 49, loss is 2.542555332183838\n",
      "epoch: 5 step: 50, loss is 0.4758581221103668\n",
      "epoch: 5 step: 51, loss is 0.552153468132019\n",
      "epoch: 5 step: 52, loss is 0.22865241765975952\n",
      "epoch: 5 step: 53, loss is 2.1630759239196777\n",
      "epoch: 5 step: 54, loss is 1.851639747619629\n",
      "epoch: 5 step: 55, loss is 0.3924901485443115\n",
      "epoch: 5 step: 56, loss is 0.40532204508781433\n",
      "epoch: 5 step: 57, loss is 0.23822021484375\n",
      "epoch: 5 step: 58, loss is 0.8817877173423767\n",
      "epoch: 5 step: 59, loss is 0.5889191031455994\n",
      "epoch: 5 step: 60, loss is 0.2411212921142578\n",
      "epoch: 5 step: 61, loss is 0.17313167452812195\n",
      "epoch: 5 step: 62, loss is 2.0257837772369385\n",
      "epoch: 5 step: 63, loss is 0.19887717068195343\n",
      "epoch: 5 step: 64, loss is 0.23680898547172546\n",
      "epoch: 5 step: 65, loss is 1.9057329893112183\n",
      "epoch: 5 step: 66, loss is 2.033107042312622\n",
      "epoch: 5 step: 67, loss is 2.6721701622009277\n",
      "epoch: 5 step: 68, loss is 0.8537883758544922\n",
      "epoch: 5 step: 69, loss is 0.3248862624168396\n",
      "epoch: 5 step: 70, loss is 0.157399982213974\n",
      "epoch: 5 step: 71, loss is 0.5164604783058167\n",
      "epoch: 5 step: 72, loss is 1.3460767269134521\n",
      "epoch: 5 step: 73, loss is 2.9074130058288574\n",
      "epoch: 5 step: 74, loss is 0.44748175144195557\n",
      "epoch: 5 step: 75, loss is 0.8754816651344299\n",
      "epoch: 5 step: 76, loss is 0.1961866170167923\n",
      "epoch: 5 step: 77, loss is 0.3123953640460968\n",
      "epoch: 5 step: 78, loss is 0.4527219533920288\n",
      "epoch: 5 step: 79, loss is 3.0228774547576904\n",
      "epoch: 5 step: 80, loss is 1.9609754085540771\n",
      "epoch: 5 step: 81, loss is 0.3255743682384491\n",
      "epoch: 5 step: 82, loss is 1.7883528470993042\n",
      "epoch: 5 step: 83, loss is 1.3462567329406738\n",
      "epoch: 5 step: 84, loss is 0.39763545989990234\n",
      "epoch: 5 step: 85, loss is 1.7535150051116943\n",
      "epoch: 5 step: 86, loss is 1.8004071712493896\n",
      "epoch: 5 step: 87, loss is 0.340554803609848\n",
      "epoch: 5 step: 88, loss is 1.094508171081543\n",
      "epoch: 5 step: 89, loss is 0.034912653267383575\n",
      "epoch: 5 step: 90, loss is 1.8648171424865723\n",
      "epoch: 5 step: 91, loss is 1.9746849536895752\n",
      "epoch: 5 step: 92, loss is 3.5405220985412598\n",
      "epoch: 5 step: 93, loss is 0.6350396275520325\n",
      "epoch: 5 step: 94, loss is 1.7206478118896484\n",
      "epoch: 5 step: 95, loss is 0.4964638352394104\n",
      "epoch: 5 step: 96, loss is 0.5707125067710876\n",
      "epoch: 5 step: 97, loss is 0.2663281261920929\n",
      "epoch: 5 step: 98, loss is 0.07672131061553955\n",
      "epoch: 5 step: 99, loss is 0.24794910848140717\n",
      "epoch: 5 step: 100, loss is 0.5318239331245422\n",
      "epoch: 5 step: 101, loss is 2.076108455657959\n",
      "epoch: 5 step: 102, loss is 0.21589305996894836\n",
      "epoch: 5 step: 103, loss is 3.1134390830993652\n",
      "epoch: 5 step: 104, loss is 0.18181492388248444\n",
      "epoch: 5 step: 105, loss is 2.443448066711426\n",
      "epoch: 5 step: 106, loss is 0.31060758233070374\n",
      "epoch: 5 step: 107, loss is 2.965287923812866\n",
      "epoch: 5 step: 108, loss is 2.13387393951416\n",
      "epoch: 5 step: 109, loss is 0.9911472797393799\n",
      "epoch: 5 step: 110, loss is 2.2673308849334717\n",
      "epoch: 5 step: 111, loss is 0.4810485541820526\n",
      "epoch: 5 step: 112, loss is 0.5180490612983704\n",
      "epoch: 5 step: 113, loss is 0.7242121696472168\n",
      "epoch: 5 step: 114, loss is 0.9273119568824768\n",
      "epoch: 5 step: 115, loss is 1.961197853088379\n",
      "epoch: 5 step: 116, loss is 0.22455675899982452\n",
      "epoch: 5 step: 117, loss is 1.7553114891052246\n",
      "epoch: 5 step: 118, loss is 0.2946077585220337\n",
      "epoch: 5 step: 119, loss is 0.46057870984077454\n",
      "epoch: 5 step: 120, loss is 0.3411734104156494\n",
      "epoch: 5 step: 121, loss is 2.217082977294922\n",
      "epoch: 5 step: 122, loss is 0.1704120934009552\n",
      "epoch: 5 step: 123, loss is 1.8617602586746216\n",
      "epoch: 5 step: 124, loss is 2.392793655395508\n",
      "epoch: 5 step: 125, loss is 2.1016039848327637\n",
      "epoch: 5 step: 126, loss is 0.45015594363212585\n",
      "epoch: 5 step: 127, loss is 2.3666577339172363\n",
      "epoch: 5 step: 128, loss is 0.5569600462913513\n",
      "epoch: 5 step: 129, loss is 1.347238540649414\n",
      "epoch: 5 step: 130, loss is 1.9408537149429321\n",
      "epoch: 5 step: 131, loss is 0.4835291802883148\n",
      "epoch: 5 step: 132, loss is 3.1498186588287354\n",
      "epoch: 5 step: 133, loss is 0.536907970905304\n",
      "epoch: 5 step: 134, loss is 1.8043321371078491\n",
      "epoch: 5 step: 135, loss is 1.9729549884796143\n",
      "epoch: 5 step: 136, loss is 0.44193515181541443\n",
      "epoch: 5 step: 137, loss is 0.34250715374946594\n",
      "epoch: 5 step: 138, loss is 0.2880554795265198\n",
      "epoch: 5 step: 139, loss is 1.565505027770996\n",
      "epoch: 5 step: 140, loss is 1.3466999530792236\n",
      "epoch: 5 step: 141, loss is 0.464295357465744\n",
      "epoch: 5 step: 142, loss is 2.206908941268921\n",
      "epoch: 5 step: 143, loss is 2.007882833480835\n",
      "epoch: 5 step: 144, loss is 1.6821129322052002\n",
      "epoch: 5 step: 145, loss is 0.7243788242340088\n",
      "epoch: 5 step: 146, loss is 1.34610915184021\n",
      "epoch: 5 step: 147, loss is 0.7877917289733887\n",
      "epoch: 5 step: 148, loss is 0.13167627155780792\n",
      "epoch: 5 step: 149, loss is 0.112626813352108\n",
      "epoch: 5 step: 150, loss is 0.08342151343822479\n",
      "epoch: 5 step: 151, loss is 1.7928107976913452\n",
      "epoch: 5 step: 152, loss is 0.6701111793518066\n",
      "epoch: 5 step: 153, loss is 0.757212221622467\n",
      "epoch: 5 step: 154, loss is 0.7470623850822449\n",
      "epoch: 5 step: 155, loss is 0.2508053481578827\n",
      "epoch: 5 step: 156, loss is 2.8889987468719482\n",
      "epoch: 5 step: 157, loss is 2.07627534866333\n",
      "epoch: 5 step: 158, loss is 1.6059050559997559\n",
      "epoch: 5 step: 159, loss is 0.16438612341880798\n",
      "epoch: 5 step: 160, loss is 2.8735733032226562\n",
      "epoch: 5 step: 161, loss is 0.40882307291030884\n",
      "epoch: 5 step: 162, loss is 0.7833060026168823\n",
      "epoch: 5 step: 163, loss is 1.6632739305496216\n",
      "epoch: 5 step: 164, loss is 0.19752717018127441\n",
      "epoch: 5 step: 165, loss is 0.6555740833282471\n",
      "epoch: 5 step: 166, loss is 2.1146655082702637\n",
      "epoch: 5 step: 167, loss is 0.6304320096969604\n",
      "epoch: 5 step: 168, loss is 0.10306259989738464\n",
      "epoch: 5 step: 169, loss is 1.095967173576355\n",
      "epoch: 5 step: 170, loss is 0.3019868731498718\n",
      "epoch: 5 step: 171, loss is 0.7566528916358948\n",
      "epoch: 5 step: 172, loss is 0.39366695284843445\n",
      "epoch: 5 step: 173, loss is 0.20398108661174774\n",
      "epoch: 5 step: 174, loss is 0.3563779294490814\n",
      "epoch: 5 step: 175, loss is 0.01819479651749134\n",
      "epoch: 5 step: 176, loss is 3.0297911167144775\n",
      "epoch: 5 step: 177, loss is 2.2338130474090576\n",
      "epoch: 5 step: 178, loss is 0.08948201686143875\n",
      "epoch: 5 step: 179, loss is 2.073362112045288\n",
      "epoch: 5 step: 180, loss is 2.2425050735473633\n",
      "epoch: 5 step: 181, loss is 0.6171205639839172\n",
      "epoch: 5 step: 182, loss is 0.4039105176925659\n",
      "epoch: 5 step: 183, loss is 0.39398741722106934\n",
      "epoch: 5 step: 184, loss is 0.1845354437828064\n",
      "epoch: 5 step: 185, loss is 2.322162628173828\n",
      "epoch: 5 step: 186, loss is 1.9930564165115356\n",
      "epoch: 5 step: 187, loss is 0.3489452302455902\n",
      "epoch: 5 step: 188, loss is 0.8745627999305725\n",
      "epoch: 5 step: 189, loss is 0.09861787408590317\n",
      "epoch: 5 step: 190, loss is 1.9933114051818848\n",
      "epoch: 5 step: 191, loss is 3.3801522254943848\n",
      "epoch: 5 step: 192, loss is 1.7795238494873047\n",
      "epoch: 5 step: 193, loss is 2.2551286220550537\n",
      "epoch: 5 step: 194, loss is 1.7412652969360352\n",
      "epoch: 5 step: 195, loss is 0.8606224656105042\n",
      "epoch: 5 step: 196, loss is 0.5550639629364014\n",
      "epoch: 5 step: 197, loss is 0.428925096988678\n",
      "epoch: 5 step: 198, loss is 2.69985294342041\n",
      "epoch: 5 step: 199, loss is 0.3061693012714386\n",
      "epoch: 5 step: 200, loss is 1.0756996870040894\n",
      "epoch: 5 step: 201, loss is 2.029179573059082\n",
      "epoch: 5 step: 202, loss is 0.6053664088249207\n",
      "epoch: 5 step: 203, loss is 1.0843392610549927\n",
      "epoch: 5 step: 204, loss is 0.4282490313053131\n",
      "epoch: 5 step: 205, loss is 0.2051486074924469\n",
      "epoch: 5 step: 206, loss is 1.062279462814331\n",
      "epoch: 5 step: 207, loss is 0.1139814630150795\n",
      "epoch: 5 step: 208, loss is 2.0471205711364746\n",
      "epoch: 5 step: 209, loss is 0.24089543521404266\n",
      "epoch: 5 step: 210, loss is 1.6097157001495361\n",
      "epoch: 5 step: 211, loss is 0.25994420051574707\n",
      "epoch: 5 step: 212, loss is 1.011501669883728\n",
      "epoch: 5 step: 213, loss is 2.770232915878296\n",
      "epoch: 5 step: 214, loss is 0.43882763385772705\n",
      "epoch: 5 step: 215, loss is 1.8094167709350586\n",
      "epoch: 5 step: 216, loss is 0.5397051572799683\n",
      "epoch: 5 step: 217, loss is 0.2631668150424957\n",
      "epoch: 5 step: 218, loss is 0.24448637664318085\n",
      "epoch: 5 step: 219, loss is 1.879596471786499\n",
      "epoch: 5 step: 220, loss is 0.2971140742301941\n",
      "epoch: 5 step: 221, loss is 0.5263034105300903\n",
      "epoch: 5 step: 222, loss is 0.37063053250312805\n",
      "epoch: 5 step: 223, loss is 0.22228248417377472\n",
      "epoch: 5 step: 224, loss is 3.537841796875\n",
      "epoch: 5 step: 225, loss is 0.6601296663284302\n",
      "epoch: 5 step: 226, loss is 2.0972506999969482\n",
      "epoch: 5 step: 227, loss is 0.36433911323547363\n",
      "epoch: 5 step: 228, loss is 2.1724908351898193\n",
      "epoch: 5 step: 229, loss is 1.3435558080673218\n",
      "epoch: 5 step: 230, loss is 0.9864378571510315\n",
      "epoch: 5 step: 231, loss is 0.2471066415309906\n",
      "epoch: 5 step: 232, loss is 2.400446891784668\n",
      "epoch: 5 step: 233, loss is 0.2531263530254364\n",
      "epoch: 5 step: 234, loss is 0.9976341724395752\n",
      "epoch: 5 step: 235, loss is 0.2539496123790741\n",
      "epoch: 5 step: 236, loss is 0.2894153594970703\n",
      "epoch: 5 step: 237, loss is 0.5363167524337769\n",
      "epoch: 5 step: 238, loss is 1.8316091299057007\n",
      "epoch: 5 step: 239, loss is 0.36416321992874146\n",
      "epoch: 5 step: 240, loss is 2.431981086730957\n",
      "epoch: 5 step: 241, loss is 0.24414706230163574\n",
      "epoch: 5 step: 242, loss is 3.504471778869629\n",
      "epoch: 5 step: 243, loss is 1.0239472389221191\n",
      "epoch: 5 step: 244, loss is 0.3398984670639038\n",
      "epoch: 5 step: 245, loss is 1.5348697900772095\n",
      "epoch: 5 step: 246, loss is 1.8775840997695923\n",
      "epoch: 5 step: 247, loss is 0.5949815511703491\n",
      "epoch: 5 step: 248, loss is 1.875913381576538\n",
      "epoch: 5 step: 249, loss is 2.1837029457092285\n",
      "epoch: 5 step: 250, loss is 0.7189959287643433\n",
      "epoch: 5 step: 251, loss is 2.361931800842285\n",
      "epoch: 5 step: 252, loss is 0.4877792298793793\n",
      "epoch: 5 step: 253, loss is 1.6473853588104248\n",
      "epoch: 5 step: 254, loss is 2.1383936405181885\n",
      "epoch: 5 step: 255, loss is 1.8343349695205688\n",
      "epoch: 5 step: 256, loss is 0.6814963817596436\n",
      "epoch: 5 step: 257, loss is 1.6519402265548706\n",
      "epoch: 5 step: 258, loss is 0.7022386193275452\n",
      "epoch: 5 step: 259, loss is 1.3167665004730225\n",
      "epoch: 5 step: 260, loss is 0.6664401888847351\n",
      "epoch: 5 step: 261, loss is 0.4335327744483948\n",
      "epoch: 5 step: 262, loss is 0.29199838638305664\n",
      "epoch: 5 step: 263, loss is 0.32887551188468933\n",
      "epoch: 5 step: 264, loss is 0.6495683193206787\n",
      "epoch: 5 step: 265, loss is 0.42617765069007874\n",
      "epoch: 5 step: 266, loss is 3.0375962257385254\n",
      "epoch: 5 step: 267, loss is 0.08299316465854645\n",
      "epoch: 5 step: 268, loss is 0.5385105013847351\n",
      "epoch: 5 step: 269, loss is 0.1600925773382187\n",
      "epoch: 5 step: 270, loss is 2.511934757232666\n",
      "epoch: 5 step: 271, loss is 0.4994414150714874\n",
      "epoch: 5 step: 272, loss is 2.2751011848449707\n",
      "epoch: 5 step: 273, loss is 1.7412829399108887\n",
      "epoch: 5 step: 274, loss is 0.7124320268630981\n",
      "epoch: 5 step: 275, loss is 0.6466304063796997\n",
      "epoch: 5 step: 276, loss is 0.2758079171180725\n",
      "epoch: 5 step: 277, loss is 1.5353851318359375\n",
      "epoch: 5 step: 278, loss is 1.569706916809082\n",
      "epoch: 5 step: 279, loss is 0.5698394775390625\n",
      "epoch: 5 step: 280, loss is 0.48938101530075073\n",
      "epoch: 5 step: 281, loss is 0.5994946956634521\n",
      "epoch: 5 step: 282, loss is 0.2081548422574997\n",
      "epoch: 5 step: 283, loss is 0.6326711773872375\n",
      "epoch: 5 step: 284, loss is 3.299189329147339\n",
      "epoch: 5 step: 285, loss is 0.3553365170955658\n",
      "epoch: 5 step: 286, loss is 2.04858660697937\n",
      "epoch: 5 step: 287, loss is 0.4018653631210327\n",
      "epoch: 5 step: 288, loss is 0.6397203207015991\n",
      "epoch: 5 step: 289, loss is 1.7510408163070679\n",
      "epoch: 5 step: 290, loss is 3.8986566066741943\n",
      "epoch: 5 step: 291, loss is 0.21229755878448486\n",
      "epoch: 5 step: 292, loss is 0.7871575951576233\n",
      "epoch: 5 step: 293, loss is 0.19099125266075134\n",
      "epoch: 5 step: 294, loss is 2.510467767715454\n",
      "epoch: 5 step: 295, loss is 0.24375700950622559\n",
      "epoch: 5 step: 296, loss is 0.23865514993667603\n",
      "epoch: 5 step: 297, loss is 0.6520611643791199\n",
      "epoch: 5 step: 298, loss is 1.7151230573654175\n",
      "epoch: 5 step: 299, loss is 1.8799269199371338\n",
      "epoch: 5 step: 300, loss is 0.37061333656311035\n",
      "epoch: 5 step: 301, loss is 0.15035545825958252\n",
      "epoch: 5 step: 302, loss is 0.10802516341209412\n",
      "epoch: 5 step: 303, loss is 0.48428571224212646\n",
      "epoch: 5 step: 304, loss is 0.36409133672714233\n",
      "epoch: 5 step: 305, loss is 0.49842336773872375\n",
      "epoch: 5 step: 306, loss is 3.892059087753296\n",
      "epoch: 5 step: 307, loss is 0.6628416180610657\n",
      "epoch: 5 step: 308, loss is 3.158398151397705\n",
      "epoch: 5 step: 309, loss is 2.126492738723755\n",
      "epoch: 5 step: 310, loss is 1.7464282512664795\n",
      "epoch: 5 step: 311, loss is 0.5832796096801758\n",
      "epoch: 5 step: 312, loss is 2.1779019832611084\n",
      "epoch: 5 step: 313, loss is 1.743017554283142\n",
      "epoch: 5 step: 314, loss is 0.7095769047737122\n",
      "epoch: 5 step: 315, loss is 2.149890899658203\n",
      "epoch: 5 step: 316, loss is 1.6435573101043701\n",
      "epoch: 5 step: 317, loss is 1.0979527235031128\n",
      "epoch: 5 step: 318, loss is 1.672753095626831\n",
      "epoch: 5 step: 319, loss is 2.254443645477295\n",
      "epoch: 5 step: 320, loss is 1.9446704387664795\n",
      "epoch: 5 step: 321, loss is 1.0477194786071777\n",
      "epoch: 5 step: 322, loss is 0.2874175012111664\n",
      "epoch: 5 step: 323, loss is 0.5536807775497437\n",
      "epoch: 5 step: 324, loss is 1.6060419082641602\n",
      "epoch: 5 step: 325, loss is 0.6517946720123291\n",
      "epoch: 5 step: 326, loss is 0.4465644657611847\n",
      "epoch: 5 step: 327, loss is 2.3694424629211426\n",
      "epoch: 5 step: 328, loss is 2.7323951721191406\n",
      "epoch: 5 step: 329, loss is 0.6843103766441345\n",
      "epoch: 5 step: 330, loss is 0.4604702591896057\n",
      "epoch: 5 step: 331, loss is 0.688678503036499\n",
      "epoch: 5 step: 332, loss is 1.3396960496902466\n",
      "epoch: 5 step: 333, loss is 0.9545267820358276\n",
      "epoch: 5 step: 334, loss is 0.7114206552505493\n",
      "epoch: 5 step: 335, loss is 0.7647119760513306\n",
      "epoch: 5 step: 336, loss is 0.46421509981155396\n",
      "epoch: 5 step: 337, loss is 0.3173595368862152\n",
      "epoch: 5 step: 338, loss is 2.267444133758545\n",
      "epoch: 5 step: 339, loss is 2.3719377517700195\n",
      "epoch: 5 step: 340, loss is 0.4534834325313568\n",
      "epoch: 5 step: 341, loss is 1.2991539239883423\n",
      "epoch: 5 step: 342, loss is 1.7453527450561523\n",
      "epoch: 5 step: 343, loss is 0.15228934586048126\n",
      "epoch: 5 step: 344, loss is 0.4526703357696533\n",
      "epoch: 5 step: 345, loss is 0.23540735244750977\n",
      "epoch: 5 step: 346, loss is 0.0679367408156395\n",
      "epoch: 5 step: 347, loss is 0.49240100383758545\n",
      "epoch: 5 step: 348, loss is 0.13937757909297943\n",
      "epoch: 5 step: 349, loss is 2.3091747760772705\n",
      "epoch: 5 step: 350, loss is 1.828198790550232\n",
      "epoch: 5 step: 351, loss is 1.3359639644622803\n",
      "epoch: 5 step: 352, loss is 2.223607301712036\n",
      "epoch: 5 step: 353, loss is 1.881683588027954\n",
      "epoch: 5 step: 354, loss is 0.25669804215431213\n",
      "epoch: 5 step: 355, loss is 0.6507871150970459\n",
      "epoch: 5 step: 356, loss is 0.7082406878471375\n",
      "epoch: 5 step: 357, loss is 0.6403483748435974\n",
      "epoch: 5 step: 358, loss is 0.1967850625514984\n",
      "epoch: 5 step: 359, loss is 0.5221970677375793\n",
      "epoch: 5 step: 360, loss is 1.7538516521453857\n",
      "epoch: 5 step: 361, loss is 1.8683347702026367\n",
      "epoch: 5 step: 362, loss is 0.4639641046524048\n",
      "epoch: 5 step: 363, loss is 0.11766350269317627\n",
      "epoch: 5 step: 364, loss is 0.192473903298378\n",
      "epoch: 5 step: 365, loss is 0.7482861876487732\n",
      "epoch: 5 step: 366, loss is 0.5035874247550964\n",
      "epoch: 5 step: 367, loss is 0.027891812846064568\n",
      "epoch: 5 step: 368, loss is 1.845853567123413\n",
      "epoch: 5 step: 369, loss is 3.619967460632324\n",
      "epoch: 5 step: 370, loss is 0.06321469694375992\n",
      "epoch: 5 step: 371, loss is 0.2263479083776474\n",
      "epoch: 5 step: 372, loss is 3.689697265625\n",
      "epoch: 5 step: 373, loss is 0.0972769558429718\n",
      "epoch: 5 step: 374, loss is 0.029821811243891716\n",
      "epoch: 5 step: 375, loss is 0.4690897762775421\n",
      "epoch: 5 step: 376, loss is 1.5901219844818115\n",
      "epoch: 5 step: 377, loss is 2.462393283843994\n",
      "epoch: 5 step: 378, loss is 2.3575820922851562\n",
      "epoch: 5 step: 379, loss is 0.4737143814563751\n",
      "epoch: 5 step: 380, loss is 0.15171438455581665\n",
      "epoch: 5 step: 381, loss is 1.6930139064788818\n",
      "epoch: 5 step: 382, loss is 2.4463605880737305\n",
      "epoch: 5 step: 383, loss is 0.12650880217552185\n",
      "epoch: 5 step: 384, loss is 1.7143001556396484\n",
      "epoch: 5 step: 385, loss is 0.4085351824760437\n",
      "epoch: 5 step: 386, loss is 0.2381393313407898\n",
      "epoch: 5 step: 387, loss is 1.8717284202575684\n",
      "epoch: 5 step: 388, loss is 2.059410810470581\n",
      "epoch: 5 step: 389, loss is 0.21658627688884735\n",
      "epoch: 5 step: 390, loss is 1.7128748893737793\n",
      "epoch: 5 step: 391, loss is 1.3486334085464478\n",
      "epoch: 5 step: 392, loss is 1.6449716091156006\n",
      "epoch: 5 step: 393, loss is 1.7634251117706299\n",
      "epoch: 5 step: 394, loss is 0.12586183845996857\n",
      "epoch: 5 step: 395, loss is 2.6967248916625977\n",
      "epoch: 5 step: 396, loss is 0.9066914916038513\n",
      "epoch: 5 step: 397, loss is 0.737391471862793\n",
      "epoch: 5 step: 398, loss is 0.14614573121070862\n",
      "epoch: 5 step: 399, loss is 0.629439115524292\n",
      "epoch: 5 step: 400, loss is 0.7149603962898254\n",
      "epoch: 5 step: 401, loss is 1.9022353887557983\n",
      "epoch: 5 step: 402, loss is 2.02059268951416\n",
      "epoch: 5 step: 403, loss is 1.7116827964782715\n",
      "epoch: 5 step: 404, loss is 0.32181066274642944\n",
      "epoch: 5 step: 405, loss is 1.753955602645874\n",
      "epoch: 5 step: 406, loss is 0.23617388308048248\n",
      "epoch: 5 step: 407, loss is 1.0009266138076782\n",
      "epoch: 5 step: 408, loss is 0.3794179856777191\n",
      "epoch: 5 step: 409, loss is 0.10959366708993912\n",
      "epoch: 5 step: 410, loss is 1.8103282451629639\n",
      "epoch: 5 step: 411, loss is 2.1539697647094727\n",
      "epoch: 5 step: 412, loss is 1.7088998556137085\n",
      "epoch: 5 step: 413, loss is 1.928359031677246\n",
      "epoch: 5 step: 414, loss is 0.13012321293354034\n",
      "epoch: 5 step: 415, loss is 1.6140106916427612\n",
      "epoch: 5 step: 416, loss is 1.9070875644683838\n",
      "epoch: 5 step: 417, loss is 1.8797004222869873\n",
      "epoch: 5 step: 418, loss is 0.960446834564209\n",
      "epoch: 5 step: 419, loss is 1.5935420989990234\n",
      "epoch: 5 step: 420, loss is 2.7293829917907715\n",
      "epoch: 5 step: 421, loss is 0.33785733580589294\n",
      "epoch: 5 step: 422, loss is 1.7309950590133667\n",
      "epoch: 5 step: 423, loss is 2.4080731868743896\n",
      "epoch: 5 step: 424, loss is 1.8090271949768066\n",
      "epoch: 5 step: 425, loss is 0.21909062564373016\n",
      "epoch: 5 step: 426, loss is 1.0133023262023926\n",
      "epoch: 5 step: 427, loss is 0.7360896468162537\n",
      "epoch: 5 step: 428, loss is 0.9617089033126831\n",
      "epoch: 5 step: 429, loss is 1.0847537517547607\n",
      "epoch: 5 step: 430, loss is 1.6183607578277588\n",
      "epoch: 5 step: 431, loss is 1.5928279161453247\n",
      "epoch: 5 step: 432, loss is 1.029386043548584\n",
      "epoch: 5 step: 433, loss is 1.7841744422912598\n",
      "epoch: 5 step: 434, loss is 1.7918269634246826\n",
      "epoch: 5 step: 435, loss is 0.5154803395271301\n",
      "epoch: 5 step: 436, loss is 0.14611390233039856\n",
      "epoch: 5 step: 437, loss is 0.458069384098053\n",
      "epoch: 5 step: 438, loss is 2.155409097671509\n",
      "epoch: 5 step: 439, loss is 2.7170169353485107\n",
      "epoch: 5 step: 440, loss is 2.231934070587158\n",
      "epoch: 5 step: 441, loss is 1.0309141874313354\n",
      "epoch: 5 step: 442, loss is 0.1796998232603073\n",
      "epoch: 5 step: 443, loss is 1.82745361328125\n",
      "epoch: 5 step: 444, loss is 2.658656597137451\n",
      "epoch: 5 step: 445, loss is 0.6591113805770874\n",
      "epoch: 5 step: 446, loss is 1.5604143142700195\n",
      "epoch: 5 step: 447, loss is 1.6183991432189941\n",
      "epoch: 5 step: 448, loss is 2.2537026405334473\n",
      "epoch: 5 step: 449, loss is 0.6161559224128723\n",
      "epoch: 5 step: 450, loss is 0.12750433385372162\n",
      "epoch: 5 step: 451, loss is 2.220362901687622\n",
      "epoch: 5 step: 452, loss is 0.681857705116272\n",
      "epoch: 5 step: 453, loss is 0.42207202315330505\n",
      "epoch: 5 step: 454, loss is 2.0764732360839844\n",
      "epoch: 5 step: 455, loss is 1.7080875635147095\n",
      "epoch: 5 step: 456, loss is 2.202829360961914\n",
      "epoch: 5 step: 457, loss is 0.5743604302406311\n",
      "epoch: 5 step: 458, loss is 1.7926719188690186\n",
      "epoch: 5 step: 459, loss is 0.7532958388328552\n",
      "epoch: 5 step: 460, loss is 0.5156936645507812\n",
      "epoch: 5 step: 461, loss is 0.798723042011261\n",
      "epoch: 5 step: 462, loss is 1.8082494735717773\n",
      "epoch: 5 step: 463, loss is 1.9672832489013672\n",
      "epoch: 5 step: 464, loss is 2.2011590003967285\n",
      "epoch: 5 step: 465, loss is 1.6487274169921875\n",
      "epoch: 5 step: 466, loss is 0.5184369087219238\n",
      "epoch: 5 step: 467, loss is 0.9586973786354065\n",
      "epoch: 5 step: 468, loss is 0.28475868701934814\n",
      "epoch: 5 step: 469, loss is 0.13753126561641693\n",
      "epoch: 5 step: 470, loss is 1.061303973197937\n",
      "epoch: 5 step: 471, loss is 1.748610258102417\n",
      "epoch: 5 step: 472, loss is 0.36919519305229187\n",
      "epoch: 5 step: 473, loss is 0.06409244239330292\n",
      "epoch: 5 step: 474, loss is 0.4075593948364258\n",
      "epoch: 5 step: 475, loss is 0.12697236239910126\n",
      "epoch: 5 step: 476, loss is 0.4531879723072052\n",
      "epoch: 5 step: 477, loss is 2.084998607635498\n",
      "epoch: 5 step: 478, loss is 0.40115684270858765\n",
      "epoch: 5 step: 479, loss is 0.022363727912306786\n",
      "epoch: 5 step: 480, loss is 0.08849764615297318\n",
      "epoch: 5 step: 481, loss is 0.6041904091835022\n",
      "epoch: 5 step: 482, loss is 0.049548570066690445\n",
      "epoch: 5 step: 483, loss is 0.25498902797698975\n",
      "epoch: 5 step: 484, loss is 3.4196395874023438\n",
      "epoch: 5 step: 485, loss is 0.38752517104148865\n",
      "epoch: 5 step: 486, loss is 0.07780347019433975\n",
      "epoch: 5 step: 487, loss is 0.08771204948425293\n",
      "epoch: 5 step: 488, loss is 0.08861908316612244\n",
      "epoch: 5 step: 489, loss is 2.6842525005340576\n",
      "epoch: 5 step: 490, loss is 3.348942995071411\n",
      "epoch: 5 step: 491, loss is 0.08186926692724228\n",
      "epoch: 5 step: 492, loss is 2.6272287368774414\n",
      "epoch: 5 step: 493, loss is 0.5693129897117615\n",
      "epoch: 5 step: 494, loss is 0.46119946241378784\n",
      "epoch: 5 step: 495, loss is 1.9412250518798828\n",
      "epoch: 5 step: 496, loss is 2.2920873165130615\n",
      "epoch: 5 step: 497, loss is 3.8313608169555664\n",
      "epoch: 5 step: 498, loss is 1.982628583908081\n",
      "epoch: 5 step: 499, loss is 1.0911743640899658\n",
      "epoch: 5 step: 500, loss is 1.1905370950698853\n",
      "epoch: 5 step: 501, loss is 1.0027960538864136\n",
      "epoch: 5 step: 502, loss is 1.5405867099761963\n",
      "epoch: 5 step: 503, loss is 1.4519567489624023\n",
      "epoch: 5 step: 504, loss is 0.6475964784622192\n",
      "epoch: 5 step: 505, loss is 1.9308719635009766\n",
      "epoch: 5 step: 506, loss is 0.5999199151992798\n",
      "epoch: 5 step: 507, loss is 1.70279860496521\n",
      "epoch: 5 step: 508, loss is 0.49439504742622375\n",
      "epoch: 5 step: 509, loss is 1.7133158445358276\n",
      "epoch: 5 step: 510, loss is 1.8085094690322876\n",
      "epoch: 5 step: 511, loss is 0.4233655631542206\n",
      "epoch: 5 step: 512, loss is 0.2626894414424896\n",
      "epoch: 5 step: 513, loss is 1.699444055557251\n",
      "epoch: 5 step: 514, loss is 1.1757633686065674\n",
      "epoch: 5 step: 515, loss is 0.3575795292854309\n",
      "epoch: 5 step: 516, loss is 2.8987386226654053\n",
      "epoch: 5 step: 517, loss is 0.8079155683517456\n",
      "epoch: 5 step: 518, loss is 2.1646676063537598\n",
      "epoch: 5 step: 519, loss is 2.766381025314331\n",
      "epoch: 5 step: 520, loss is 1.7315387725830078\n",
      "epoch: 5 step: 521, loss is 1.6122421026229858\n",
      "epoch: 5 step: 522, loss is 1.628352165222168\n",
      "epoch: 5 step: 523, loss is 1.6864635944366455\n",
      "epoch: 5 step: 524, loss is 1.8746013641357422\n",
      "epoch: 5 step: 525, loss is 0.755542516708374\n",
      "epoch: 5 step: 526, loss is 1.8080267906188965\n",
      "epoch: 5 step: 527, loss is 1.8917391300201416\n",
      "epoch: 5 step: 528, loss is 1.2648086547851562\n",
      "epoch: 5 step: 529, loss is 1.6444326639175415\n",
      "epoch: 5 step: 530, loss is 0.2744671106338501\n",
      "epoch: 5 step: 531, loss is 0.7575173377990723\n",
      "epoch: 5 step: 532, loss is 0.21028660237789154\n",
      "epoch: 5 step: 533, loss is 1.7355444431304932\n",
      "epoch: 5 step: 534, loss is 0.2315949648618698\n",
      "epoch: 5 step: 535, loss is 0.6139065027236938\n",
      "epoch: 5 step: 536, loss is 0.7415789365768433\n",
      "epoch: 5 step: 537, loss is 2.032073497772217\n",
      "epoch: 5 step: 538, loss is 1.620221734046936\n",
      "epoch: 5 step: 539, loss is 0.7701231837272644\n",
      "epoch: 5 step: 540, loss is 1.8875253200531006\n",
      "epoch: 5 step: 541, loss is 0.38129591941833496\n",
      "epoch: 5 step: 542, loss is 0.9166104197502136\n",
      "epoch: 5 step: 543, loss is 1.907494068145752\n",
      "epoch: 5 step: 544, loss is 0.40030643343925476\n",
      "epoch: 5 step: 545, loss is 0.8084613680839539\n",
      "epoch: 5 step: 546, loss is 2.6916823387145996\n",
      "epoch: 5 step: 547, loss is 0.46488168835639954\n",
      "epoch: 5 step: 548, loss is 0.18621166050434113\n",
      "epoch: 5 step: 549, loss is 1.777280330657959\n",
      "epoch: 5 step: 550, loss is 1.8806289434432983\n",
      "epoch: 5 step: 551, loss is 0.5653321743011475\n",
      "epoch: 5 step: 552, loss is 1.7444841861724854\n",
      "epoch: 5 step: 553, loss is 1.6835801601409912\n",
      "epoch: 5 step: 554, loss is 1.6832531690597534\n",
      "epoch: 5 step: 555, loss is 0.9762298464775085\n",
      "epoch: 5 step: 556, loss is 0.830077052116394\n",
      "epoch: 5 step: 557, loss is 0.4996607303619385\n",
      "epoch: 5 step: 558, loss is 0.29166093468666077\n",
      "epoch: 5 step: 559, loss is 0.41033437848091125\n",
      "epoch: 5 step: 560, loss is 0.33636772632598877\n",
      "epoch: 5 step: 561, loss is 0.17998374998569489\n",
      "epoch: 5 step: 562, loss is 1.8025133609771729\n",
      "epoch: 5 step: 563, loss is 1.7338752746582031\n",
      "epoch: 5 step: 564, loss is 0.5628270506858826\n",
      "epoch: 5 step: 565, loss is 0.21438366174697876\n",
      "epoch: 5 step: 566, loss is 2.038269519805908\n",
      "epoch: 5 step: 567, loss is 0.0894438624382019\n",
      "epoch: 5 step: 568, loss is 0.32894545793533325\n",
      "epoch: 5 step: 569, loss is 0.08726555109024048\n",
      "epoch: 5 step: 570, loss is 0.55683434009552\n",
      "epoch: 5 step: 571, loss is 0.24696063995361328\n",
      "epoch: 5 step: 572, loss is 1.7361609935760498\n",
      "epoch: 5 step: 573, loss is 0.14316953718662262\n",
      "epoch: 5 step: 574, loss is 2.944176435470581\n",
      "epoch: 5 step: 575, loss is 0.8838170170783997\n",
      "epoch: 5 step: 576, loss is 0.14274640381336212\n",
      "epoch: 5 step: 577, loss is 0.8836638331413269\n",
      "epoch: 5 step: 578, loss is 2.5127298831939697\n",
      "epoch: 5 step: 579, loss is 0.08530733734369278\n",
      "epoch: 5 step: 580, loss is 1.7319490909576416\n",
      "epoch: 5 step: 581, loss is 2.637782335281372\n",
      "epoch: 5 step: 582, loss is 1.691307544708252\n",
      "epoch: 5 step: 583, loss is 1.6804413795471191\n",
      "epoch: 5 step: 584, loss is 1.107923984527588\n",
      "epoch: 5 step: 585, loss is 1.7492303848266602\n",
      "epoch: 5 step: 586, loss is 0.6045173406600952\n",
      "epoch: 5 step: 587, loss is 0.38593292236328125\n",
      "epoch: 5 step: 588, loss is 0.07842716574668884\n",
      "epoch: 5 step: 589, loss is 0.2850971519947052\n",
      "epoch: 5 step: 590, loss is 1.7619826793670654\n",
      "epoch: 5 step: 591, loss is 0.539613664150238\n",
      "epoch: 5 step: 592, loss is 0.6058959364891052\n",
      "epoch: 5 step: 593, loss is 0.0805339515209198\n",
      "epoch: 5 step: 594, loss is 0.9610485434532166\n",
      "epoch: 5 step: 595, loss is 2.195756435394287\n",
      "epoch: 5 step: 596, loss is 1.9955947399139404\n",
      "epoch: 5 step: 597, loss is 1.5666674375534058\n",
      "epoch: 5 step: 598, loss is 2.7491633892059326\n",
      "epoch: 5 step: 599, loss is 1.2720215320587158\n",
      "epoch: 5 step: 600, loss is 0.9509914517402649\n",
      "epoch: 5 step: 601, loss is 0.35087350010871887\n",
      "epoch: 5 step: 602, loss is 1.5771746635437012\n",
      "epoch: 5 step: 603, loss is 0.2600242495536804\n",
      "epoch: 5 step: 604, loss is 1.8004629611968994\n",
      "epoch: 5 step: 605, loss is 0.592319905757904\n",
      "epoch: 5 step: 606, loss is 0.28601202368736267\n",
      "epoch: 5 step: 607, loss is 0.34260380268096924\n",
      "epoch: 5 step: 608, loss is 0.20294971764087677\n",
      "epoch: 5 step: 609, loss is 0.1552855223417282\n",
      "epoch: 5 step: 610, loss is 0.41552960872650146\n",
      "epoch: 5 step: 611, loss is 0.12166351824998856\n",
      "epoch: 5 step: 612, loss is 0.0713786780834198\n",
      "epoch: 5 step: 613, loss is 2.4205126762390137\n",
      "epoch: 5 step: 614, loss is 0.7343389391899109\n",
      "epoch: 5 step: 615, loss is 0.03822730854153633\n",
      "epoch: 5 step: 616, loss is 0.4002976417541504\n",
      "epoch: 5 step: 617, loss is 0.5135501027107239\n",
      "epoch: 5 step: 618, loss is 0.1175018772482872\n",
      "epoch: 5 step: 619, loss is 0.2994942367076874\n",
      "epoch: 5 step: 620, loss is 2.6334056854248047\n",
      "epoch: 5 step: 621, loss is 0.04474426805973053\n",
      "epoch: 5 step: 622, loss is 0.06925905495882034\n",
      "epoch: 5 step: 623, loss is 0.001064806361682713\n",
      "epoch: 5 step: 624, loss is 0.013768108561635017\n",
      "epoch: 5 step: 625, loss is 1.0269441604614258\n",
      "epoch: 5 step: 626, loss is 0.0948716327548027\n",
      "epoch: 5 step: 627, loss is 0.6225095987319946\n",
      "epoch: 5 step: 628, loss is 5.38758659362793\n",
      "epoch: 5 step: 629, loss is 0.1742524355649948\n",
      "epoch: 5 step: 630, loss is 2.857074737548828\n",
      "epoch: 5 step: 631, loss is 1.945350170135498\n",
      "epoch: 5 step: 632, loss is 0.09628041833639145\n",
      "epoch: 5 step: 633, loss is 0.15885604918003082\n",
      "epoch: 5 step: 634, loss is 0.45433756709098816\n",
      "epoch: 5 step: 635, loss is 2.1196370124816895\n",
      "epoch: 5 step: 636, loss is 1.8078253269195557\n",
      "epoch: 5 step: 637, loss is 1.717018961906433\n",
      "epoch: 5 step: 638, loss is 0.16447198390960693\n",
      "epoch: 5 step: 639, loss is 2.5753862857818604\n",
      "epoch: 5 step: 640, loss is 0.8104105591773987\n",
      "epoch: 5 step: 641, loss is 2.2907042503356934\n",
      "epoch: 5 step: 642, loss is 0.21532796323299408\n",
      "epoch: 5 step: 643, loss is 1.9419987201690674\n",
      "epoch: 5 step: 644, loss is 2.7497780323028564\n",
      "epoch: 5 step: 645, loss is 1.6195011138916016\n",
      "epoch: 5 step: 646, loss is 0.41831961274147034\n",
      "epoch: 5 step: 647, loss is 1.2330212593078613\n",
      "epoch: 5 step: 648, loss is 0.4555051922798157\n",
      "epoch: 5 step: 649, loss is 1.8535406589508057\n",
      "epoch: 5 step: 650, loss is 2.2952237129211426\n",
      "epoch: 5 step: 651, loss is 0.7740824818611145\n",
      "epoch: 5 step: 652, loss is 0.8434842824935913\n",
      "epoch: 5 step: 653, loss is 1.7270009517669678\n",
      "epoch: 5 step: 654, loss is 1.6711065769195557\n",
      "epoch: 5 step: 655, loss is 2.382831573486328\n",
      "epoch: 5 step: 656, loss is 0.574673593044281\n",
      "epoch: 5 step: 657, loss is 1.662089228630066\n",
      "epoch: 5 step: 658, loss is 1.6430953741073608\n",
      "epoch: 5 step: 659, loss is 1.9870998859405518\n",
      "epoch: 5 step: 660, loss is 0.9982041716575623\n",
      "epoch: 5 step: 661, loss is 2.4195666313171387\n",
      "epoch: 5 step: 662, loss is 0.8712093234062195\n",
      "epoch: 5 step: 663, loss is 0.6765111684799194\n",
      "epoch: 5 step: 664, loss is 0.33578047156333923\n",
      "epoch: 5 step: 665, loss is 1.0614360570907593\n",
      "epoch: 5 step: 666, loss is 0.277965247631073\n",
      "epoch: 5 step: 667, loss is 0.30921876430511475\n",
      "epoch: 5 step: 668, loss is 1.60624098777771\n",
      "epoch: 5 step: 669, loss is 1.5559132099151611\n",
      "epoch: 5 step: 670, loss is 2.754448890686035\n",
      "epoch: 5 step: 671, loss is 0.8743011355400085\n",
      "epoch: 5 step: 672, loss is 1.7866588830947876\n",
      "epoch: 5 step: 673, loss is 0.4149720072746277\n",
      "epoch: 5 step: 674, loss is 1.8997021913528442\n",
      "epoch: 5 step: 675, loss is 0.45959559082984924\n",
      "epoch: 5 step: 676, loss is 2.0229477882385254\n",
      "epoch: 5 step: 677, loss is 0.883080244064331\n",
      "epoch: 5 step: 678, loss is 1.9863401651382446\n",
      "epoch: 5 step: 679, loss is 1.3676575422286987\n",
      "epoch: 5 step: 680, loss is 1.7607717514038086\n",
      "epoch: 5 step: 681, loss is 1.338565707206726\n",
      "epoch: 5 step: 682, loss is 1.1461416482925415\n",
      "epoch: 5 step: 683, loss is 0.5966687798500061\n",
      "epoch: 5 step: 684, loss is 0.3102794289588928\n",
      "epoch: 5 step: 685, loss is 0.5541452765464783\n",
      "epoch: 5 step: 686, loss is 1.8896008729934692\n",
      "epoch: 5 step: 687, loss is 0.184625044465065\n",
      "epoch: 5 step: 688, loss is 1.7205142974853516\n",
      "epoch: 5 step: 689, loss is 1.1761277914047241\n",
      "epoch: 5 step: 690, loss is 0.8430697917938232\n",
      "epoch: 5 step: 691, loss is 0.41319891810417175\n",
      "epoch: 5 step: 692, loss is 2.1941490173339844\n",
      "epoch: 5 step: 693, loss is 2.147298574447632\n",
      "epoch: 5 step: 694, loss is 2.431011199951172\n",
      "epoch: 5 step: 695, loss is 0.1944892704486847\n",
      "epoch: 5 step: 696, loss is 0.3628551661968231\n",
      "epoch: 5 step: 697, loss is 1.6535474061965942\n",
      "epoch: 5 step: 698, loss is 0.27000853419303894\n",
      "epoch: 5 step: 699, loss is 1.7212506532669067\n",
      "epoch: 5 step: 700, loss is 0.0993378534913063\n",
      "epoch: 5 step: 701, loss is 0.31461015343666077\n",
      "epoch: 5 step: 702, loss is 1.8007538318634033\n",
      "epoch: 5 step: 703, loss is 1.350046992301941\n",
      "epoch: 5 step: 704, loss is 0.28907543420791626\n",
      "epoch: 5 step: 705, loss is 0.6556046009063721\n",
      "epoch: 5 step: 706, loss is 1.64788818359375\n",
      "epoch: 5 step: 707, loss is 1.699692964553833\n",
      "epoch: 5 step: 708, loss is 0.973778247833252\n",
      "epoch: 5 step: 709, loss is 1.7827073335647583\n",
      "epoch: 5 step: 710, loss is 1.534074068069458\n",
      "epoch: 5 step: 711, loss is 0.27714207768440247\n",
      "epoch: 5 step: 712, loss is 0.21194252371788025\n",
      "epoch: 5 step: 713, loss is 0.09927006810903549\n",
      "epoch: 5 step: 714, loss is 0.026037296280264854\n",
      "epoch: 5 step: 715, loss is 1.4654356241226196\n",
      "epoch: 5 step: 716, loss is 0.11425915360450745\n",
      "epoch: 5 step: 717, loss is 1.4721604585647583\n",
      "epoch: 5 step: 718, loss is 0.6058430075645447\n",
      "epoch: 5 step: 719, loss is 0.42445847392082214\n",
      "epoch: 5 step: 720, loss is 0.4851186275482178\n",
      "epoch: 5 step: 721, loss is 2.541476011276245\n",
      "epoch: 5 step: 722, loss is 0.3506118357181549\n",
      "epoch: 5 step: 723, loss is 0.31383946537971497\n",
      "epoch: 5 step: 724, loss is 0.8334551453590393\n",
      "epoch: 5 step: 725, loss is 0.0771864503622055\n",
      "epoch: 5 step: 726, loss is 0.4854291081428528\n",
      "epoch: 5 step: 727, loss is 5.183335781097412\n",
      "epoch: 5 step: 728, loss is 0.5241451263427734\n",
      "epoch: 5 step: 729, loss is 2.186189889907837\n",
      "epoch: 5 step: 730, loss is 0.4144628047943115\n",
      "epoch: 5 step: 731, loss is 1.6986792087554932\n",
      "epoch: 5 step: 732, loss is 0.5021348595619202\n",
      "epoch: 5 step: 733, loss is 0.17731650173664093\n",
      "epoch: 5 step: 734, loss is 1.912489891052246\n",
      "epoch: 5 step: 735, loss is 2.2746987342834473\n",
      "epoch: 5 step: 736, loss is 1.6248302459716797\n",
      "epoch: 5 step: 737, loss is 0.8705217838287354\n",
      "epoch: 5 step: 738, loss is 0.32360976934432983\n",
      "epoch: 5 step: 739, loss is 0.6695421934127808\n",
      "epoch: 5 step: 740, loss is 1.5956635475158691\n",
      "epoch: 5 step: 741, loss is 3.7429633140563965\n",
      "epoch: 5 step: 742, loss is 1.839163064956665\n",
      "epoch: 5 step: 743, loss is 2.8567450046539307\n",
      "epoch: 5 step: 744, loss is 1.3358887434005737\n",
      "epoch: 5 step: 745, loss is 0.5571992993354797\n",
      "epoch: 5 step: 746, loss is 0.37246793508529663\n",
      "epoch: 5 step: 747, loss is 0.6284192800521851\n",
      "epoch: 5 step: 748, loss is 1.554058313369751\n",
      "epoch: 5 step: 749, loss is 0.5802197456359863\n",
      "epoch: 5 step: 750, loss is 0.48278674483299255\n",
      "epoch: 5 step: 751, loss is 0.30901169776916504\n",
      "epoch: 5 step: 752, loss is 0.19560842216014862\n",
      "epoch: 5 step: 753, loss is 2.563755989074707\n",
      "epoch: 5 step: 754, loss is 1.7239573001861572\n",
      "epoch: 5 step: 755, loss is 2.5672690868377686\n",
      "epoch: 5 step: 756, loss is 0.3837828040122986\n",
      "epoch: 5 step: 757, loss is 0.46820226311683655\n",
      "epoch: 5 step: 758, loss is 0.4405449330806732\n",
      "epoch: 5 step: 759, loss is 1.596372127532959\n",
      "epoch: 5 step: 760, loss is 0.5092121958732605\n",
      "epoch: 5 step: 761, loss is 0.5961484313011169\n",
      "epoch: 5 step: 762, loss is 2.5004019737243652\n",
      "epoch: 5 step: 763, loss is 1.5580605268478394\n",
      "epoch: 5 step: 764, loss is 0.5882323384284973\n",
      "epoch: 5 step: 765, loss is 1.9412965774536133\n",
      "epoch: 5 step: 766, loss is 0.35794830322265625\n",
      "epoch: 5 step: 767, loss is 0.659214973449707\n",
      "epoch: 5 step: 768, loss is 1.1576555967330933\n",
      "epoch: 5 step: 769, loss is 3.8135452270507812\n",
      "epoch: 5 step: 770, loss is 0.30099695920944214\n",
      "epoch: 5 step: 771, loss is 1.7504210472106934\n",
      "epoch: 5 step: 772, loss is 0.21838419139385223\n",
      "epoch: 5 step: 773, loss is 0.4734932780265808\n",
      "epoch: 5 step: 774, loss is 3.0260279178619385\n",
      "epoch: 5 step: 775, loss is 0.5483348965644836\n",
      "epoch: 5 step: 776, loss is 3.018479585647583\n",
      "epoch: 5 step: 777, loss is 1.842061161994934\n",
      "epoch: 5 step: 778, loss is 2.1406638622283936\n",
      "epoch: 5 step: 779, loss is 0.49720048904418945\n",
      "epoch: 5 step: 780, loss is 0.29027965664863586\n",
      "epoch: 5 step: 781, loss is 1.9571338891983032\n",
      "epoch: 5 step: 782, loss is 0.5841208696365356\n",
      "epoch: 5 step: 783, loss is 0.31118255853652954\n",
      "epoch: 5 step: 784, loss is 0.2950802743434906\n",
      "epoch: 5 step: 785, loss is 0.4869111478328705\n",
      "epoch: 5 step: 786, loss is 0.049985017627477646\n",
      "epoch: 5 step: 787, loss is 0.27574440836906433\n",
      "epoch: 5 step: 788, loss is 0.6330046057701111\n",
      "epoch: 5 step: 789, loss is 3.602262020111084\n",
      "epoch: 5 step: 790, loss is 0.11590921878814697\n",
      "epoch: 5 step: 791, loss is 3.159397602081299\n",
      "epoch: 5 step: 792, loss is 0.8778460621833801\n",
      "epoch: 5 step: 793, loss is 1.869657278060913\n",
      "epoch: 5 step: 794, loss is 0.5538195371627808\n",
      "epoch: 5 step: 795, loss is 0.464842826128006\n",
      "epoch: 5 step: 796, loss is 0.7621728181838989\n",
      "epoch: 5 step: 797, loss is 1.7242145538330078\n",
      "epoch: 5 step: 798, loss is 0.19475547969341278\n",
      "epoch: 5 step: 799, loss is 2.196664571762085\n",
      "epoch: 5 step: 800, loss is 2.6574349403381348\n",
      "epoch: 5 step: 801, loss is 0.44892704486846924\n",
      "epoch: 5 step: 802, loss is 0.7289106845855713\n",
      "epoch: 5 step: 803, loss is 1.7509037256240845\n",
      "epoch: 5 step: 804, loss is 1.6981415748596191\n",
      "epoch: 5 step: 805, loss is 1.98074209690094\n",
      "epoch: 5 step: 806, loss is 3.0639541149139404\n",
      "epoch: 5 step: 807, loss is 0.2868102788925171\n",
      "epoch: 5 step: 808, loss is 0.34899190068244934\n",
      "epoch: 5 step: 809, loss is 0.11216156929731369\n",
      "epoch: 5 step: 810, loss is 1.333353042602539\n",
      "epoch: 5 step: 811, loss is 0.920617401599884\n",
      "epoch: 5 step: 812, loss is 1.97262704372406\n",
      "epoch: 5 step: 813, loss is 0.25280052423477173\n",
      "epoch: 5 step: 814, loss is 0.6368123292922974\n",
      "epoch: 5 step: 815, loss is 0.22126322984695435\n",
      "epoch: 5 step: 816, loss is 0.1973903775215149\n",
      "epoch: 5 step: 817, loss is 0.13919422030448914\n",
      "epoch: 5 step: 818, loss is 2.1746227741241455\n",
      "epoch: 5 step: 819, loss is 1.576127529144287\n",
      "epoch: 5 step: 820, loss is 2.0657706260681152\n",
      "epoch: 5 step: 821, loss is 0.3901604413986206\n",
      "epoch: 5 step: 822, loss is 0.29665857553482056\n",
      "epoch: 5 step: 823, loss is 2.292099952697754\n",
      "epoch: 5 step: 824, loss is 1.9128971099853516\n",
      "epoch: 5 step: 825, loss is 2.7572076320648193\n",
      "epoch: 5 step: 826, loss is 0.7693066000938416\n",
      "epoch: 5 step: 827, loss is 1.1322922706604004\n",
      "epoch: 5 step: 828, loss is 0.7392994165420532\n",
      "epoch: 5 step: 829, loss is 0.12196134775876999\n",
      "epoch: 5 step: 830, loss is 0.1513473093509674\n",
      "epoch: 5 step: 831, loss is 1.9813156127929688\n",
      "epoch: 5 step: 832, loss is 0.31477418541908264\n",
      "epoch: 5 step: 833, loss is 0.11951277405023575\n",
      "epoch: 5 step: 834, loss is 0.05374397337436676\n",
      "epoch: 5 step: 835, loss is 0.21869269013404846\n",
      "epoch: 5 step: 836, loss is 2.02703595161438\n",
      "epoch: 5 step: 837, loss is 0.11480111628770828\n",
      "epoch: 5 step: 838, loss is 0.3108949363231659\n",
      "epoch: 5 step: 839, loss is 0.7907266020774841\n",
      "epoch: 5 step: 840, loss is 0.5498393177986145\n",
      "epoch: 5 step: 841, loss is 0.10701218992471695\n",
      "epoch: 5 step: 842, loss is 1.1648659706115723\n",
      "epoch: 5 step: 843, loss is 2.31453275680542\n",
      "epoch: 5 step: 844, loss is 0.9217699766159058\n",
      "epoch: 5 step: 845, loss is 0.12539051473140717\n",
      "epoch: 5 step: 846, loss is 0.2844058871269226\n",
      "epoch: 5 step: 847, loss is 0.1781941056251526\n",
      "epoch: 5 step: 848, loss is 0.04873142018914223\n",
      "epoch: 5 step: 849, loss is 0.2992081940174103\n",
      "epoch: 5 step: 850, loss is 0.10665662586688995\n",
      "epoch: 5 step: 851, loss is 0.1466146856546402\n",
      "epoch: 5 step: 852, loss is 1.917670726776123\n",
      "epoch: 5 step: 853, loss is 0.38306134939193726\n",
      "epoch: 5 step: 854, loss is 0.05075298622250557\n",
      "epoch: 5 step: 855, loss is 2.5251402854919434\n",
      "epoch: 5 step: 856, loss is 2.1936287879943848\n",
      "epoch: 5 step: 857, loss is 2.855260133743286\n",
      "epoch: 5 step: 858, loss is 0.18090945482254028\n",
      "epoch: 5 step: 859, loss is 1.3311712741851807\n",
      "epoch: 5 step: 860, loss is 0.7196894884109497\n",
      "epoch: 5 step: 861, loss is 0.06340435892343521\n",
      "epoch: 5 step: 862, loss is 0.09970487654209137\n",
      "epoch: 5 step: 863, loss is 0.38353678584098816\n",
      "epoch: 5 step: 864, loss is 0.969913125038147\n",
      "epoch: 5 step: 865, loss is 4.3464179039001465\n",
      "epoch: 5 step: 866, loss is 0.20455233752727509\n",
      "epoch: 5 step: 867, loss is 2.6879098415374756\n",
      "epoch: 5 step: 868, loss is 0.6047091484069824\n",
      "epoch: 5 step: 869, loss is 1.870703935623169\n",
      "epoch: 5 step: 870, loss is 1.8650009632110596\n",
      "epoch: 5 step: 871, loss is 0.5686774849891663\n",
      "epoch: 5 step: 872, loss is 0.2961910367012024\n",
      "epoch: 5 step: 873, loss is 0.3569343686103821\n",
      "epoch: 5 step: 874, loss is 1.5197796821594238\n",
      "epoch: 5 step: 875, loss is 0.3257419764995575\n",
      "epoch: 5 step: 876, loss is 1.8406709432601929\n",
      "epoch: 5 step: 877, loss is 0.2882169783115387\n",
      "epoch: 5 step: 878, loss is 0.6704199910163879\n",
      "epoch: 5 step: 879, loss is 0.16522108018398285\n",
      "epoch: 5 step: 880, loss is 0.5206769704818726\n",
      "epoch: 5 step: 881, loss is 0.3786356747150421\n",
      "epoch: 5 step: 882, loss is 0.3845194876194\n",
      "epoch: 5 step: 883, loss is 1.8632404804229736\n",
      "epoch: 5 step: 884, loss is 1.7315361499786377\n",
      "epoch: 5 step: 885, loss is 0.18973617255687714\n",
      "epoch: 5 step: 886, loss is 0.431936115026474\n",
      "epoch: 5 step: 887, loss is 3.3293988704681396\n",
      "epoch: 5 step: 888, loss is 0.1816413700580597\n",
      "epoch: 5 step: 889, loss is 3.045175552368164\n",
      "epoch: 5 step: 890, loss is 1.9862990379333496\n",
      "epoch: 5 step: 891, loss is 2.5110490322113037\n",
      "epoch: 5 step: 892, loss is 0.20776279270648956\n",
      "epoch: 5 step: 893, loss is 3.2809062004089355\n",
      "epoch: 5 step: 894, loss is 1.8438024520874023\n",
      "epoch: 5 step: 895, loss is 1.5493342876434326\n",
      "epoch: 5 step: 896, loss is 0.28946641087532043\n",
      "epoch: 5 step: 897, loss is 0.2500559985637665\n",
      "epoch: 5 step: 898, loss is 0.18895716965198517\n",
      "epoch: 5 step: 899, loss is 1.7957721948623657\n",
      "epoch: 5 step: 900, loss is 0.7959948778152466\n",
      "epoch: 5 step: 901, loss is 1.9692513942718506\n",
      "epoch: 5 step: 902, loss is 0.40798360109329224\n",
      "epoch: 5 step: 903, loss is 0.884449303150177\n",
      "epoch: 5 step: 904, loss is 0.07706041634082794\n",
      "epoch: 5 step: 905, loss is 3.065690279006958\n",
      "epoch: 5 step: 906, loss is 0.2662462890148163\n",
      "epoch: 5 step: 907, loss is 1.3446248769760132\n",
      "epoch: 5 step: 908, loss is 0.26002252101898193\n",
      "epoch: 5 step: 909, loss is 0.18237832188606262\n",
      "epoch: 5 step: 910, loss is 0.9625372290611267\n",
      "epoch: 5 step: 911, loss is 1.6828227043151855\n",
      "epoch: 5 step: 912, loss is 0.25810039043426514\n",
      "epoch: 5 step: 913, loss is 0.8998321890830994\n",
      "epoch: 5 step: 914, loss is 1.9832860231399536\n",
      "epoch: 5 step: 915, loss is 0.4296010434627533\n",
      "epoch: 5 step: 916, loss is 0.3813542127609253\n",
      "epoch: 5 step: 917, loss is 0.5727841854095459\n",
      "epoch: 5 step: 918, loss is 2.6465163230895996\n",
      "epoch: 5 step: 919, loss is 1.7410205602645874\n",
      "epoch: 5 step: 920, loss is 1.2071655988693237\n",
      "epoch: 5 step: 921, loss is 0.11028646677732468\n",
      "epoch: 5 step: 922, loss is 0.149495467543602\n",
      "epoch: 5 step: 923, loss is 0.2036745399236679\n",
      "epoch: 5 step: 924, loss is 1.5907789468765259\n",
      "epoch: 5 step: 925, loss is 0.7080631256103516\n",
      "epoch: 5 step: 926, loss is 0.2065185159444809\n",
      "epoch: 5 step: 927, loss is 0.14993679523468018\n",
      "epoch: 5 step: 928, loss is 0.08543966710567474\n",
      "epoch: 5 step: 929, loss is 0.13045473396778107\n",
      "epoch: 5 step: 930, loss is 0.06871642917394638\n",
      "epoch: 5 step: 931, loss is 2.1911864280700684\n",
      "epoch: 5 step: 932, loss is 0.559200644493103\n",
      "epoch: 5 step: 933, loss is 2.2701025009155273\n",
      "epoch: 5 step: 934, loss is 2.545295476913452\n",
      "epoch: 5 step: 935, loss is 0.3191027045249939\n",
      "epoch: 5 step: 936, loss is 2.3973939418792725\n",
      "epoch: 5 step: 937, loss is 0.3685483932495117\n",
      "epoch: 5 step: 938, loss is 1.9631885290145874\n",
      "epoch: 5 step: 939, loss is 0.2105696052312851\n",
      "epoch: 5 step: 940, loss is 1.7185242176055908\n",
      "epoch: 5 step: 941, loss is 3.0097010135650635\n",
      "epoch: 5 step: 942, loss is 0.782005250453949\n",
      "epoch: 5 step: 943, loss is 0.17392539978027344\n",
      "epoch: 5 step: 944, loss is 2.0907058715820312\n",
      "epoch: 5 step: 945, loss is 0.37030723690986633\n",
      "epoch: 5 step: 946, loss is 3.119446039199829\n",
      "epoch: 5 step: 947, loss is 0.19740153849124908\n",
      "epoch: 5 step: 948, loss is 0.9282777905464172\n",
      "epoch: 5 step: 949, loss is 1.8218541145324707\n",
      "epoch: 5 step: 950, loss is 1.0218127965927124\n",
      "epoch: 5 step: 951, loss is 0.21056486666202545\n",
      "epoch: 5 step: 952, loss is 0.8633279204368591\n",
      "epoch: 5 step: 953, loss is 0.6020702719688416\n",
      "epoch: 5 step: 954, loss is 0.705213189125061\n",
      "epoch: 5 step: 955, loss is 3.3059964179992676\n",
      "epoch: 5 step: 956, loss is 1.6709297895431519\n",
      "epoch: 5 step: 957, loss is 1.0722728967666626\n",
      "epoch: 5 step: 958, loss is 0.4539671838283539\n",
      "epoch: 5 step: 959, loss is 1.7850379943847656\n",
      "epoch: 5 step: 960, loss is 0.6654292345046997\n",
      "epoch: 5 step: 961, loss is 1.9096713066101074\n",
      "epoch: 5 step: 962, loss is 0.2597716450691223\n",
      "epoch: 5 step: 963, loss is 1.1065866947174072\n",
      "epoch: 5 step: 964, loss is 0.359380304813385\n",
      "epoch: 5 step: 965, loss is 0.3794735372066498\n",
      "epoch: 5 step: 966, loss is 0.3979955315589905\n",
      "epoch: 5 step: 967, loss is 0.02196286991238594\n",
      "epoch: 5 step: 968, loss is 0.08762042969465256\n",
      "epoch: 5 step: 969, loss is 4.118345260620117\n",
      "epoch: 5 step: 970, loss is 0.08668068796396255\n",
      "epoch: 5 step: 971, loss is 0.5931368470191956\n",
      "epoch: 5 step: 972, loss is 0.4144727289676666\n",
      "epoch: 5 step: 973, loss is 0.5790612101554871\n",
      "epoch: 5 step: 974, loss is 2.2732791900634766\n",
      "epoch: 5 step: 975, loss is 0.2202165424823761\n",
      "epoch: 5 step: 976, loss is 0.5451165437698364\n",
      "epoch: 5 step: 977, loss is 0.6045133471488953\n",
      "epoch: 5 step: 978, loss is 0.22141380608081818\n",
      "epoch: 5 step: 979, loss is 3.529261350631714\n",
      "epoch: 5 step: 980, loss is 2.3643417358398438\n",
      "epoch: 5 step: 981, loss is 0.3338097035884857\n",
      "epoch: 5 step: 982, loss is 0.7468370199203491\n",
      "epoch: 5 step: 983, loss is 0.3596111536026001\n",
      "epoch: 5 step: 984, loss is 0.42297816276550293\n",
      "epoch: 5 step: 985, loss is 1.1498126983642578\n",
      "epoch: 5 step: 986, loss is 0.11396157741546631\n",
      "epoch: 5 step: 987, loss is 2.4270317554473877\n",
      "epoch: 5 step: 988, loss is 1.6382194757461548\n",
      "epoch: 5 step: 989, loss is 0.3829728364944458\n",
      "epoch: 5 step: 990, loss is 0.05719224363565445\n",
      "epoch: 5 step: 991, loss is 0.14181311428546906\n",
      "epoch: 5 step: 992, loss is 0.4806073009967804\n",
      "epoch: 5 step: 993, loss is 0.3621289134025574\n",
      "epoch: 5 step: 994, loss is 0.256102591753006\n",
      "epoch: 5 step: 995, loss is 0.05542764067649841\n",
      "epoch: 5 step: 996, loss is 0.277214914560318\n",
      "epoch: 5 step: 997, loss is 0.29535695910453796\n",
      "epoch: 5 step: 998, loss is 4.237046241760254\n",
      "epoch: 5 step: 999, loss is 1.8623123168945312\n",
      "epoch: 5 step: 1000, loss is 1.861424446105957\n",
      "epoch: 5 step: 1001, loss is 0.2141929566860199\n",
      "epoch: 5 step: 1002, loss is 0.21645812690258026\n",
      "epoch: 5 step: 1003, loss is 2.7860794067382812\n",
      "epoch: 5 step: 1004, loss is 0.2365802675485611\n",
      "epoch: 5 step: 1005, loss is 2.469175338745117\n",
      "epoch: 5 step: 1006, loss is 1.6115162372589111\n",
      "epoch: 5 step: 1007, loss is 3.4915287494659424\n",
      "epoch: 5 step: 1008, loss is 1.7548463344573975\n",
      "epoch: 5 step: 1009, loss is 0.762923002243042\n",
      "epoch: 5 step: 1010, loss is 1.9379830360412598\n",
      "epoch: 5 step: 1011, loss is 2.6304473876953125\n",
      "epoch: 5 step: 1012, loss is 0.7691053152084351\n",
      "epoch: 5 step: 1013, loss is 1.0071402788162231\n",
      "epoch: 5 step: 1014, loss is 1.9042305946350098\n",
      "epoch: 5 step: 1015, loss is 1.774770736694336\n",
      "epoch: 5 step: 1016, loss is 1.1909712553024292\n",
      "epoch: 5 step: 1017, loss is 0.8247469663619995\n",
      "epoch: 5 step: 1018, loss is 0.9343979358673096\n",
      "epoch: 5 step: 1019, loss is 0.46612951159477234\n",
      "epoch: 5 step: 1020, loss is 1.903769850730896\n",
      "epoch: 5 step: 1021, loss is 0.4503823220729828\n",
      "epoch: 5 step: 1022, loss is 2.3344950675964355\n",
      "epoch: 5 step: 1023, loss is 0.2375091165304184\n",
      "epoch: 5 step: 1024, loss is 0.5013100504875183\n",
      "epoch: 5 step: 1025, loss is 1.3142629861831665\n",
      "epoch: 5 step: 1026, loss is 0.4520132541656494\n",
      "epoch: 5 step: 1027, loss is 0.594745397567749\n",
      "epoch: 5 step: 1028, loss is 0.6040430665016174\n",
      "epoch: 5 step: 1029, loss is 0.30759671330451965\n",
      "epoch: 5 step: 1030, loss is 0.2181396186351776\n",
      "epoch: 5 step: 1031, loss is 1.198997139930725\n",
      "epoch: 5 step: 1032, loss is 0.22173866629600525\n",
      "epoch: 5 step: 1033, loss is 0.36741918325424194\n",
      "epoch: 5 step: 1034, loss is 1.833353877067566\n",
      "epoch: 5 step: 1035, loss is 0.3621976971626282\n",
      "epoch: 5 step: 1036, loss is 0.167398139834404\n",
      "epoch: 5 step: 1037, loss is 2.1342341899871826\n",
      "epoch: 5 step: 1038, loss is 0.1735553741455078\n",
      "epoch: 5 step: 1039, loss is 2.5287678241729736\n",
      "epoch: 5 step: 1040, loss is 0.15147487819194794\n",
      "epoch: 5 step: 1041, loss is 0.17095521092414856\n",
      "epoch: 5 step: 1042, loss is 0.1376350373029709\n",
      "epoch: 5 step: 1043, loss is 0.14477282762527466\n",
      "epoch: 5 step: 1044, loss is 0.5503466129302979\n",
      "epoch: 5 step: 1045, loss is 1.941044569015503\n",
      "epoch: 5 step: 1046, loss is 2.7576725482940674\n",
      "epoch: 5 step: 1047, loss is 0.8496057391166687\n",
      "epoch: 5 step: 1048, loss is 2.130359411239624\n",
      "epoch: 5 step: 1049, loss is 0.22373923659324646\n",
      "epoch: 5 step: 1050, loss is 1.7846370935440063\n",
      "epoch: 5 step: 1051, loss is 0.33576157689094543\n",
      "epoch: 5 step: 1052, loss is 1.7901180982589722\n",
      "epoch: 5 step: 1053, loss is 2.2446720600128174\n",
      "epoch: 5 step: 1054, loss is 0.983924150466919\n",
      "epoch: 5 step: 1055, loss is 1.9327681064605713\n",
      "epoch: 5 step: 1056, loss is 0.4023502469062805\n",
      "epoch: 5 step: 1057, loss is 0.2722937762737274\n",
      "epoch: 5 step: 1058, loss is 1.8547465801239014\n",
      "epoch: 5 step: 1059, loss is 0.296573668718338\n",
      "epoch: 5 step: 1060, loss is 2.0822370052337646\n",
      "epoch: 5 step: 1061, loss is 2.82570219039917\n",
      "epoch: 5 step: 1062, loss is 0.7841008901596069\n",
      "epoch: 5 step: 1063, loss is 0.2297838181257248\n",
      "epoch: 5 step: 1064, loss is 0.6416400671005249\n",
      "epoch: 5 step: 1065, loss is 0.23065303266048431\n",
      "epoch: 5 step: 1066, loss is 1.928891658782959\n",
      "epoch: 5 step: 1067, loss is 0.2567511796951294\n",
      "epoch: 5 step: 1068, loss is 0.2655406892299652\n",
      "epoch: 5 step: 1069, loss is 1.7357237339019775\n",
      "epoch: 5 step: 1070, loss is 2.4530816078186035\n",
      "epoch: 5 step: 1071, loss is 0.3645230233669281\n",
      "epoch: 5 step: 1072, loss is 3.2288596630096436\n",
      "epoch: 5 step: 1073, loss is 0.435743123292923\n",
      "epoch: 5 step: 1074, loss is 1.770759105682373\n",
      "epoch: 5 step: 1075, loss is 0.32036885619163513\n",
      "epoch: 5 step: 1076, loss is 0.22717346251010895\n",
      "epoch: 5 step: 1077, loss is 0.08554670214653015\n",
      "epoch: 5 step: 1078, loss is 0.28845953941345215\n",
      "epoch: 5 step: 1079, loss is 0.1793488711118698\n",
      "epoch: 5 step: 1080, loss is 0.07151530683040619\n",
      "epoch: 5 step: 1081, loss is 2.38745379447937\n",
      "epoch: 5 step: 1082, loss is 1.3250172138214111\n",
      "epoch: 5 step: 1083, loss is 0.6184086203575134\n",
      "epoch: 5 step: 1084, loss is 0.2560499906539917\n",
      "epoch: 5 step: 1085, loss is 2.120878219604492\n",
      "epoch: 5 step: 1086, loss is 0.22098591923713684\n",
      "epoch: 5 step: 1087, loss is 1.2488714456558228\n",
      "epoch: 5 step: 1088, loss is 0.23677559196949005\n",
      "epoch: 5 step: 1089, loss is 2.68053936958313\n",
      "epoch: 5 step: 1090, loss is 2.202272891998291\n",
      "epoch: 5 step: 1091, loss is 0.4967432916164398\n",
      "epoch: 5 step: 1092, loss is 0.1790432333946228\n",
      "epoch: 5 step: 1093, loss is 1.7520105838775635\n",
      "epoch: 5 step: 1094, loss is 0.29095885157585144\n",
      "epoch: 5 step: 1095, loss is 0.5677278637886047\n",
      "epoch: 5 step: 1096, loss is 0.5959711074829102\n",
      "epoch: 5 step: 1097, loss is 0.6484262347221375\n",
      "epoch: 5 step: 1098, loss is 2.7286782264709473\n",
      "epoch: 5 step: 1099, loss is 2.0965359210968018\n",
      "epoch: 5 step: 1100, loss is 0.23750656843185425\n",
      "epoch: 5 step: 1101, loss is 2.0008933544158936\n",
      "epoch: 5 step: 1102, loss is 0.13724946975708008\n",
      "epoch: 5 step: 1103, loss is 0.24671867489814758\n",
      "epoch: 5 step: 1104, loss is 0.22946129739284515\n",
      "epoch: 5 step: 1105, loss is 2.4733574390411377\n",
      "epoch: 5 step: 1106, loss is 0.56879061460495\n",
      "epoch: 5 step: 1107, loss is 1.5446807146072388\n",
      "epoch: 5 step: 1108, loss is 1.7781307697296143\n",
      "epoch: 5 step: 1109, loss is 1.9568774700164795\n",
      "epoch: 5 step: 1110, loss is 0.5219835638999939\n",
      "epoch: 5 step: 1111, loss is 1.7005815505981445\n",
      "epoch: 5 step: 1112, loss is 0.9595156908035278\n",
      "epoch: 5 step: 1113, loss is 2.15322208404541\n",
      "epoch: 5 step: 1114, loss is 0.2533884048461914\n",
      "epoch: 5 step: 1115, loss is 0.3652189075946808\n",
      "epoch: 5 step: 1116, loss is 2.2726891040802\n",
      "epoch: 5 step: 1117, loss is 0.16598869860172272\n",
      "epoch: 5 step: 1118, loss is 0.4669681489467621\n",
      "epoch: 5 step: 1119, loss is 0.17336013913154602\n",
      "epoch: 5 step: 1120, loss is 2.1805992126464844\n",
      "epoch: 5 step: 1121, loss is 0.13575510680675507\n",
      "epoch: 5 step: 1122, loss is 1.8658456802368164\n",
      "epoch: 5 step: 1123, loss is 0.46169424057006836\n",
      "epoch: 5 step: 1124, loss is 0.1429370641708374\n",
      "epoch: 5 step: 1125, loss is 2.399150848388672\n",
      "epoch: 5 step: 1126, loss is 0.33100971579551697\n",
      "epoch: 5 step: 1127, loss is 0.08040976524353027\n",
      "epoch: 5 step: 1128, loss is 0.6881713271141052\n",
      "epoch: 5 step: 1129, loss is 3.8601465225219727\n",
      "epoch: 5 step: 1130, loss is 2.308539390563965\n",
      "epoch: 5 step: 1131, loss is 1.7894368171691895\n",
      "epoch: 5 step: 1132, loss is 0.6355290412902832\n",
      "epoch: 5 step: 1133, loss is 1.9348762035369873\n",
      "epoch: 5 step: 1134, loss is 0.4689636826515198\n",
      "epoch: 5 step: 1135, loss is 0.5783259868621826\n",
      "epoch: 5 step: 1136, loss is 0.935174286365509\n",
      "epoch: 5 step: 1137, loss is 1.6947143077850342\n",
      "epoch: 5 step: 1138, loss is 2.5812458992004395\n",
      "epoch: 5 step: 1139, loss is 2.2323532104492188\n",
      "epoch: 5 step: 1140, loss is 2.2821812629699707\n",
      "epoch: 5 step: 1141, loss is 1.5689988136291504\n",
      "epoch: 5 step: 1142, loss is 0.682467520236969\n",
      "epoch: 5 step: 1143, loss is 2.423046588897705\n",
      "epoch: 5 step: 1144, loss is 2.0460896492004395\n",
      "epoch: 5 step: 1145, loss is 1.5613975524902344\n",
      "epoch: 5 step: 1146, loss is 1.7360361814498901\n",
      "epoch: 5 step: 1147, loss is 0.9350709915161133\n",
      "epoch: 5 step: 1148, loss is 0.906767725944519\n",
      "epoch: 5 step: 1149, loss is 1.6305201053619385\n",
      "epoch: 5 step: 1150, loss is 1.7346265316009521\n",
      "epoch: 5 step: 1151, loss is 0.5240108370780945\n",
      "epoch: 5 step: 1152, loss is 0.8584780097007751\n",
      "epoch: 5 step: 1153, loss is 0.5799815058708191\n",
      "epoch: 5 step: 1154, loss is 0.31634700298309326\n",
      "epoch: 5 step: 1155, loss is 0.5033499598503113\n",
      "epoch: 5 step: 1156, loss is 1.6914716958999634\n",
      "epoch: 5 step: 1157, loss is 0.22785978019237518\n",
      "epoch: 5 step: 1158, loss is 0.6672452688217163\n",
      "epoch: 5 step: 1159, loss is 0.17552758753299713\n",
      "epoch: 5 step: 1160, loss is 0.6148735284805298\n",
      "epoch: 5 step: 1161, loss is 0.2176526039838791\n",
      "epoch: 5 step: 1162, loss is 3.53607177734375\n",
      "epoch: 5 step: 1163, loss is 0.3818123936653137\n",
      "epoch: 5 step: 1164, loss is 2.2538280487060547\n",
      "epoch: 5 step: 1165, loss is 2.6359262466430664\n",
      "epoch: 5 step: 1166, loss is 0.5643339157104492\n",
      "epoch: 5 step: 1167, loss is 0.36578789353370667\n",
      "epoch: 5 step: 1168, loss is 0.6128533482551575\n",
      "epoch: 5 step: 1169, loss is 2.74885892868042\n",
      "epoch: 5 step: 1170, loss is 2.7532482147216797\n",
      "epoch: 5 step: 1171, loss is 2.3847522735595703\n",
      "epoch: 5 step: 1172, loss is 1.129376769065857\n",
      "epoch: 5 step: 1173, loss is 1.7122502326965332\n",
      "epoch: 5 step: 1174, loss is 0.5338747501373291\n",
      "epoch: 5 step: 1175, loss is 2.2852163314819336\n",
      "epoch: 5 step: 1176, loss is 1.633897066116333\n",
      "epoch: 5 step: 1177, loss is 1.7600820064544678\n",
      "epoch: 5 step: 1178, loss is 0.9924135208129883\n",
      "epoch: 5 step: 1179, loss is 1.842719316482544\n",
      "epoch: 5 step: 1180, loss is 2.0248470306396484\n",
      "epoch: 5 step: 1181, loss is 2.081122398376465\n",
      "epoch: 5 step: 1182, loss is 1.834331750869751\n",
      "epoch: 5 step: 1183, loss is 1.6453379392623901\n",
      "epoch: 5 step: 1184, loss is 0.9739001393318176\n",
      "epoch: 5 step: 1185, loss is 1.8487377166748047\n",
      "epoch: 5 step: 1186, loss is 1.707262396812439\n",
      "epoch: 5 step: 1187, loss is 1.7044612169265747\n",
      "epoch: 5 step: 1188, loss is 0.8374562859535217\n",
      "epoch: 5 step: 1189, loss is 1.684798240661621\n",
      "epoch: 5 step: 1190, loss is 0.9846867918968201\n",
      "epoch: 5 step: 1191, loss is 0.6813270449638367\n",
      "epoch: 5 step: 1192, loss is 0.5970145463943481\n",
      "epoch: 5 step: 1193, loss is 2.5046472549438477\n",
      "epoch: 5 step: 1194, loss is 1.751185417175293\n",
      "epoch: 5 step: 1195, loss is 1.2292932271957397\n",
      "epoch: 5 step: 1196, loss is 0.8217467069625854\n",
      "epoch: 5 step: 1197, loss is 0.7773644328117371\n",
      "epoch: 5 step: 1198, loss is 0.5111265778541565\n",
      "epoch: 5 step: 1199, loss is 2.0900795459747314\n",
      "epoch: 5 step: 1200, loss is 0.5006158351898193\n",
      "epoch: 5 step: 1201, loss is 0.6844172477722168\n",
      "epoch: 5 step: 1202, loss is 0.32588937878608704\n",
      "epoch: 5 step: 1203, loss is 0.8742959499359131\n",
      "epoch: 5 step: 1204, loss is 0.8372522592544556\n",
      "epoch: 5 step: 1205, loss is 0.5446197986602783\n",
      "epoch: 5 step: 1206, loss is 0.6416364312171936\n",
      "epoch: 5 step: 1207, loss is 1.326901912689209\n",
      "epoch: 5 step: 1208, loss is 2.625770092010498\n",
      "epoch: 5 step: 1209, loss is 0.1228257268667221\n",
      "epoch: 5 step: 1210, loss is 1.326932668685913\n",
      "epoch: 5 step: 1211, loss is 0.3409487009048462\n",
      "epoch: 5 step: 1212, loss is 0.32472100853919983\n",
      "epoch: 5 step: 1213, loss is 1.738274097442627\n",
      "epoch: 5 step: 1214, loss is 0.26651591062545776\n",
      "epoch: 5 step: 1215, loss is 1.8117188215255737\n",
      "epoch: 5 step: 1216, loss is 2.7196836471557617\n",
      "epoch: 5 step: 1217, loss is 1.7763422727584839\n",
      "epoch: 5 step: 1218, loss is 0.9770467281341553\n",
      "epoch: 5 step: 1219, loss is 2.831153392791748\n",
      "epoch: 5 step: 1220, loss is 2.4106361865997314\n",
      "epoch: 5 step: 1221, loss is 1.9664397239685059\n",
      "epoch: 5 step: 1222, loss is 0.8251147270202637\n",
      "epoch: 5 step: 1223, loss is 1.6780507564544678\n",
      "epoch: 5 step: 1224, loss is 0.9480905532836914\n",
      "epoch: 5 step: 1225, loss is 1.883381962776184\n",
      "epoch: 5 step: 1226, loss is 0.5390306711196899\n",
      "epoch: 5 step: 1227, loss is 1.5923519134521484\n",
      "epoch: 5 step: 1228, loss is 0.8765088319778442\n",
      "epoch: 5 step: 1229, loss is 0.8070709109306335\n",
      "epoch: 5 step: 1230, loss is 3.8287577629089355\n",
      "epoch: 5 step: 1231, loss is 1.694437026977539\n",
      "epoch: 5 step: 1232, loss is 1.6395761966705322\n",
      "epoch: 5 step: 1233, loss is 0.8285670876502991\n",
      "epoch: 5 step: 1234, loss is 0.744328498840332\n",
      "epoch: 5 step: 1235, loss is 0.7314285039901733\n",
      "epoch: 5 step: 1236, loss is 1.778486728668213\n",
      "epoch: 5 step: 1237, loss is 1.6029973030090332\n",
      "epoch: 5 step: 1238, loss is 1.63899827003479\n",
      "epoch: 5 step: 1239, loss is 0.8391538262367249\n",
      "epoch: 5 step: 1240, loss is 0.8194661736488342\n",
      "epoch: 5 step: 1241, loss is 2.2825422286987305\n",
      "epoch: 5 step: 1242, loss is 1.7576206922531128\n",
      "epoch: 5 step: 1243, loss is 1.8391773700714111\n",
      "epoch: 5 step: 1244, loss is 1.7310116291046143\n",
      "epoch: 5 step: 1245, loss is 1.6451421976089478\n",
      "epoch: 5 step: 1246, loss is 2.202422618865967\n",
      "epoch: 5 step: 1247, loss is 0.43710336089134216\n",
      "epoch: 5 step: 1248, loss is 2.0158517360687256\n",
      "epoch: 5 step: 1249, loss is 1.1966221332550049\n",
      "epoch: 5 step: 1250, loss is 0.8955351710319519\n",
      "epoch: 5 step: 1251, loss is 0.7914502620697021\n",
      "epoch: 5 step: 1252, loss is 0.7590765357017517\n",
      "epoch: 5 step: 1253, loss is 0.41204649209976196\n",
      "epoch: 5 step: 1254, loss is 1.6999335289001465\n",
      "epoch: 5 step: 1255, loss is 1.9504621028900146\n",
      "epoch: 5 step: 1256, loss is 0.6924660205841064\n",
      "epoch: 5 step: 1257, loss is 1.7610305547714233\n",
      "epoch: 5 step: 1258, loss is 0.7921478748321533\n",
      "epoch: 5 step: 1259, loss is 0.4936337471008301\n",
      "epoch: 5 step: 1260, loss is 1.1013332605361938\n",
      "epoch: 5 step: 1261, loss is 0.5783102512359619\n",
      "epoch: 5 step: 1262, loss is 0.6526196002960205\n",
      "epoch: 5 step: 1263, loss is 1.868110179901123\n",
      "epoch: 5 step: 1264, loss is 0.3218643069267273\n",
      "epoch: 5 step: 1265, loss is 0.6475021243095398\n",
      "epoch: 5 step: 1266, loss is 0.28950923681259155\n",
      "epoch: 5 step: 1267, loss is 1.812982201576233\n",
      "epoch: 5 step: 1268, loss is 0.7088233232498169\n",
      "epoch: 5 step: 1269, loss is 1.647579550743103\n",
      "epoch: 5 step: 1270, loss is 0.5335392951965332\n",
      "epoch: 5 step: 1271, loss is 0.17010822892189026\n",
      "epoch: 5 step: 1272, loss is 0.25532984733581543\n",
      "epoch: 5 step: 1273, loss is 1.9560415744781494\n",
      "epoch: 5 step: 1274, loss is 0.37461021542549133\n",
      "epoch: 5 step: 1275, loss is 0.2194482982158661\n",
      "epoch: 5 step: 1276, loss is 0.13225848972797394\n",
      "epoch: 5 step: 1277, loss is 0.10179707407951355\n",
      "epoch: 5 step: 1278, loss is 0.6101148724555969\n",
      "epoch: 5 step: 1279, loss is 0.15537747740745544\n",
      "epoch: 5 step: 1280, loss is 1.6722726821899414\n",
      "epoch: 5 step: 1281, loss is 0.6207510828971863\n",
      "epoch: 5 step: 1282, loss is 1.95880126953125\n",
      "epoch: 5 step: 1283, loss is 0.7602635025978088\n",
      "epoch: 5 step: 1284, loss is 2.8401381969451904\n",
      "epoch: 5 step: 1285, loss is 0.5006884932518005\n",
      "epoch: 5 step: 1286, loss is 7.917245864868164\n",
      "epoch: 5 step: 1287, loss is 0.17646151781082153\n",
      "epoch: 5 step: 1288, loss is 1.5976755619049072\n",
      "epoch: 5 step: 1289, loss is 0.5895071625709534\n",
      "epoch: 5 step: 1290, loss is 2.0663251876831055\n",
      "epoch: 5 step: 1291, loss is 1.9889980554580688\n",
      "epoch: 5 step: 1292, loss is 0.49999216198921204\n",
      "epoch: 5 step: 1293, loss is 2.480530261993408\n",
      "epoch: 5 step: 1294, loss is 0.6516130566596985\n",
      "epoch: 5 step: 1295, loss is 0.715582013130188\n",
      "epoch: 5 step: 1296, loss is 2.031644821166992\n",
      "epoch: 5 step: 1297, loss is 1.6846709251403809\n",
      "epoch: 5 step: 1298, loss is 1.0371514558792114\n",
      "epoch: 5 step: 1299, loss is 0.7350674867630005\n",
      "epoch: 5 step: 1300, loss is 1.3343733549118042\n",
      "epoch: 5 step: 1301, loss is 2.101550817489624\n",
      "epoch: 5 step: 1302, loss is 0.9415397644042969\n",
      "epoch: 5 step: 1303, loss is 0.4897707998752594\n",
      "epoch: 5 step: 1304, loss is 0.5116680264472961\n",
      "epoch: 5 step: 1305, loss is 0.3174540400505066\n",
      "epoch: 5 step: 1306, loss is 1.3244582414627075\n",
      "epoch: 5 step: 1307, loss is 0.5251539349555969\n",
      "epoch: 5 step: 1308, loss is 1.3204759359359741\n",
      "epoch: 5 step: 1309, loss is 0.33627745509147644\n",
      "epoch: 5 step: 1310, loss is 0.6353563070297241\n",
      "epoch: 5 step: 1311, loss is 0.33016252517700195\n",
      "epoch: 5 step: 1312, loss is 0.5440325736999512\n",
      "epoch: 5 step: 1313, loss is 1.7389497756958008\n",
      "epoch: 5 step: 1314, loss is 0.4798479974269867\n",
      "epoch: 5 step: 1315, loss is 2.1353302001953125\n",
      "epoch: 5 step: 1316, loss is 0.22634857892990112\n",
      "epoch: 5 step: 1317, loss is 2.042743444442749\n",
      "epoch: 5 step: 1318, loss is 0.3655517101287842\n",
      "epoch: 5 step: 1319, loss is 0.308999627828598\n",
      "epoch: 5 step: 1320, loss is 0.45036372542381287\n",
      "epoch: 5 step: 1321, loss is 0.21953214704990387\n",
      "epoch: 5 step: 1322, loss is 2.4493722915649414\n",
      "epoch: 5 step: 1323, loss is 0.15619520843029022\n",
      "epoch: 5 step: 1324, loss is 0.23488427698612213\n",
      "epoch: 5 step: 1325, loss is 0.22539730370044708\n",
      "epoch: 5 step: 1326, loss is 3.0451161861419678\n",
      "epoch: 5 step: 1327, loss is 1.6951637268066406\n",
      "epoch: 5 step: 1328, loss is 0.11043303459882736\n",
      "epoch: 5 step: 1329, loss is 1.748787522315979\n",
      "epoch: 5 step: 1330, loss is 0.586201548576355\n",
      "epoch: 5 step: 1331, loss is 1.7498250007629395\n",
      "epoch: 5 step: 1332, loss is 1.2506355047225952\n",
      "epoch: 5 step: 1333, loss is 0.9416833519935608\n",
      "epoch: 5 step: 1334, loss is 1.7064523696899414\n",
      "epoch: 5 step: 1335, loss is 0.17329387366771698\n",
      "epoch: 5 step: 1336, loss is 0.12528230249881744\n",
      "epoch: 5 step: 1337, loss is 1.788784384727478\n",
      "epoch: 5 step: 1338, loss is 0.589992880821228\n",
      "epoch: 5 step: 1339, loss is 0.4232848584651947\n",
      "epoch: 5 step: 1340, loss is 2.834476947784424\n",
      "epoch: 5 step: 1341, loss is 0.8339498043060303\n",
      "epoch: 5 step: 1342, loss is 2.3546533584594727\n",
      "epoch: 5 step: 1343, loss is 0.22932301461696625\n",
      "epoch: 5 step: 1344, loss is 1.9210437536239624\n",
      "epoch: 5 step: 1345, loss is 0.12730030715465546\n",
      "epoch: 5 step: 1346, loss is 0.43565452098846436\n",
      "epoch: 5 step: 1347, loss is 0.19366544485092163\n",
      "epoch: 5 step: 1348, loss is 0.1941874474287033\n",
      "epoch: 5 step: 1349, loss is 0.8697909712791443\n",
      "epoch: 5 step: 1350, loss is 2.6926932334899902\n",
      "epoch: 5 step: 1351, loss is 0.4927448332309723\n",
      "epoch: 5 step: 1352, loss is 0.25006258487701416\n",
      "epoch: 5 step: 1353, loss is 0.4102359116077423\n",
      "epoch: 5 step: 1354, loss is 0.12564866244792938\n",
      "epoch: 5 step: 1355, loss is 1.904064416885376\n",
      "epoch: 5 step: 1356, loss is 0.4256089925765991\n",
      "epoch: 5 step: 1357, loss is 3.885805130004883\n",
      "epoch: 5 step: 1358, loss is 0.9038085341453552\n",
      "epoch: 5 step: 1359, loss is 1.7310402393341064\n",
      "epoch: 5 step: 1360, loss is 0.18523915112018585\n",
      "epoch: 5 step: 1361, loss is 2.575239658355713\n",
      "epoch: 5 step: 1362, loss is 0.42450401186943054\n",
      "epoch: 5 step: 1363, loss is 3.1759872436523438\n",
      "epoch: 5 step: 1364, loss is 0.9348559975624084\n",
      "epoch: 5 step: 1365, loss is 0.2463158220052719\n",
      "epoch: 5 step: 1366, loss is 0.32767051458358765\n",
      "epoch: 5 step: 1367, loss is 2.981015205383301\n",
      "epoch: 5 step: 1368, loss is 1.3064342737197876\n",
      "epoch: 5 step: 1369, loss is 1.7824974060058594\n",
      "epoch: 5 step: 1370, loss is 1.582822322845459\n",
      "epoch: 5 step: 1371, loss is 2.5861685276031494\n",
      "epoch: 5 step: 1372, loss is 0.834757924079895\n",
      "epoch: 5 step: 1373, loss is 2.6375579833984375\n",
      "epoch: 5 step: 1374, loss is 0.6520295739173889\n",
      "epoch: 5 step: 1375, loss is 1.5957331657409668\n",
      "epoch: 5 step: 1376, loss is 2.3182852268218994\n",
      "epoch: 5 step: 1377, loss is 1.3215961456298828\n",
      "epoch: 5 step: 1378, loss is 1.6828877925872803\n",
      "epoch: 5 step: 1379, loss is 0.5484856367111206\n",
      "epoch: 5 step: 1380, loss is 0.08436968922615051\n",
      "epoch: 5 step: 1381, loss is 0.2685132622718811\n",
      "epoch: 5 step: 1382, loss is 0.497664213180542\n",
      "epoch: 5 step: 1383, loss is 0.12262865900993347\n",
      "epoch: 5 step: 1384, loss is 0.17251740396022797\n",
      "epoch: 5 step: 1385, loss is 1.7252345085144043\n",
      "epoch: 5 step: 1386, loss is 0.3066224455833435\n",
      "epoch: 5 step: 1387, loss is 0.5976786613464355\n",
      "epoch: 5 step: 1388, loss is 2.689310073852539\n",
      "epoch: 5 step: 1389, loss is 0.5380354523658752\n",
      "epoch: 5 step: 1390, loss is 1.7084118127822876\n",
      "epoch: 5 step: 1391, loss is 0.2540515065193176\n",
      "epoch: 5 step: 1392, loss is 0.6115372180938721\n",
      "epoch: 5 step: 1393, loss is 0.3942386209964752\n",
      "epoch: 5 step: 1394, loss is 0.12916862964630127\n",
      "epoch: 5 step: 1395, loss is 2.283851146697998\n",
      "epoch: 5 step: 1396, loss is 0.4394036531448364\n",
      "epoch: 5 step: 1397, loss is 0.21636365354061127\n",
      "epoch: 5 step: 1398, loss is 1.757859468460083\n",
      "epoch: 5 step: 1399, loss is 1.0676765441894531\n",
      "epoch: 5 step: 1400, loss is 2.0674023628234863\n",
      "epoch: 5 step: 1401, loss is 1.3181036710739136\n",
      "epoch: 5 step: 1402, loss is 1.7727891206741333\n",
      "epoch: 5 step: 1403, loss is 0.16751913726329803\n",
      "epoch: 5 step: 1404, loss is 1.950556993484497\n",
      "epoch: 5 step: 1405, loss is 1.8465197086334229\n",
      "epoch: 5 step: 1406, loss is 0.6011735200881958\n",
      "epoch: 5 step: 1407, loss is 1.739351749420166\n",
      "epoch: 5 step: 1408, loss is 1.709573745727539\n",
      "epoch: 5 step: 1409, loss is 0.783931314945221\n",
      "epoch: 5 step: 1410, loss is 1.7808079719543457\n",
      "epoch: 5 step: 1411, loss is 1.6690908670425415\n",
      "epoch: 5 step: 1412, loss is 0.6232106685638428\n",
      "epoch: 5 step: 1413, loss is 1.6726274490356445\n",
      "epoch: 5 step: 1414, loss is 1.9329605102539062\n",
      "epoch: 5 step: 1415, loss is 1.8520241975784302\n",
      "epoch: 5 step: 1416, loss is 0.44546768069267273\n",
      "epoch: 5 step: 1417, loss is 0.4248649775981903\n",
      "epoch: 5 step: 1418, loss is 0.22199037671089172\n",
      "epoch: 5 step: 1419, loss is 0.4133335053920746\n",
      "epoch: 5 step: 1420, loss is 0.14818419516086578\n",
      "epoch: 5 step: 1421, loss is 0.13496088981628418\n",
      "epoch: 5 step: 1422, loss is 0.26602110266685486\n",
      "epoch: 5 step: 1423, loss is 0.6918519735336304\n",
      "epoch: 5 step: 1424, loss is 3.681990146636963\n",
      "epoch: 5 step: 1425, loss is 0.36487773060798645\n",
      "epoch: 5 step: 1426, loss is 1.9245002269744873\n",
      "epoch: 5 step: 1427, loss is 0.3431318402290344\n",
      "epoch: 5 step: 1428, loss is 0.1207956001162529\n",
      "epoch: 5 step: 1429, loss is 0.16787537932395935\n",
      "epoch: 5 step: 1430, loss is 0.16190959513187408\n",
      "epoch: 5 step: 1431, loss is 0.11738983541727066\n",
      "epoch: 5 step: 1432, loss is 0.24400492012500763\n",
      "epoch: 5 step: 1433, loss is 0.06452114135026932\n",
      "epoch: 5 step: 1434, loss is 0.1982988566160202\n",
      "epoch: 5 step: 1435, loss is 0.3581452965736389\n",
      "epoch: 5 step: 1436, loss is 0.5509650707244873\n",
      "epoch: 5 step: 1437, loss is 0.04471474513411522\n",
      "epoch: 5 step: 1438, loss is 0.32463857531547546\n",
      "epoch: 5 step: 1439, loss is 0.025581669062376022\n",
      "epoch: 5 step: 1440, loss is 0.1830195188522339\n",
      "epoch: 5 step: 1441, loss is 0.019323669373989105\n",
      "epoch: 5 step: 1442, loss is 2.3324592113494873\n",
      "epoch: 5 step: 1443, loss is 2.5032262802124023\n",
      "epoch: 5 step: 1444, loss is 0.3187667429447174\n",
      "epoch: 5 step: 1445, loss is 0.03196067363023758\n",
      "epoch: 5 step: 1446, loss is 1.728470802307129\n",
      "epoch: 5 step: 1447, loss is 0.5745984315872192\n",
      "epoch: 5 step: 1448, loss is 3.2640349864959717\n",
      "epoch: 5 step: 1449, loss is 1.6952385902404785\n",
      "epoch: 5 step: 1450, loss is 2.298525810241699\n",
      "epoch: 5 step: 1451, loss is 0.2605823874473572\n",
      "epoch: 5 step: 1452, loss is 0.16398198902606964\n",
      "epoch: 5 step: 1453, loss is 2.439876079559326\n",
      "epoch: 5 step: 1454, loss is 0.3182356655597687\n",
      "epoch: 5 step: 1455, loss is 0.29436194896698\n",
      "epoch: 5 step: 1456, loss is 0.6338467597961426\n",
      "epoch: 5 step: 1457, loss is 0.46636345982551575\n",
      "epoch: 5 step: 1458, loss is 0.39639487862586975\n",
      "epoch: 5 step: 1459, loss is 0.0967259481549263\n",
      "epoch: 5 step: 1460, loss is 0.26775363087654114\n",
      "epoch: 5 step: 1461, loss is 0.12210959941148758\n",
      "epoch: 5 step: 1462, loss is 0.11247864365577698\n",
      "epoch: 5 step: 1463, loss is 0.1388332098722458\n",
      "epoch: 5 step: 1464, loss is 0.062311649322509766\n",
      "epoch: 5 step: 1465, loss is 4.265527725219727\n",
      "epoch: 5 step: 1466, loss is 2.245403528213501\n",
      "epoch: 5 step: 1467, loss is 0.13917212188243866\n",
      "epoch: 5 step: 1468, loss is 0.3296893239021301\n",
      "epoch: 5 step: 1469, loss is 0.8941046595573425\n",
      "epoch: 5 step: 1470, loss is 0.06927841156721115\n",
      "epoch: 5 step: 1471, loss is 3.975337505340576\n",
      "epoch: 5 step: 1472, loss is 1.4253032207489014\n",
      "epoch: 5 step: 1473, loss is 0.34131044149398804\n",
      "epoch: 5 step: 1474, loss is 0.44925686717033386\n",
      "epoch: 5 step: 1475, loss is 0.3160814642906189\n",
      "epoch: 5 step: 1476, loss is 1.8252911567687988\n",
      "epoch: 5 step: 1477, loss is 0.29086047410964966\n",
      "epoch: 5 step: 1478, loss is 0.0881880447268486\n",
      "epoch: 5 step: 1479, loss is 2.5447566509246826\n",
      "epoch: 5 step: 1480, loss is 0.843488872051239\n",
      "epoch: 5 step: 1481, loss is 0.062741219997406\n",
      "epoch: 5 step: 1482, loss is 1.3114081621170044\n",
      "epoch: 5 step: 1483, loss is 0.28625908493995667\n",
      "epoch: 5 step: 1484, loss is 1.8121459484100342\n",
      "epoch: 5 step: 1485, loss is 0.26935210824012756\n",
      "epoch: 5 step: 1486, loss is 0.4631769061088562\n",
      "epoch: 5 step: 1487, loss is 0.1734391152858734\n",
      "epoch: 5 step: 1488, loss is 3.1052424907684326\n",
      "epoch: 5 step: 1489, loss is 1.7349529266357422\n",
      "epoch: 5 step: 1490, loss is 2.9399874210357666\n",
      "epoch: 5 step: 1491, loss is 1.6472692489624023\n",
      "epoch: 5 step: 1492, loss is 1.682558536529541\n",
      "epoch: 5 step: 1493, loss is 0.7831124067306519\n",
      "epoch: 5 step: 1494, loss is 0.6055635809898376\n",
      "epoch: 5 step: 1495, loss is 0.323809415102005\n",
      "epoch: 5 step: 1496, loss is 0.4887849986553192\n",
      "epoch: 5 step: 1497, loss is 0.1520925760269165\n",
      "epoch: 5 step: 1498, loss is 0.22885070741176605\n",
      "epoch: 5 step: 1499, loss is 2.118959426879883\n",
      "epoch: 5 step: 1500, loss is 1.7128716707229614\n",
      "epoch: 5 step: 1501, loss is 1.934335470199585\n",
      "epoch: 5 step: 1502, loss is 0.4087250232696533\n",
      "epoch: 5 step: 1503, loss is 1.4480922222137451\n",
      "epoch: 5 step: 1504, loss is 2.2265305519104004\n",
      "epoch: 5 step: 1505, loss is 1.328266978263855\n",
      "epoch: 5 step: 1506, loss is 0.21636220812797546\n",
      "epoch: 5 step: 1507, loss is 1.3179504871368408\n",
      "epoch: 5 step: 1508, loss is 1.2896701097488403\n",
      "epoch: 5 step: 1509, loss is 0.4208974540233612\n",
      "epoch: 5 step: 1510, loss is 0.44280585646629333\n",
      "epoch: 5 step: 1511, loss is 0.10889846086502075\n",
      "epoch: 5 step: 1512, loss is 0.20406635105609894\n",
      "epoch: 5 step: 1513, loss is 0.4460046887397766\n",
      "epoch: 5 step: 1514, loss is 0.05721047893166542\n",
      "epoch: 5 step: 1515, loss is 1.4659818410873413\n",
      "epoch: 5 step: 1516, loss is 0.3408257067203522\n",
      "epoch: 5 step: 1517, loss is 0.0529463030397892\n",
      "epoch: 5 step: 1518, loss is 1.2876427173614502\n",
      "epoch: 5 step: 1519, loss is 1.6071562767028809\n",
      "epoch: 5 step: 1520, loss is 0.14461325109004974\n",
      "epoch: 5 step: 1521, loss is 0.009657448157668114\n",
      "epoch: 5 step: 1522, loss is 1.7066727876663208\n",
      "epoch: 5 step: 1523, loss is 1.2516192197799683\n",
      "epoch: 5 step: 1524, loss is 0.048611968755722046\n",
      "epoch: 5 step: 1525, loss is 0.21243946254253387\n",
      "epoch: 5 step: 1526, loss is 0.3332039415836334\n",
      "epoch: 5 step: 1527, loss is 1.9225246906280518\n",
      "epoch: 5 step: 1528, loss is 2.8066189289093018\n",
      "epoch: 5 step: 1529, loss is 0.36027270555496216\n",
      "epoch: 5 step: 1530, loss is 0.4716564416885376\n",
      "epoch: 5 step: 1531, loss is 1.3007827997207642\n",
      "epoch: 5 step: 1532, loss is 1.1586486101150513\n",
      "epoch: 5 step: 1533, loss is 1.727622628211975\n",
      "epoch: 5 step: 1534, loss is 0.6641483902931213\n",
      "epoch: 5 step: 1535, loss is 0.022814881056547165\n",
      "epoch: 5 step: 1536, loss is 2.2667062282562256\n",
      "epoch: 5 step: 1537, loss is 0.12925809621810913\n",
      "epoch: 5 step: 1538, loss is 0.8659027218818665\n",
      "epoch: 5 step: 1539, loss is 3.9385764598846436\n",
      "epoch: 5 step: 1540, loss is 2.1034436225891113\n",
      "epoch: 5 step: 1541, loss is 0.3985131084918976\n",
      "epoch: 5 step: 1542, loss is 0.3522486090660095\n",
      "epoch: 5 step: 1543, loss is 0.07611963897943497\n",
      "epoch: 5 step: 1544, loss is 3.3406500816345215\n",
      "epoch: 5 step: 1545, loss is 2.588218927383423\n",
      "epoch: 5 step: 1546, loss is 0.31057506799697876\n",
      "epoch: 5 step: 1547, loss is 0.2775803804397583\n",
      "epoch: 5 step: 1548, loss is 0.21913409233093262\n",
      "epoch: 5 step: 1549, loss is 1.6986396312713623\n",
      "epoch: 5 step: 1550, loss is 0.4152851104736328\n",
      "epoch: 5 step: 1551, loss is 0.40953323245048523\n",
      "epoch: 5 step: 1552, loss is 3.1495420932769775\n",
      "epoch: 5 step: 1553, loss is 2.2789463996887207\n",
      "epoch: 5 step: 1554, loss is 2.0481815338134766\n",
      "epoch: 5 step: 1555, loss is 1.6486446857452393\n",
      "epoch: 5 step: 1556, loss is 1.2055385112762451\n",
      "epoch: 5 step: 1557, loss is 0.9953797459602356\n",
      "epoch: 5 step: 1558, loss is 2.1915268898010254\n",
      "epoch: 5 step: 1559, loss is 0.3412156105041504\n",
      "epoch: 5 step: 1560, loss is 1.3174498081207275\n",
      "epoch: 5 step: 1561, loss is 0.8425993323326111\n",
      "epoch: 5 step: 1562, loss is 1.3142716884613037\n",
      "epoch: 5 step: 1563, loss is 0.5274439454078674\n",
      "epoch: 5 step: 1564, loss is 0.7595869898796082\n",
      "epoch: 5 step: 1565, loss is 3.094175100326538\n",
      "epoch: 5 step: 1566, loss is 0.662516713142395\n",
      "epoch: 5 step: 1567, loss is 1.6044108867645264\n",
      "epoch: 5 step: 1568, loss is 3.0888612270355225\n",
      "epoch: 5 step: 1569, loss is 2.2503280639648438\n",
      "epoch: 5 step: 1570, loss is 1.3162009716033936\n",
      "epoch: 5 step: 1571, loss is 0.47741034626960754\n",
      "epoch: 5 step: 1572, loss is 0.4573468565940857\n",
      "epoch: 5 step: 1573, loss is 0.7577829957008362\n",
      "epoch: 5 step: 1574, loss is 0.2226533442735672\n",
      "epoch: 5 step: 1575, loss is 0.21648961305618286\n",
      "epoch: 5 step: 1576, loss is 0.6589086055755615\n",
      "epoch: 5 step: 1577, loss is 0.1084679514169693\n",
      "epoch: 5 step: 1578, loss is 2.372344970703125\n",
      "epoch: 5 step: 1579, loss is 2.011911153793335\n",
      "epoch: 5 step: 1580, loss is 2.2016818523406982\n",
      "epoch: 5 step: 1581, loss is 0.32491210103034973\n",
      "epoch: 5 step: 1582, loss is 0.4678051769733429\n",
      "epoch: 5 step: 1583, loss is 0.5871420502662659\n",
      "epoch: 5 step: 1584, loss is 1.9285852909088135\n",
      "epoch: 5 step: 1585, loss is 1.1983027458190918\n",
      "epoch: 5 step: 1586, loss is 1.8403260707855225\n",
      "epoch: 5 step: 1587, loss is 1.782118320465088\n",
      "epoch: 5 step: 1588, loss is 0.3540569245815277\n",
      "epoch: 5 step: 1589, loss is 1.8476824760437012\n",
      "epoch: 5 step: 1590, loss is 0.8959433436393738\n",
      "epoch: 5 step: 1591, loss is 2.6431312561035156\n",
      "epoch: 5 step: 1592, loss is 0.4775563180446625\n",
      "epoch: 5 step: 1593, loss is 1.9086716175079346\n",
      "epoch: 5 step: 1594, loss is 1.979137659072876\n",
      "epoch: 5 step: 1595, loss is 1.0342882871627808\n",
      "epoch: 5 step: 1596, loss is 1.671446681022644\n",
      "epoch: 5 step: 1597, loss is 1.9316662549972534\n",
      "epoch: 5 step: 1598, loss is 0.4376915991306305\n",
      "epoch: 5 step: 1599, loss is 0.2548670768737793\n",
      "epoch: 5 step: 1600, loss is 0.2906664311885834\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T11:35:41.490745Z",
     "start_time": "2024-07-19T11:35:41.476745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "steps_per_epoch = train_dataset.get_dataset_size()\n",
    "config = CheckpointConfig(save_checkpoint_steps=steps_per_epoch)\n",
    "ckpt_callback = ModelCheckpoint(prefix=\"mnist\", directory=\"./checkpoint\", config=config)\n",
    "loss_callback = LossMonitor(steps_per_epoch)"
   ],
   "id": "4060d932ced1d34",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:09:16.323633Z",
     "start_time": "2024-07-19T11:35:41.492745Z"
    }
   },
   "cell_type": "code",
   "source": "cassavamodel.fit(10, train_dataset, val_dataset, callbacks=[ckpt_callback, loss_callback])",
   "id": "171ddcae4170fb9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1600, loss is 1.9980413913726807\n",
      "Eval result: epoch 1, metrics: {'Accuracy': 0.6225}\n",
      "epoch: 2 step: 1600, loss is 0.8570265769958496\n",
      "Eval result: epoch 2, metrics: {'Accuracy': 0.6425}\n",
      "epoch: 3 step: 1600, loss is 0.8822121024131775\n",
      "Eval result: epoch 3, metrics: {'Accuracy': 0.66}\n",
      "epoch: 4 step: 1600, loss is 1.3794121742248535\n",
      "Eval result: epoch 4, metrics: {'Accuracy': 0.625}\n",
      "epoch: 5 step: 1600, loss is 0.14761272072792053\n",
      "Eval result: epoch 5, metrics: {'Accuracy': 0.6125}\n",
      "epoch: 6 step: 1600, loss is 0.24511556327342987\n",
      "Eval result: epoch 6, metrics: {'Accuracy': 0.64}\n",
      "epoch: 7 step: 1600, loss is 0.13353675603866577\n",
      "Eval result: epoch 7, metrics: {'Accuracy': 0.6025}\n",
      "epoch: 8 step: 1600, loss is 0.17282673716545105\n",
      "Eval result: epoch 8, metrics: {'Accuracy': 0.66}\n",
      "epoch: 9 step: 1600, loss is 0.4964216649532318\n",
      "Eval result: epoch 9, metrics: {'Accuracy': 0.61}\n",
      "epoch: 10 step: 1600, loss is 1.4970145225524902\n",
      "Eval result: epoch 10, metrics: {'Accuracy': 0.605}\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:12:38.918344Z",
     "start_time": "2024-07-19T12:12:37.858379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "param_dict = load_checkpoint(\"checkpoint/mnist_1-6_1600.ckpt\")  \n",
    "load_param_into_net(model, param_dict)"
   ],
   "id": "af0a55314c22ef70",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " ['global_step',\n",
       "  'learning_rate',\n",
       "  'momentum',\n",
       "  'moments.conv_layers.0.weight',\n",
       "  'moments.conv_layers.1.gamma',\n",
       "  'moments.conv_layers.1.beta',\n",
       "  'moments.conv_layers.4.conv1.weight',\n",
       "  'moments.conv_layers.4.bn1.gamma',\n",
       "  'moments.conv_layers.4.bn1.beta',\n",
       "  'moments.conv_layers.4.conv2.weight',\n",
       "  'moments.conv_layers.4.bn2.gamma',\n",
       "  'moments.conv_layers.4.bn2.beta',\n",
       "  'moments.conv_layers.5.weight',\n",
       "  'moments.conv_layers.6.gamma',\n",
       "  'moments.conv_layers.6.beta',\n",
       "  'moments.conv_layers.9.conv1.weight',\n",
       "  'moments.conv_layers.9.bn1.gamma',\n",
       "  'moments.conv_layers.9.bn1.beta',\n",
       "  'moments.conv_layers.9.conv2.weight',\n",
       "  'moments.conv_layers.9.bn2.gamma',\n",
       "  'moments.conv_layers.9.bn2.beta',\n",
       "  'moments.conv_layers.10.weight',\n",
       "  'moments.conv_layers.11.gamma',\n",
       "  'moments.conv_layers.11.beta',\n",
       "  'moments.conv_layers.14.conv1.weight',\n",
       "  'moments.conv_layers.14.bn1.gamma',\n",
       "  'moments.conv_layers.14.bn1.beta',\n",
       "  'moments.conv_layers.14.conv2.weight',\n",
       "  'moments.conv_layers.14.bn2.gamma',\n",
       "  'moments.conv_layers.14.bn2.beta',\n",
       "  'moments.fc_layers.0.weight',\n",
       "  'moments.fc_layers.0.bias',\n",
       "  'moments.fc_layers.3.weight',\n",
       "  'moments.fc_layers.3.bias',\n",
       "  'moments.fc_layers.5.weight',\n",
       "  'moments.fc_layers.5.bias'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:12:51.662277Z",
     "start_time": "2024-07-19T12:12:41.696356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "acc = cassavamodel.eval(val_dataset)\n",
    "acc"
   ],
   "id": "c7b902308dc14f5d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.64}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:35:10.353883Z",
     "start_time": "2024-07-19T12:25:31.067607Z"
    }
   },
   "cell_type": "code",
   "source": "cassavamodel.train(3, train_dataset,callbacks=[loss_monitor])",
   "id": "8bfdbe3805577bc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1, loss is 1.931178331375122\n",
      "epoch: 1 step: 2, loss is 0.5072121024131775\n",
      "epoch: 1 step: 3, loss is 0.1654486209154129\n",
      "epoch: 1 step: 4, loss is 3.1891872882843018\n",
      "epoch: 1 step: 5, loss is 1.5751099586486816\n",
      "epoch: 1 step: 6, loss is 1.63521409034729\n",
      "epoch: 1 step: 7, loss is 0.7946819067001343\n",
      "epoch: 1 step: 8, loss is 1.456412434577942\n",
      "epoch: 1 step: 9, loss is 2.1961214542388916\n",
      "epoch: 1 step: 10, loss is 1.667017936706543\n",
      "epoch: 1 step: 11, loss is 0.35358208417892456\n",
      "epoch: 1 step: 12, loss is 0.18713706731796265\n",
      "epoch: 1 step: 13, loss is 0.1853591948747635\n",
      "epoch: 1 step: 14, loss is 1.2681711912155151\n",
      "epoch: 1 step: 15, loss is 0.8070141077041626\n",
      "epoch: 1 step: 16, loss is 1.1728487014770508\n",
      "epoch: 1 step: 17, loss is 1.9993051290512085\n",
      "epoch: 1 step: 18, loss is 0.5277007222175598\n",
      "epoch: 1 step: 19, loss is 1.2655935287475586\n",
      "epoch: 1 step: 20, loss is 0.30447620153427124\n",
      "epoch: 1 step: 21, loss is 3.6689813137054443\n",
      "epoch: 1 step: 22, loss is 1.8269691467285156\n",
      "epoch: 1 step: 23, loss is 0.3066013753414154\n",
      "epoch: 1 step: 24, loss is 0.9985113739967346\n",
      "epoch: 1 step: 25, loss is 1.807452917098999\n",
      "epoch: 1 step: 26, loss is 1.7577428817749023\n",
      "epoch: 1 step: 27, loss is 1.9347429275512695\n",
      "epoch: 1 step: 28, loss is 0.42132917046546936\n",
      "epoch: 1 step: 29, loss is 0.09615980088710785\n",
      "epoch: 1 step: 30, loss is 2.5200085639953613\n",
      "epoch: 1 step: 31, loss is 0.3821278214454651\n",
      "epoch: 1 step: 32, loss is 1.617774248123169\n",
      "epoch: 1 step: 33, loss is 0.5981206297874451\n",
      "epoch: 1 step: 34, loss is 0.37304380536079407\n",
      "epoch: 1 step: 35, loss is 0.34531790018081665\n",
      "epoch: 1 step: 36, loss is 1.245843768119812\n",
      "epoch: 1 step: 37, loss is 0.35328906774520874\n",
      "epoch: 1 step: 38, loss is 0.3327329754829407\n",
      "epoch: 1 step: 39, loss is 0.3396588861942291\n",
      "epoch: 1 step: 40, loss is 2.1880104541778564\n",
      "epoch: 1 step: 41, loss is 3.5054705142974854\n",
      "epoch: 1 step: 42, loss is 1.7633635997772217\n",
      "epoch: 1 step: 43, loss is 1.963161826133728\n",
      "epoch: 1 step: 44, loss is 0.6431971788406372\n",
      "epoch: 1 step: 45, loss is 1.8315587043762207\n",
      "epoch: 1 step: 46, loss is 0.550007700920105\n",
      "epoch: 1 step: 47, loss is 0.2679731249809265\n",
      "epoch: 1 step: 48, loss is 1.8152351379394531\n",
      "epoch: 1 step: 49, loss is 0.5346993803977966\n",
      "epoch: 1 step: 50, loss is 0.2682156562805176\n",
      "epoch: 1 step: 51, loss is 1.8263986110687256\n",
      "epoch: 1 step: 52, loss is 0.6782799363136292\n",
      "epoch: 1 step: 53, loss is 0.6348058581352234\n",
      "epoch: 1 step: 54, loss is 0.1679954081773758\n",
      "epoch: 1 step: 55, loss is 1.917111873626709\n",
      "epoch: 1 step: 56, loss is 0.11246820539236069\n",
      "epoch: 1 step: 57, loss is 0.6971954107284546\n",
      "epoch: 1 step: 58, loss is 0.045145560055971146\n",
      "epoch: 1 step: 59, loss is 0.0721810832619667\n",
      "epoch: 1 step: 60, loss is 3.2599096298217773\n",
      "epoch: 1 step: 61, loss is 2.36207914352417\n",
      "epoch: 1 step: 62, loss is 1.6608195304870605\n",
      "epoch: 1 step: 63, loss is 0.6703817248344421\n",
      "epoch: 1 step: 64, loss is 2.133726119995117\n",
      "epoch: 1 step: 65, loss is 0.13097304105758667\n",
      "epoch: 1 step: 66, loss is 1.7858681678771973\n",
      "epoch: 1 step: 67, loss is 0.7080537676811218\n",
      "epoch: 1 step: 68, loss is 1.8101856708526611\n",
      "epoch: 1 step: 69, loss is 0.14029252529144287\n",
      "epoch: 1 step: 70, loss is 0.6784592270851135\n",
      "epoch: 1 step: 71, loss is 0.4833463728427887\n",
      "epoch: 1 step: 72, loss is 0.23313820362091064\n",
      "epoch: 1 step: 73, loss is 0.4107096493244171\n",
      "epoch: 1 step: 74, loss is 0.19432437419891357\n",
      "epoch: 1 step: 75, loss is 1.8052575588226318\n",
      "epoch: 1 step: 76, loss is 0.6450522541999817\n",
      "epoch: 1 step: 77, loss is 0.2688189744949341\n",
      "epoch: 1 step: 78, loss is 0.050121650099754333\n",
      "epoch: 1 step: 79, loss is 0.5128309726715088\n",
      "epoch: 1 step: 80, loss is 0.11074831336736679\n",
      "epoch: 1 step: 81, loss is 0.06714697182178497\n",
      "epoch: 1 step: 82, loss is 0.49822869896888733\n",
      "epoch: 1 step: 83, loss is 2.436298370361328\n",
      "epoch: 1 step: 84, loss is 1.5748991966247559\n",
      "epoch: 1 step: 85, loss is 0.18580785393714905\n",
      "epoch: 1 step: 86, loss is 0.2450200319290161\n",
      "epoch: 1 step: 87, loss is 0.1441878378391266\n",
      "epoch: 1 step: 88, loss is 0.29273226857185364\n",
      "epoch: 1 step: 89, loss is 3.2672204971313477\n",
      "epoch: 1 step: 90, loss is 2.6394340991973877\n",
      "epoch: 1 step: 91, loss is 1.9809291362762451\n",
      "epoch: 1 step: 92, loss is 1.6570465564727783\n",
      "epoch: 1 step: 93, loss is 0.7185937166213989\n",
      "epoch: 1 step: 94, loss is 1.2336245775222778\n",
      "epoch: 1 step: 95, loss is 1.359433650970459\n",
      "epoch: 1 step: 96, loss is 1.6570032835006714\n",
      "epoch: 1 step: 97, loss is 1.598026156425476\n",
      "epoch: 1 step: 98, loss is 0.4686162769794464\n",
      "epoch: 1 step: 99, loss is 0.20238299667835236\n",
      "epoch: 1 step: 100, loss is 0.28892436623573303\n",
      "epoch: 1 step: 101, loss is 0.3556843101978302\n",
      "epoch: 1 step: 102, loss is 1.5724905729293823\n",
      "epoch: 1 step: 103, loss is 1.9583699703216553\n",
      "epoch: 1 step: 104, loss is 0.9228565692901611\n",
      "epoch: 1 step: 105, loss is 0.5744211077690125\n",
      "epoch: 1 step: 106, loss is 1.352601170539856\n",
      "epoch: 1 step: 107, loss is 1.8466148376464844\n",
      "epoch: 1 step: 108, loss is 1.0733593702316284\n",
      "epoch: 1 step: 109, loss is 0.6404122114181519\n",
      "epoch: 1 step: 110, loss is 0.08191825449466705\n",
      "epoch: 1 step: 111, loss is 0.5320284366607666\n",
      "epoch: 1 step: 112, loss is 0.08851204812526703\n",
      "epoch: 1 step: 113, loss is 0.18607886135578156\n",
      "epoch: 1 step: 114, loss is 1.9111578464508057\n",
      "epoch: 1 step: 115, loss is 0.2855072319507599\n",
      "epoch: 1 step: 116, loss is 1.6890466213226318\n",
      "epoch: 1 step: 117, loss is 0.06235858052968979\n",
      "epoch: 1 step: 118, loss is 1.978757619857788\n",
      "epoch: 1 step: 119, loss is 0.09462082386016846\n",
      "epoch: 1 step: 120, loss is 1.327406883239746\n",
      "epoch: 1 step: 121, loss is 1.918402910232544\n",
      "epoch: 1 step: 122, loss is 0.04986537620425224\n",
      "epoch: 1 step: 123, loss is 1.9157037734985352\n",
      "epoch: 1 step: 124, loss is 1.8385419845581055\n",
      "epoch: 1 step: 125, loss is 0.6493964791297913\n",
      "epoch: 1 step: 126, loss is 1.9173829555511475\n",
      "epoch: 1 step: 127, loss is 0.20739364624023438\n",
      "epoch: 1 step: 128, loss is 0.6989898085594177\n",
      "epoch: 1 step: 129, loss is 0.0981949120759964\n",
      "epoch: 1 step: 130, loss is 0.006553349085152149\n",
      "epoch: 1 step: 131, loss is 0.09955133497714996\n",
      "epoch: 1 step: 132, loss is 0.07606483995914459\n",
      "epoch: 1 step: 133, loss is 0.09924308210611343\n",
      "epoch: 1 step: 134, loss is 0.7248801589012146\n",
      "epoch: 1 step: 135, loss is 0.11984095722436905\n",
      "epoch: 1 step: 136, loss is 3.1560423374176025\n",
      "epoch: 1 step: 137, loss is 0.013182509690523148\n",
      "epoch: 1 step: 138, loss is 0.2607080340385437\n",
      "epoch: 1 step: 139, loss is 2.7254180908203125\n",
      "epoch: 1 step: 140, loss is 0.07535698264837265\n",
      "epoch: 1 step: 141, loss is 0.20189331471920013\n",
      "epoch: 1 step: 142, loss is 3.666903495788574\n",
      "epoch: 1 step: 143, loss is 1.5940841436386108\n",
      "epoch: 1 step: 144, loss is 0.9215956330299377\n",
      "epoch: 1 step: 145, loss is 1.808160662651062\n",
      "epoch: 1 step: 146, loss is 2.3771471977233887\n",
      "epoch: 1 step: 147, loss is 1.0829434394836426\n",
      "epoch: 1 step: 148, loss is 0.46828681230545044\n",
      "epoch: 1 step: 149, loss is 1.7329776287078857\n",
      "epoch: 1 step: 150, loss is 0.968477725982666\n",
      "epoch: 1 step: 151, loss is 1.706322193145752\n",
      "epoch: 1 step: 152, loss is 1.9730983972549438\n",
      "epoch: 1 step: 153, loss is 0.2987154424190521\n",
      "epoch: 1 step: 154, loss is 0.7298374176025391\n",
      "epoch: 1 step: 155, loss is 0.46176499128341675\n",
      "epoch: 1 step: 156, loss is 1.8800827264785767\n",
      "epoch: 1 step: 157, loss is 0.294400155544281\n",
      "epoch: 1 step: 158, loss is 0.4158875048160553\n",
      "epoch: 1 step: 159, loss is 0.2590670585632324\n",
      "epoch: 1 step: 160, loss is 0.2582700848579407\n",
      "epoch: 1 step: 161, loss is 1.6641709804534912\n",
      "epoch: 1 step: 162, loss is 0.16551610827445984\n",
      "epoch: 1 step: 163, loss is 0.08697283267974854\n",
      "epoch: 1 step: 164, loss is 1.8083558082580566\n",
      "epoch: 1 step: 165, loss is 0.11247842758893967\n",
      "epoch: 1 step: 166, loss is 0.8603127002716064\n",
      "epoch: 1 step: 167, loss is 0.15213486552238464\n",
      "epoch: 1 step: 168, loss is 1.6606146097183228\n",
      "epoch: 1 step: 169, loss is 1.659691572189331\n",
      "epoch: 1 step: 170, loss is 1.1837269067764282\n",
      "epoch: 1 step: 171, loss is 2.0086255073547363\n",
      "epoch: 1 step: 172, loss is 1.5354135036468506\n",
      "epoch: 1 step: 173, loss is 2.7873215675354004\n",
      "epoch: 1 step: 174, loss is 1.3344805240631104\n",
      "epoch: 1 step: 175, loss is 0.8376166224479675\n",
      "epoch: 1 step: 176, loss is 0.12990161776542664\n",
      "epoch: 1 step: 177, loss is 1.7223514318466187\n",
      "epoch: 1 step: 178, loss is 0.47948935627937317\n",
      "epoch: 1 step: 179, loss is 0.732946515083313\n",
      "epoch: 1 step: 180, loss is 0.10490663349628448\n",
      "epoch: 1 step: 181, loss is 1.7180125713348389\n",
      "epoch: 1 step: 182, loss is 0.16127856075763702\n",
      "epoch: 1 step: 183, loss is 3.431372880935669\n",
      "epoch: 1 step: 184, loss is 0.21579323709011078\n",
      "epoch: 1 step: 185, loss is 3.0013225078582764\n",
      "epoch: 1 step: 186, loss is 1.3389370441436768\n",
      "epoch: 1 step: 187, loss is 1.0468770265579224\n",
      "epoch: 1 step: 188, loss is 0.3039400279521942\n",
      "epoch: 1 step: 189, loss is 1.964118242263794\n",
      "epoch: 1 step: 190, loss is 1.9443634748458862\n",
      "epoch: 1 step: 191, loss is 0.6688675880432129\n",
      "epoch: 1 step: 192, loss is 0.41437703371047974\n",
      "epoch: 1 step: 193, loss is 1.660670518875122\n",
      "epoch: 1 step: 194, loss is 0.4259676933288574\n",
      "epoch: 1 step: 195, loss is 0.2938809394836426\n",
      "epoch: 1 step: 196, loss is 1.377541184425354\n",
      "epoch: 1 step: 197, loss is 0.787743091583252\n",
      "epoch: 1 step: 198, loss is 1.2145260572433472\n",
      "epoch: 1 step: 199, loss is 1.1890192031860352\n",
      "epoch: 1 step: 200, loss is 1.2176786661148071\n",
      "epoch: 1 step: 201, loss is 2.132432222366333\n",
      "epoch: 1 step: 202, loss is 0.13770537078380585\n",
      "epoch: 1 step: 203, loss is 0.04542514681816101\n",
      "epoch: 1 step: 204, loss is 0.13427509367465973\n",
      "epoch: 1 step: 205, loss is 0.0756005048751831\n",
      "epoch: 1 step: 206, loss is 1.6686376333236694\n",
      "epoch: 1 step: 207, loss is 2.2232229709625244\n",
      "epoch: 1 step: 208, loss is 1.5684943199157715\n",
      "epoch: 1 step: 209, loss is 0.09919698536396027\n",
      "epoch: 1 step: 210, loss is 1.4561963081359863\n",
      "epoch: 1 step: 211, loss is 0.41384392976760864\n",
      "epoch: 1 step: 212, loss is 0.1248411163687706\n",
      "epoch: 1 step: 213, loss is 0.28506550192832947\n",
      "epoch: 1 step: 214, loss is 1.5160592794418335\n",
      "epoch: 1 step: 215, loss is 0.08763004094362259\n",
      "epoch: 1 step: 216, loss is 2.138599395751953\n",
      "epoch: 1 step: 217, loss is 2.706782579421997\n",
      "epoch: 1 step: 218, loss is 0.8017981052398682\n",
      "epoch: 1 step: 219, loss is 1.7397515773773193\n",
      "epoch: 1 step: 220, loss is 0.7519993185997009\n",
      "epoch: 1 step: 221, loss is 1.3263317346572876\n",
      "epoch: 1 step: 222, loss is 0.36502304673194885\n",
      "epoch: 1 step: 223, loss is 2.6628079414367676\n",
      "epoch: 1 step: 224, loss is 0.8598066568374634\n",
      "epoch: 1 step: 225, loss is 0.7271436452865601\n",
      "epoch: 1 step: 226, loss is 1.9182496070861816\n",
      "epoch: 1 step: 227, loss is 1.6138701438903809\n",
      "epoch: 1 step: 228, loss is 0.7374227046966553\n",
      "epoch: 1 step: 229, loss is 0.20349939167499542\n",
      "epoch: 1 step: 230, loss is 0.13441725075244904\n",
      "epoch: 1 step: 231, loss is 2.259188652038574\n",
      "epoch: 1 step: 232, loss is 0.47257956862449646\n",
      "epoch: 1 step: 233, loss is 1.4877760410308838\n",
      "epoch: 1 step: 234, loss is 0.1861676275730133\n",
      "epoch: 1 step: 235, loss is 2.8734631538391113\n",
      "epoch: 1 step: 236, loss is 0.6807159781455994\n",
      "epoch: 1 step: 237, loss is 1.622153401374817\n",
      "epoch: 1 step: 238, loss is 0.4351615905761719\n",
      "epoch: 1 step: 239, loss is 0.17184463143348694\n",
      "epoch: 1 step: 240, loss is 0.27970269322395325\n",
      "epoch: 1 step: 241, loss is 1.7984955310821533\n",
      "epoch: 1 step: 242, loss is 1.6336283683776855\n",
      "epoch: 1 step: 243, loss is 3.390430212020874\n",
      "epoch: 1 step: 244, loss is 1.8050302267074585\n",
      "epoch: 1 step: 245, loss is 0.42290669679641724\n",
      "epoch: 1 step: 246, loss is 2.367044448852539\n",
      "epoch: 1 step: 247, loss is 1.5783970355987549\n",
      "epoch: 1 step: 248, loss is 0.27888917922973633\n",
      "epoch: 1 step: 249, loss is 0.2569749653339386\n",
      "epoch: 1 step: 250, loss is 1.5917290449142456\n",
      "epoch: 1 step: 251, loss is 1.5707104206085205\n",
      "epoch: 1 step: 252, loss is 2.1189324855804443\n",
      "epoch: 1 step: 253, loss is 1.566314697265625\n",
      "epoch: 1 step: 254, loss is 2.8037924766540527\n",
      "epoch: 1 step: 255, loss is 0.27810433506965637\n",
      "epoch: 1 step: 256, loss is 0.5238640308380127\n",
      "epoch: 1 step: 257, loss is 1.9373247623443604\n",
      "epoch: 1 step: 258, loss is 0.2347206473350525\n",
      "epoch: 1 step: 259, loss is 0.9983184933662415\n",
      "epoch: 1 step: 260, loss is 2.0583841800689697\n",
      "epoch: 1 step: 261, loss is 0.9653983116149902\n",
      "epoch: 1 step: 262, loss is 0.1710323691368103\n",
      "epoch: 1 step: 263, loss is 0.2825984060764313\n",
      "epoch: 1 step: 264, loss is 1.438565731048584\n",
      "epoch: 1 step: 265, loss is 1.488174319267273\n",
      "epoch: 1 step: 266, loss is 1.3725066184997559\n",
      "epoch: 1 step: 267, loss is 0.10613113641738892\n",
      "epoch: 1 step: 268, loss is 1.1643725633621216\n",
      "epoch: 1 step: 269, loss is 0.7187617421150208\n",
      "epoch: 1 step: 270, loss is 0.09997620433568954\n",
      "epoch: 1 step: 271, loss is 1.84576416015625\n",
      "epoch: 1 step: 272, loss is 0.289962500333786\n",
      "epoch: 1 step: 273, loss is 2.7445390224456787\n",
      "epoch: 1 step: 274, loss is 1.6816343069076538\n",
      "epoch: 1 step: 275, loss is 3.566861391067505\n",
      "epoch: 1 step: 276, loss is 0.9538339376449585\n",
      "epoch: 1 step: 277, loss is 0.9244783520698547\n",
      "epoch: 1 step: 278, loss is 0.2314337193965912\n",
      "epoch: 1 step: 279, loss is 1.657823085784912\n",
      "epoch: 1 step: 280, loss is 0.5283721089363098\n",
      "epoch: 1 step: 281, loss is 1.6543811559677124\n",
      "epoch: 1 step: 282, loss is 0.22913959622383118\n",
      "epoch: 1 step: 283, loss is 0.39147940278053284\n",
      "epoch: 1 step: 284, loss is 0.259259432554245\n",
      "epoch: 1 step: 285, loss is 2.151747703552246\n",
      "epoch: 1 step: 286, loss is 0.17905011773109436\n",
      "epoch: 1 step: 287, loss is 2.265021800994873\n",
      "epoch: 1 step: 288, loss is 0.1504538208246231\n",
      "epoch: 1 step: 289, loss is 0.4511170983314514\n",
      "epoch: 1 step: 290, loss is 4.76092004776001\n",
      "epoch: 1 step: 291, loss is 0.3419060707092285\n",
      "epoch: 1 step: 292, loss is 0.4930249750614166\n",
      "epoch: 1 step: 293, loss is 0.1897273063659668\n",
      "epoch: 1 step: 294, loss is 0.16735045611858368\n",
      "epoch: 1 step: 295, loss is 1.6538777351379395\n",
      "epoch: 1 step: 296, loss is 1.33175790309906\n",
      "epoch: 1 step: 297, loss is 0.3854480981826782\n",
      "epoch: 1 step: 298, loss is 1.8505139350891113\n",
      "epoch: 1 step: 299, loss is 1.79608154296875\n",
      "epoch: 1 step: 300, loss is 0.15318560600280762\n",
      "epoch: 1 step: 301, loss is 0.1579262912273407\n",
      "epoch: 1 step: 302, loss is 6.422512531280518\n",
      "epoch: 1 step: 303, loss is 0.5682886838912964\n",
      "epoch: 1 step: 304, loss is 0.40712812542915344\n",
      "epoch: 1 step: 305, loss is 1.852987289428711\n",
      "epoch: 1 step: 306, loss is 0.5467618703842163\n",
      "epoch: 1 step: 307, loss is 0.19272522628307343\n",
      "epoch: 1 step: 308, loss is 1.3687317371368408\n",
      "epoch: 1 step: 309, loss is 1.5653066635131836\n",
      "epoch: 1 step: 310, loss is 1.8067551851272583\n",
      "epoch: 1 step: 311, loss is 1.1667284965515137\n",
      "epoch: 1 step: 312, loss is 0.15221308171749115\n",
      "epoch: 1 step: 313, loss is 0.19397468864917755\n",
      "epoch: 1 step: 314, loss is 0.6185881495475769\n",
      "epoch: 1 step: 315, loss is 0.07714716345071793\n",
      "epoch: 1 step: 316, loss is 0.12175492942333221\n",
      "epoch: 1 step: 317, loss is 1.1535937786102295\n",
      "epoch: 1 step: 318, loss is 0.30061963200569153\n",
      "epoch: 1 step: 319, loss is 0.565657913684845\n",
      "epoch: 1 step: 320, loss is 0.39099815487861633\n",
      "epoch: 1 step: 321, loss is 1.7393290996551514\n",
      "epoch: 1 step: 322, loss is 2.125042200088501\n",
      "epoch: 1 step: 323, loss is 0.14534592628479004\n",
      "epoch: 1 step: 324, loss is 0.13037364184856415\n",
      "epoch: 1 step: 325, loss is 1.655164361000061\n",
      "epoch: 1 step: 326, loss is 1.569892406463623\n",
      "epoch: 1 step: 327, loss is 0.4782419800758362\n",
      "epoch: 1 step: 328, loss is 0.40746748447418213\n",
      "epoch: 1 step: 329, loss is 1.6549041271209717\n",
      "epoch: 1 step: 330, loss is 0.3475021421909332\n",
      "epoch: 1 step: 331, loss is 0.21842950582504272\n",
      "epoch: 1 step: 332, loss is 0.8711051344871521\n",
      "epoch: 1 step: 333, loss is 2.2589728832244873\n",
      "epoch: 1 step: 334, loss is 1.0966026782989502\n",
      "epoch: 1 step: 335, loss is 0.017906436696648598\n",
      "epoch: 1 step: 336, loss is 2.223785161972046\n",
      "epoch: 1 step: 337, loss is 0.08687687665224075\n",
      "epoch: 1 step: 338, loss is 0.1891007423400879\n",
      "epoch: 1 step: 339, loss is 0.18587912619113922\n",
      "epoch: 1 step: 340, loss is 1.5692203044891357\n",
      "epoch: 1 step: 341, loss is 1.1247614622116089\n",
      "epoch: 1 step: 342, loss is 0.03563234955072403\n",
      "epoch: 1 step: 343, loss is 0.0336102694272995\n",
      "epoch: 1 step: 344, loss is 0.2623640298843384\n",
      "epoch: 1 step: 345, loss is 0.05039406940340996\n",
      "epoch: 1 step: 346, loss is 0.11639256775379181\n",
      "epoch: 1 step: 347, loss is 0.33994317054748535\n",
      "epoch: 1 step: 348, loss is 3.1836166381835938\n",
      "epoch: 1 step: 349, loss is 0.021337710320949554\n",
      "epoch: 1 step: 350, loss is 0.33515894412994385\n",
      "epoch: 1 step: 351, loss is 1.9506659507751465\n",
      "epoch: 1 step: 352, loss is 0.20055919885635376\n",
      "epoch: 1 step: 353, loss is 2.013244390487671\n",
      "epoch: 1 step: 354, loss is 0.1700792759656906\n",
      "epoch: 1 step: 355, loss is 3.106473207473755\n",
      "epoch: 1 step: 356, loss is 0.08876799046993256\n",
      "epoch: 1 step: 357, loss is 1.9142680168151855\n",
      "epoch: 1 step: 358, loss is 1.653929352760315\n",
      "epoch: 1 step: 359, loss is 0.48805221915245056\n",
      "epoch: 1 step: 360, loss is 1.5329227447509766\n",
      "epoch: 1 step: 361, loss is 0.4123503267765045\n",
      "epoch: 1 step: 362, loss is 0.3803649842739105\n",
      "epoch: 1 step: 363, loss is 0.18403097987174988\n",
      "epoch: 1 step: 364, loss is 0.5560905933380127\n",
      "epoch: 1 step: 365, loss is 1.4859418869018555\n",
      "epoch: 1 step: 366, loss is 0.07057718187570572\n",
      "epoch: 1 step: 367, loss is 0.1136927455663681\n",
      "epoch: 1 step: 368, loss is 0.08870919048786163\n",
      "epoch: 1 step: 369, loss is 0.16561612486839294\n",
      "epoch: 1 step: 370, loss is 2.2454004287719727\n",
      "epoch: 1 step: 371, loss is 0.0567958727478981\n",
      "epoch: 1 step: 372, loss is 0.09969646483659744\n",
      "epoch: 1 step: 373, loss is 3.9643640518188477\n",
      "epoch: 1 step: 374, loss is 2.052422046661377\n",
      "epoch: 1 step: 375, loss is 2.356466770172119\n",
      "epoch: 1 step: 376, loss is 0.6129016876220703\n",
      "epoch: 1 step: 377, loss is 0.2527408003807068\n",
      "epoch: 1 step: 378, loss is 1.833303451538086\n",
      "epoch: 1 step: 379, loss is 0.1571127325296402\n",
      "epoch: 1 step: 380, loss is 1.3287444114685059\n",
      "epoch: 1 step: 381, loss is 0.64952552318573\n",
      "epoch: 1 step: 382, loss is 0.40866369009017944\n",
      "epoch: 1 step: 383, loss is 1.515593409538269\n",
      "epoch: 1 step: 384, loss is 0.08106482028961182\n",
      "epoch: 1 step: 385, loss is 1.9466044902801514\n",
      "epoch: 1 step: 386, loss is 0.1889197677373886\n",
      "epoch: 1 step: 387, loss is 0.17885075509548187\n",
      "epoch: 1 step: 388, loss is 0.13210682570934296\n",
      "epoch: 1 step: 389, loss is 0.2544165849685669\n",
      "epoch: 1 step: 390, loss is 2.309328079223633\n",
      "epoch: 1 step: 391, loss is 0.4366544485092163\n",
      "epoch: 1 step: 392, loss is 0.008594311773777008\n",
      "epoch: 1 step: 393, loss is 2.0141940116882324\n",
      "epoch: 1 step: 394, loss is 0.0858529657125473\n",
      "epoch: 1 step: 395, loss is 2.1334116458892822\n",
      "epoch: 1 step: 396, loss is 1.3485947847366333\n",
      "epoch: 1 step: 397, loss is 3.6404764652252197\n",
      "epoch: 1 step: 398, loss is 0.13680998980998993\n",
      "epoch: 1 step: 399, loss is 1.9778289794921875\n",
      "epoch: 1 step: 400, loss is 1.5683763027191162\n",
      "epoch: 1 step: 401, loss is 3.213585376739502\n",
      "epoch: 1 step: 402, loss is 1.567439079284668\n",
      "epoch: 1 step: 403, loss is 1.722151279449463\n",
      "epoch: 1 step: 404, loss is 1.8295915126800537\n",
      "epoch: 1 step: 405, loss is 0.45602521300315857\n",
      "epoch: 1 step: 406, loss is 1.815768837928772\n",
      "epoch: 1 step: 407, loss is 1.80619215965271\n",
      "epoch: 1 step: 408, loss is 1.6545641422271729\n",
      "epoch: 1 step: 409, loss is 1.653645396232605\n",
      "epoch: 1 step: 410, loss is 0.8746200203895569\n",
      "epoch: 1 step: 411, loss is 0.17304494976997375\n",
      "epoch: 1 step: 412, loss is 0.9641879200935364\n",
      "epoch: 1 step: 413, loss is 1.9581313133239746\n",
      "epoch: 1 step: 414, loss is 1.6010253429412842\n",
      "epoch: 1 step: 415, loss is 0.2518899440765381\n",
      "epoch: 1 step: 416, loss is 0.21225696802139282\n",
      "epoch: 1 step: 417, loss is 1.9143340587615967\n",
      "epoch: 1 step: 418, loss is 0.3259164094924927\n",
      "epoch: 1 step: 419, loss is 0.9210438132286072\n",
      "epoch: 1 step: 420, loss is 0.2975958585739136\n",
      "epoch: 1 step: 421, loss is 0.4408966898918152\n",
      "epoch: 1 step: 422, loss is 2.1435000896453857\n",
      "epoch: 1 step: 423, loss is 1.3549975156784058\n",
      "epoch: 1 step: 424, loss is 2.249140739440918\n",
      "epoch: 1 step: 425, loss is 0.042626891285181046\n",
      "epoch: 1 step: 426, loss is 0.0901508703827858\n",
      "epoch: 1 step: 427, loss is 1.9791505336761475\n",
      "epoch: 1 step: 428, loss is 0.701259970664978\n",
      "epoch: 1 step: 429, loss is 1.239838719367981\n",
      "epoch: 1 step: 430, loss is 0.09808230400085449\n",
      "epoch: 1 step: 431, loss is 0.6720272302627563\n",
      "epoch: 1 step: 432, loss is 0.24807274341583252\n",
      "epoch: 1 step: 433, loss is 0.32000043988227844\n",
      "epoch: 1 step: 434, loss is 0.2894365191459656\n",
      "epoch: 1 step: 435, loss is 0.08820004761219025\n",
      "epoch: 1 step: 436, loss is 0.07581524550914764\n",
      "epoch: 1 step: 437, loss is 0.196241095662117\n",
      "epoch: 1 step: 438, loss is 0.5511841773986816\n",
      "epoch: 1 step: 439, loss is 0.06436567008495331\n",
      "epoch: 1 step: 440, loss is 1.2260427474975586\n",
      "epoch: 1 step: 441, loss is 0.10390123724937439\n",
      "epoch: 1 step: 442, loss is 0.03938159719109535\n",
      "epoch: 1 step: 443, loss is 1.8907666206359863\n",
      "epoch: 1 step: 444, loss is 0.008497746661305428\n",
      "epoch: 1 step: 445, loss is 0.026480408385396004\n",
      "epoch: 1 step: 446, loss is 0.02615099586546421\n",
      "epoch: 1 step: 447, loss is 0.2716129422187805\n",
      "epoch: 1 step: 448, loss is 0.012429042719304562\n",
      "epoch: 1 step: 449, loss is 1.924010992050171\n",
      "epoch: 1 step: 450, loss is 0.007265810389071703\n",
      "epoch: 1 step: 451, loss is 0.0241488479077816\n",
      "epoch: 1 step: 452, loss is 1.6310995817184448\n",
      "epoch: 1 step: 453, loss is 4.779299736022949\n",
      "epoch: 1 step: 454, loss is 1.7814807891845703\n",
      "epoch: 1 step: 455, loss is 1.6559462547302246\n",
      "epoch: 1 step: 456, loss is 0.05378983914852142\n",
      "epoch: 1 step: 457, loss is 0.3695932924747467\n",
      "epoch: 1 step: 458, loss is 0.36540308594703674\n",
      "epoch: 1 step: 459, loss is 0.08450663834810257\n",
      "epoch: 1 step: 460, loss is 0.2574767470359802\n",
      "epoch: 1 step: 461, loss is 0.21369920670986176\n",
      "epoch: 1 step: 462, loss is 0.15587598085403442\n",
      "epoch: 1 step: 463, loss is 0.512097954750061\n",
      "epoch: 1 step: 464, loss is 0.15676017105579376\n",
      "epoch: 1 step: 465, loss is 2.3292436599731445\n",
      "epoch: 1 step: 466, loss is 2.1953351497650146\n",
      "epoch: 1 step: 467, loss is 2.2627930641174316\n",
      "epoch: 1 step: 468, loss is 0.13364127278327942\n",
      "epoch: 1 step: 469, loss is 0.41727155447006226\n",
      "epoch: 1 step: 470, loss is 0.2937053442001343\n",
      "epoch: 1 step: 471, loss is 0.29984885454177856\n",
      "epoch: 1 step: 472, loss is 1.9902567863464355\n",
      "epoch: 1 step: 473, loss is 0.4009805917739868\n",
      "epoch: 1 step: 474, loss is 0.11839447170495987\n",
      "epoch: 1 step: 475, loss is 1.5537253618240356\n",
      "epoch: 1 step: 476, loss is 0.012634001672267914\n",
      "epoch: 1 step: 477, loss is 0.23108455538749695\n",
      "epoch: 1 step: 478, loss is 2.7916266918182373\n",
      "epoch: 1 step: 479, loss is 0.28821250796318054\n",
      "epoch: 1 step: 480, loss is 0.11993411928415298\n",
      "epoch: 1 step: 481, loss is 2.4254062175750732\n",
      "epoch: 1 step: 482, loss is 0.5891861319541931\n",
      "epoch: 1 step: 483, loss is 1.6534762382507324\n",
      "epoch: 1 step: 484, loss is 2.77695369720459\n",
      "epoch: 1 step: 485, loss is 2.3064184188842773\n",
      "epoch: 1 step: 486, loss is 0.3922233283519745\n",
      "epoch: 1 step: 487, loss is 0.22733178734779358\n",
      "epoch: 1 step: 488, loss is 0.4795464873313904\n",
      "epoch: 1 step: 489, loss is 1.83109712600708\n",
      "epoch: 1 step: 490, loss is 0.20654237270355225\n",
      "epoch: 1 step: 491, loss is 0.36336034536361694\n",
      "epoch: 1 step: 492, loss is 0.15680694580078125\n",
      "epoch: 1 step: 493, loss is 0.30974310636520386\n",
      "epoch: 1 step: 494, loss is 0.41736266016960144\n",
      "epoch: 1 step: 495, loss is 2.974954128265381\n",
      "epoch: 1 step: 496, loss is 0.33681216835975647\n",
      "epoch: 1 step: 497, loss is 0.6066753268241882\n",
      "epoch: 1 step: 498, loss is 1.4720299243927002\n",
      "epoch: 1 step: 499, loss is 1.8506770133972168\n",
      "epoch: 1 step: 500, loss is 0.25701025128364563\n",
      "epoch: 1 step: 501, loss is 0.057181209325790405\n",
      "epoch: 1 step: 502, loss is 0.816307783126831\n",
      "epoch: 1 step: 503, loss is 0.18268422782421112\n",
      "epoch: 1 step: 504, loss is 2.5213963985443115\n",
      "epoch: 1 step: 505, loss is 0.5537099242210388\n",
      "epoch: 1 step: 506, loss is 2.5758986473083496\n",
      "epoch: 1 step: 507, loss is 0.1955016553401947\n",
      "epoch: 1 step: 508, loss is 0.028388334438204765\n",
      "epoch: 1 step: 509, loss is 1.6621348857879639\n",
      "epoch: 1 step: 510, loss is 1.7994415760040283\n",
      "epoch: 1 step: 511, loss is 1.8217697143554688\n",
      "epoch: 1 step: 512, loss is 0.19887346029281616\n",
      "epoch: 1 step: 513, loss is 1.7010066509246826\n",
      "epoch: 1 step: 514, loss is 1.6557639837265015\n",
      "epoch: 1 step: 515, loss is 2.0385522842407227\n",
      "epoch: 1 step: 516, loss is 0.20588940382003784\n",
      "epoch: 1 step: 517, loss is 0.7861388921737671\n",
      "epoch: 1 step: 518, loss is 1.7540080547332764\n",
      "epoch: 1 step: 519, loss is 0.1069473847746849\n",
      "epoch: 1 step: 520, loss is 1.2403488159179688\n",
      "epoch: 1 step: 521, loss is 3.6984622478485107\n",
      "epoch: 1 step: 522, loss is 0.38718777894973755\n",
      "epoch: 1 step: 523, loss is 0.15888544917106628\n",
      "epoch: 1 step: 524, loss is 1.4832755327224731\n",
      "epoch: 1 step: 525, loss is 0.3974932134151459\n",
      "epoch: 1 step: 526, loss is 0.43248245120048523\n",
      "epoch: 1 step: 527, loss is 0.21542128920555115\n",
      "epoch: 1 step: 528, loss is 0.277972549200058\n",
      "epoch: 1 step: 529, loss is 0.42808976769447327\n",
      "epoch: 1 step: 530, loss is 0.02332371100783348\n",
      "epoch: 1 step: 531, loss is 0.4383915662765503\n",
      "epoch: 1 step: 532, loss is 0.05721824988722801\n",
      "epoch: 1 step: 533, loss is 1.8176523447036743\n",
      "epoch: 1 step: 534, loss is 1.645427942276001\n",
      "epoch: 1 step: 535, loss is 0.6040579676628113\n",
      "epoch: 1 step: 536, loss is 0.09395398199558258\n",
      "epoch: 1 step: 537, loss is 0.2513238787651062\n",
      "epoch: 1 step: 538, loss is 0.06691943854093552\n",
      "epoch: 1 step: 539, loss is 0.030943188816308975\n",
      "epoch: 1 step: 540, loss is 1.400172233581543\n",
      "epoch: 1 step: 541, loss is 1.486535668373108\n",
      "epoch: 1 step: 542, loss is 0.3445901870727539\n",
      "epoch: 1 step: 543, loss is 0.46702635288238525\n",
      "epoch: 1 step: 544, loss is 0.03875702992081642\n",
      "epoch: 1 step: 545, loss is 2.5822935104370117\n",
      "epoch: 1 step: 546, loss is 1.8029004335403442\n",
      "epoch: 1 step: 547, loss is 1.6910476684570312\n",
      "epoch: 1 step: 548, loss is 3.2218642234802246\n",
      "epoch: 1 step: 549, loss is 1.7782161235809326\n",
      "epoch: 1 step: 550, loss is 0.11957698315382004\n",
      "epoch: 1 step: 551, loss is 1.8330353498458862\n",
      "epoch: 1 step: 552, loss is 0.07089605927467346\n",
      "epoch: 1 step: 553, loss is 0.0471951887011528\n",
      "epoch: 1 step: 554, loss is 2.2633981704711914\n",
      "epoch: 1 step: 555, loss is 0.4874073565006256\n",
      "epoch: 1 step: 556, loss is 1.2030738592147827\n",
      "epoch: 1 step: 557, loss is 3.089616298675537\n",
      "epoch: 1 step: 558, loss is 0.15100644528865814\n",
      "epoch: 1 step: 559, loss is 0.03147539496421814\n",
      "epoch: 1 step: 560, loss is 0.11320574581623077\n",
      "epoch: 1 step: 561, loss is 0.2650255560874939\n",
      "epoch: 1 step: 562, loss is 1.5467617511749268\n",
      "epoch: 1 step: 563, loss is 0.14361417293548584\n",
      "epoch: 1 step: 564, loss is 0.832920491695404\n",
      "epoch: 1 step: 565, loss is 1.9280178546905518\n",
      "epoch: 1 step: 566, loss is 0.17381760478019714\n",
      "epoch: 1 step: 567, loss is 2.071587562561035\n",
      "epoch: 1 step: 568, loss is 0.14860689640045166\n",
      "epoch: 1 step: 569, loss is 0.14748889207839966\n",
      "epoch: 1 step: 570, loss is 2.028535842895508\n",
      "epoch: 1 step: 571, loss is 0.0438842810690403\n",
      "epoch: 1 step: 572, loss is 1.1701661348342896\n",
      "epoch: 1 step: 573, loss is 0.17333176732063293\n",
      "epoch: 1 step: 574, loss is 0.28215697407722473\n",
      "epoch: 1 step: 575, loss is 0.8871046900749207\n",
      "epoch: 1 step: 576, loss is 4.328959941864014\n",
      "epoch: 1 step: 577, loss is 0.722565770149231\n",
      "epoch: 1 step: 578, loss is 0.5795445442199707\n",
      "epoch: 1 step: 579, loss is 0.09006426483392715\n",
      "epoch: 1 step: 580, loss is 3.366302251815796\n",
      "epoch: 1 step: 581, loss is 0.5167003273963928\n",
      "epoch: 1 step: 582, loss is 1.0913232564926147\n",
      "epoch: 1 step: 583, loss is 1.5667195320129395\n",
      "epoch: 1 step: 584, loss is 0.20939494669437408\n",
      "epoch: 1 step: 585, loss is 0.15588700771331787\n",
      "epoch: 1 step: 586, loss is 1.7965822219848633\n",
      "epoch: 1 step: 587, loss is 1.6579358577728271\n",
      "epoch: 1 step: 588, loss is 0.6264175772666931\n",
      "epoch: 1 step: 589, loss is 0.6613887548446655\n",
      "epoch: 1 step: 590, loss is 1.9445009231567383\n",
      "epoch: 1 step: 591, loss is 1.6428240537643433\n",
      "epoch: 1 step: 592, loss is 0.4124932587146759\n",
      "epoch: 1 step: 593, loss is 0.44058284163475037\n",
      "epoch: 1 step: 594, loss is 1.3617188930511475\n",
      "epoch: 1 step: 595, loss is 1.8925106525421143\n",
      "epoch: 1 step: 596, loss is 1.8350353240966797\n",
      "epoch: 1 step: 597, loss is 4.225297451019287\n",
      "epoch: 1 step: 598, loss is 1.4254624843597412\n",
      "epoch: 1 step: 599, loss is 0.8314200639724731\n",
      "epoch: 1 step: 600, loss is 1.684586763381958\n",
      "epoch: 1 step: 601, loss is 1.981041669845581\n",
      "epoch: 1 step: 602, loss is 0.7253290414810181\n",
      "epoch: 1 step: 603, loss is 0.654735803604126\n",
      "epoch: 1 step: 604, loss is 0.8392989635467529\n",
      "epoch: 1 step: 605, loss is 0.430761456489563\n",
      "epoch: 1 step: 606, loss is 0.5996962189674377\n",
      "epoch: 1 step: 607, loss is 0.3782542049884796\n",
      "epoch: 1 step: 608, loss is 0.14648352563381195\n",
      "epoch: 1 step: 609, loss is 1.0514485836029053\n",
      "epoch: 1 step: 610, loss is 2.3498992919921875\n",
      "epoch: 1 step: 611, loss is 0.4449526071548462\n",
      "epoch: 1 step: 612, loss is 0.1916431039571762\n",
      "epoch: 1 step: 613, loss is 0.11967100948095322\n",
      "epoch: 1 step: 614, loss is 0.2425822913646698\n",
      "epoch: 1 step: 615, loss is 3.0324547290802\n",
      "epoch: 1 step: 616, loss is 0.9316889047622681\n",
      "epoch: 1 step: 617, loss is 0.3447933793067932\n",
      "epoch: 1 step: 618, loss is 1.981317400932312\n",
      "epoch: 1 step: 619, loss is 1.8505675792694092\n",
      "epoch: 1 step: 620, loss is 0.9718404412269592\n",
      "epoch: 1 step: 621, loss is 2.264392137527466\n",
      "epoch: 1 step: 622, loss is 0.5388681888580322\n",
      "epoch: 1 step: 623, loss is 1.8422253131866455\n",
      "epoch: 1 step: 624, loss is 0.37508508563041687\n",
      "epoch: 1 step: 625, loss is 1.7029519081115723\n",
      "epoch: 1 step: 626, loss is 1.239648699760437\n",
      "epoch: 1 step: 627, loss is 0.1265650987625122\n",
      "epoch: 1 step: 628, loss is 1.5916391611099243\n",
      "epoch: 1 step: 629, loss is 0.07185185700654984\n",
      "epoch: 1 step: 630, loss is 0.05231578275561333\n",
      "epoch: 1 step: 631, loss is 0.8494192957878113\n",
      "epoch: 1 step: 632, loss is 2.177288055419922\n",
      "epoch: 1 step: 633, loss is 3.011918783187866\n",
      "epoch: 1 step: 634, loss is 1.566835880279541\n",
      "epoch: 1 step: 635, loss is 0.49673938751220703\n",
      "epoch: 1 step: 636, loss is 2.0608415603637695\n",
      "epoch: 1 step: 637, loss is 0.17905430495738983\n",
      "epoch: 1 step: 638, loss is 0.17282183468341827\n",
      "epoch: 1 step: 639, loss is 1.927809715270996\n",
      "epoch: 1 step: 640, loss is 1.7636363506317139\n",
      "epoch: 1 step: 641, loss is 1.4651882648468018\n",
      "epoch: 1 step: 642, loss is 0.03287031129002571\n",
      "epoch: 1 step: 643, loss is 0.3635190427303314\n",
      "epoch: 1 step: 644, loss is 0.11146537214517593\n",
      "epoch: 1 step: 645, loss is 0.02559015154838562\n",
      "epoch: 1 step: 646, loss is 1.8003315925598145\n",
      "epoch: 1 step: 647, loss is 0.006324514746665955\n",
      "epoch: 1 step: 648, loss is 2.4351556301116943\n",
      "epoch: 1 step: 649, loss is 3.037860631942749\n",
      "epoch: 1 step: 650, loss is 3.223768711090088\n",
      "epoch: 1 step: 651, loss is 0.1094217523932457\n",
      "epoch: 1 step: 652, loss is 0.12827785313129425\n",
      "epoch: 1 step: 653, loss is 0.04126245528459549\n",
      "epoch: 1 step: 654, loss is 1.2409265041351318\n",
      "epoch: 1 step: 655, loss is 0.05186529830098152\n",
      "epoch: 1 step: 656, loss is 0.14619280397891998\n",
      "epoch: 1 step: 657, loss is 0.13472327589988708\n",
      "epoch: 1 step: 658, loss is 1.240187644958496\n",
      "epoch: 1 step: 659, loss is 0.01877278834581375\n",
      "epoch: 1 step: 660, loss is 0.19517287611961365\n",
      "epoch: 1 step: 661, loss is 0.18478688597679138\n",
      "epoch: 1 step: 662, loss is 1.2365764379501343\n",
      "epoch: 1 step: 663, loss is 2.5993032455444336\n",
      "epoch: 1 step: 664, loss is 0.6157178282737732\n",
      "epoch: 1 step: 665, loss is 0.04851658269762993\n",
      "epoch: 1 step: 666, loss is 0.967814028263092\n",
      "epoch: 1 step: 667, loss is 1.0450750589370728\n",
      "epoch: 1 step: 668, loss is 2.1040103435516357\n",
      "epoch: 1 step: 669, loss is 2.3375027179718018\n",
      "epoch: 1 step: 670, loss is 1.6840856075286865\n",
      "epoch: 1 step: 671, loss is 0.31448987126350403\n",
      "epoch: 1 step: 672, loss is 1.5770602226257324\n",
      "epoch: 1 step: 673, loss is 0.7712787985801697\n",
      "epoch: 1 step: 674, loss is 0.20630459487438202\n",
      "epoch: 1 step: 675, loss is 0.31223756074905396\n",
      "epoch: 1 step: 676, loss is 0.120716892182827\n",
      "epoch: 1 step: 677, loss is 1.5432175397872925\n",
      "epoch: 1 step: 678, loss is 0.10481517761945724\n",
      "epoch: 1 step: 679, loss is 0.3648901581764221\n",
      "epoch: 1 step: 680, loss is 3.3934459686279297\n",
      "epoch: 1 step: 681, loss is 0.998114287853241\n",
      "epoch: 1 step: 682, loss is 1.6143064498901367\n",
      "epoch: 1 step: 683, loss is 0.20716148614883423\n",
      "epoch: 1 step: 684, loss is 0.6363261342048645\n",
      "epoch: 1 step: 685, loss is 0.04830555617809296\n",
      "epoch: 1 step: 686, loss is 0.06452762335538864\n",
      "epoch: 1 step: 687, loss is 0.08226186782121658\n",
      "epoch: 1 step: 688, loss is 1.5693284273147583\n",
      "epoch: 1 step: 689, loss is 1.8033945560455322\n",
      "epoch: 1 step: 690, loss is 1.5996062755584717\n",
      "epoch: 1 step: 691, loss is 0.06952286511659622\n",
      "epoch: 1 step: 692, loss is 1.8820693492889404\n",
      "epoch: 1 step: 693, loss is 0.3300969898700714\n",
      "epoch: 1 step: 694, loss is 1.533719778060913\n",
      "epoch: 1 step: 695, loss is 0.0697437971830368\n",
      "epoch: 1 step: 696, loss is 2.2072372436523438\n",
      "epoch: 1 step: 697, loss is 0.33145466446876526\n",
      "epoch: 1 step: 698, loss is 0.5260262489318848\n",
      "epoch: 1 step: 699, loss is 1.4129551649093628\n",
      "epoch: 1 step: 700, loss is 0.5336117148399353\n",
      "epoch: 1 step: 701, loss is 5.104455471038818\n",
      "epoch: 1 step: 702, loss is 1.5406521558761597\n",
      "epoch: 1 step: 703, loss is 1.7723205089569092\n",
      "epoch: 1 step: 704, loss is 0.7141186594963074\n",
      "epoch: 1 step: 705, loss is 1.2387850284576416\n",
      "epoch: 1 step: 706, loss is 1.702486515045166\n",
      "epoch: 1 step: 707, loss is 2.6326699256896973\n",
      "epoch: 1 step: 708, loss is 0.33683010935783386\n",
      "epoch: 1 step: 709, loss is 0.32498592138290405\n",
      "epoch: 1 step: 710, loss is 0.16570915281772614\n",
      "epoch: 1 step: 711, loss is 0.12265702337026596\n",
      "epoch: 1 step: 712, loss is 0.3846070468425751\n",
      "epoch: 1 step: 713, loss is 1.5380995273590088\n",
      "epoch: 1 step: 714, loss is 0.26793810725212097\n",
      "epoch: 1 step: 715, loss is 3.3604648113250732\n",
      "epoch: 1 step: 716, loss is 0.19157035648822784\n",
      "epoch: 1 step: 717, loss is 0.1221434623003006\n",
      "epoch: 1 step: 718, loss is 0.4389864206314087\n",
      "epoch: 1 step: 719, loss is 3.7033848762512207\n",
      "epoch: 1 step: 720, loss is 0.4313056766986847\n",
      "epoch: 1 step: 721, loss is 1.823947787284851\n",
      "epoch: 1 step: 722, loss is 0.7646440863609314\n",
      "epoch: 1 step: 723, loss is 0.20261548459529877\n",
      "epoch: 1 step: 724, loss is 0.09606494754552841\n",
      "epoch: 1 step: 725, loss is 2.628157377243042\n",
      "epoch: 1 step: 726, loss is 0.37074393033981323\n",
      "epoch: 1 step: 727, loss is 0.44419676065444946\n",
      "epoch: 1 step: 728, loss is 0.8875457644462585\n",
      "epoch: 1 step: 729, loss is 0.10978103429079056\n",
      "epoch: 1 step: 730, loss is 0.08771161735057831\n",
      "epoch: 1 step: 731, loss is 3.2910146713256836\n",
      "epoch: 1 step: 732, loss is 1.8951873779296875\n",
      "epoch: 1 step: 733, loss is 0.618971049785614\n",
      "epoch: 1 step: 734, loss is 0.04555420204997063\n",
      "epoch: 1 step: 735, loss is 0.16709357500076294\n",
      "epoch: 1 step: 736, loss is 0.3731147348880768\n",
      "epoch: 1 step: 737, loss is 0.1491561233997345\n",
      "epoch: 1 step: 738, loss is 0.7386070489883423\n",
      "epoch: 1 step: 739, loss is 2.273848533630371\n",
      "epoch: 1 step: 740, loss is 1.79573655128479\n",
      "epoch: 1 step: 741, loss is 0.7985979914665222\n",
      "epoch: 1 step: 742, loss is 1.8322577476501465\n",
      "epoch: 1 step: 743, loss is 2.336214065551758\n",
      "epoch: 1 step: 744, loss is 0.1093691810965538\n",
      "epoch: 1 step: 745, loss is 1.6424205303192139\n",
      "epoch: 1 step: 746, loss is 1.737550973892212\n",
      "epoch: 1 step: 747, loss is 1.3633555173873901\n",
      "epoch: 1 step: 748, loss is 0.6278157830238342\n",
      "epoch: 1 step: 749, loss is 1.3004114627838135\n",
      "epoch: 1 step: 750, loss is 1.4742813110351562\n",
      "epoch: 1 step: 751, loss is 1.6733627319335938\n",
      "epoch: 1 step: 752, loss is 0.713879406452179\n",
      "epoch: 1 step: 753, loss is 0.750023365020752\n",
      "epoch: 1 step: 754, loss is 4.029372692108154\n",
      "epoch: 1 step: 755, loss is 0.024033406749367714\n",
      "epoch: 1 step: 756, loss is 1.372053623199463\n",
      "epoch: 1 step: 757, loss is 0.3836348354816437\n",
      "epoch: 1 step: 758, loss is 0.6011098623275757\n",
      "epoch: 1 step: 759, loss is 1.6606296300888062\n",
      "epoch: 1 step: 760, loss is 1.0267956256866455\n",
      "epoch: 1 step: 761, loss is 0.7715105414390564\n",
      "epoch: 1 step: 762, loss is 2.0842580795288086\n",
      "epoch: 1 step: 763, loss is 0.3332708477973938\n",
      "epoch: 1 step: 764, loss is 1.2923911809921265\n",
      "epoch: 1 step: 765, loss is 0.15209677815437317\n",
      "epoch: 1 step: 766, loss is 1.8423775434494019\n",
      "epoch: 1 step: 767, loss is 3.198476552963257\n",
      "epoch: 1 step: 768, loss is 1.6213655471801758\n",
      "epoch: 1 step: 769, loss is 0.3313227593898773\n",
      "epoch: 1 step: 770, loss is 1.1910737752914429\n",
      "epoch: 1 step: 771, loss is 0.2393995076417923\n",
      "epoch: 1 step: 772, loss is 2.2732739448547363\n",
      "epoch: 1 step: 773, loss is 0.052867043763399124\n",
      "epoch: 1 step: 774, loss is 0.7772356867790222\n",
      "epoch: 1 step: 775, loss is 0.1298554390668869\n",
      "epoch: 1 step: 776, loss is 0.18365605175495148\n",
      "epoch: 1 step: 777, loss is 0.09028343111276627\n",
      "epoch: 1 step: 778, loss is 0.021146666258573532\n",
      "epoch: 1 step: 779, loss is 0.025073520839214325\n",
      "epoch: 1 step: 780, loss is 0.14426936209201813\n",
      "epoch: 1 step: 781, loss is 0.1322815716266632\n",
      "epoch: 1 step: 782, loss is 1.6609623432159424\n",
      "epoch: 1 step: 783, loss is 0.14784874022006989\n",
      "epoch: 1 step: 784, loss is 1.2097190618515015\n",
      "epoch: 1 step: 785, loss is 1.679741621017456\n",
      "epoch: 1 step: 786, loss is 1.0350483655929565\n",
      "epoch: 1 step: 787, loss is 0.03148937225341797\n",
      "epoch: 1 step: 788, loss is 1.5244208574295044\n",
      "epoch: 1 step: 789, loss is 2.2886385917663574\n",
      "epoch: 1 step: 790, loss is 0.10843554139137268\n",
      "epoch: 1 step: 791, loss is 1.707573652267456\n",
      "epoch: 1 step: 792, loss is 0.2738906443119049\n",
      "epoch: 1 step: 793, loss is 0.20704568922519684\n",
      "epoch: 1 step: 794, loss is 3.6862430572509766\n",
      "epoch: 1 step: 795, loss is 0.43364572525024414\n",
      "epoch: 1 step: 796, loss is 1.9647456407546997\n",
      "epoch: 1 step: 797, loss is 2.1513376235961914\n",
      "epoch: 1 step: 798, loss is 1.9373403787612915\n",
      "epoch: 1 step: 799, loss is 0.35863903164863586\n",
      "epoch: 1 step: 800, loss is 1.5632754564285278\n",
      "epoch: 1 step: 801, loss is 1.7550911903381348\n",
      "epoch: 1 step: 802, loss is 1.306803822517395\n",
      "epoch: 1 step: 803, loss is 0.8476245403289795\n",
      "epoch: 1 step: 804, loss is 1.5629935264587402\n",
      "epoch: 1 step: 805, loss is 0.28180116415023804\n",
      "epoch: 1 step: 806, loss is 1.9021559953689575\n",
      "epoch: 1 step: 807, loss is 2.1854023933410645\n",
      "epoch: 1 step: 808, loss is 0.6489093899726868\n",
      "epoch: 1 step: 809, loss is 0.9031897187232971\n",
      "epoch: 1 step: 810, loss is 1.617668628692627\n",
      "epoch: 1 step: 811, loss is 1.0910370349884033\n",
      "epoch: 1 step: 812, loss is 0.2524258494377136\n",
      "epoch: 1 step: 813, loss is 0.13246765732765198\n",
      "epoch: 1 step: 814, loss is 2.0557150840759277\n",
      "epoch: 1 step: 815, loss is 1.7943336963653564\n",
      "epoch: 1 step: 816, loss is 0.9213329553604126\n",
      "epoch: 1 step: 817, loss is 0.2987006604671478\n",
      "epoch: 1 step: 818, loss is 0.5853771567344666\n",
      "epoch: 1 step: 819, loss is 0.020116126164793968\n",
      "epoch: 1 step: 820, loss is 1.1238222122192383\n",
      "epoch: 1 step: 821, loss is 0.8716224431991577\n",
      "epoch: 1 step: 822, loss is 0.11071352660655975\n",
      "epoch: 1 step: 823, loss is 1.6626957654953003\n",
      "epoch: 1 step: 824, loss is 1.7573800086975098\n",
      "epoch: 1 step: 825, loss is 3.528184413909912\n",
      "epoch: 1 step: 826, loss is 1.8126991987228394\n",
      "epoch: 1 step: 827, loss is 1.8385728597640991\n",
      "epoch: 1 step: 828, loss is 1.92905855178833\n",
      "epoch: 1 step: 829, loss is 1.671029806137085\n",
      "epoch: 1 step: 830, loss is 0.6288259029388428\n",
      "epoch: 1 step: 831, loss is 2.018362045288086\n",
      "epoch: 1 step: 832, loss is 0.1678345650434494\n",
      "epoch: 1 step: 833, loss is 0.3264686167240143\n",
      "epoch: 1 step: 834, loss is 0.545549750328064\n",
      "epoch: 1 step: 835, loss is 2.3104076385498047\n",
      "epoch: 1 step: 836, loss is 1.5616953372955322\n",
      "epoch: 1 step: 837, loss is 0.4074934124946594\n",
      "epoch: 1 step: 838, loss is 1.109632134437561\n",
      "epoch: 1 step: 839, loss is 1.8133115768432617\n",
      "epoch: 1 step: 840, loss is 0.2942970395088196\n",
      "epoch: 1 step: 841, loss is 0.09714910387992859\n",
      "epoch: 1 step: 842, loss is 1.6523120403289795\n",
      "epoch: 1 step: 843, loss is 1.9925367832183838\n",
      "epoch: 1 step: 844, loss is 1.9284664392471313\n",
      "epoch: 1 step: 845, loss is 0.4859953820705414\n",
      "epoch: 1 step: 846, loss is 2.6938316822052\n",
      "epoch: 1 step: 847, loss is 0.2223808914422989\n",
      "epoch: 1 step: 848, loss is 0.47442716360092163\n",
      "epoch: 1 step: 849, loss is 0.8974094986915588\n",
      "epoch: 1 step: 850, loss is 0.046513356268405914\n",
      "epoch: 1 step: 851, loss is 1.5617414712905884\n",
      "epoch: 1 step: 852, loss is 0.17105086147785187\n",
      "epoch: 1 step: 853, loss is 1.6646486520767212\n",
      "epoch: 1 step: 854, loss is 1.5610963106155396\n",
      "epoch: 1 step: 855, loss is 0.17713788151741028\n",
      "epoch: 1 step: 856, loss is 1.6320149898529053\n",
      "epoch: 1 step: 857, loss is 0.015186283737421036\n",
      "epoch: 1 step: 858, loss is 0.07300268113613129\n",
      "epoch: 1 step: 859, loss is 3.1711387634277344\n",
      "epoch: 1 step: 860, loss is 0.937951385974884\n",
      "epoch: 1 step: 861, loss is 0.30145782232284546\n",
      "epoch: 1 step: 862, loss is 0.6189293265342712\n",
      "epoch: 1 step: 863, loss is 1.6719098091125488\n",
      "epoch: 1 step: 864, loss is 0.1665676236152649\n",
      "epoch: 1 step: 865, loss is 0.12411694973707199\n",
      "epoch: 1 step: 866, loss is 4.533019065856934\n",
      "epoch: 1 step: 867, loss is 1.2376154661178589\n",
      "epoch: 1 step: 868, loss is 0.20035745203495026\n",
      "epoch: 1 step: 869, loss is 1.8825995922088623\n",
      "epoch: 1 step: 870, loss is 2.213881015777588\n",
      "epoch: 1 step: 871, loss is 1.0928223133087158\n",
      "epoch: 1 step: 872, loss is 0.9426171183586121\n",
      "epoch: 1 step: 873, loss is 2.068976402282715\n",
      "epoch: 1 step: 874, loss is 1.6438167095184326\n",
      "epoch: 1 step: 875, loss is 1.6583836078643799\n",
      "epoch: 1 step: 876, loss is 1.48966383934021\n",
      "epoch: 1 step: 877, loss is 1.1366955041885376\n",
      "epoch: 1 step: 878, loss is 1.0541353225708008\n",
      "epoch: 1 step: 879, loss is 0.9994407296180725\n",
      "epoch: 1 step: 880, loss is 1.6260768175125122\n",
      "epoch: 1 step: 881, loss is 0.3602048456668854\n",
      "epoch: 1 step: 882, loss is 1.9289569854736328\n",
      "epoch: 1 step: 883, loss is 1.8939595222473145\n",
      "epoch: 1 step: 884, loss is 0.46362605690956116\n",
      "epoch: 1 step: 885, loss is 2.1608593463897705\n",
      "epoch: 1 step: 886, loss is 2.0384764671325684\n",
      "epoch: 1 step: 887, loss is 0.9747007489204407\n",
      "epoch: 1 step: 888, loss is 1.0248233079910278\n",
      "epoch: 1 step: 889, loss is 4.016869068145752\n",
      "epoch: 1 step: 890, loss is 1.237247347831726\n",
      "epoch: 1 step: 891, loss is 0.22183941304683685\n",
      "epoch: 1 step: 892, loss is 0.08944222331047058\n",
      "epoch: 1 step: 893, loss is 1.8072236776351929\n",
      "epoch: 1 step: 894, loss is 1.5623056888580322\n",
      "epoch: 1 step: 895, loss is 0.35021498799324036\n",
      "epoch: 1 step: 896, loss is 2.4915835857391357\n",
      "epoch: 1 step: 897, loss is 2.3865818977355957\n",
      "epoch: 1 step: 898, loss is 1.2376612424850464\n",
      "epoch: 1 step: 899, loss is 0.2530275881290436\n",
      "epoch: 1 step: 900, loss is 1.190189003944397\n",
      "epoch: 1 step: 901, loss is 1.677380084991455\n",
      "epoch: 1 step: 902, loss is 1.6620665788650513\n",
      "epoch: 1 step: 903, loss is 0.3353363573551178\n",
      "epoch: 1 step: 904, loss is 1.8991811275482178\n",
      "epoch: 1 step: 905, loss is 1.8112633228302002\n",
      "epoch: 1 step: 906, loss is 0.908200204372406\n",
      "epoch: 1 step: 907, loss is 0.3057366907596588\n",
      "epoch: 1 step: 908, loss is 0.38851404190063477\n",
      "epoch: 1 step: 909, loss is 1.6608569622039795\n",
      "epoch: 1 step: 910, loss is 0.02284296043217182\n",
      "epoch: 1 step: 911, loss is 0.3360692858695984\n",
      "epoch: 1 step: 912, loss is 0.1339772492647171\n",
      "epoch: 1 step: 913, loss is 1.7288250923156738\n",
      "epoch: 1 step: 914, loss is 0.7113692760467529\n",
      "epoch: 1 step: 915, loss is 0.3513915538787842\n",
      "epoch: 1 step: 916, loss is 0.1887415200471878\n",
      "epoch: 1 step: 917, loss is 1.1023815870285034\n",
      "epoch: 1 step: 918, loss is 0.35072383284568787\n",
      "epoch: 1 step: 919, loss is 3.5601999759674072\n",
      "epoch: 1 step: 920, loss is 0.08212724328041077\n",
      "epoch: 1 step: 921, loss is 0.1716739684343338\n",
      "epoch: 1 step: 922, loss is 0.13838540017604828\n",
      "epoch: 1 step: 923, loss is 2.1992321014404297\n",
      "epoch: 1 step: 924, loss is 0.5386722087860107\n",
      "epoch: 1 step: 925, loss is 0.018291015177965164\n",
      "epoch: 1 step: 926, loss is 0.9323909878730774\n",
      "epoch: 1 step: 927, loss is 0.653043806552887\n",
      "epoch: 1 step: 928, loss is 0.3866161108016968\n",
      "epoch: 1 step: 929, loss is 0.18355871737003326\n",
      "epoch: 1 step: 930, loss is 2.0072803497314453\n",
      "epoch: 1 step: 931, loss is 0.5649915933609009\n",
      "epoch: 1 step: 932, loss is 0.20000731945037842\n",
      "epoch: 1 step: 933, loss is 3.5983662605285645\n",
      "epoch: 1 step: 934, loss is 0.08146695792675018\n",
      "epoch: 1 step: 935, loss is 1.6643893718719482\n",
      "epoch: 1 step: 936, loss is 0.6811719536781311\n",
      "epoch: 1 step: 937, loss is 0.6862182021141052\n",
      "epoch: 1 step: 938, loss is 1.9419913291931152\n",
      "epoch: 1 step: 939, loss is 0.1110813096165657\n",
      "epoch: 1 step: 940, loss is 3.3996694087982178\n",
      "epoch: 1 step: 941, loss is 1.6466537714004517\n",
      "epoch: 1 step: 942, loss is 2.43407940864563\n",
      "epoch: 1 step: 943, loss is 0.6343250274658203\n",
      "epoch: 1 step: 944, loss is 0.33484163880348206\n",
      "epoch: 1 step: 945, loss is 1.0050042867660522\n",
      "epoch: 1 step: 946, loss is 0.44393593072891235\n",
      "epoch: 1 step: 947, loss is 0.3779867887496948\n",
      "epoch: 1 step: 948, loss is 1.9955140352249146\n",
      "epoch: 1 step: 949, loss is 0.44590404629707336\n",
      "epoch: 1 step: 950, loss is 1.7003767490386963\n",
      "epoch: 1 step: 951, loss is 0.33495908975601196\n",
      "epoch: 1 step: 952, loss is 0.03488387539982796\n",
      "epoch: 1 step: 953, loss is 0.9170835614204407\n",
      "epoch: 1 step: 954, loss is 3.090987205505371\n",
      "epoch: 1 step: 955, loss is 1.2203359603881836\n",
      "epoch: 1 step: 956, loss is 0.33786505460739136\n",
      "epoch: 1 step: 957, loss is 1.6561181545257568\n",
      "epoch: 1 step: 958, loss is 1.4816265106201172\n",
      "epoch: 1 step: 959, loss is 0.1048172116279602\n",
      "epoch: 1 step: 960, loss is 1.721541166305542\n",
      "epoch: 1 step: 961, loss is 0.2363463193178177\n",
      "epoch: 1 step: 962, loss is 1.2692720890045166\n",
      "epoch: 1 step: 963, loss is 3.953169345855713\n",
      "epoch: 1 step: 964, loss is 0.27837738394737244\n",
      "epoch: 1 step: 965, loss is 0.620476245880127\n",
      "epoch: 1 step: 966, loss is 0.5755102038383484\n",
      "epoch: 1 step: 967, loss is 1.0673503875732422\n",
      "epoch: 1 step: 968, loss is 0.32262757420539856\n",
      "epoch: 1 step: 969, loss is 0.08154837787151337\n",
      "epoch: 1 step: 970, loss is 0.049845755100250244\n",
      "epoch: 1 step: 971, loss is 1.8564796447753906\n",
      "epoch: 1 step: 972, loss is 0.183409184217453\n",
      "epoch: 1 step: 973, loss is 1.8146908283233643\n",
      "epoch: 1 step: 974, loss is 0.37431100010871887\n",
      "epoch: 1 step: 975, loss is 0.843573808670044\n",
      "epoch: 1 step: 976, loss is 0.01976029947400093\n",
      "epoch: 1 step: 977, loss is 0.030037233605980873\n",
      "epoch: 1 step: 978, loss is 0.07432474195957184\n",
      "epoch: 1 step: 979, loss is 1.7600712776184082\n",
      "epoch: 1 step: 980, loss is 0.19068463146686554\n",
      "epoch: 1 step: 981, loss is 3.5175490379333496\n",
      "epoch: 1 step: 982, loss is 1.9330437183380127\n",
      "epoch: 1 step: 983, loss is 0.1346563994884491\n",
      "epoch: 1 step: 984, loss is 0.37999600172042847\n",
      "epoch: 1 step: 985, loss is 1.4769803285598755\n",
      "epoch: 1 step: 986, loss is 0.5825057625770569\n",
      "epoch: 1 step: 987, loss is 0.3081178069114685\n",
      "epoch: 1 step: 988, loss is 0.36727213859558105\n",
      "epoch: 1 step: 989, loss is 2.389953851699829\n",
      "epoch: 1 step: 990, loss is 0.23633229732513428\n",
      "epoch: 1 step: 991, loss is 1.5369094610214233\n",
      "epoch: 1 step: 992, loss is 0.653058648109436\n",
      "epoch: 1 step: 993, loss is 0.7300920486450195\n",
      "epoch: 1 step: 994, loss is 2.1678216457366943\n",
      "epoch: 1 step: 995, loss is 2.5062475204467773\n",
      "epoch: 1 step: 996, loss is 2.07800555229187\n",
      "epoch: 1 step: 997, loss is 1.6191787719726562\n",
      "epoch: 1 step: 998, loss is 1.7873778343200684\n",
      "epoch: 1 step: 999, loss is 1.1874444484710693\n",
      "epoch: 1 step: 1000, loss is 0.47032636404037476\n",
      "epoch: 1 step: 1001, loss is 0.29533833265304565\n",
      "epoch: 1 step: 1002, loss is 1.1108804941177368\n",
      "epoch: 1 step: 1003, loss is 0.3974093198776245\n",
      "epoch: 1 step: 1004, loss is 1.6893045902252197\n",
      "epoch: 1 step: 1005, loss is 0.7448000311851501\n",
      "epoch: 1 step: 1006, loss is 2.0165812969207764\n",
      "epoch: 1 step: 1007, loss is 1.6633684635162354\n",
      "epoch: 1 step: 1008, loss is 0.47790178656578064\n",
      "epoch: 1 step: 1009, loss is 1.0479187965393066\n",
      "epoch: 1 step: 1010, loss is 1.978535771369934\n",
      "epoch: 1 step: 1011, loss is 0.12649209797382355\n",
      "epoch: 1 step: 1012, loss is 0.17429229617118835\n",
      "epoch: 1 step: 1013, loss is 1.8901000022888184\n",
      "epoch: 1 step: 1014, loss is 0.26748186349868774\n",
      "epoch: 1 step: 1015, loss is 1.56857168674469\n",
      "epoch: 1 step: 1016, loss is 0.9758581519126892\n",
      "epoch: 1 step: 1017, loss is 0.2667734920978546\n",
      "epoch: 1 step: 1018, loss is 0.3451874852180481\n",
      "epoch: 1 step: 1019, loss is 0.11029810458421707\n",
      "epoch: 1 step: 1020, loss is 2.4455103874206543\n",
      "epoch: 1 step: 1021, loss is 0.15654265880584717\n",
      "epoch: 1 step: 1022, loss is 0.8261306285858154\n",
      "epoch: 1 step: 1023, loss is 0.10899478197097778\n",
      "epoch: 1 step: 1024, loss is 0.9997323155403137\n",
      "epoch: 1 step: 1025, loss is 1.5434070825576782\n",
      "epoch: 1 step: 1026, loss is 2.279423475265503\n",
      "epoch: 1 step: 1027, loss is 0.01885526441037655\n",
      "epoch: 1 step: 1028, loss is 0.07805775851011276\n",
      "epoch: 1 step: 1029, loss is 0.07664435356855392\n",
      "epoch: 1 step: 1030, loss is 0.3560788929462433\n",
      "epoch: 1 step: 1031, loss is 0.24138998985290527\n",
      "epoch: 1 step: 1032, loss is 1.7502250671386719\n",
      "epoch: 1 step: 1033, loss is 0.3165806233882904\n",
      "epoch: 1 step: 1034, loss is 0.011746053583920002\n",
      "epoch: 1 step: 1035, loss is 0.13327491283416748\n",
      "epoch: 1 step: 1036, loss is 0.06792181730270386\n",
      "epoch: 1 step: 1037, loss is 2.540062427520752\n",
      "epoch: 1 step: 1038, loss is 0.039929263293743134\n",
      "epoch: 1 step: 1039, loss is 0.2596557140350342\n",
      "epoch: 1 step: 1040, loss is 0.24122217297554016\n",
      "epoch: 1 step: 1041, loss is 0.026081547141075134\n",
      "epoch: 1 step: 1042, loss is 0.01580473966896534\n",
      "epoch: 1 step: 1043, loss is 0.24210956692695618\n",
      "epoch: 1 step: 1044, loss is 1.1981806755065918\n",
      "epoch: 1 step: 1045, loss is 0.09399337321519852\n",
      "epoch: 1 step: 1046, loss is 0.5987545251846313\n",
      "epoch: 1 step: 1047, loss is 0.866200864315033\n",
      "epoch: 1 step: 1048, loss is 0.339552104473114\n",
      "epoch: 1 step: 1049, loss is 0.03488721325993538\n",
      "epoch: 1 step: 1050, loss is 0.027874654158949852\n",
      "epoch: 1 step: 1051, loss is 0.02211248129606247\n",
      "epoch: 1 step: 1052, loss is 0.17732040584087372\n",
      "epoch: 1 step: 1053, loss is 0.06791145354509354\n",
      "epoch: 1 step: 1054, loss is 1.9030451774597168\n",
      "epoch: 1 step: 1055, loss is 1.6951043605804443\n",
      "epoch: 1 step: 1056, loss is 1.912437081336975\n",
      "epoch: 1 step: 1057, loss is 3.4617724418640137\n",
      "epoch: 1 step: 1058, loss is 0.19144830107688904\n",
      "epoch: 1 step: 1059, loss is 1.9966557025909424\n",
      "epoch: 1 step: 1060, loss is 2.8102736473083496\n",
      "epoch: 1 step: 1061, loss is 0.7450629472732544\n",
      "epoch: 1 step: 1062, loss is 0.08060653507709503\n",
      "epoch: 1 step: 1063, loss is 0.016188837587833405\n",
      "epoch: 1 step: 1064, loss is 2.1523232460021973\n",
      "epoch: 1 step: 1065, loss is 0.15174828469753265\n",
      "epoch: 1 step: 1066, loss is 0.2684110105037689\n",
      "epoch: 1 step: 1067, loss is 0.27171844244003296\n",
      "epoch: 1 step: 1068, loss is 0.15389148890972137\n",
      "epoch: 1 step: 1069, loss is 0.2264517992734909\n",
      "epoch: 1 step: 1070, loss is 0.05997759848833084\n",
      "epoch: 1 step: 1071, loss is 0.052302319556474686\n",
      "epoch: 1 step: 1072, loss is 1.9367178678512573\n",
      "epoch: 1 step: 1073, loss is 2.0783205032348633\n",
      "epoch: 1 step: 1074, loss is 0.38208916783332825\n",
      "epoch: 1 step: 1075, loss is 0.04530700668692589\n",
      "epoch: 1 step: 1076, loss is 0.11202260106801987\n",
      "epoch: 1 step: 1077, loss is 0.1269153505563736\n",
      "epoch: 1 step: 1078, loss is 0.00697546498849988\n",
      "epoch: 1 step: 1079, loss is 2.0568790435791016\n",
      "epoch: 1 step: 1080, loss is 1.0234402418136597\n",
      "epoch: 1 step: 1081, loss is 0.017729725688695908\n",
      "epoch: 1 step: 1082, loss is 0.9137851595878601\n",
      "epoch: 1 step: 1083, loss is 1.8179243803024292\n",
      "epoch: 1 step: 1084, loss is 0.36254262924194336\n",
      "epoch: 1 step: 1085, loss is 0.007207582704722881\n",
      "epoch: 1 step: 1086, loss is 2.0038466453552246\n",
      "epoch: 1 step: 1087, loss is 0.007719683926552534\n",
      "epoch: 1 step: 1088, loss is 0.09701301157474518\n",
      "epoch: 1 step: 1089, loss is 0.14204098284244537\n",
      "epoch: 1 step: 1090, loss is 0.21144099533557892\n",
      "epoch: 1 step: 1091, loss is 1.2741310596466064\n",
      "epoch: 1 step: 1092, loss is 0.005360633600503206\n",
      "epoch: 1 step: 1093, loss is 0.03382384032011032\n",
      "epoch: 1 step: 1094, loss is 0.004805800039321184\n",
      "epoch: 1 step: 1095, loss is 1.8025884628295898\n",
      "epoch: 1 step: 1096, loss is 1.2283209562301636\n",
      "epoch: 1 step: 1097, loss is 0.10369223356246948\n",
      "epoch: 1 step: 1098, loss is 0.0713239535689354\n",
      "epoch: 1 step: 1099, loss is 0.0016750366194173694\n",
      "epoch: 1 step: 1100, loss is 0.03989993780851364\n",
      "epoch: 1 step: 1101, loss is 0.003130893921479583\n",
      "epoch: 1 step: 1102, loss is 0.8642550110816956\n",
      "epoch: 1 step: 1103, loss is 0.01011920627206564\n",
      "epoch: 1 step: 1104, loss is 2.5068576335906982\n",
      "epoch: 1 step: 1105, loss is 4.276143550872803\n",
      "epoch: 1 step: 1106, loss is 2.9159717559814453\n",
      "epoch: 1 step: 1107, loss is 2.595677137374878\n",
      "epoch: 1 step: 1108, loss is 0.6167005300521851\n",
      "epoch: 1 step: 1109, loss is 1.1155123710632324\n",
      "epoch: 1 step: 1110, loss is 0.37954580783843994\n",
      "epoch: 1 step: 1111, loss is 1.5271018743515015\n",
      "epoch: 1 step: 1112, loss is 0.04561400040984154\n",
      "epoch: 1 step: 1113, loss is 0.9062201380729675\n",
      "epoch: 1 step: 1114, loss is 0.025365401059389114\n",
      "epoch: 1 step: 1115, loss is 1.6519567966461182\n",
      "epoch: 1 step: 1116, loss is 0.27762681245803833\n",
      "epoch: 1 step: 1117, loss is 1.4630520343780518\n",
      "epoch: 1 step: 1118, loss is 0.09264840185642242\n",
      "epoch: 1 step: 1119, loss is 0.07754327356815338\n",
      "epoch: 1 step: 1120, loss is 0.09840203821659088\n",
      "epoch: 1 step: 1121, loss is 0.07626600563526154\n",
      "epoch: 1 step: 1122, loss is 0.28851136565208435\n",
      "epoch: 1 step: 1123, loss is 0.02885090745985508\n",
      "epoch: 1 step: 1124, loss is 0.03357096016407013\n",
      "epoch: 1 step: 1125, loss is 2.0100245475769043\n",
      "epoch: 1 step: 1126, loss is 1.8831427097320557\n",
      "epoch: 1 step: 1127, loss is 3.819016218185425\n",
      "epoch: 1 step: 1128, loss is 0.12634292244911194\n",
      "epoch: 1 step: 1129, loss is 0.1080736368894577\n",
      "epoch: 1 step: 1130, loss is 1.84645414352417\n",
      "epoch: 1 step: 1131, loss is 5.192788600921631\n",
      "epoch: 1 step: 1132, loss is 0.24060486257076263\n",
      "epoch: 1 step: 1133, loss is 1.157747745513916\n",
      "epoch: 1 step: 1134, loss is 0.506203830242157\n",
      "epoch: 1 step: 1135, loss is 0.11489410698413849\n",
      "epoch: 1 step: 1136, loss is 1.0656710863113403\n",
      "epoch: 1 step: 1137, loss is 1.7296721935272217\n",
      "epoch: 1 step: 1138, loss is 2.195140838623047\n",
      "epoch: 1 step: 1139, loss is 0.19341887533664703\n",
      "epoch: 1 step: 1140, loss is 1.8245940208435059\n",
      "epoch: 1 step: 1141, loss is 0.7946311235427856\n",
      "epoch: 1 step: 1142, loss is 1.6940057277679443\n",
      "epoch: 1 step: 1143, loss is 0.14951373636722565\n",
      "epoch: 1 step: 1144, loss is 2.4037351608276367\n",
      "epoch: 1 step: 1145, loss is 1.6442615985870361\n",
      "epoch: 1 step: 1146, loss is 1.5651912689208984\n",
      "epoch: 1 step: 1147, loss is 0.1280021369457245\n",
      "epoch: 1 step: 1148, loss is 0.48907631635665894\n",
      "epoch: 1 step: 1149, loss is 2.430015802383423\n",
      "epoch: 1 step: 1150, loss is 0.3457392156124115\n",
      "epoch: 1 step: 1151, loss is 0.32411861419677734\n",
      "epoch: 1 step: 1152, loss is 0.2247125506401062\n",
      "epoch: 1 step: 1153, loss is 0.41042840480804443\n",
      "epoch: 1 step: 1154, loss is 0.052018653601408005\n",
      "epoch: 1 step: 1155, loss is 1.7078595161437988\n",
      "epoch: 1 step: 1156, loss is 0.37948307394981384\n",
      "epoch: 1 step: 1157, loss is 0.1709916889667511\n",
      "epoch: 1 step: 1158, loss is 0.07153550535440445\n",
      "epoch: 1 step: 1159, loss is 1.820103645324707\n",
      "epoch: 1 step: 1160, loss is 0.1743534803390503\n",
      "epoch: 1 step: 1161, loss is 2.3433024883270264\n",
      "epoch: 1 step: 1162, loss is 1.693609356880188\n",
      "epoch: 1 step: 1163, loss is 0.40976786613464355\n",
      "epoch: 1 step: 1164, loss is 2.615602970123291\n",
      "epoch: 1 step: 1165, loss is 0.24738751351833344\n",
      "epoch: 1 step: 1166, loss is 2.604379177093506\n",
      "epoch: 1 step: 1167, loss is 1.6563830375671387\n",
      "epoch: 1 step: 1168, loss is 1.8916046619415283\n",
      "epoch: 1 step: 1169, loss is 1.829353928565979\n",
      "epoch: 1 step: 1170, loss is 2.0178170204162598\n",
      "epoch: 1 step: 1171, loss is 0.868770182132721\n",
      "epoch: 1 step: 1172, loss is 1.6521669626235962\n",
      "epoch: 1 step: 1173, loss is 0.4883779287338257\n",
      "epoch: 1 step: 1174, loss is 0.08260129392147064\n",
      "epoch: 1 step: 1175, loss is 0.3237644135951996\n",
      "epoch: 1 step: 1176, loss is 1.1109384298324585\n",
      "epoch: 1 step: 1177, loss is 1.2746846675872803\n",
      "epoch: 1 step: 1178, loss is 3.024094581604004\n",
      "epoch: 1 step: 1179, loss is 0.8134970664978027\n",
      "epoch: 1 step: 1180, loss is 2.3977713584899902\n",
      "epoch: 1 step: 1181, loss is 1.376519799232483\n",
      "epoch: 1 step: 1182, loss is 0.23506371676921844\n",
      "epoch: 1 step: 1183, loss is 0.4525323510169983\n",
      "epoch: 1 step: 1184, loss is 1.2133278846740723\n",
      "epoch: 1 step: 1185, loss is 1.2668497562408447\n",
      "epoch: 1 step: 1186, loss is 1.7542883157730103\n",
      "epoch: 1 step: 1187, loss is 0.02325488068163395\n",
      "epoch: 1 step: 1188, loss is 0.1258077174425125\n",
      "epoch: 1 step: 1189, loss is 0.42331841588020325\n",
      "epoch: 1 step: 1190, loss is 0.044827140867710114\n",
      "epoch: 1 step: 1191, loss is 1.5009045600891113\n",
      "epoch: 1 step: 1192, loss is 2.1253628730773926\n",
      "epoch: 1 step: 1193, loss is 0.0814627856016159\n",
      "epoch: 1 step: 1194, loss is 0.15427325665950775\n",
      "epoch: 1 step: 1195, loss is 0.12730859220027924\n",
      "epoch: 1 step: 1196, loss is 0.08918547630310059\n",
      "epoch: 1 step: 1197, loss is 0.14592477679252625\n",
      "epoch: 1 step: 1198, loss is 0.04786326363682747\n",
      "epoch: 1 step: 1199, loss is 1.8238182067871094\n",
      "epoch: 1 step: 1200, loss is 1.9783084392547607\n",
      "epoch: 1 step: 1201, loss is 0.13175547122955322\n",
      "epoch: 1 step: 1202, loss is 0.5031646490097046\n",
      "epoch: 1 step: 1203, loss is 2.7740306854248047\n",
      "epoch: 1 step: 1204, loss is 0.16847962141036987\n",
      "epoch: 1 step: 1205, loss is 0.044685788452625275\n",
      "epoch: 1 step: 1206, loss is 0.3451279103755951\n",
      "epoch: 1 step: 1207, loss is 0.7269089221954346\n",
      "epoch: 1 step: 1208, loss is 0.02833711728453636\n",
      "epoch: 1 step: 1209, loss is 1.9225690364837646\n",
      "epoch: 1 step: 1210, loss is 2.804293394088745\n",
      "epoch: 1 step: 1211, loss is 0.4888060390949249\n",
      "epoch: 1 step: 1212, loss is 3.055692672729492\n",
      "epoch: 1 step: 1213, loss is 0.8160486221313477\n",
      "epoch: 1 step: 1214, loss is 0.5200543403625488\n",
      "epoch: 1 step: 1215, loss is 1.3831394910812378\n",
      "epoch: 1 step: 1216, loss is 0.30578330159187317\n",
      "epoch: 1 step: 1217, loss is 1.5422394275665283\n",
      "epoch: 1 step: 1218, loss is 1.055052638053894\n",
      "epoch: 1 step: 1219, loss is 0.16908590495586395\n",
      "epoch: 1 step: 1220, loss is 0.4904101490974426\n",
      "epoch: 1 step: 1221, loss is 0.14742419123649597\n",
      "epoch: 1 step: 1222, loss is 0.00890072900801897\n",
      "epoch: 1 step: 1223, loss is 2.6776745319366455\n",
      "epoch: 1 step: 1224, loss is 0.12350837141275406\n",
      "epoch: 1 step: 1225, loss is 1.4067842960357666\n",
      "epoch: 1 step: 1226, loss is 2.0529894828796387\n",
      "epoch: 1 step: 1227, loss is 0.3536631166934967\n",
      "epoch: 1 step: 1228, loss is 0.2740800082683563\n",
      "epoch: 1 step: 1229, loss is 1.8990764617919922\n",
      "epoch: 1 step: 1230, loss is 1.672212839126587\n",
      "epoch: 1 step: 1231, loss is 0.15694645047187805\n",
      "epoch: 1 step: 1232, loss is 0.07353269308805466\n",
      "epoch: 1 step: 1233, loss is 1.690364956855774\n",
      "epoch: 1 step: 1234, loss is 0.20889998972415924\n",
      "epoch: 1 step: 1235, loss is 2.478468656539917\n",
      "epoch: 1 step: 1236, loss is 0.4110866189002991\n",
      "epoch: 1 step: 1237, loss is 2.1089677810668945\n",
      "epoch: 1 step: 1238, loss is 1.709127426147461\n",
      "epoch: 1 step: 1239, loss is 0.07873252779245377\n",
      "epoch: 1 step: 1240, loss is 0.20034164190292358\n",
      "epoch: 1 step: 1241, loss is 1.5737494230270386\n",
      "epoch: 1 step: 1242, loss is 0.46643882989883423\n",
      "epoch: 1 step: 1243, loss is 5.453512668609619\n",
      "epoch: 1 step: 1244, loss is 0.17349565029144287\n",
      "epoch: 1 step: 1245, loss is 0.8433441519737244\n",
      "epoch: 1 step: 1246, loss is 2.5124998092651367\n",
      "epoch: 1 step: 1247, loss is 2.1002120971679688\n",
      "epoch: 1 step: 1248, loss is 1.8645710945129395\n",
      "epoch: 1 step: 1249, loss is 0.6441644430160522\n",
      "epoch: 1 step: 1250, loss is 0.14376844465732574\n",
      "epoch: 1 step: 1251, loss is 0.05304771289229393\n",
      "epoch: 1 step: 1252, loss is 1.2867337465286255\n",
      "epoch: 1 step: 1253, loss is 2.4798738956451416\n",
      "epoch: 1 step: 1254, loss is 1.9553710222244263\n",
      "epoch: 1 step: 1255, loss is 0.48624926805496216\n",
      "epoch: 1 step: 1256, loss is 0.2124561369419098\n",
      "epoch: 1 step: 1257, loss is 0.49338415265083313\n",
      "epoch: 1 step: 1258, loss is 0.3817334473133087\n",
      "epoch: 1 step: 1259, loss is 0.2341945767402649\n",
      "epoch: 1 step: 1260, loss is 1.8846678733825684\n",
      "epoch: 1 step: 1261, loss is 0.16924524307250977\n",
      "epoch: 1 step: 1262, loss is 0.257929265499115\n",
      "epoch: 1 step: 1263, loss is 0.11109880357980728\n",
      "epoch: 1 step: 1264, loss is 0.3699024021625519\n",
      "epoch: 1 step: 1265, loss is 1.1686418056488037\n",
      "epoch: 1 step: 1266, loss is 1.8706332445144653\n",
      "epoch: 1 step: 1267, loss is 1.8812766075134277\n",
      "epoch: 1 step: 1268, loss is 0.35577332973480225\n",
      "epoch: 1 step: 1269, loss is 0.5609292984008789\n",
      "epoch: 1 step: 1270, loss is 1.2766038179397583\n",
      "epoch: 1 step: 1271, loss is 0.2714208662509918\n",
      "epoch: 1 step: 1272, loss is 1.5712223052978516\n",
      "epoch: 1 step: 1273, loss is 0.8665167689323425\n",
      "epoch: 1 step: 1274, loss is 1.986229658126831\n",
      "epoch: 1 step: 1275, loss is 3.368366003036499\n",
      "epoch: 1 step: 1276, loss is 1.0938241481781006\n",
      "epoch: 1 step: 1277, loss is 1.3459925651550293\n",
      "epoch: 1 step: 1278, loss is 2.617398738861084\n",
      "epoch: 1 step: 1279, loss is 0.26822295784950256\n",
      "epoch: 1 step: 1280, loss is 0.9761625528335571\n",
      "epoch: 1 step: 1281, loss is 0.44885939359664917\n",
      "epoch: 1 step: 1282, loss is 1.1151291131973267\n",
      "epoch: 1 step: 1283, loss is 0.5258551239967346\n",
      "epoch: 1 step: 1284, loss is 0.3487032651901245\n",
      "epoch: 1 step: 1285, loss is 0.20659492909908295\n",
      "epoch: 1 step: 1286, loss is 0.22912727296352386\n",
      "epoch: 1 step: 1287, loss is 0.48428526520729065\n",
      "epoch: 1 step: 1288, loss is 0.48733776807785034\n",
      "epoch: 1 step: 1289, loss is 0.12914946675300598\n",
      "epoch: 1 step: 1290, loss is 0.4255600869655609\n",
      "epoch: 1 step: 1291, loss is 0.18274787068367004\n",
      "epoch: 1 step: 1292, loss is 2.185037136077881\n",
      "epoch: 1 step: 1293, loss is 0.37917089462280273\n",
      "epoch: 1 step: 1294, loss is 0.24948090314865112\n",
      "epoch: 1 step: 1295, loss is 0.3224506378173828\n",
      "epoch: 1 step: 1296, loss is 2.7693159580230713\n",
      "epoch: 1 step: 1297, loss is 0.39444804191589355\n",
      "epoch: 1 step: 1298, loss is 3.3254613876342773\n",
      "epoch: 1 step: 1299, loss is 2.57948899269104\n",
      "epoch: 1 step: 1300, loss is 1.4120185375213623\n",
      "epoch: 1 step: 1301, loss is 0.10399127006530762\n",
      "epoch: 1 step: 1302, loss is 0.2681097984313965\n",
      "epoch: 1 step: 1303, loss is 0.17482270300388336\n",
      "epoch: 1 step: 1304, loss is 0.5732094049453735\n",
      "epoch: 1 step: 1305, loss is 0.662290096282959\n",
      "epoch: 1 step: 1306, loss is 0.46338197588920593\n",
      "epoch: 1 step: 1307, loss is 0.34018024802207947\n",
      "epoch: 1 step: 1308, loss is 2.068406105041504\n",
      "epoch: 1 step: 1309, loss is 0.05587911605834961\n",
      "epoch: 1 step: 1310, loss is 0.21258094906806946\n",
      "epoch: 1 step: 1311, loss is 2.5461299419403076\n",
      "epoch: 1 step: 1312, loss is 0.2497720569372177\n",
      "epoch: 1 step: 1313, loss is 1.8403632640838623\n",
      "epoch: 1 step: 1314, loss is 2.1639227867126465\n",
      "epoch: 1 step: 1315, loss is 0.2445397675037384\n",
      "epoch: 1 step: 1316, loss is 0.3440854251384735\n",
      "epoch: 1 step: 1317, loss is 2.02260684967041\n",
      "epoch: 1 step: 1318, loss is 1.761324405670166\n",
      "epoch: 1 step: 1319, loss is 1.2312816381454468\n",
      "epoch: 1 step: 1320, loss is 0.7718822360038757\n",
      "epoch: 1 step: 1321, loss is 0.4799579083919525\n",
      "epoch: 1 step: 1322, loss is 1.7789196968078613\n",
      "epoch: 1 step: 1323, loss is 0.22857102751731873\n",
      "epoch: 1 step: 1324, loss is 0.08550730347633362\n",
      "epoch: 1 step: 1325, loss is 1.7965909242630005\n",
      "epoch: 1 step: 1326, loss is 0.22385035455226898\n",
      "epoch: 1 step: 1327, loss is 0.0956946313381195\n",
      "epoch: 1 step: 1328, loss is 0.08111483603715897\n",
      "epoch: 1 step: 1329, loss is 1.6617462635040283\n",
      "epoch: 1 step: 1330, loss is 1.8864197731018066\n",
      "epoch: 1 step: 1331, loss is 1.5701067447662354\n",
      "epoch: 1 step: 1332, loss is 0.05794075131416321\n",
      "epoch: 1 step: 1333, loss is 2.4817147254943848\n",
      "epoch: 1 step: 1334, loss is 0.6163039803504944\n",
      "epoch: 1 step: 1335, loss is 0.1026000902056694\n",
      "epoch: 1 step: 1336, loss is 0.20327351987361908\n",
      "epoch: 1 step: 1337, loss is 1.7686775922775269\n",
      "epoch: 1 step: 1338, loss is 0.30382785201072693\n",
      "epoch: 1 step: 1339, loss is 0.015002398751676083\n",
      "epoch: 1 step: 1340, loss is 0.121147021651268\n",
      "epoch: 1 step: 1341, loss is 0.5306644439697266\n",
      "epoch: 1 step: 1342, loss is 2.189032793045044\n",
      "epoch: 1 step: 1343, loss is 0.13109402358531952\n",
      "epoch: 1 step: 1344, loss is 1.8251922130584717\n",
      "epoch: 1 step: 1345, loss is 0.10323098301887512\n",
      "epoch: 1 step: 1346, loss is 0.05169369652867317\n",
      "epoch: 1 step: 1347, loss is 1.8078457117080688\n",
      "epoch: 1 step: 1348, loss is 0.13020683825016022\n",
      "epoch: 1 step: 1349, loss is 0.052972644567489624\n",
      "epoch: 1 step: 1350, loss is 2.145503520965576\n",
      "epoch: 1 step: 1351, loss is 1.8716723918914795\n",
      "epoch: 1 step: 1352, loss is 2.1962122917175293\n",
      "epoch: 1 step: 1353, loss is 1.738684892654419\n",
      "epoch: 1 step: 1354, loss is 0.04150059074163437\n",
      "epoch: 1 step: 1355, loss is 0.03115478903055191\n",
      "epoch: 1 step: 1356, loss is 0.2585946023464203\n",
      "epoch: 1 step: 1357, loss is 0.30733534693717957\n",
      "epoch: 1 step: 1358, loss is 1.9372738599777222\n",
      "epoch: 1 step: 1359, loss is 1.668541431427002\n",
      "epoch: 1 step: 1360, loss is 0.22812001407146454\n",
      "epoch: 1 step: 1361, loss is 0.40538182854652405\n",
      "epoch: 1 step: 1362, loss is 0.27675962448120117\n",
      "epoch: 1 step: 1363, loss is 2.328650951385498\n",
      "epoch: 1 step: 1364, loss is 0.25856882333755493\n",
      "epoch: 1 step: 1365, loss is 0.9859979152679443\n",
      "epoch: 1 step: 1366, loss is 1.935150384902954\n",
      "epoch: 1 step: 1367, loss is 2.0021684169769287\n",
      "epoch: 1 step: 1368, loss is 1.0984208583831787\n",
      "epoch: 1 step: 1369, loss is 1.5152508020401\n",
      "epoch: 1 step: 1370, loss is 2.387308120727539\n",
      "epoch: 1 step: 1371, loss is 1.629455327987671\n",
      "epoch: 1 step: 1372, loss is 3.0117852687835693\n",
      "epoch: 1 step: 1373, loss is 0.5622480511665344\n",
      "epoch: 1 step: 1374, loss is 0.7392104864120483\n",
      "epoch: 1 step: 1375, loss is 3.1742777824401855\n",
      "epoch: 1 step: 1376, loss is 1.2538490295410156\n",
      "epoch: 1 step: 1377, loss is 0.21003539860248566\n",
      "epoch: 1 step: 1378, loss is 0.38078799843788147\n",
      "epoch: 1 step: 1379, loss is 0.175654798746109\n",
      "epoch: 1 step: 1380, loss is 1.5888762474060059\n",
      "epoch: 1 step: 1381, loss is 1.6524863243103027\n",
      "epoch: 1 step: 1382, loss is 0.08799058198928833\n",
      "epoch: 1 step: 1383, loss is 0.6044622659683228\n",
      "epoch: 1 step: 1384, loss is 0.18731984496116638\n",
      "epoch: 1 step: 1385, loss is 0.0937420204281807\n",
      "epoch: 1 step: 1386, loss is 1.4636634588241577\n",
      "epoch: 1 step: 1387, loss is 1.3843774795532227\n",
      "epoch: 1 step: 1388, loss is 1.7349789142608643\n",
      "epoch: 1 step: 1389, loss is 1.0147045850753784\n",
      "epoch: 1 step: 1390, loss is 0.24190470576286316\n",
      "epoch: 1 step: 1391, loss is 0.07296910881996155\n",
      "epoch: 1 step: 1392, loss is 0.037493746727705\n",
      "epoch: 1 step: 1393, loss is 1.9381948709487915\n",
      "epoch: 1 step: 1394, loss is 1.7965636253356934\n",
      "epoch: 1 step: 1395, loss is 2.38165545463562\n",
      "epoch: 1 step: 1396, loss is 1.1111609935760498\n",
      "epoch: 1 step: 1397, loss is 0.37399324774742126\n",
      "epoch: 1 step: 1398, loss is 1.1359885931015015\n",
      "epoch: 1 step: 1399, loss is 1.1896562576293945\n",
      "epoch: 1 step: 1400, loss is 0.05312955752015114\n",
      "epoch: 1 step: 1401, loss is 0.667860209941864\n",
      "epoch: 1 step: 1402, loss is 0.1507653445005417\n",
      "epoch: 1 step: 1403, loss is 0.14284272491931915\n",
      "epoch: 1 step: 1404, loss is 0.11366678029298782\n",
      "epoch: 1 step: 1405, loss is 1.3394595384597778\n",
      "epoch: 1 step: 1406, loss is 1.5313752889633179\n",
      "epoch: 1 step: 1407, loss is 0.11292276531457901\n",
      "epoch: 1 step: 1408, loss is 1.8244379758834839\n",
      "epoch: 1 step: 1409, loss is 2.1497910022735596\n",
      "epoch: 1 step: 1410, loss is 0.5399841666221619\n",
      "epoch: 1 step: 1411, loss is 0.2781163454055786\n",
      "epoch: 1 step: 1412, loss is 0.8511808514595032\n",
      "epoch: 1 step: 1413, loss is 0.14470165967941284\n",
      "epoch: 1 step: 1414, loss is 3.0480711460113525\n",
      "epoch: 1 step: 1415, loss is 0.09646975994110107\n",
      "epoch: 1 step: 1416, loss is 0.22364887595176697\n",
      "epoch: 1 step: 1417, loss is 0.20125611126422882\n",
      "epoch: 1 step: 1418, loss is 2.1478140354156494\n",
      "epoch: 1 step: 1419, loss is 0.08296255022287369\n",
      "epoch: 1 step: 1420, loss is 1.2618443965911865\n",
      "epoch: 1 step: 1421, loss is 0.0031512149143964052\n",
      "epoch: 1 step: 1422, loss is 1.8336880207061768\n",
      "epoch: 1 step: 1423, loss is 1.386269211769104\n",
      "epoch: 1 step: 1424, loss is 0.19903524219989777\n",
      "epoch: 1 step: 1425, loss is 0.6300380825996399\n",
      "epoch: 1 step: 1426, loss is 1.168592095375061\n",
      "epoch: 1 step: 1427, loss is 0.054366253316402435\n",
      "epoch: 1 step: 1428, loss is 2.1613411903381348\n",
      "epoch: 1 step: 1429, loss is 1.562657356262207\n",
      "epoch: 1 step: 1430, loss is 1.4780616760253906\n",
      "epoch: 1 step: 1431, loss is 2.0475921630859375\n",
      "epoch: 1 step: 1432, loss is 0.22584538161754608\n",
      "epoch: 1 step: 1433, loss is 0.1532958596944809\n",
      "epoch: 1 step: 1434, loss is 0.03295474871993065\n",
      "epoch: 1 step: 1435, loss is 0.41598832607269287\n",
      "epoch: 1 step: 1436, loss is 0.08292480558156967\n",
      "epoch: 1 step: 1437, loss is 0.06640364974737167\n",
      "epoch: 1 step: 1438, loss is 2.1033847332000732\n",
      "epoch: 1 step: 1439, loss is 0.46842995285987854\n",
      "epoch: 1 step: 1440, loss is 6.431336879730225\n",
      "epoch: 1 step: 1441, loss is 1.350663423538208\n",
      "epoch: 1 step: 1442, loss is 0.6482876539230347\n",
      "epoch: 1 step: 1443, loss is 0.32772257924079895\n",
      "epoch: 1 step: 1444, loss is 0.7601107954978943\n",
      "epoch: 1 step: 1445, loss is 2.023348331451416\n",
      "epoch: 1 step: 1446, loss is 0.7589401006698608\n",
      "epoch: 1 step: 1447, loss is 0.2077593058347702\n",
      "epoch: 1 step: 1448, loss is 1.6608198881149292\n",
      "epoch: 1 step: 1449, loss is 0.44438818097114563\n",
      "epoch: 1 step: 1450, loss is 0.5196803212165833\n",
      "epoch: 1 step: 1451, loss is 0.4209827482700348\n",
      "epoch: 1 step: 1452, loss is 0.012762182392179966\n",
      "epoch: 1 step: 1453, loss is 0.06220277398824692\n",
      "epoch: 1 step: 1454, loss is 0.2973140478134155\n",
      "epoch: 1 step: 1455, loss is 0.3917591869831085\n",
      "epoch: 1 step: 1456, loss is 2.1941213607788086\n",
      "epoch: 1 step: 1457, loss is 2.3410098552703857\n",
      "epoch: 1 step: 1458, loss is 0.04160499945282936\n",
      "epoch: 1 step: 1459, loss is 3.5071897506713867\n",
      "epoch: 1 step: 1460, loss is 2.1547372341156006\n",
      "epoch: 1 step: 1461, loss is 0.42341428995132446\n",
      "epoch: 1 step: 1462, loss is 1.832484483718872\n",
      "epoch: 1 step: 1463, loss is 0.3861565887928009\n",
      "epoch: 1 step: 1464, loss is 0.13161523640155792\n",
      "epoch: 1 step: 1465, loss is 0.01730743981897831\n",
      "epoch: 1 step: 1466, loss is 0.08521495014429092\n",
      "epoch: 1 step: 1467, loss is 0.6014807224273682\n",
      "epoch: 1 step: 1468, loss is 0.03557460010051727\n",
      "epoch: 1 step: 1469, loss is 0.007703477516770363\n",
      "epoch: 1 step: 1470, loss is 2.907353401184082\n",
      "epoch: 1 step: 1471, loss is 1.8084396123886108\n",
      "epoch: 1 step: 1472, loss is 1.6946055889129639\n",
      "epoch: 1 step: 1473, loss is 0.3746275007724762\n",
      "epoch: 1 step: 1474, loss is 0.03260323032736778\n",
      "epoch: 1 step: 1475, loss is 0.2595793902873993\n",
      "epoch: 1 step: 1476, loss is 1.8640726804733276\n",
      "epoch: 1 step: 1477, loss is 1.7894108295440674\n",
      "epoch: 1 step: 1478, loss is 1.078359842300415\n",
      "epoch: 1 step: 1479, loss is 0.9106932282447815\n",
      "epoch: 1 step: 1480, loss is 1.3000847101211548\n",
      "epoch: 1 step: 1481, loss is 0.06760432571172714\n",
      "epoch: 1 step: 1482, loss is 0.09048871695995331\n",
      "epoch: 1 step: 1483, loss is 0.24571098387241364\n",
      "epoch: 1 step: 1484, loss is 0.499176025390625\n",
      "epoch: 1 step: 1485, loss is 1.6541533470153809\n",
      "epoch: 1 step: 1486, loss is 4.516770839691162\n",
      "epoch: 1 step: 1487, loss is 1.9951761960983276\n",
      "epoch: 1 step: 1488, loss is 0.5227959156036377\n",
      "epoch: 1 step: 1489, loss is 1.305727481842041\n",
      "epoch: 1 step: 1490, loss is 0.15642818808555603\n",
      "epoch: 1 step: 1491, loss is 1.644284963607788\n",
      "epoch: 1 step: 1492, loss is 2.072772741317749\n",
      "epoch: 1 step: 1493, loss is 0.3810145854949951\n",
      "epoch: 1 step: 1494, loss is 0.20208998024463654\n",
      "epoch: 1 step: 1495, loss is 0.43289390206336975\n",
      "epoch: 1 step: 1496, loss is 2.03820538520813\n",
      "epoch: 1 step: 1497, loss is 0.2648170292377472\n",
      "epoch: 1 step: 1498, loss is 1.3372220993041992\n",
      "epoch: 1 step: 1499, loss is 0.7642213702201843\n",
      "epoch: 1 step: 1500, loss is 0.21339677274227142\n",
      "epoch: 1 step: 1501, loss is 0.07502570003271103\n",
      "epoch: 1 step: 1502, loss is 0.27881306409835815\n",
      "epoch: 1 step: 1503, loss is 1.9373753070831299\n",
      "epoch: 1 step: 1504, loss is 0.59984290599823\n",
      "epoch: 1 step: 1505, loss is 0.9300750494003296\n",
      "epoch: 1 step: 1506, loss is 0.1978742629289627\n",
      "epoch: 1 step: 1507, loss is 0.11267793923616409\n",
      "epoch: 1 step: 1508, loss is 0.13947266340255737\n",
      "epoch: 1 step: 1509, loss is 2.014451026916504\n",
      "epoch: 1 step: 1510, loss is 0.3644666373729706\n",
      "epoch: 1 step: 1511, loss is 1.6515849828720093\n",
      "epoch: 1 step: 1512, loss is 1.733985185623169\n",
      "epoch: 1 step: 1513, loss is 1.813195824623108\n",
      "epoch: 1 step: 1514, loss is 2.60304594039917\n",
      "epoch: 1 step: 1515, loss is 2.3814313411712646\n",
      "epoch: 1 step: 1516, loss is 0.2479032427072525\n",
      "epoch: 1 step: 1517, loss is 2.1893630027770996\n",
      "epoch: 1 step: 1518, loss is 1.9393362998962402\n",
      "epoch: 1 step: 1519, loss is 0.08059950172901154\n",
      "epoch: 1 step: 1520, loss is 0.159683957695961\n",
      "epoch: 1 step: 1521, loss is 1.7013691663742065\n",
      "epoch: 1 step: 1522, loss is 1.5954008102416992\n",
      "epoch: 1 step: 1523, loss is 0.5001603960990906\n",
      "epoch: 1 step: 1524, loss is 0.20633000135421753\n",
      "epoch: 1 step: 1525, loss is 0.1480863392353058\n",
      "epoch: 1 step: 1526, loss is 2.372666358947754\n",
      "epoch: 1 step: 1527, loss is 1.8004951477050781\n",
      "epoch: 1 step: 1528, loss is 0.5026308298110962\n",
      "epoch: 1 step: 1529, loss is 1.6509382724761963\n",
      "epoch: 1 step: 1530, loss is 2.484250545501709\n",
      "epoch: 1 step: 1531, loss is 0.06552380323410034\n",
      "epoch: 1 step: 1532, loss is 3.540781259536743\n",
      "epoch: 1 step: 1533, loss is 1.1650745868682861\n",
      "epoch: 1 step: 1534, loss is 1.014099359512329\n",
      "epoch: 1 step: 1535, loss is 1.1548495292663574\n",
      "epoch: 1 step: 1536, loss is 1.254758596420288\n",
      "epoch: 1 step: 1537, loss is 0.5196093320846558\n",
      "epoch: 1 step: 1538, loss is 3.4707837104797363\n",
      "epoch: 1 step: 1539, loss is 1.319138765335083\n",
      "epoch: 1 step: 1540, loss is 0.1289568841457367\n",
      "epoch: 1 step: 1541, loss is 2.1785383224487305\n",
      "epoch: 1 step: 1542, loss is 0.43271535634994507\n",
      "epoch: 1 step: 1543, loss is 0.6761156916618347\n",
      "epoch: 1 step: 1544, loss is 0.5915866494178772\n",
      "epoch: 1 step: 1545, loss is 0.2725643813610077\n",
      "epoch: 1 step: 1546, loss is 0.25780096650123596\n",
      "epoch: 1 step: 1547, loss is 0.042747173458337784\n",
      "epoch: 1 step: 1548, loss is 0.7340240478515625\n",
      "epoch: 1 step: 1549, loss is 1.6607236862182617\n",
      "epoch: 1 step: 1550, loss is 1.7800214290618896\n",
      "epoch: 1 step: 1551, loss is 0.41886746883392334\n",
      "epoch: 1 step: 1552, loss is 1.8137589693069458\n",
      "epoch: 1 step: 1553, loss is 2.0108747482299805\n",
      "epoch: 1 step: 1554, loss is 0.16824883222579956\n",
      "epoch: 1 step: 1555, loss is 1.8129334449768066\n",
      "epoch: 1 step: 1556, loss is 0.24761730432510376\n",
      "epoch: 1 step: 1557, loss is 0.5589249134063721\n",
      "epoch: 1 step: 1558, loss is 2.5451395511627197\n",
      "epoch: 1 step: 1559, loss is 1.9262970685958862\n",
      "epoch: 1 step: 1560, loss is 2.1637628078460693\n",
      "epoch: 1 step: 1561, loss is 0.5996465086936951\n",
      "epoch: 1 step: 1562, loss is 0.4810642600059509\n",
      "epoch: 1 step: 1563, loss is 3.4685544967651367\n",
      "epoch: 1 step: 1564, loss is 1.207914113998413\n",
      "epoch: 1 step: 1565, loss is 1.9550087451934814\n",
      "epoch: 1 step: 1566, loss is 0.2898428738117218\n",
      "epoch: 1 step: 1567, loss is 1.4250361919403076\n",
      "epoch: 1 step: 1568, loss is 0.18879590928554535\n",
      "epoch: 1 step: 1569, loss is 0.19576731324195862\n",
      "epoch: 1 step: 1570, loss is 1.7205541133880615\n",
      "epoch: 1 step: 1571, loss is 0.262513130903244\n",
      "epoch: 1 step: 1572, loss is 0.4067156910896301\n",
      "epoch: 1 step: 1573, loss is 0.14248551428318024\n",
      "epoch: 1 step: 1574, loss is 2.0572762489318848\n",
      "epoch: 1 step: 1575, loss is 0.3315446674823761\n",
      "epoch: 1 step: 1576, loss is 0.18890339136123657\n",
      "epoch: 1 step: 1577, loss is 1.64967679977417\n",
      "epoch: 1 step: 1578, loss is 0.4978578984737396\n",
      "epoch: 1 step: 1579, loss is 0.2419503778219223\n",
      "epoch: 1 step: 1580, loss is 2.835599899291992\n",
      "epoch: 1 step: 1581, loss is 3.0056869983673096\n",
      "epoch: 1 step: 1582, loss is 1.9408475160598755\n",
      "epoch: 1 step: 1583, loss is 0.6306278705596924\n",
      "epoch: 1 step: 1584, loss is 0.2115684449672699\n",
      "epoch: 1 step: 1585, loss is 0.34558507800102234\n",
      "epoch: 1 step: 1586, loss is 0.058124441653490067\n",
      "epoch: 1 step: 1587, loss is 1.6463000774383545\n",
      "epoch: 1 step: 1588, loss is 0.07475891709327698\n",
      "epoch: 1 step: 1589, loss is 2.2868492603302\n",
      "epoch: 1 step: 1590, loss is 1.7541087865829468\n",
      "epoch: 1 step: 1591, loss is 1.6491882801055908\n",
      "epoch: 1 step: 1592, loss is 3.801459312438965\n",
      "epoch: 1 step: 1593, loss is 0.9351033568382263\n",
      "epoch: 1 step: 1594, loss is 0.2523439824581146\n",
      "epoch: 1 step: 1595, loss is 0.7505340576171875\n",
      "epoch: 1 step: 1596, loss is 0.24710068106651306\n",
      "epoch: 1 step: 1597, loss is 0.29632145166397095\n",
      "epoch: 1 step: 1598, loss is 1.8579766750335693\n",
      "epoch: 1 step: 1599, loss is 1.5188626050949097\n",
      "epoch: 1 step: 1600, loss is 2.018986225128174\n",
      "epoch: 2 step: 1, loss is 0.77345210313797\n",
      "epoch: 2 step: 2, loss is 0.3528914451599121\n",
      "epoch: 2 step: 3, loss is 0.2855784595012665\n",
      "epoch: 2 step: 4, loss is 0.7926532030105591\n",
      "epoch: 2 step: 5, loss is 0.09196621179580688\n",
      "epoch: 2 step: 6, loss is 0.13595356047153473\n",
      "epoch: 2 step: 7, loss is 2.0207605361938477\n",
      "epoch: 2 step: 8, loss is 1.376450777053833\n",
      "epoch: 2 step: 9, loss is 0.42495444416999817\n",
      "epoch: 2 step: 10, loss is 0.03667806088924408\n",
      "epoch: 2 step: 11, loss is 0.03153488412499428\n",
      "epoch: 2 step: 12, loss is 3.160750150680542\n",
      "epoch: 2 step: 13, loss is 0.10007575899362564\n",
      "epoch: 2 step: 14, loss is 5.53875732421875\n",
      "epoch: 2 step: 15, loss is 1.435313105583191\n",
      "epoch: 2 step: 16, loss is 0.16003172099590302\n",
      "epoch: 2 step: 17, loss is 1.7980034351348877\n",
      "epoch: 2 step: 18, loss is 0.9048402905464172\n",
      "epoch: 2 step: 19, loss is 1.5636754035949707\n",
      "epoch: 2 step: 20, loss is 2.236058473587036\n",
      "epoch: 2 step: 21, loss is 1.0769520998001099\n",
      "epoch: 2 step: 22, loss is 1.7391692399978638\n",
      "epoch: 2 step: 23, loss is 1.234447956085205\n",
      "epoch: 2 step: 24, loss is 0.7959513664245605\n",
      "epoch: 2 step: 25, loss is 0.9535598754882812\n",
      "epoch: 2 step: 26, loss is 0.025157107040286064\n",
      "epoch: 2 step: 27, loss is 0.5363132357597351\n",
      "epoch: 2 step: 28, loss is 2.704536199569702\n",
      "epoch: 2 step: 29, loss is 0.34455057978630066\n",
      "epoch: 2 step: 30, loss is 2.274930238723755\n",
      "epoch: 2 step: 31, loss is 1.5634970664978027\n",
      "epoch: 2 step: 32, loss is 1.810404896736145\n",
      "epoch: 2 step: 33, loss is 1.1208964586257935\n",
      "epoch: 2 step: 34, loss is 0.17259013652801514\n",
      "epoch: 2 step: 35, loss is 0.5336407423019409\n",
      "epoch: 2 step: 36, loss is 0.1751578450202942\n",
      "epoch: 2 step: 37, loss is 0.683445155620575\n",
      "epoch: 2 step: 38, loss is 1.5642626285552979\n",
      "epoch: 2 step: 39, loss is 0.443807989358902\n",
      "epoch: 2 step: 40, loss is 0.1987973302602768\n",
      "epoch: 2 step: 41, loss is 1.8288253545761108\n",
      "epoch: 2 step: 42, loss is 0.15185029804706573\n",
      "epoch: 2 step: 43, loss is 1.8121564388275146\n",
      "epoch: 2 step: 44, loss is 0.1745363026857376\n",
      "epoch: 2 step: 45, loss is 0.10602006316184998\n",
      "epoch: 2 step: 46, loss is 1.830101728439331\n",
      "epoch: 2 step: 47, loss is 0.42176494002342224\n",
      "epoch: 2 step: 48, loss is 0.1518765091896057\n",
      "epoch: 2 step: 49, loss is 2.755500316619873\n",
      "epoch: 2 step: 50, loss is 0.10327925533056259\n",
      "epoch: 2 step: 51, loss is 0.33758509159088135\n",
      "epoch: 2 step: 52, loss is 1.909818172454834\n",
      "epoch: 2 step: 53, loss is 0.025409100577235222\n",
      "epoch: 2 step: 54, loss is 1.6779780387878418\n",
      "epoch: 2 step: 55, loss is 0.1775577962398529\n",
      "epoch: 2 step: 56, loss is 1.9117448329925537\n",
      "epoch: 2 step: 57, loss is 0.0432741641998291\n",
      "epoch: 2 step: 58, loss is 1.8075954914093018\n",
      "epoch: 2 step: 59, loss is 3.4165303707122803\n",
      "epoch: 2 step: 60, loss is 2.1542155742645264\n",
      "epoch: 2 step: 61, loss is 0.5419644713401794\n",
      "epoch: 2 step: 62, loss is 0.11178000271320343\n",
      "epoch: 2 step: 63, loss is 0.16092625260353088\n",
      "epoch: 2 step: 64, loss is 0.9817066788673401\n",
      "epoch: 2 step: 65, loss is 1.79296875\n",
      "epoch: 2 step: 66, loss is 2.724409818649292\n",
      "epoch: 2 step: 67, loss is 1.6765245199203491\n",
      "epoch: 2 step: 68, loss is 1.2363080978393555\n",
      "epoch: 2 step: 69, loss is 1.7751493453979492\n",
      "epoch: 2 step: 70, loss is 0.4434034526348114\n",
      "epoch: 2 step: 71, loss is 2.073604106903076\n",
      "epoch: 2 step: 72, loss is 0.18118169903755188\n",
      "epoch: 2 step: 73, loss is 1.5663124322891235\n",
      "epoch: 2 step: 74, loss is 2.6541647911071777\n",
      "epoch: 2 step: 75, loss is 2.0976123809814453\n",
      "epoch: 2 step: 76, loss is 1.9155962467193604\n",
      "epoch: 2 step: 77, loss is 0.35524752736091614\n",
      "epoch: 2 step: 78, loss is 0.07955162972211838\n",
      "epoch: 2 step: 79, loss is 2.1855928897857666\n",
      "epoch: 2 step: 80, loss is 1.6495282649993896\n",
      "epoch: 2 step: 81, loss is 0.9228785037994385\n",
      "epoch: 2 step: 82, loss is 0.345109760761261\n",
      "epoch: 2 step: 83, loss is 0.3014949560165405\n",
      "epoch: 2 step: 84, loss is 0.05600063130259514\n",
      "epoch: 2 step: 85, loss is 2.301400899887085\n",
      "epoch: 2 step: 86, loss is 0.18902970850467682\n",
      "epoch: 2 step: 87, loss is 1.7207777500152588\n",
      "epoch: 2 step: 88, loss is 0.34782901406288147\n",
      "epoch: 2 step: 89, loss is 0.11174812912940979\n",
      "epoch: 2 step: 90, loss is 1.1939891576766968\n",
      "epoch: 2 step: 91, loss is 0.03736364468932152\n",
      "epoch: 2 step: 92, loss is 1.7916805744171143\n",
      "epoch: 2 step: 93, loss is 0.4397958815097809\n",
      "epoch: 2 step: 94, loss is 1.0382540225982666\n",
      "epoch: 2 step: 95, loss is 1.8027029037475586\n",
      "epoch: 2 step: 96, loss is 0.4281839430332184\n",
      "epoch: 2 step: 97, loss is 1.9178074598312378\n",
      "epoch: 2 step: 98, loss is 0.34969162940979004\n",
      "epoch: 2 step: 99, loss is 0.06359745562076569\n",
      "epoch: 2 step: 100, loss is 0.13573075830936432\n",
      "epoch: 2 step: 101, loss is 1.9538838863372803\n",
      "epoch: 2 step: 102, loss is 0.020226063206791878\n",
      "epoch: 2 step: 103, loss is 0.3752281963825226\n",
      "epoch: 2 step: 104, loss is 2.8358707427978516\n",
      "epoch: 2 step: 105, loss is 0.40039604902267456\n",
      "epoch: 2 step: 106, loss is 0.43611785769462585\n",
      "epoch: 2 step: 107, loss is 0.15257246792316437\n",
      "epoch: 2 step: 108, loss is 0.0922812819480896\n",
      "epoch: 2 step: 109, loss is 0.0120955565944314\n",
      "epoch: 2 step: 110, loss is 0.1687602996826172\n",
      "epoch: 2 step: 111, loss is 4.296035289764404\n",
      "epoch: 2 step: 112, loss is 0.5197352766990662\n",
      "epoch: 2 step: 113, loss is 1.758284568786621\n",
      "epoch: 2 step: 114, loss is 2.2784876823425293\n",
      "epoch: 2 step: 115, loss is 1.6393837928771973\n",
      "epoch: 2 step: 116, loss is 0.10775826126337051\n",
      "epoch: 2 step: 117, loss is 0.1990397423505783\n",
      "epoch: 2 step: 118, loss is 0.4769192337989807\n",
      "epoch: 2 step: 119, loss is 1.7700772285461426\n",
      "epoch: 2 step: 120, loss is 2.316053867340088\n",
      "epoch: 2 step: 121, loss is 2.639606475830078\n",
      "epoch: 2 step: 122, loss is 0.32679522037506104\n",
      "epoch: 2 step: 123, loss is 0.164626806974411\n",
      "epoch: 2 step: 124, loss is 0.3843686878681183\n",
      "epoch: 2 step: 125, loss is 0.3479759991168976\n",
      "epoch: 2 step: 126, loss is 0.06162435933947563\n",
      "epoch: 2 step: 127, loss is 0.10427292436361313\n",
      "epoch: 2 step: 128, loss is 1.9391933679580688\n",
      "epoch: 2 step: 129, loss is 0.1161857321858406\n",
      "epoch: 2 step: 130, loss is 1.6499640941619873\n",
      "epoch: 2 step: 131, loss is 0.07185406982898712\n",
      "epoch: 2 step: 132, loss is 0.24537992477416992\n",
      "epoch: 2 step: 133, loss is 0.2582760751247406\n",
      "epoch: 2 step: 134, loss is 0.04200160503387451\n",
      "epoch: 2 step: 135, loss is 0.3885849416255951\n",
      "epoch: 2 step: 136, loss is 0.18949298560619354\n",
      "epoch: 2 step: 137, loss is 3.916566848754883\n",
      "epoch: 2 step: 138, loss is 0.05588306114077568\n",
      "epoch: 2 step: 139, loss is 0.08952157944440842\n",
      "epoch: 2 step: 140, loss is 0.19205893576145172\n",
      "epoch: 2 step: 141, loss is 0.44634005427360535\n",
      "epoch: 2 step: 142, loss is 1.9686354398727417\n",
      "epoch: 2 step: 143, loss is 0.034536488354206085\n",
      "epoch: 2 step: 144, loss is 0.5334367752075195\n",
      "epoch: 2 step: 145, loss is 1.7917540073394775\n",
      "epoch: 2 step: 146, loss is 0.24486148357391357\n",
      "epoch: 2 step: 147, loss is 0.20625056326389313\n",
      "epoch: 2 step: 148, loss is 2.8798656463623047\n",
      "epoch: 2 step: 149, loss is 0.025807999074459076\n",
      "epoch: 2 step: 150, loss is 0.2953268885612488\n",
      "epoch: 2 step: 151, loss is 1.8841133117675781\n",
      "epoch: 2 step: 152, loss is 0.6286988258361816\n",
      "epoch: 2 step: 153, loss is 0.38226333260536194\n",
      "epoch: 2 step: 154, loss is 0.22590510547161102\n",
      "epoch: 2 step: 155, loss is 0.20871597528457642\n",
      "epoch: 2 step: 156, loss is 0.061681631952524185\n",
      "epoch: 2 step: 157, loss is 3.393580675125122\n",
      "epoch: 2 step: 158, loss is 1.7931463718414307\n",
      "epoch: 2 step: 159, loss is 0.6001270413398743\n",
      "epoch: 2 step: 160, loss is 0.3014111816883087\n",
      "epoch: 2 step: 161, loss is 1.5751197338104248\n",
      "epoch: 2 step: 162, loss is 0.22058548033237457\n",
      "epoch: 2 step: 163, loss is 0.03182673454284668\n",
      "epoch: 2 step: 164, loss is 1.568382740020752\n",
      "epoch: 2 step: 165, loss is 0.0089132534340024\n",
      "epoch: 2 step: 166, loss is 0.02716408483684063\n",
      "epoch: 2 step: 167, loss is 0.23193760216236115\n",
      "epoch: 2 step: 168, loss is 1.6574820280075073\n",
      "epoch: 2 step: 169, loss is 1.6745920181274414\n",
      "epoch: 2 step: 170, loss is 4.346945285797119\n",
      "epoch: 2 step: 171, loss is 0.1381923109292984\n",
      "epoch: 2 step: 172, loss is 1.9402281045913696\n",
      "epoch: 2 step: 173, loss is 0.057870324701070786\n",
      "epoch: 2 step: 174, loss is 0.14559701085090637\n",
      "epoch: 2 step: 175, loss is 1.0593565702438354\n",
      "epoch: 2 step: 176, loss is 0.09132827818393707\n",
      "epoch: 2 step: 177, loss is 1.1694625616073608\n",
      "epoch: 2 step: 178, loss is 0.5766527056694031\n",
      "epoch: 2 step: 179, loss is 1.0797590017318726\n",
      "epoch: 2 step: 180, loss is 1.9016492366790771\n",
      "epoch: 2 step: 181, loss is 0.09636973589658737\n",
      "epoch: 2 step: 182, loss is 0.06623653322458267\n",
      "epoch: 2 step: 183, loss is 2.068401336669922\n",
      "epoch: 2 step: 184, loss is 1.798515796661377\n",
      "epoch: 2 step: 185, loss is 0.1800137311220169\n",
      "epoch: 2 step: 186, loss is 0.9082812666893005\n",
      "epoch: 2 step: 187, loss is 0.2791648805141449\n",
      "epoch: 2 step: 188, loss is 1.9406063556671143\n",
      "epoch: 2 step: 189, loss is 0.2656067907810211\n",
      "epoch: 2 step: 190, loss is 1.635911464691162\n",
      "epoch: 2 step: 191, loss is 0.07794087380170822\n",
      "epoch: 2 step: 192, loss is 0.14624327421188354\n",
      "epoch: 2 step: 193, loss is 0.08531773835420609\n",
      "epoch: 2 step: 194, loss is 0.016227660700678825\n",
      "epoch: 2 step: 195, loss is 0.01800900511443615\n",
      "epoch: 2 step: 196, loss is 0.3163282573223114\n",
      "epoch: 2 step: 197, loss is 0.03181818872690201\n",
      "epoch: 2 step: 198, loss is 1.775181770324707\n",
      "epoch: 2 step: 199, loss is 1.6515660285949707\n",
      "epoch: 2 step: 200, loss is 0.12800633907318115\n",
      "epoch: 2 step: 201, loss is 0.08782997727394104\n",
      "epoch: 2 step: 202, loss is 0.039552345871925354\n",
      "epoch: 2 step: 203, loss is 1.0238542556762695\n",
      "epoch: 2 step: 204, loss is 0.00818351935595274\n",
      "epoch: 2 step: 205, loss is 3.899688959121704\n",
      "epoch: 2 step: 206, loss is 0.2458825260400772\n",
      "epoch: 2 step: 207, loss is 0.49185341596603394\n",
      "epoch: 2 step: 208, loss is 0.4255003333091736\n",
      "epoch: 2 step: 209, loss is 0.024038642644882202\n",
      "epoch: 2 step: 210, loss is 0.19903749227523804\n",
      "epoch: 2 step: 211, loss is 0.2457401603460312\n",
      "epoch: 2 step: 212, loss is 0.19631123542785645\n",
      "epoch: 2 step: 213, loss is 0.043642036616802216\n",
      "epoch: 2 step: 214, loss is 1.5650532245635986\n",
      "epoch: 2 step: 215, loss is 0.02714088186621666\n",
      "epoch: 2 step: 216, loss is 2.4218225479125977\n",
      "epoch: 2 step: 217, loss is 1.956674575805664\n",
      "epoch: 2 step: 218, loss is 0.17867888510227203\n",
      "epoch: 2 step: 219, loss is 1.5628879070281982\n",
      "epoch: 2 step: 220, loss is 1.2382361888885498\n",
      "epoch: 2 step: 221, loss is 1.3780956268310547\n",
      "epoch: 2 step: 222, loss is 1.4566805362701416\n",
      "epoch: 2 step: 223, loss is 0.00860033929347992\n",
      "epoch: 2 step: 224, loss is 0.3800135850906372\n",
      "epoch: 2 step: 225, loss is 0.23037414252758026\n",
      "epoch: 2 step: 226, loss is 1.691323161125183\n",
      "epoch: 2 step: 227, loss is 1.6518807411193848\n",
      "epoch: 2 step: 228, loss is 2.4268712997436523\n",
      "epoch: 2 step: 229, loss is 0.6864408850669861\n",
      "epoch: 2 step: 230, loss is 0.025152457877993584\n",
      "epoch: 2 step: 231, loss is 1.8713691234588623\n",
      "epoch: 2 step: 232, loss is 0.4454461336135864\n",
      "epoch: 2 step: 233, loss is 0.01868784800171852\n",
      "epoch: 2 step: 234, loss is 2.2140042781829834\n",
      "epoch: 2 step: 235, loss is 0.35881307721138\n",
      "epoch: 2 step: 236, loss is 1.6829917430877686\n",
      "epoch: 2 step: 237, loss is 0.04733265936374664\n",
      "epoch: 2 step: 238, loss is 1.6591283082962036\n",
      "epoch: 2 step: 239, loss is 1.7022018432617188\n",
      "epoch: 2 step: 240, loss is 5.343010902404785\n",
      "epoch: 2 step: 241, loss is 0.8699193000793457\n",
      "epoch: 2 step: 242, loss is 1.486371636390686\n",
      "epoch: 2 step: 243, loss is 1.1685574054718018\n",
      "epoch: 2 step: 244, loss is 0.40380632877349854\n",
      "epoch: 2 step: 245, loss is 2.236599922180176\n",
      "epoch: 2 step: 246, loss is 0.07578220218420029\n",
      "epoch: 2 step: 247, loss is 1.4698892831802368\n",
      "epoch: 2 step: 248, loss is 0.24805301427841187\n",
      "epoch: 2 step: 249, loss is 1.959609031677246\n",
      "epoch: 2 step: 250, loss is 1.8101145029067993\n",
      "epoch: 2 step: 251, loss is 1.649336814880371\n",
      "epoch: 2 step: 252, loss is 0.7057235240936279\n",
      "epoch: 2 step: 253, loss is 0.5582026839256287\n",
      "epoch: 2 step: 254, loss is 0.5081969499588013\n",
      "epoch: 2 step: 255, loss is 0.4413602948188782\n",
      "epoch: 2 step: 256, loss is 3.155421495437622\n",
      "epoch: 2 step: 257, loss is 0.050875015556812286\n",
      "epoch: 2 step: 258, loss is 1.5653984546661377\n",
      "epoch: 2 step: 259, loss is 0.4921508729457855\n",
      "epoch: 2 step: 260, loss is 0.2711859345436096\n",
      "epoch: 2 step: 261, loss is 2.385561466217041\n",
      "epoch: 2 step: 262, loss is 0.06964684277772903\n",
      "epoch: 2 step: 263, loss is 0.055853527039289474\n",
      "epoch: 2 step: 264, loss is 3.4578723907470703\n",
      "epoch: 2 step: 265, loss is 1.1520357131958008\n",
      "epoch: 2 step: 266, loss is 0.793954074382782\n",
      "epoch: 2 step: 267, loss is 1.2302839756011963\n",
      "epoch: 2 step: 268, loss is 0.037649087607860565\n",
      "epoch: 2 step: 269, loss is 0.04689346253871918\n",
      "epoch: 2 step: 270, loss is 0.12282878160476685\n",
      "epoch: 2 step: 271, loss is 0.07671590149402618\n",
      "epoch: 2 step: 272, loss is 1.0433993339538574\n",
      "epoch: 2 step: 273, loss is 1.6484217643737793\n",
      "epoch: 2 step: 274, loss is 0.24585045874118805\n",
      "epoch: 2 step: 275, loss is 0.0202538650482893\n",
      "epoch: 2 step: 276, loss is 0.05682177469134331\n",
      "epoch: 2 step: 277, loss is 0.22208470106124878\n",
      "epoch: 2 step: 278, loss is 0.10199980437755585\n",
      "epoch: 2 step: 279, loss is 0.6140474677085876\n",
      "epoch: 2 step: 280, loss is 2.5555107593536377\n",
      "epoch: 2 step: 281, loss is 1.7036962509155273\n",
      "epoch: 2 step: 282, loss is 1.5255248546600342\n",
      "epoch: 2 step: 283, loss is 1.941394329071045\n",
      "epoch: 2 step: 284, loss is 0.09984837472438812\n",
      "epoch: 2 step: 285, loss is 1.9604768753051758\n",
      "epoch: 2 step: 286, loss is 0.02565266378223896\n",
      "epoch: 2 step: 287, loss is 0.8333590030670166\n",
      "epoch: 2 step: 288, loss is 0.015347125940024853\n",
      "epoch: 2 step: 289, loss is 0.22771236300468445\n",
      "epoch: 2 step: 290, loss is 0.0939335823059082\n",
      "epoch: 2 step: 291, loss is 0.09393748641014099\n",
      "epoch: 2 step: 292, loss is 0.5742953419685364\n",
      "epoch: 2 step: 293, loss is 1.3850160837173462\n",
      "epoch: 2 step: 294, loss is 0.011590758338570595\n",
      "epoch: 2 step: 295, loss is 0.11108578741550446\n",
      "epoch: 2 step: 296, loss is 0.0019442004850134254\n",
      "epoch: 2 step: 297, loss is 0.014881785959005356\n",
      "epoch: 2 step: 298, loss is 3.4000165462493896\n",
      "epoch: 2 step: 299, loss is 0.10192153602838516\n",
      "epoch: 2 step: 300, loss is 0.21449439227581024\n",
      "epoch: 2 step: 301, loss is 1.6809980869293213\n",
      "epoch: 2 step: 302, loss is 0.6471185684204102\n",
      "epoch: 2 step: 303, loss is 1.0993393659591675\n",
      "epoch: 2 step: 304, loss is 0.014502591453492641\n",
      "epoch: 2 step: 305, loss is 0.7809678912162781\n",
      "epoch: 2 step: 306, loss is 1.6034209728240967\n",
      "epoch: 2 step: 307, loss is 2.0553054809570312\n",
      "epoch: 2 step: 308, loss is 2.175509452819824\n",
      "epoch: 2 step: 309, loss is 3.6907706260681152\n",
      "epoch: 2 step: 310, loss is 1.23866605758667\n",
      "epoch: 2 step: 311, loss is 1.7634607553482056\n",
      "epoch: 2 step: 312, loss is 1.0953296422958374\n",
      "epoch: 2 step: 313, loss is 1.7946481704711914\n",
      "epoch: 2 step: 314, loss is 1.239243745803833\n",
      "epoch: 2 step: 315, loss is 1.8081287145614624\n",
      "epoch: 2 step: 316, loss is 1.1619846820831299\n",
      "epoch: 2 step: 317, loss is 0.2560909688472748\n",
      "epoch: 2 step: 318, loss is 2.8020243644714355\n",
      "epoch: 2 step: 319, loss is 1.8058245182037354\n",
      "epoch: 2 step: 320, loss is 0.970366358757019\n",
      "epoch: 2 step: 321, loss is 1.2392817735671997\n",
      "epoch: 2 step: 322, loss is 1.914413332939148\n",
      "epoch: 2 step: 323, loss is 1.3015038967132568\n",
      "epoch: 2 step: 324, loss is 1.38137948513031\n",
      "epoch: 2 step: 325, loss is 0.27382782101631165\n",
      "epoch: 2 step: 326, loss is 0.09304450452327728\n",
      "epoch: 2 step: 327, loss is 0.2329263985157013\n",
      "epoch: 2 step: 328, loss is 0.29029715061187744\n",
      "epoch: 2 step: 329, loss is 0.1336837112903595\n",
      "epoch: 2 step: 330, loss is 1.1489336490631104\n",
      "epoch: 2 step: 331, loss is 0.7678970098495483\n",
      "epoch: 2 step: 332, loss is 0.34408169984817505\n",
      "epoch: 2 step: 333, loss is 1.7198798656463623\n",
      "epoch: 2 step: 334, loss is 0.02005794085562229\n",
      "epoch: 2 step: 335, loss is 0.22221261262893677\n",
      "epoch: 2 step: 336, loss is 1.6718311309814453\n",
      "epoch: 2 step: 337, loss is 1.6243183612823486\n",
      "epoch: 2 step: 338, loss is 0.7501400113105774\n",
      "epoch: 2 step: 339, loss is 0.13417866826057434\n",
      "epoch: 2 step: 340, loss is 5.501001358032227\n",
      "epoch: 2 step: 341, loss is 1.842437744140625\n",
      "epoch: 2 step: 342, loss is 0.299764484167099\n",
      "epoch: 2 step: 343, loss is 0.2904109060764313\n",
      "epoch: 2 step: 344, loss is 0.07221047580242157\n",
      "epoch: 2 step: 345, loss is 0.6744940280914307\n",
      "epoch: 2 step: 346, loss is 0.029875265434384346\n",
      "epoch: 2 step: 347, loss is 2.901902675628662\n",
      "epoch: 2 step: 348, loss is 0.02858182229101658\n",
      "epoch: 2 step: 349, loss is 1.2973884344100952\n",
      "epoch: 2 step: 350, loss is 1.5877046585083008\n",
      "epoch: 2 step: 351, loss is 3.396949529647827\n",
      "epoch: 2 step: 352, loss is 0.9309900403022766\n",
      "epoch: 2 step: 353, loss is 2.340610980987549\n",
      "epoch: 2 step: 354, loss is 2.162043571472168\n",
      "epoch: 2 step: 355, loss is 0.20743481814861298\n",
      "epoch: 2 step: 356, loss is 1.8201825618743896\n",
      "epoch: 2 step: 357, loss is 0.932013750076294\n",
      "epoch: 2 step: 358, loss is 0.4650227725505829\n",
      "epoch: 2 step: 359, loss is 1.2382444143295288\n",
      "epoch: 2 step: 360, loss is 1.8687002658843994\n",
      "epoch: 2 step: 361, loss is 2.0181937217712402\n",
      "epoch: 2 step: 362, loss is 0.9842387437820435\n",
      "epoch: 2 step: 363, loss is 0.374697744846344\n",
      "epoch: 2 step: 364, loss is 1.6691715717315674\n",
      "epoch: 2 step: 365, loss is 1.2364321947097778\n",
      "epoch: 2 step: 366, loss is 3.9894912242889404\n",
      "epoch: 2 step: 367, loss is 1.8032150268554688\n",
      "epoch: 2 step: 368, loss is 0.951418399810791\n",
      "epoch: 2 step: 369, loss is 0.6216433644294739\n",
      "epoch: 2 step: 370, loss is 0.5793107748031616\n",
      "epoch: 2 step: 371, loss is 0.49603113532066345\n",
      "epoch: 2 step: 372, loss is 0.7700725197792053\n",
      "epoch: 2 step: 373, loss is 0.41578078269958496\n",
      "epoch: 2 step: 374, loss is 0.45080500841140747\n",
      "epoch: 2 step: 375, loss is 0.12490708380937576\n",
      "epoch: 2 step: 376, loss is 1.6383092403411865\n",
      "epoch: 2 step: 377, loss is 0.061215613037347794\n",
      "epoch: 2 step: 378, loss is 0.07953830808401108\n",
      "epoch: 2 step: 379, loss is 0.08220531791448593\n",
      "epoch: 2 step: 380, loss is 0.7459957003593445\n",
      "epoch: 2 step: 381, loss is 0.08851958066225052\n",
      "epoch: 2 step: 382, loss is 3.0895237922668457\n",
      "epoch: 2 step: 383, loss is 0.05492834374308586\n",
      "epoch: 2 step: 384, loss is 0.7838271856307983\n",
      "epoch: 2 step: 385, loss is 0.302163302898407\n",
      "epoch: 2 step: 386, loss is 2.291186571121216\n",
      "epoch: 2 step: 387, loss is 3.478998899459839\n",
      "epoch: 2 step: 388, loss is 0.06901709735393524\n",
      "epoch: 2 step: 389, loss is 2.1379964351654053\n",
      "epoch: 2 step: 390, loss is 0.5487043857574463\n",
      "epoch: 2 step: 391, loss is 1.4519178867340088\n",
      "epoch: 2 step: 392, loss is 1.235560655593872\n",
      "epoch: 2 step: 393, loss is 1.4803307056427002\n",
      "epoch: 2 step: 394, loss is 0.5748996138572693\n",
      "epoch: 2 step: 395, loss is 1.5685123205184937\n",
      "epoch: 2 step: 396, loss is 2.0703935623168945\n",
      "epoch: 2 step: 397, loss is 0.39962342381477356\n",
      "epoch: 2 step: 398, loss is 0.6250135898590088\n",
      "epoch: 2 step: 399, loss is 1.6526985168457031\n",
      "epoch: 2 step: 400, loss is 1.9717254638671875\n",
      "epoch: 2 step: 401, loss is 2.298348903656006\n",
      "epoch: 2 step: 402, loss is 1.800311803817749\n",
      "epoch: 2 step: 403, loss is 1.5618033409118652\n",
      "epoch: 2 step: 404, loss is 1.1074280738830566\n",
      "epoch: 2 step: 405, loss is 0.4708879292011261\n",
      "epoch: 2 step: 406, loss is 0.40525034070014954\n",
      "epoch: 2 step: 407, loss is 0.4007262885570526\n",
      "epoch: 2 step: 408, loss is 1.8106145858764648\n",
      "epoch: 2 step: 409, loss is 1.7994581460952759\n",
      "epoch: 2 step: 410, loss is 0.8498853445053101\n",
      "epoch: 2 step: 411, loss is 2.085505723953247\n",
      "epoch: 2 step: 412, loss is 3.706803560256958\n",
      "epoch: 2 step: 413, loss is 1.798884391784668\n",
      "epoch: 2 step: 414, loss is 1.7997314929962158\n",
      "epoch: 2 step: 415, loss is 0.45648932456970215\n",
      "epoch: 2 step: 416, loss is 0.05566997826099396\n",
      "epoch: 2 step: 417, loss is 1.9226455688476562\n",
      "epoch: 2 step: 418, loss is 0.6288962364196777\n",
      "epoch: 2 step: 419, loss is 1.803741693496704\n",
      "epoch: 2 step: 420, loss is 1.6529873609542847\n",
      "epoch: 2 step: 421, loss is 0.4728899896144867\n",
      "epoch: 2 step: 422, loss is 0.4647497236728668\n",
      "epoch: 2 step: 423, loss is 0.3073367476463318\n",
      "epoch: 2 step: 424, loss is 0.09449675679206848\n",
      "epoch: 2 step: 425, loss is 0.22901664674282074\n",
      "epoch: 2 step: 426, loss is 0.1807512789964676\n",
      "epoch: 2 step: 427, loss is 0.05217232182621956\n",
      "epoch: 2 step: 428, loss is 0.338253915309906\n",
      "epoch: 2 step: 429, loss is 0.11188596487045288\n",
      "epoch: 2 step: 430, loss is 0.12062222510576248\n",
      "epoch: 2 step: 431, loss is 0.3374701142311096\n",
      "epoch: 2 step: 432, loss is 0.5313217043876648\n",
      "epoch: 2 step: 433, loss is 0.35638904571533203\n",
      "epoch: 2 step: 434, loss is 0.0481182336807251\n",
      "epoch: 2 step: 435, loss is 2.6774890422821045\n",
      "epoch: 2 step: 436, loss is 0.0904875174164772\n",
      "epoch: 2 step: 437, loss is 0.01651873253285885\n",
      "epoch: 2 step: 438, loss is 0.021376334130764008\n",
      "epoch: 2 step: 439, loss is 0.056276749819517136\n",
      "epoch: 2 step: 440, loss is 3.4158384799957275\n",
      "epoch: 2 step: 441, loss is 0.17764432728290558\n",
      "epoch: 2 step: 442, loss is 0.2726711332798004\n",
      "epoch: 2 step: 443, loss is 0.3597450852394104\n",
      "epoch: 2 step: 444, loss is 0.37125393748283386\n",
      "epoch: 2 step: 445, loss is 1.0121115446090698\n",
      "epoch: 2 step: 446, loss is 0.11598140746355057\n",
      "epoch: 2 step: 447, loss is 1.7986809015274048\n",
      "epoch: 2 step: 448, loss is 0.3881113529205322\n",
      "epoch: 2 step: 449, loss is 0.25380468368530273\n",
      "epoch: 2 step: 450, loss is 0.1153334379196167\n",
      "epoch: 2 step: 451, loss is 0.026658713817596436\n",
      "epoch: 2 step: 452, loss is 0.885103702545166\n",
      "epoch: 2 step: 453, loss is 0.08223101496696472\n",
      "epoch: 2 step: 454, loss is 0.15927131474018097\n",
      "epoch: 2 step: 455, loss is 0.08686912059783936\n",
      "epoch: 2 step: 456, loss is 0.06016417220234871\n",
      "epoch: 2 step: 457, loss is 2.5906710624694824\n",
      "epoch: 2 step: 458, loss is 2.7936954498291016\n",
      "epoch: 2 step: 459, loss is 0.062072932720184326\n",
      "epoch: 2 step: 460, loss is 0.09510188549757004\n",
      "epoch: 2 step: 461, loss is 0.12462339550256729\n",
      "epoch: 2 step: 462, loss is 0.6103471517562866\n",
      "epoch: 2 step: 463, loss is 2.038773536682129\n",
      "epoch: 2 step: 464, loss is 0.1691438853740692\n",
      "epoch: 2 step: 465, loss is 3.5837502479553223\n",
      "epoch: 2 step: 466, loss is 0.33792465925216675\n",
      "epoch: 2 step: 467, loss is 0.19172684848308563\n",
      "epoch: 2 step: 468, loss is 0.18892578780651093\n",
      "epoch: 2 step: 469, loss is 0.34632647037506104\n",
      "epoch: 2 step: 470, loss is 3.5229315757751465\n",
      "epoch: 2 step: 471, loss is 0.6054077744483948\n",
      "epoch: 2 step: 472, loss is 0.4349147081375122\n",
      "epoch: 2 step: 473, loss is 0.15914270281791687\n",
      "epoch: 2 step: 474, loss is 2.5865426063537598\n",
      "epoch: 2 step: 475, loss is 0.15465354919433594\n",
      "epoch: 2 step: 476, loss is 0.3435879945755005\n",
      "epoch: 2 step: 477, loss is 0.16810786724090576\n",
      "epoch: 2 step: 478, loss is 1.8756471872329712\n",
      "epoch: 2 step: 479, loss is 1.6753580570220947\n",
      "epoch: 2 step: 480, loss is 0.6620934009552002\n",
      "epoch: 2 step: 481, loss is 0.16185332834720612\n",
      "epoch: 2 step: 482, loss is 0.10437463223934174\n",
      "epoch: 2 step: 483, loss is 1.9151952266693115\n",
      "epoch: 2 step: 484, loss is 0.2044207900762558\n",
      "epoch: 2 step: 485, loss is 1.56935715675354\n",
      "epoch: 2 step: 486, loss is 0.1435660570859909\n",
      "epoch: 2 step: 487, loss is 0.14118146896362305\n",
      "epoch: 2 step: 488, loss is 2.302030563354492\n",
      "epoch: 2 step: 489, loss is 0.0716642290353775\n",
      "epoch: 2 step: 490, loss is 0.3039087951183319\n",
      "epoch: 2 step: 491, loss is 0.3908047676086426\n",
      "epoch: 2 step: 492, loss is 0.16650767624378204\n",
      "epoch: 2 step: 493, loss is 0.04560340568423271\n",
      "epoch: 2 step: 494, loss is 0.04786360263824463\n",
      "epoch: 2 step: 495, loss is 1.8042645454406738\n",
      "epoch: 2 step: 496, loss is 0.1164146363735199\n",
      "epoch: 2 step: 497, loss is 2.091435670852661\n",
      "epoch: 2 step: 498, loss is 2.269436836242676\n",
      "epoch: 2 step: 499, loss is 2.2321250438690186\n",
      "epoch: 2 step: 500, loss is 0.2551504969596863\n",
      "epoch: 2 step: 501, loss is 0.20957845449447632\n",
      "epoch: 2 step: 502, loss is 0.24326400458812714\n",
      "epoch: 2 step: 503, loss is 0.18311014771461487\n",
      "epoch: 2 step: 504, loss is 0.33596518635749817\n",
      "epoch: 2 step: 505, loss is 0.08919801563024521\n",
      "epoch: 2 step: 506, loss is 0.10957614332437515\n",
      "epoch: 2 step: 507, loss is 1.3169326782226562\n",
      "epoch: 2 step: 508, loss is 1.2322989702224731\n",
      "epoch: 2 step: 509, loss is 1.5678939819335938\n",
      "epoch: 2 step: 510, loss is 0.0653020441532135\n",
      "epoch: 2 step: 511, loss is 0.3228168785572052\n",
      "epoch: 2 step: 512, loss is 3.7057745456695557\n",
      "epoch: 2 step: 513, loss is 1.6500252485275269\n",
      "epoch: 2 step: 514, loss is 0.4225411117076874\n",
      "epoch: 2 step: 515, loss is 1.383105993270874\n",
      "epoch: 2 step: 516, loss is 0.27123475074768066\n",
      "epoch: 2 step: 517, loss is 0.0956750214099884\n",
      "epoch: 2 step: 518, loss is 2.166627883911133\n",
      "epoch: 2 step: 519, loss is 1.5668489933013916\n",
      "epoch: 2 step: 520, loss is 0.22163093090057373\n",
      "epoch: 2 step: 521, loss is 0.4185267984867096\n",
      "epoch: 2 step: 522, loss is 0.6073737740516663\n",
      "epoch: 2 step: 523, loss is 3.197986125946045\n",
      "epoch: 2 step: 524, loss is 0.13730527460575104\n",
      "epoch: 2 step: 525, loss is 0.4206763505935669\n",
      "epoch: 2 step: 526, loss is 0.9088165760040283\n",
      "epoch: 2 step: 527, loss is 0.04407753050327301\n",
      "epoch: 2 step: 528, loss is 0.034306254237890244\n",
      "epoch: 2 step: 529, loss is 1.639641284942627\n",
      "epoch: 2 step: 530, loss is 0.08050942420959473\n",
      "epoch: 2 step: 531, loss is 1.651873230934143\n",
      "epoch: 2 step: 532, loss is 0.27172350883483887\n",
      "epoch: 2 step: 533, loss is 0.20668227970600128\n",
      "epoch: 2 step: 534, loss is 0.6128990650177002\n",
      "epoch: 2 step: 535, loss is 0.062376610934734344\n",
      "epoch: 2 step: 536, loss is 0.05577720329165459\n",
      "epoch: 2 step: 537, loss is 2.2512969970703125\n",
      "epoch: 2 step: 538, loss is 1.5729877948760986\n",
      "epoch: 2 step: 539, loss is 0.11047551780939102\n",
      "epoch: 2 step: 540, loss is 0.1041896864771843\n",
      "epoch: 2 step: 541, loss is 3.5215024948120117\n",
      "epoch: 2 step: 542, loss is 0.38155993819236755\n",
      "epoch: 2 step: 543, loss is 0.08711444586515427\n",
      "epoch: 2 step: 544, loss is 0.5557819604873657\n",
      "epoch: 2 step: 545, loss is 1.5669033527374268\n",
      "epoch: 2 step: 546, loss is 1.5158774852752686\n",
      "epoch: 2 step: 547, loss is 0.21479187905788422\n",
      "epoch: 2 step: 548, loss is 1.5912405252456665\n",
      "epoch: 2 step: 549, loss is 2.5989248752593994\n",
      "epoch: 2 step: 550, loss is 0.5251284241676331\n",
      "epoch: 2 step: 551, loss is 1.2337521314620972\n",
      "epoch: 2 step: 552, loss is 1.6513359546661377\n",
      "epoch: 2 step: 553, loss is 1.3872981071472168\n",
      "epoch: 2 step: 554, loss is 1.2412787675857544\n",
      "epoch: 2 step: 555, loss is 0.9390920996665955\n",
      "epoch: 2 step: 556, loss is 1.3063743114471436\n",
      "epoch: 2 step: 557, loss is 1.805015206336975\n",
      "epoch: 2 step: 558, loss is 2.4720706939697266\n",
      "epoch: 2 step: 559, loss is 0.3379311263561249\n",
      "epoch: 2 step: 560, loss is 0.34596994519233704\n",
      "epoch: 2 step: 561, loss is 0.6982439756393433\n",
      "epoch: 2 step: 562, loss is 0.5867837071418762\n",
      "epoch: 2 step: 563, loss is 1.5653424263000488\n",
      "epoch: 2 step: 564, loss is 0.03509889915585518\n",
      "epoch: 2 step: 565, loss is 0.16680142283439636\n",
      "epoch: 2 step: 566, loss is 0.25039970874786377\n",
      "epoch: 2 step: 567, loss is 1.3851698637008667\n",
      "epoch: 2 step: 568, loss is 1.8032357692718506\n",
      "epoch: 2 step: 569, loss is 4.31258487701416\n",
      "epoch: 2 step: 570, loss is 0.05441863834857941\n",
      "epoch: 2 step: 571, loss is 0.40024539828300476\n",
      "epoch: 2 step: 572, loss is 0.09475843608379364\n",
      "epoch: 2 step: 573, loss is 0.647726833820343\n",
      "epoch: 2 step: 574, loss is 0.13285884261131287\n",
      "epoch: 2 step: 575, loss is 0.5050013065338135\n",
      "epoch: 2 step: 576, loss is 3.4104979038238525\n",
      "epoch: 2 step: 577, loss is 2.020157814025879\n",
      "epoch: 2 step: 578, loss is 1.4467257261276245\n",
      "epoch: 2 step: 579, loss is 1.2307062149047852\n",
      "epoch: 2 step: 580, loss is 1.8489015102386475\n",
      "epoch: 2 step: 581, loss is 2.8397858142852783\n",
      "epoch: 2 step: 582, loss is 0.9228622317314148\n",
      "epoch: 2 step: 583, loss is 1.5578004121780396\n",
      "epoch: 2 step: 584, loss is 0.12425118684768677\n",
      "epoch: 2 step: 585, loss is 1.8532034158706665\n",
      "epoch: 2 step: 586, loss is 0.9030938744544983\n",
      "epoch: 2 step: 587, loss is 0.2020363062620163\n",
      "epoch: 2 step: 588, loss is 0.46215030550956726\n",
      "epoch: 2 step: 589, loss is 0.7990803718566895\n",
      "epoch: 2 step: 590, loss is 0.11468367278575897\n",
      "epoch: 2 step: 591, loss is 1.5646560192108154\n",
      "epoch: 2 step: 592, loss is 0.06702044606208801\n",
      "epoch: 2 step: 593, loss is 1.4825387001037598\n",
      "epoch: 2 step: 594, loss is 1.7927768230438232\n",
      "epoch: 2 step: 595, loss is 0.38640448451042175\n",
      "epoch: 2 step: 596, loss is 0.04890988767147064\n",
      "epoch: 2 step: 597, loss is 1.0568300485610962\n",
      "epoch: 2 step: 598, loss is 0.0696798712015152\n",
      "epoch: 2 step: 599, loss is 1.9479410648345947\n",
      "epoch: 2 step: 600, loss is 0.09816886484622955\n",
      "epoch: 2 step: 601, loss is 0.09451334923505783\n",
      "epoch: 2 step: 602, loss is 1.3452694416046143\n",
      "epoch: 2 step: 603, loss is 2.598745346069336\n",
      "epoch: 2 step: 604, loss is 0.06528741121292114\n",
      "epoch: 2 step: 605, loss is 1.0573245286941528\n",
      "epoch: 2 step: 606, loss is 1.8819925785064697\n",
      "epoch: 2 step: 607, loss is 0.5856616497039795\n",
      "epoch: 2 step: 608, loss is 0.021284380927681923\n",
      "epoch: 2 step: 609, loss is 1.9473228454589844\n",
      "epoch: 2 step: 610, loss is 0.008380248211324215\n",
      "epoch: 2 step: 611, loss is 0.5696418285369873\n",
      "epoch: 2 step: 612, loss is 0.044047873467206955\n",
      "epoch: 2 step: 613, loss is 0.01418730802834034\n",
      "epoch: 2 step: 614, loss is 1.5647656917572021\n",
      "epoch: 2 step: 615, loss is 4.480111122131348\n",
      "epoch: 2 step: 616, loss is 0.15653206408023834\n",
      "epoch: 2 step: 617, loss is 0.03971217945218086\n",
      "epoch: 2 step: 618, loss is 0.39667582511901855\n",
      "epoch: 2 step: 619, loss is 0.06608355790376663\n",
      "epoch: 2 step: 620, loss is 2.7567241191864014\n",
      "epoch: 2 step: 621, loss is 0.42384961247444153\n",
      "epoch: 2 step: 622, loss is 3.380812406539917\n",
      "epoch: 2 step: 623, loss is 0.6903901100158691\n",
      "epoch: 2 step: 624, loss is 0.14909975230693817\n",
      "epoch: 2 step: 625, loss is 2.6018545627593994\n",
      "epoch: 2 step: 626, loss is 0.7095401883125305\n",
      "epoch: 2 step: 627, loss is 1.575050711631775\n",
      "epoch: 2 step: 628, loss is 0.023927729576826096\n",
      "epoch: 2 step: 629, loss is 1.3479325771331787\n",
      "epoch: 2 step: 630, loss is 0.9636010527610779\n",
      "epoch: 2 step: 631, loss is 0.12664808332920074\n",
      "epoch: 2 step: 632, loss is 1.0160902738571167\n",
      "epoch: 2 step: 633, loss is 0.4482518136501312\n",
      "epoch: 2 step: 634, loss is 1.9552884101867676\n",
      "epoch: 2 step: 635, loss is 0.019796064123511314\n",
      "epoch: 2 step: 636, loss is 2.3925280570983887\n",
      "epoch: 2 step: 637, loss is 0.3025470972061157\n",
      "epoch: 2 step: 638, loss is 0.07869693636894226\n",
      "epoch: 2 step: 639, loss is 0.03980852663516998\n",
      "epoch: 2 step: 640, loss is 0.038940150290727615\n",
      "epoch: 2 step: 641, loss is 1.8373029232025146\n",
      "epoch: 2 step: 642, loss is 0.010859793052077293\n",
      "epoch: 2 step: 643, loss is 3.05178165435791\n",
      "epoch: 2 step: 644, loss is 0.6114228367805481\n",
      "epoch: 2 step: 645, loss is 0.02600698173046112\n",
      "epoch: 2 step: 646, loss is 5.983255386352539\n",
      "epoch: 2 step: 647, loss is 1.2329877614974976\n",
      "epoch: 2 step: 648, loss is 0.46812134981155396\n",
      "epoch: 2 step: 649, loss is 0.9956141114234924\n",
      "epoch: 2 step: 650, loss is 1.9528448581695557\n",
      "epoch: 2 step: 651, loss is 1.2790180444717407\n",
      "epoch: 2 step: 652, loss is 3.002488613128662\n",
      "epoch: 2 step: 653, loss is 1.771289348602295\n",
      "epoch: 2 step: 654, loss is 0.0822751522064209\n",
      "epoch: 2 step: 655, loss is 0.517854630947113\n",
      "epoch: 2 step: 656, loss is 0.08740941435098648\n",
      "epoch: 2 step: 657, loss is 0.3296561539173126\n",
      "epoch: 2 step: 658, loss is 0.17810802161693573\n",
      "epoch: 2 step: 659, loss is 0.3954235315322876\n",
      "epoch: 2 step: 660, loss is 0.4562729299068451\n",
      "epoch: 2 step: 661, loss is 1.2299079895019531\n",
      "epoch: 2 step: 662, loss is 2.0182061195373535\n",
      "epoch: 2 step: 663, loss is 4.019865989685059\n",
      "epoch: 2 step: 664, loss is 1.23091721534729\n",
      "epoch: 2 step: 665, loss is 1.499993920326233\n",
      "epoch: 2 step: 666, loss is 3.3538155555725098\n",
      "epoch: 2 step: 667, loss is 1.8458150625228882\n",
      "epoch: 2 step: 668, loss is 1.5629980564117432\n",
      "epoch: 2 step: 669, loss is 1.656579613685608\n",
      "epoch: 2 step: 670, loss is 1.7294204235076904\n",
      "epoch: 2 step: 671, loss is 1.206915259361267\n",
      "epoch: 2 step: 672, loss is 1.8229626417160034\n",
      "epoch: 2 step: 673, loss is 1.6563096046447754\n",
      "epoch: 2 step: 674, loss is 1.8629817962646484\n",
      "epoch: 2 step: 675, loss is 1.7614047527313232\n",
      "epoch: 2 step: 676, loss is 0.768033504486084\n",
      "epoch: 2 step: 677, loss is 1.5007742643356323\n",
      "epoch: 2 step: 678, loss is 0.6502283215522766\n",
      "epoch: 2 step: 679, loss is 0.8719750046730042\n",
      "epoch: 2 step: 680, loss is 1.780818223953247\n",
      "epoch: 2 step: 681, loss is 1.232367753982544\n",
      "epoch: 2 step: 682, loss is 1.7954379320144653\n",
      "epoch: 2 step: 683, loss is 0.9810314774513245\n",
      "epoch: 2 step: 684, loss is 0.2126738578081131\n",
      "epoch: 2 step: 685, loss is 1.266131043434143\n",
      "epoch: 2 step: 686, loss is 0.4694516956806183\n",
      "epoch: 2 step: 687, loss is 1.4822136163711548\n",
      "epoch: 2 step: 688, loss is 1.7813092470169067\n",
      "epoch: 2 step: 689, loss is 0.19786114990711212\n",
      "epoch: 2 step: 690, loss is 2.284334659576416\n",
      "epoch: 2 step: 691, loss is 0.7236834764480591\n",
      "epoch: 2 step: 692, loss is 0.6312702298164368\n",
      "epoch: 2 step: 693, loss is 2.213712453842163\n",
      "epoch: 2 step: 694, loss is 0.2422262579202652\n",
      "epoch: 2 step: 695, loss is 2.020901918411255\n",
      "epoch: 2 step: 696, loss is 1.7101826667785645\n",
      "epoch: 2 step: 697, loss is 1.9549140930175781\n",
      "epoch: 2 step: 698, loss is 0.10233722627162933\n",
      "epoch: 2 step: 699, loss is 2.7930378913879395\n",
      "epoch: 2 step: 700, loss is 0.9932068586349487\n",
      "epoch: 2 step: 701, loss is 1.750035047531128\n",
      "epoch: 2 step: 702, loss is 1.559645175933838\n",
      "epoch: 2 step: 703, loss is 1.723433256149292\n",
      "epoch: 2 step: 704, loss is 0.7330207824707031\n",
      "epoch: 2 step: 705, loss is 0.5279039144515991\n",
      "epoch: 2 step: 706, loss is 1.476510763168335\n",
      "epoch: 2 step: 707, loss is 2.1468758583068848\n",
      "epoch: 2 step: 708, loss is 0.3862903416156769\n",
      "epoch: 2 step: 709, loss is 0.3572532534599304\n",
      "epoch: 2 step: 710, loss is 1.9547537565231323\n",
      "epoch: 2 step: 711, loss is 0.9161401391029358\n",
      "epoch: 2 step: 712, loss is 1.987575888633728\n",
      "epoch: 2 step: 713, loss is 0.656989574432373\n",
      "epoch: 2 step: 714, loss is 4.624030590057373\n",
      "epoch: 2 step: 715, loss is 2.866827964782715\n",
      "epoch: 2 step: 716, loss is 1.7005764245986938\n",
      "epoch: 2 step: 717, loss is 1.7978880405426025\n",
      "epoch: 2 step: 718, loss is 1.2361525297164917\n",
      "epoch: 2 step: 719, loss is 1.8727649450302124\n",
      "epoch: 2 step: 720, loss is 1.0692393779754639\n",
      "epoch: 2 step: 721, loss is 1.3767564296722412\n",
      "epoch: 2 step: 722, loss is 1.6944280862808228\n",
      "epoch: 2 step: 723, loss is 1.797329068183899\n",
      "epoch: 2 step: 724, loss is 1.8960018157958984\n",
      "epoch: 2 step: 725, loss is 0.7872813940048218\n",
      "epoch: 2 step: 726, loss is 1.7966119050979614\n",
      "epoch: 2 step: 727, loss is 1.657962679862976\n",
      "epoch: 2 step: 728, loss is 1.777195692062378\n",
      "epoch: 2 step: 729, loss is 1.593000888824463\n",
      "epoch: 2 step: 730, loss is 1.6713035106658936\n",
      "epoch: 2 step: 731, loss is 1.77838134765625\n",
      "epoch: 2 step: 732, loss is 1.2610065937042236\n",
      "epoch: 2 step: 733, loss is 0.6001166701316833\n",
      "epoch: 2 step: 734, loss is 1.6612733602523804\n",
      "epoch: 2 step: 735, loss is 0.36232075095176697\n",
      "epoch: 2 step: 736, loss is 0.47702932357788086\n",
      "epoch: 2 step: 737, loss is 1.225111484527588\n",
      "epoch: 2 step: 738, loss is 0.7829555869102478\n",
      "epoch: 2 step: 739, loss is 0.25101813673973083\n",
      "epoch: 2 step: 740, loss is 1.655945062637329\n",
      "epoch: 2 step: 741, loss is 1.5201284885406494\n",
      "epoch: 2 step: 742, loss is 0.2733602225780487\n",
      "epoch: 2 step: 743, loss is 1.2346763610839844\n",
      "epoch: 2 step: 744, loss is 0.15567287802696228\n",
      "epoch: 2 step: 745, loss is 0.49724188446998596\n",
      "epoch: 2 step: 746, loss is 1.9477684497833252\n",
      "epoch: 2 step: 747, loss is 1.6212360858917236\n",
      "epoch: 2 step: 748, loss is 0.21656334400177002\n",
      "epoch: 2 step: 749, loss is 0.32396894693374634\n",
      "epoch: 2 step: 750, loss is 1.6667895317077637\n",
      "epoch: 2 step: 751, loss is 0.2065238505601883\n",
      "epoch: 2 step: 752, loss is 0.3389589786529541\n",
      "epoch: 2 step: 753, loss is 0.3115570545196533\n",
      "epoch: 2 step: 754, loss is 1.7550400495529175\n",
      "epoch: 2 step: 755, loss is 0.44641831517219543\n",
      "epoch: 2 step: 756, loss is 0.0634407252073288\n",
      "epoch: 2 step: 757, loss is 0.2101452648639679\n",
      "epoch: 2 step: 758, loss is 0.23423559963703156\n",
      "epoch: 2 step: 759, loss is 1.6646901369094849\n",
      "epoch: 2 step: 760, loss is 0.14977885782718658\n",
      "epoch: 2 step: 761, loss is 0.08269524574279785\n",
      "epoch: 2 step: 762, loss is 0.023110564798116684\n",
      "epoch: 2 step: 763, loss is 0.2098398059606552\n",
      "epoch: 2 step: 764, loss is 1.6104861497879028\n",
      "epoch: 2 step: 765, loss is 0.9083382487297058\n",
      "epoch: 2 step: 766, loss is 0.19162803888320923\n",
      "epoch: 2 step: 767, loss is 2.1006593704223633\n",
      "epoch: 2 step: 768, loss is 2.278393268585205\n",
      "epoch: 2 step: 769, loss is 0.10798696428537369\n",
      "epoch: 2 step: 770, loss is 0.882499098777771\n",
      "epoch: 2 step: 771, loss is 0.19570830464363098\n",
      "epoch: 2 step: 772, loss is 1.2142200469970703\n",
      "epoch: 2 step: 773, loss is 1.65311861038208\n",
      "epoch: 2 step: 774, loss is 1.6110392808914185\n",
      "epoch: 2 step: 775, loss is 0.43738120794296265\n",
      "epoch: 2 step: 776, loss is 1.4166488647460938\n",
      "epoch: 2 step: 777, loss is 1.789480209350586\n",
      "epoch: 2 step: 778, loss is 0.1128794252872467\n",
      "epoch: 2 step: 779, loss is 0.04062464088201523\n",
      "epoch: 2 step: 780, loss is 0.05713684856891632\n",
      "epoch: 2 step: 781, loss is 0.21840958297252655\n",
      "epoch: 2 step: 782, loss is 0.2062138020992279\n",
      "epoch: 2 step: 783, loss is 0.03105032444000244\n",
      "epoch: 2 step: 784, loss is 0.1352207362651825\n",
      "epoch: 2 step: 785, loss is 1.3753942251205444\n",
      "epoch: 2 step: 786, loss is 2.1857991218566895\n",
      "epoch: 2 step: 787, loss is 0.08980102092027664\n",
      "epoch: 2 step: 788, loss is 1.8077675104141235\n",
      "epoch: 2 step: 789, loss is 1.9629509449005127\n",
      "epoch: 2 step: 790, loss is 0.07113611698150635\n",
      "epoch: 2 step: 791, loss is 2.812940835952759\n",
      "epoch: 2 step: 792, loss is 0.03722318634390831\n",
      "epoch: 2 step: 793, loss is 0.4095982015132904\n",
      "epoch: 2 step: 794, loss is 0.5170305371284485\n",
      "epoch: 2 step: 795, loss is 0.18498772382736206\n",
      "epoch: 2 step: 796, loss is 0.12799961864948273\n",
      "epoch: 2 step: 797, loss is 2.3281381130218506\n",
      "epoch: 2 step: 798, loss is 0.37818071246147156\n",
      "epoch: 2 step: 799, loss is 1.5025297403335571\n",
      "epoch: 2 step: 800, loss is 0.39433038234710693\n",
      "epoch: 2 step: 801, loss is 0.3455565571784973\n",
      "epoch: 2 step: 802, loss is 1.7926297187805176\n",
      "epoch: 2 step: 803, loss is 1.2250393629074097\n",
      "epoch: 2 step: 804, loss is 0.22138409316539764\n",
      "epoch: 2 step: 805, loss is 1.7823302745819092\n",
      "epoch: 2 step: 806, loss is 0.047182224690914154\n",
      "epoch: 2 step: 807, loss is 2.0124518871307373\n",
      "epoch: 2 step: 808, loss is 1.4734314680099487\n",
      "epoch: 2 step: 809, loss is 0.11176145821809769\n",
      "epoch: 2 step: 810, loss is 1.7977657318115234\n",
      "epoch: 2 step: 811, loss is 0.6479032039642334\n",
      "epoch: 2 step: 812, loss is 0.021777544170618057\n",
      "epoch: 2 step: 813, loss is 0.08632131665945053\n",
      "epoch: 2 step: 814, loss is 1.5735712051391602\n",
      "epoch: 2 step: 815, loss is 0.06613656133413315\n",
      "epoch: 2 step: 816, loss is 0.08264926075935364\n",
      "epoch: 2 step: 817, loss is 0.055012404918670654\n",
      "epoch: 2 step: 818, loss is 2.966547966003418\n",
      "epoch: 2 step: 819, loss is 1.5680553913116455\n",
      "epoch: 2 step: 820, loss is 1.230625033378601\n",
      "epoch: 2 step: 821, loss is 1.5674755573272705\n",
      "epoch: 2 step: 822, loss is 3.2006359100341797\n",
      "epoch: 2 step: 823, loss is 0.3756454288959503\n",
      "epoch: 2 step: 824, loss is 1.4302198886871338\n",
      "epoch: 2 step: 825, loss is 2.7753140926361084\n",
      "epoch: 2 step: 826, loss is 1.2593467235565186\n",
      "epoch: 2 step: 827, loss is 1.3562963008880615\n",
      "epoch: 2 step: 828, loss is 0.4556707441806793\n",
      "epoch: 2 step: 829, loss is 1.5656838417053223\n",
      "epoch: 2 step: 830, loss is 1.7998237609863281\n",
      "epoch: 2 step: 831, loss is 0.9953290820121765\n",
      "epoch: 2 step: 832, loss is 1.4413366317749023\n",
      "epoch: 2 step: 833, loss is 0.041306037455797195\n",
      "epoch: 2 step: 834, loss is 0.9499263167381287\n",
      "epoch: 2 step: 835, loss is 0.026612399145960808\n",
      "epoch: 2 step: 836, loss is 1.7994697093963623\n",
      "epoch: 2 step: 837, loss is 1.9495611190795898\n",
      "epoch: 2 step: 838, loss is 2.096804141998291\n",
      "epoch: 2 step: 839, loss is 1.902080774307251\n",
      "epoch: 2 step: 840, loss is 1.9887306690216064\n",
      "epoch: 2 step: 841, loss is 1.1579984426498413\n",
      "epoch: 2 step: 842, loss is 0.7480125427246094\n",
      "epoch: 2 step: 843, loss is 1.8845632076263428\n",
      "epoch: 2 step: 844, loss is 3.419510841369629\n",
      "epoch: 2 step: 845, loss is 3.01725435256958\n",
      "epoch: 2 step: 846, loss is 0.9028509259223938\n",
      "epoch: 2 step: 847, loss is 1.2337353229522705\n",
      "epoch: 2 step: 848, loss is 1.5711653232574463\n",
      "epoch: 2 step: 849, loss is 0.11596941202878952\n",
      "epoch: 2 step: 850, loss is 1.9113545417785645\n",
      "epoch: 2 step: 851, loss is 0.10057900100946426\n",
      "epoch: 2 step: 852, loss is 1.655871868133545\n",
      "epoch: 2 step: 853, loss is 0.24015754461288452\n",
      "epoch: 2 step: 854, loss is 0.07144782692193985\n",
      "epoch: 2 step: 855, loss is 2.948660373687744\n",
      "epoch: 2 step: 856, loss is 0.08590230345726013\n",
      "epoch: 2 step: 857, loss is 0.6481305360794067\n",
      "epoch: 2 step: 858, loss is 0.903588593006134\n",
      "epoch: 2 step: 859, loss is 1.8946999311447144\n",
      "epoch: 2 step: 860, loss is 0.794918417930603\n",
      "epoch: 2 step: 861, loss is 0.004995602648705244\n",
      "epoch: 2 step: 862, loss is 2.1310219764709473\n",
      "epoch: 2 step: 863, loss is 1.5630097389221191\n",
      "epoch: 2 step: 864, loss is 1.5620906352996826\n",
      "epoch: 2 step: 865, loss is 0.16817669570446014\n",
      "epoch: 2 step: 866, loss is 0.03878753259778023\n",
      "epoch: 2 step: 867, loss is 1.586714744567871\n",
      "epoch: 2 step: 868, loss is 0.6167319416999817\n",
      "epoch: 2 step: 869, loss is 0.29389166831970215\n",
      "epoch: 2 step: 870, loss is 1.3421313762664795\n",
      "epoch: 2 step: 871, loss is 0.057170964777469635\n",
      "epoch: 2 step: 872, loss is 1.5597243309020996\n",
      "epoch: 2 step: 873, loss is 0.16879373788833618\n",
      "epoch: 2 step: 874, loss is 2.943556308746338\n",
      "epoch: 2 step: 875, loss is 0.7177353501319885\n",
      "epoch: 2 step: 876, loss is 0.3947731852531433\n",
      "epoch: 2 step: 877, loss is 0.023537278175354004\n",
      "epoch: 2 step: 878, loss is 1.652742624282837\n",
      "epoch: 2 step: 879, loss is 3.6082565784454346\n",
      "epoch: 2 step: 880, loss is 0.28804224729537964\n",
      "epoch: 2 step: 881, loss is 0.24661387503147125\n",
      "epoch: 2 step: 882, loss is 0.18392585217952728\n",
      "epoch: 2 step: 883, loss is 2.235753297805786\n",
      "epoch: 2 step: 884, loss is 0.5633605718612671\n",
      "epoch: 2 step: 885, loss is 0.7849664688110352\n",
      "epoch: 2 step: 886, loss is 1.9848555326461792\n",
      "epoch: 2 step: 887, loss is 1.8316011428833008\n",
      "epoch: 2 step: 888, loss is 0.27519702911376953\n",
      "epoch: 2 step: 889, loss is 0.34896785020828247\n",
      "epoch: 2 step: 890, loss is 0.020962122827768326\n",
      "epoch: 2 step: 891, loss is 0.06611848622560501\n",
      "epoch: 2 step: 892, loss is 0.20679056644439697\n",
      "epoch: 2 step: 893, loss is 0.17454862594604492\n",
      "epoch: 2 step: 894, loss is 3.5725908279418945\n",
      "epoch: 2 step: 895, loss is 0.12052088975906372\n",
      "epoch: 2 step: 896, loss is 3.0551881790161133\n",
      "epoch: 2 step: 897, loss is 0.7046434283256531\n",
      "epoch: 2 step: 898, loss is 1.5113190412521362\n",
      "epoch: 2 step: 899, loss is 1.0451314449310303\n",
      "epoch: 2 step: 900, loss is 0.046329565346241\n",
      "epoch: 2 step: 901, loss is 0.7878476977348328\n",
      "epoch: 2 step: 902, loss is 1.6502532958984375\n",
      "epoch: 2 step: 903, loss is 0.30586618185043335\n",
      "epoch: 2 step: 904, loss is 1.6224334239959717\n",
      "epoch: 2 step: 905, loss is 1.8600633144378662\n",
      "epoch: 2 step: 906, loss is 0.2057531625032425\n",
      "epoch: 2 step: 907, loss is 0.03240613266825676\n",
      "epoch: 2 step: 908, loss is 0.4150272011756897\n",
      "epoch: 2 step: 909, loss is 1.7874815464019775\n",
      "epoch: 2 step: 910, loss is 2.1835989952087402\n",
      "epoch: 2 step: 911, loss is 1.9685838222503662\n",
      "epoch: 2 step: 912, loss is 1.6531001329421997\n",
      "epoch: 2 step: 913, loss is 0.8948367834091187\n",
      "epoch: 2 step: 914, loss is 2.2350404262542725\n",
      "epoch: 2 step: 915, loss is 0.5343940258026123\n",
      "epoch: 2 step: 916, loss is 1.5755839347839355\n",
      "epoch: 2 step: 917, loss is 0.054807715117931366\n",
      "epoch: 2 step: 918, loss is 2.587697744369507\n",
      "epoch: 2 step: 919, loss is 0.7934045791625977\n",
      "epoch: 2 step: 920, loss is 0.2585040330886841\n",
      "epoch: 2 step: 921, loss is 0.17226186394691467\n",
      "epoch: 2 step: 922, loss is 0.29717910289764404\n",
      "epoch: 2 step: 923, loss is 1.4331417083740234\n",
      "epoch: 2 step: 924, loss is 1.7378628253936768\n",
      "epoch: 2 step: 925, loss is 0.041730090975761414\n",
      "epoch: 2 step: 926, loss is 0.25857049226760864\n",
      "epoch: 2 step: 927, loss is 0.43981048464775085\n",
      "epoch: 2 step: 928, loss is 2.0068023204803467\n",
      "epoch: 2 step: 929, loss is 1.8450123071670532\n",
      "epoch: 2 step: 930, loss is 1.4764257669448853\n",
      "epoch: 2 step: 931, loss is 3.7676172256469727\n",
      "epoch: 2 step: 932, loss is 1.7994123697280884\n",
      "epoch: 2 step: 933, loss is 2.031477212905884\n",
      "epoch: 2 step: 934, loss is 0.3750070631504059\n",
      "epoch: 2 step: 935, loss is 0.2550533413887024\n",
      "epoch: 2 step: 936, loss is 0.5958060622215271\n",
      "epoch: 2 step: 937, loss is 1.9730045795440674\n",
      "epoch: 2 step: 938, loss is 1.1561436653137207\n",
      "epoch: 2 step: 939, loss is 0.7074228525161743\n",
      "epoch: 2 step: 940, loss is 0.4245697557926178\n",
      "epoch: 2 step: 941, loss is 0.9937227964401245\n",
      "epoch: 2 step: 942, loss is 1.8833882808685303\n",
      "epoch: 2 step: 943, loss is 1.049288272857666\n",
      "epoch: 2 step: 944, loss is 0.9912813305854797\n",
      "epoch: 2 step: 945, loss is 2.822301149368286\n",
      "epoch: 2 step: 946, loss is 1.6556916236877441\n",
      "epoch: 2 step: 947, loss is 0.5856422781944275\n",
      "epoch: 2 step: 948, loss is 0.8273569941520691\n",
      "epoch: 2 step: 949, loss is 0.3484173119068146\n",
      "epoch: 2 step: 950, loss is 0.09469922631978989\n",
      "epoch: 2 step: 951, loss is 0.15664826333522797\n",
      "epoch: 2 step: 952, loss is 0.6299675107002258\n",
      "epoch: 2 step: 953, loss is 0.37471362948417664\n",
      "epoch: 2 step: 954, loss is 2.92699933052063\n",
      "epoch: 2 step: 955, loss is 1.7648494243621826\n",
      "epoch: 2 step: 956, loss is 0.35985714197158813\n",
      "epoch: 2 step: 957, loss is 0.12948842346668243\n",
      "epoch: 2 step: 958, loss is 0.0822928249835968\n",
      "epoch: 2 step: 959, loss is 0.5000612735748291\n",
      "epoch: 2 step: 960, loss is 0.686913013458252\n",
      "epoch: 2 step: 961, loss is 1.452960729598999\n",
      "epoch: 2 step: 962, loss is 0.18589168787002563\n",
      "epoch: 2 step: 963, loss is 0.1034630835056305\n",
      "epoch: 2 step: 964, loss is 1.7778453826904297\n",
      "epoch: 2 step: 965, loss is 2.002476930618286\n",
      "epoch: 2 step: 966, loss is 0.39228999614715576\n",
      "epoch: 2 step: 967, loss is 0.8247114419937134\n",
      "epoch: 2 step: 968, loss is 1.8612957000732422\n",
      "epoch: 2 step: 969, loss is 2.4237873554229736\n",
      "epoch: 2 step: 970, loss is 0.011063187383115292\n",
      "epoch: 2 step: 971, loss is 0.056709371507167816\n",
      "epoch: 2 step: 972, loss is 1.2917567491531372\n",
      "epoch: 2 step: 973, loss is 0.009888708591461182\n",
      "epoch: 2 step: 974, loss is 0.04788440093398094\n",
      "epoch: 2 step: 975, loss is 1.8070013523101807\n",
      "epoch: 2 step: 976, loss is 0.09326443076133728\n",
      "epoch: 2 step: 977, loss is 0.4657527208328247\n",
      "epoch: 2 step: 978, loss is 0.11698979139328003\n",
      "epoch: 2 step: 979, loss is 0.0018598416354507208\n",
      "epoch: 2 step: 980, loss is 0.012802904471755028\n",
      "epoch: 2 step: 981, loss is 3.6365630626678467\n",
      "epoch: 2 step: 982, loss is 0.2797502875328064\n",
      "epoch: 2 step: 983, loss is 0.01869334653019905\n",
      "epoch: 2 step: 984, loss is 0.07827549427747726\n",
      "epoch: 2 step: 985, loss is 0.03146476671099663\n",
      "epoch: 2 step: 986, loss is 1.8187450170516968\n",
      "epoch: 2 step: 987, loss is 0.08242237567901611\n",
      "epoch: 2 step: 988, loss is 0.024742132052779198\n",
      "epoch: 2 step: 989, loss is 0.019145572558045387\n",
      "epoch: 2 step: 990, loss is 5.017794132232666\n",
      "epoch: 2 step: 991, loss is 0.25387081503868103\n",
      "epoch: 2 step: 992, loss is 1.863482117652893\n",
      "epoch: 2 step: 993, loss is 1.5561825037002563\n",
      "epoch: 2 step: 994, loss is 0.08918493241071701\n",
      "epoch: 2 step: 995, loss is 1.9407793283462524\n",
      "epoch: 2 step: 996, loss is 0.2581748068332672\n",
      "epoch: 2 step: 997, loss is 0.13445642590522766\n",
      "epoch: 2 step: 998, loss is 0.12375371903181076\n",
      "epoch: 2 step: 999, loss is 2.0208520889282227\n",
      "epoch: 2 step: 1000, loss is 2.0816152095794678\n",
      "epoch: 2 step: 1001, loss is 0.6020842790603638\n",
      "epoch: 2 step: 1002, loss is 0.0288307536393404\n",
      "epoch: 2 step: 1003, loss is 2.040022850036621\n",
      "epoch: 2 step: 1004, loss is 0.09351296722888947\n",
      "epoch: 2 step: 1005, loss is 1.8010814189910889\n",
      "epoch: 2 step: 1006, loss is 0.7799811959266663\n",
      "epoch: 2 step: 1007, loss is 1.307884931564331\n",
      "epoch: 2 step: 1008, loss is 3.9707655906677246\n",
      "epoch: 2 step: 1009, loss is 1.2381579875946045\n",
      "epoch: 2 step: 1010, loss is 1.1522310972213745\n",
      "epoch: 2 step: 1011, loss is 0.30940431356430054\n",
      "epoch: 2 step: 1012, loss is 1.6252241134643555\n",
      "epoch: 2 step: 1013, loss is 1.893700122833252\n",
      "epoch: 2 step: 1014, loss is 0.2469688355922699\n",
      "epoch: 2 step: 1015, loss is 1.968508005142212\n",
      "epoch: 2 step: 1016, loss is 0.2265528440475464\n",
      "epoch: 2 step: 1017, loss is 0.8210608959197998\n",
      "epoch: 2 step: 1018, loss is 5.007937908172607\n",
      "epoch: 2 step: 1019, loss is 1.810429334640503\n",
      "epoch: 2 step: 1020, loss is 0.8673844933509827\n",
      "epoch: 2 step: 1021, loss is 0.1941768378019333\n",
      "epoch: 2 step: 1022, loss is 1.8496508598327637\n",
      "epoch: 2 step: 1023, loss is 1.9381217956542969\n",
      "epoch: 2 step: 1024, loss is 0.2747398316860199\n",
      "epoch: 2 step: 1025, loss is 2.3786275386810303\n",
      "epoch: 2 step: 1026, loss is 1.7996397018432617\n",
      "epoch: 2 step: 1027, loss is 1.2352869510650635\n",
      "epoch: 2 step: 1028, loss is 1.564345121383667\n",
      "epoch: 2 step: 1029, loss is 1.799101710319519\n",
      "epoch: 2 step: 1030, loss is 0.6739166975021362\n",
      "epoch: 2 step: 1031, loss is 0.8707043528556824\n",
      "epoch: 2 step: 1032, loss is 1.4965287446975708\n",
      "epoch: 2 step: 1033, loss is 0.11880484968423843\n",
      "epoch: 2 step: 1034, loss is 0.3210608959197998\n",
      "epoch: 2 step: 1035, loss is 0.26591429114341736\n",
      "epoch: 2 step: 1036, loss is 0.5649278163909912\n",
      "epoch: 2 step: 1037, loss is 0.37675583362579346\n",
      "epoch: 2 step: 1038, loss is 0.262276828289032\n",
      "epoch: 2 step: 1039, loss is 0.09737083315849304\n",
      "epoch: 2 step: 1040, loss is 0.3509514629840851\n",
      "epoch: 2 step: 1041, loss is 1.651271104812622\n",
      "epoch: 2 step: 1042, loss is 2.1030936241149902\n",
      "epoch: 2 step: 1043, loss is 0.5239689946174622\n",
      "epoch: 2 step: 1044, loss is 2.2951231002807617\n",
      "epoch: 2 step: 1045, loss is 1.50906503200531\n",
      "epoch: 2 step: 1046, loss is 0.25278255343437195\n",
      "epoch: 2 step: 1047, loss is 0.06867669522762299\n",
      "epoch: 2 step: 1048, loss is 1.8601186275482178\n",
      "epoch: 2 step: 1049, loss is 0.2211015522480011\n",
      "epoch: 2 step: 1050, loss is 0.20259933173656464\n",
      "epoch: 2 step: 1051, loss is 1.565760612487793\n",
      "epoch: 2 step: 1052, loss is 2.3469417095184326\n",
      "epoch: 2 step: 1053, loss is 5.236647605895996\n",
      "epoch: 2 step: 1054, loss is 0.8361976146697998\n",
      "epoch: 2 step: 1055, loss is 1.9759199619293213\n",
      "epoch: 2 step: 1056, loss is 1.6612904071807861\n",
      "epoch: 2 step: 1057, loss is 0.6964972019195557\n",
      "epoch: 2 step: 1058, loss is 1.5642589330673218\n",
      "epoch: 2 step: 1059, loss is 0.7983741760253906\n",
      "epoch: 2 step: 1060, loss is 0.24893884360790253\n",
      "epoch: 2 step: 1061, loss is 0.22196535766124725\n",
      "epoch: 2 step: 1062, loss is 0.45488226413726807\n",
      "epoch: 2 step: 1063, loss is 1.6925467252731323\n",
      "epoch: 2 step: 1064, loss is 0.9568051099777222\n",
      "epoch: 2 step: 1065, loss is 0.9261948466300964\n",
      "epoch: 2 step: 1066, loss is 0.11403847485780716\n",
      "epoch: 2 step: 1067, loss is 0.6151006817817688\n",
      "epoch: 2 step: 1068, loss is 0.5813184380531311\n",
      "epoch: 2 step: 1069, loss is 1.7830510139465332\n",
      "epoch: 2 step: 1070, loss is 1.7089835405349731\n",
      "epoch: 2 step: 1071, loss is 0.12885282933712006\n",
      "epoch: 2 step: 1072, loss is 2.5016818046569824\n",
      "epoch: 2 step: 1073, loss is 1.2326481342315674\n",
      "epoch: 2 step: 1074, loss is 2.8413150310516357\n",
      "epoch: 2 step: 1075, loss is 1.476243495941162\n",
      "epoch: 2 step: 1076, loss is 1.2334156036376953\n",
      "epoch: 2 step: 1077, loss is 2.8409342765808105\n",
      "epoch: 2 step: 1078, loss is 2.2850184440612793\n",
      "epoch: 2 step: 1079, loss is 0.7328307032585144\n",
      "epoch: 2 step: 1080, loss is 1.0380152463912964\n",
      "epoch: 2 step: 1081, loss is 1.2478867769241333\n",
      "epoch: 2 step: 1082, loss is 0.5604982376098633\n",
      "epoch: 2 step: 1083, loss is 1.4975810050964355\n",
      "epoch: 2 step: 1084, loss is 0.6661090850830078\n",
      "epoch: 2 step: 1085, loss is 1.828948974609375\n",
      "epoch: 2 step: 1086, loss is 0.2587517201900482\n",
      "epoch: 2 step: 1087, loss is 0.8279812932014465\n",
      "epoch: 2 step: 1088, loss is 0.8945007920265198\n",
      "epoch: 2 step: 1089, loss is 0.3916948735713959\n",
      "epoch: 2 step: 1090, loss is 0.256185919046402\n",
      "epoch: 2 step: 1091, loss is 0.2779468297958374\n",
      "epoch: 2 step: 1092, loss is 1.8900318145751953\n",
      "epoch: 2 step: 1093, loss is 0.23423919081687927\n",
      "epoch: 2 step: 1094, loss is 1.8214776515960693\n",
      "epoch: 2 step: 1095, loss is 0.20147745311260223\n",
      "epoch: 2 step: 1096, loss is 2.000654935836792\n",
      "epoch: 2 step: 1097, loss is 2.3579702377319336\n",
      "epoch: 2 step: 1098, loss is 0.7732915878295898\n",
      "epoch: 2 step: 1099, loss is 1.6388779878616333\n",
      "epoch: 2 step: 1100, loss is 1.407306432723999\n",
      "epoch: 2 step: 1101, loss is 0.6278565526008606\n",
      "epoch: 2 step: 1102, loss is 1.5165860652923584\n",
      "epoch: 2 step: 1103, loss is 0.4440743327140808\n",
      "epoch: 2 step: 1104, loss is 1.7914726734161377\n",
      "epoch: 2 step: 1105, loss is 1.6332578659057617\n",
      "epoch: 2 step: 1106, loss is 0.2695295810699463\n",
      "epoch: 2 step: 1107, loss is 0.053550999611616135\n",
      "epoch: 2 step: 1108, loss is 0.208772674202919\n",
      "epoch: 2 step: 1109, loss is 0.6686981320381165\n",
      "epoch: 2 step: 1110, loss is 0.08150255680084229\n",
      "epoch: 2 step: 1111, loss is 0.04946926608681679\n",
      "epoch: 2 step: 1112, loss is 0.1500692516565323\n",
      "epoch: 2 step: 1113, loss is 1.8532623052597046\n",
      "epoch: 2 step: 1114, loss is 0.35123348236083984\n",
      "epoch: 2 step: 1115, loss is 0.10420461744070053\n",
      "epoch: 2 step: 1116, loss is 0.14224906265735626\n",
      "epoch: 2 step: 1117, loss is 0.02556772530078888\n",
      "epoch: 2 step: 1118, loss is 2.951456308364868\n",
      "epoch: 2 step: 1119, loss is 0.9936433434486389\n",
      "epoch: 2 step: 1120, loss is 0.31807252764701843\n",
      "epoch: 2 step: 1121, loss is 1.6989331245422363\n",
      "epoch: 2 step: 1122, loss is 0.3128758668899536\n",
      "epoch: 2 step: 1123, loss is 2.3943052291870117\n",
      "epoch: 2 step: 1124, loss is 0.8719973564147949\n",
      "epoch: 2 step: 1125, loss is 0.07236950099468231\n",
      "epoch: 2 step: 1126, loss is 0.15467692911624908\n",
      "epoch: 2 step: 1127, loss is 1.6519395112991333\n",
      "epoch: 2 step: 1128, loss is 0.024069249629974365\n",
      "epoch: 2 step: 1129, loss is 0.12012706696987152\n",
      "epoch: 2 step: 1130, loss is 2.093125820159912\n",
      "epoch: 2 step: 1131, loss is 4.095810413360596\n",
      "epoch: 2 step: 1132, loss is 1.703148365020752\n",
      "epoch: 2 step: 1133, loss is 1.028646469116211\n",
      "epoch: 2 step: 1134, loss is 0.14188821613788605\n",
      "epoch: 2 step: 1135, loss is 2.3349199295043945\n",
      "epoch: 2 step: 1136, loss is 0.2187652885913849\n",
      "epoch: 2 step: 1137, loss is 1.0274465084075928\n",
      "epoch: 2 step: 1138, loss is 0.18108463287353516\n",
      "epoch: 2 step: 1139, loss is 0.02686193771660328\n",
      "epoch: 2 step: 1140, loss is 0.26017534732818604\n",
      "epoch: 2 step: 1141, loss is 2.176917791366577\n",
      "epoch: 2 step: 1142, loss is 1.230039119720459\n",
      "epoch: 2 step: 1143, loss is 0.8202770352363586\n",
      "epoch: 2 step: 1144, loss is 0.46417486667633057\n",
      "epoch: 2 step: 1145, loss is 0.06224578619003296\n",
      "epoch: 2 step: 1146, loss is 2.1522703170776367\n",
      "epoch: 2 step: 1147, loss is 0.8733857870101929\n",
      "epoch: 2 step: 1148, loss is 0.80760657787323\n",
      "epoch: 2 step: 1149, loss is 1.5168473720550537\n",
      "epoch: 2 step: 1150, loss is 1.0753936767578125\n",
      "epoch: 2 step: 1151, loss is 0.257272332906723\n",
      "epoch: 2 step: 1152, loss is 0.06195954605937004\n",
      "epoch: 2 step: 1153, loss is 0.04188431799411774\n",
      "epoch: 2 step: 1154, loss is 0.6028986573219299\n",
      "epoch: 2 step: 1155, loss is 2.262115955352783\n",
      "epoch: 2 step: 1156, loss is 0.33788564801216125\n",
      "epoch: 2 step: 1157, loss is 0.3710893392562866\n",
      "epoch: 2 step: 1158, loss is 0.030540669336915016\n",
      "epoch: 2 step: 1159, loss is 0.008800412528216839\n",
      "epoch: 2 step: 1160, loss is 2.0267248153686523\n",
      "epoch: 2 step: 1161, loss is 0.21068692207336426\n",
      "epoch: 2 step: 1162, loss is 3.1387596130371094\n",
      "epoch: 2 step: 1163, loss is 1.6832714080810547\n",
      "epoch: 2 step: 1164, loss is 0.2449914813041687\n",
      "epoch: 2 step: 1165, loss is 0.27765417098999023\n",
      "epoch: 2 step: 1166, loss is 1.4204094409942627\n",
      "epoch: 2 step: 1167, loss is 1.5731884241104126\n",
      "epoch: 2 step: 1168, loss is 1.4275256395339966\n",
      "epoch: 2 step: 1169, loss is 0.5654743313789368\n",
      "epoch: 2 step: 1170, loss is 0.3138769865036011\n",
      "epoch: 2 step: 1171, loss is 0.04456015303730965\n",
      "epoch: 2 step: 1172, loss is 0.02070818841457367\n",
      "epoch: 2 step: 1173, loss is 4.06754732131958\n",
      "epoch: 2 step: 1174, loss is 0.10134077072143555\n",
      "epoch: 2 step: 1175, loss is 1.5532734394073486\n",
      "epoch: 2 step: 1176, loss is 0.3751216232776642\n",
      "epoch: 2 step: 1177, loss is 1.4067965745925903\n",
      "epoch: 2 step: 1178, loss is 2.2998571395874023\n",
      "epoch: 2 step: 1179, loss is 0.3745424151420593\n",
      "epoch: 2 step: 1180, loss is 0.5083953142166138\n",
      "epoch: 2 step: 1181, loss is 0.18743973970413208\n",
      "epoch: 2 step: 1182, loss is 1.299203634262085\n",
      "epoch: 2 step: 1183, loss is 0.11995716392993927\n",
      "epoch: 2 step: 1184, loss is 0.19794213771820068\n",
      "epoch: 2 step: 1185, loss is 0.19801948964595795\n",
      "epoch: 2 step: 1186, loss is 0.4531159996986389\n",
      "epoch: 2 step: 1187, loss is 0.14240455627441406\n",
      "epoch: 2 step: 1188, loss is 0.2955731451511383\n",
      "epoch: 2 step: 1189, loss is 0.33563315868377686\n",
      "epoch: 2 step: 1190, loss is 0.1578453630208969\n",
      "epoch: 2 step: 1191, loss is 0.13197363913059235\n",
      "epoch: 2 step: 1192, loss is 4.117990016937256\n",
      "epoch: 2 step: 1193, loss is 0.08914992958307266\n",
      "epoch: 2 step: 1194, loss is 0.3751930296421051\n",
      "epoch: 2 step: 1195, loss is 4.380207061767578\n",
      "epoch: 2 step: 1196, loss is 1.261246681213379\n",
      "epoch: 2 step: 1197, loss is 1.659780740737915\n",
      "epoch: 2 step: 1198, loss is 0.23441337049007416\n",
      "epoch: 2 step: 1199, loss is 0.31493839621543884\n",
      "epoch: 2 step: 1200, loss is 0.2836838960647583\n",
      "epoch: 2 step: 1201, loss is 0.3859802484512329\n",
      "epoch: 2 step: 1202, loss is 0.44427648186683655\n",
      "epoch: 2 step: 1203, loss is 1.9646663665771484\n",
      "epoch: 2 step: 1204, loss is 0.21375061571598053\n",
      "epoch: 2 step: 1205, loss is 1.7535810470581055\n",
      "epoch: 2 step: 1206, loss is 0.3207756578922272\n",
      "epoch: 2 step: 1207, loss is 0.23463456332683563\n",
      "epoch: 2 step: 1208, loss is 0.15365372598171234\n",
      "epoch: 2 step: 1209, loss is 1.802054524421692\n",
      "epoch: 2 step: 1210, loss is 0.030889561399817467\n",
      "epoch: 2 step: 1211, loss is 0.30063313245773315\n",
      "epoch: 2 step: 1212, loss is 0.6800730228424072\n",
      "epoch: 2 step: 1213, loss is 0.21131110191345215\n",
      "epoch: 2 step: 1214, loss is 0.11507485806941986\n",
      "epoch: 2 step: 1215, loss is 0.19055980443954468\n",
      "epoch: 2 step: 1216, loss is 0.35063618421554565\n",
      "epoch: 2 step: 1217, loss is 0.3383670449256897\n",
      "epoch: 2 step: 1218, loss is 0.18458609282970428\n",
      "epoch: 2 step: 1219, loss is 0.09956233948469162\n",
      "epoch: 2 step: 1220, loss is 0.10002323240041733\n",
      "epoch: 2 step: 1221, loss is 0.09778808802366257\n",
      "epoch: 2 step: 1222, loss is 1.8573453426361084\n",
      "epoch: 2 step: 1223, loss is 0.021221360191702843\n",
      "epoch: 2 step: 1224, loss is 0.07830370962619781\n",
      "epoch: 2 step: 1225, loss is 1.9000693559646606\n",
      "epoch: 2 step: 1226, loss is 0.36829957365989685\n",
      "epoch: 2 step: 1227, loss is 0.14718374609947205\n",
      "epoch: 2 step: 1228, loss is 1.956973910331726\n",
      "epoch: 2 step: 1229, loss is 0.5337188243865967\n",
      "epoch: 2 step: 1230, loss is 1.0020791292190552\n",
      "epoch: 2 step: 1231, loss is 0.05025339126586914\n",
      "epoch: 2 step: 1232, loss is 1.5920825004577637\n",
      "epoch: 2 step: 1233, loss is 1.758897304534912\n",
      "epoch: 2 step: 1234, loss is 0.23881937563419342\n",
      "epoch: 2 step: 1235, loss is 0.13865888118743896\n",
      "epoch: 2 step: 1236, loss is 0.2092536836862564\n",
      "epoch: 2 step: 1237, loss is 0.018158389255404472\n",
      "epoch: 2 step: 1238, loss is 0.09421797096729279\n",
      "epoch: 2 step: 1239, loss is 2.317445755004883\n",
      "epoch: 2 step: 1240, loss is 1.9148118495941162\n",
      "epoch: 2 step: 1241, loss is 0.04792269319295883\n",
      "epoch: 2 step: 1242, loss is 0.6792948246002197\n",
      "epoch: 2 step: 1243, loss is 0.6042765974998474\n",
      "epoch: 2 step: 1244, loss is 0.054574646055698395\n",
      "epoch: 2 step: 1245, loss is 1.642622470855713\n",
      "epoch: 2 step: 1246, loss is 0.04129013791680336\n",
      "epoch: 2 step: 1247, loss is 0.02814752236008644\n",
      "epoch: 2 step: 1248, loss is 0.029728546738624573\n",
      "epoch: 2 step: 1249, loss is 0.028550079092383385\n",
      "epoch: 2 step: 1250, loss is 1.6345884799957275\n",
      "epoch: 2 step: 1251, loss is 0.21103160083293915\n",
      "epoch: 2 step: 1252, loss is 0.12478271871805191\n",
      "epoch: 2 step: 1253, loss is 1.9156763553619385\n",
      "epoch: 2 step: 1254, loss is 0.09691433608531952\n",
      "epoch: 2 step: 1255, loss is 0.08398274332284927\n",
      "epoch: 2 step: 1256, loss is 0.01754665933549404\n",
      "epoch: 2 step: 1257, loss is 0.035924386233091354\n",
      "epoch: 2 step: 1258, loss is 0.30386418104171753\n",
      "epoch: 2 step: 1259, loss is 0.006610194221138954\n",
      "epoch: 2 step: 1260, loss is 2.313438653945923\n",
      "epoch: 2 step: 1261, loss is 2.8027660846710205\n",
      "epoch: 2 step: 1262, loss is 0.5604820847511292\n",
      "epoch: 2 step: 1263, loss is 0.08690430968999863\n",
      "epoch: 2 step: 1264, loss is 0.5511276721954346\n",
      "epoch: 2 step: 1265, loss is 0.04019084572792053\n",
      "epoch: 2 step: 1266, loss is 1.2224104404449463\n",
      "epoch: 2 step: 1267, loss is 0.019479522481560707\n",
      "epoch: 2 step: 1268, loss is 0.003949818201363087\n",
      "epoch: 2 step: 1269, loss is 1.498839259147644\n",
      "epoch: 2 step: 1270, loss is 0.03101287968456745\n",
      "epoch: 2 step: 1271, loss is 0.5737518668174744\n",
      "epoch: 2 step: 1272, loss is 0.02817070111632347\n",
      "epoch: 2 step: 1273, loss is 0.02591928467154503\n",
      "epoch: 2 step: 1274, loss is 1.5762768983840942\n",
      "epoch: 2 step: 1275, loss is 0.007146037183701992\n",
      "epoch: 2 step: 1276, loss is 0.04626446217298508\n",
      "epoch: 2 step: 1277, loss is 0.06699234992265701\n",
      "epoch: 2 step: 1278, loss is 0.0130317909643054\n",
      "epoch: 2 step: 1279, loss is 1.5138280391693115\n",
      "epoch: 2 step: 1280, loss is 2.613835573196411\n",
      "epoch: 2 step: 1281, loss is 4.874478816986084\n",
      "epoch: 2 step: 1282, loss is 3.695974826812744\n",
      "epoch: 2 step: 1283, loss is 0.10283222794532776\n",
      "epoch: 2 step: 1284, loss is 2.2357616424560547\n",
      "epoch: 2 step: 1285, loss is 1.4089730978012085\n",
      "epoch: 2 step: 1286, loss is 0.2538715600967407\n",
      "epoch: 2 step: 1287, loss is 0.09326627850532532\n",
      "epoch: 2 step: 1288, loss is 0.2921171188354492\n",
      "epoch: 2 step: 1289, loss is 2.615616798400879\n",
      "epoch: 2 step: 1290, loss is 2.104518175125122\n",
      "epoch: 2 step: 1291, loss is 0.404131144285202\n",
      "epoch: 2 step: 1292, loss is 2.089935302734375\n",
      "epoch: 2 step: 1293, loss is 0.13220062851905823\n",
      "epoch: 2 step: 1294, loss is 0.13842837512493134\n",
      "epoch: 2 step: 1295, loss is 4.544377326965332\n",
      "epoch: 2 step: 1296, loss is 0.7829676866531372\n",
      "epoch: 2 step: 1297, loss is 0.5118299126625061\n",
      "epoch: 2 step: 1298, loss is 1.7360564470291138\n",
      "epoch: 2 step: 1299, loss is 0.45670196413993835\n",
      "epoch: 2 step: 1300, loss is 1.8197604417800903\n",
      "epoch: 2 step: 1301, loss is 1.8321640491485596\n",
      "epoch: 2 step: 1302, loss is 0.918762743473053\n",
      "epoch: 2 step: 1303, loss is 2.468883514404297\n",
      "epoch: 2 step: 1304, loss is 1.152957797050476\n",
      "epoch: 2 step: 1305, loss is 0.12549419701099396\n",
      "epoch: 2 step: 1306, loss is 0.2094046175479889\n",
      "epoch: 2 step: 1307, loss is 1.8470773696899414\n",
      "epoch: 2 step: 1308, loss is 0.12146791070699692\n",
      "epoch: 2 step: 1309, loss is 1.6582655906677246\n",
      "epoch: 2 step: 1310, loss is 2.0566928386688232\n",
      "epoch: 2 step: 1311, loss is 1.79508376121521\n",
      "epoch: 2 step: 1312, loss is 1.864180088043213\n",
      "epoch: 2 step: 1313, loss is 1.1341487169265747\n",
      "epoch: 2 step: 1314, loss is 1.4280285835266113\n",
      "epoch: 2 step: 1315, loss is 0.24593836069107056\n",
      "epoch: 2 step: 1316, loss is 2.488243341445923\n",
      "epoch: 2 step: 1317, loss is 0.912583589553833\n",
      "epoch: 2 step: 1318, loss is 0.31566321849823\n",
      "epoch: 2 step: 1319, loss is 0.45260339975357056\n",
      "epoch: 2 step: 1320, loss is 0.18895509839057922\n",
      "epoch: 2 step: 1321, loss is 0.8226377964019775\n",
      "epoch: 2 step: 1322, loss is 0.2181863933801651\n",
      "epoch: 2 step: 1323, loss is 0.7969882488250732\n",
      "epoch: 2 step: 1324, loss is 0.057707175612449646\n",
      "epoch: 2 step: 1325, loss is 0.11710495501756668\n",
      "epoch: 2 step: 1326, loss is 0.38602912425994873\n",
      "epoch: 2 step: 1327, loss is 0.1287257969379425\n",
      "epoch: 2 step: 1328, loss is 0.48540782928466797\n",
      "epoch: 2 step: 1329, loss is 1.6441090106964111\n",
      "epoch: 2 step: 1330, loss is 1.6431918144226074\n",
      "epoch: 2 step: 1331, loss is 0.04466230422258377\n",
      "epoch: 2 step: 1332, loss is 1.5741721391677856\n",
      "epoch: 2 step: 1333, loss is 2.0530481338500977\n",
      "epoch: 2 step: 1334, loss is 0.04619799181818962\n",
      "epoch: 2 step: 1335, loss is 1.4966803789138794\n",
      "epoch: 2 step: 1336, loss is 0.26977381110191345\n",
      "epoch: 2 step: 1337, loss is 0.24775084853172302\n",
      "epoch: 2 step: 1338, loss is 2.572141170501709\n",
      "epoch: 2 step: 1339, loss is 2.0321531295776367\n",
      "epoch: 2 step: 1340, loss is 1.0380616188049316\n",
      "epoch: 2 step: 1341, loss is 2.7934751510620117\n",
      "epoch: 2 step: 1342, loss is 1.5293676853179932\n",
      "epoch: 2 step: 1343, loss is 2.3029394149780273\n",
      "epoch: 2 step: 1344, loss is 0.5809125304222107\n",
      "epoch: 2 step: 1345, loss is 1.3324439525604248\n",
      "epoch: 2 step: 1346, loss is 0.4605785012245178\n",
      "epoch: 2 step: 1347, loss is 0.262754887342453\n",
      "epoch: 2 step: 1348, loss is 0.21217086911201477\n",
      "epoch: 2 step: 1349, loss is 0.07625573128461838\n",
      "epoch: 2 step: 1350, loss is 0.07228444516658783\n",
      "epoch: 2 step: 1351, loss is 0.31646159291267395\n",
      "epoch: 2 step: 1352, loss is 1.5714349746704102\n",
      "epoch: 2 step: 1353, loss is 1.3227653503417969\n",
      "epoch: 2 step: 1354, loss is 0.10538341850042343\n",
      "epoch: 2 step: 1355, loss is 0.35008975863456726\n",
      "epoch: 2 step: 1356, loss is 0.051053326576948166\n",
      "epoch: 2 step: 1357, loss is 0.2907700836658478\n",
      "epoch: 2 step: 1358, loss is 1.7119574546813965\n",
      "epoch: 2 step: 1359, loss is 0.11329250037670135\n",
      "epoch: 2 step: 1360, loss is 0.09753250330686569\n",
      "epoch: 2 step: 1361, loss is 0.6538116335868835\n",
      "epoch: 2 step: 1362, loss is 2.6928553581237793\n",
      "epoch: 2 step: 1363, loss is 0.21994315087795258\n",
      "epoch: 2 step: 1364, loss is 2.332350730895996\n",
      "epoch: 2 step: 1365, loss is 3.146911144256592\n",
      "epoch: 2 step: 1366, loss is 0.2673531472682953\n",
      "epoch: 2 step: 1367, loss is 2.605029582977295\n",
      "epoch: 2 step: 1368, loss is 2.0353453159332275\n",
      "epoch: 2 step: 1369, loss is 0.23708203434944153\n",
      "epoch: 2 step: 1370, loss is 1.5323388576507568\n",
      "epoch: 2 step: 1371, loss is 0.4252585172653198\n",
      "epoch: 2 step: 1372, loss is 0.35448527336120605\n",
      "epoch: 2 step: 1373, loss is 2.4431099891662598\n",
      "epoch: 2 step: 1374, loss is 0.7118749022483826\n",
      "epoch: 2 step: 1375, loss is 0.41234850883483887\n",
      "epoch: 2 step: 1376, loss is 0.1559980809688568\n",
      "epoch: 2 step: 1377, loss is 0.14234790205955505\n",
      "epoch: 2 step: 1378, loss is 0.08220388740301132\n",
      "epoch: 2 step: 1379, loss is 0.34119561314582825\n",
      "epoch: 2 step: 1380, loss is 1.6717978715896606\n",
      "epoch: 2 step: 1381, loss is 1.3736082315444946\n",
      "epoch: 2 step: 1382, loss is 0.282074898481369\n",
      "epoch: 2 step: 1383, loss is 0.3628982901573181\n",
      "epoch: 2 step: 1384, loss is 1.3197085857391357\n",
      "epoch: 2 step: 1385, loss is 1.42965829372406\n",
      "epoch: 2 step: 1386, loss is 0.12096430361270905\n",
      "epoch: 2 step: 1387, loss is 1.38161039352417\n",
      "epoch: 2 step: 1388, loss is 1.221055030822754\n",
      "epoch: 2 step: 1389, loss is 0.1448839008808136\n",
      "epoch: 2 step: 1390, loss is 0.7784242033958435\n",
      "epoch: 2 step: 1391, loss is 0.4282017946243286\n",
      "epoch: 2 step: 1392, loss is 0.0422370471060276\n",
      "epoch: 2 step: 1393, loss is 0.13061940670013428\n",
      "epoch: 2 step: 1394, loss is 0.012544771656394005\n",
      "epoch: 2 step: 1395, loss is 0.07822345942258835\n",
      "epoch: 2 step: 1396, loss is 0.07264667749404907\n",
      "epoch: 2 step: 1397, loss is 0.03907337412238121\n",
      "epoch: 2 step: 1398, loss is 0.04296736791729927\n",
      "epoch: 2 step: 1399, loss is 1.5936239957809448\n",
      "epoch: 2 step: 1400, loss is 0.277978777885437\n",
      "epoch: 2 step: 1401, loss is 2.1375298500061035\n",
      "epoch: 2 step: 1402, loss is 4.306661128997803\n",
      "epoch: 2 step: 1403, loss is 0.09126941859722137\n",
      "epoch: 2 step: 1404, loss is 0.8384230136871338\n",
      "epoch: 2 step: 1405, loss is 0.7901030778884888\n",
      "epoch: 2 step: 1406, loss is 0.3560662865638733\n",
      "epoch: 2 step: 1407, loss is 1.6289925575256348\n",
      "epoch: 2 step: 1408, loss is 0.023349681869149208\n",
      "epoch: 2 step: 1409, loss is 2.992341995239258\n",
      "epoch: 2 step: 1410, loss is 2.5229008197784424\n",
      "epoch: 2 step: 1411, loss is 3.3669285774230957\n",
      "epoch: 2 step: 1412, loss is 1.7604992389678955\n",
      "epoch: 2 step: 1413, loss is 2.4641339778900146\n",
      "epoch: 2 step: 1414, loss is 0.03133641928434372\n",
      "epoch: 2 step: 1415, loss is 1.9918854236602783\n",
      "epoch: 2 step: 1416, loss is 0.0240743700414896\n",
      "epoch: 2 step: 1417, loss is 1.9606704711914062\n",
      "epoch: 2 step: 1418, loss is 2.5668420791625977\n",
      "epoch: 2 step: 1419, loss is 0.04657229781150818\n",
      "epoch: 2 step: 1420, loss is 0.6265249252319336\n",
      "epoch: 2 step: 1421, loss is 1.0451589822769165\n",
      "epoch: 2 step: 1422, loss is 1.6008185148239136\n",
      "epoch: 2 step: 1423, loss is 0.2640693783760071\n",
      "epoch: 2 step: 1424, loss is 0.5434865951538086\n",
      "epoch: 2 step: 1425, loss is 0.12520867586135864\n",
      "epoch: 2 step: 1426, loss is 2.802525520324707\n",
      "epoch: 2 step: 1427, loss is 2.034315824508667\n",
      "epoch: 2 step: 1428, loss is 1.9372003078460693\n",
      "epoch: 2 step: 1429, loss is 0.4429396092891693\n",
      "epoch: 2 step: 1430, loss is 0.15136657655239105\n",
      "epoch: 2 step: 1431, loss is 0.27238601446151733\n",
      "epoch: 2 step: 1432, loss is 1.6392793655395508\n",
      "epoch: 2 step: 1433, loss is 1.9923913478851318\n",
      "epoch: 2 step: 1434, loss is 0.2825729548931122\n",
      "epoch: 2 step: 1435, loss is 0.06756466627120972\n",
      "epoch: 2 step: 1436, loss is 0.5382239818572998\n",
      "epoch: 2 step: 1437, loss is 0.48187845945358276\n",
      "epoch: 2 step: 1438, loss is 2.2013866901397705\n",
      "epoch: 2 step: 1439, loss is 1.5658698081970215\n",
      "epoch: 2 step: 1440, loss is 0.1647399365901947\n",
      "epoch: 2 step: 1441, loss is 1.5723426342010498\n",
      "epoch: 2 step: 1442, loss is 1.236685872077942\n",
      "epoch: 2 step: 1443, loss is 0.9483878016471863\n",
      "epoch: 2 step: 1444, loss is 0.8029541969299316\n",
      "epoch: 2 step: 1445, loss is 0.11606547981500626\n",
      "epoch: 2 step: 1446, loss is 2.1321892738342285\n",
      "epoch: 2 step: 1447, loss is 0.010266942903399467\n",
      "epoch: 2 step: 1448, loss is 0.025630123913288116\n",
      "epoch: 2 step: 1449, loss is 2.72009539604187\n",
      "epoch: 2 step: 1450, loss is 0.08872348070144653\n",
      "epoch: 2 step: 1451, loss is 0.1286984533071518\n",
      "epoch: 2 step: 1452, loss is 0.0279939416795969\n",
      "epoch: 2 step: 1453, loss is 3.121241331100464\n",
      "epoch: 2 step: 1454, loss is 2.820636749267578\n",
      "epoch: 2 step: 1455, loss is 0.5325294137001038\n",
      "epoch: 2 step: 1456, loss is 0.031559258699417114\n",
      "epoch: 2 step: 1457, loss is 0.06486094743013382\n",
      "epoch: 2 step: 1458, loss is 0.3270706534385681\n",
      "epoch: 2 step: 1459, loss is 1.952314019203186\n",
      "epoch: 2 step: 1460, loss is 1.867710828781128\n",
      "epoch: 2 step: 1461, loss is 0.3855274021625519\n",
      "epoch: 2 step: 1462, loss is 3.7707552909851074\n",
      "epoch: 2 step: 1463, loss is 0.3837277293205261\n",
      "epoch: 2 step: 1464, loss is 4.241016864776611\n",
      "epoch: 2 step: 1465, loss is 0.5834521055221558\n",
      "epoch: 2 step: 1466, loss is 0.10644958913326263\n",
      "epoch: 2 step: 1467, loss is 1.5751729011535645\n",
      "epoch: 2 step: 1468, loss is 1.4071424007415771\n",
      "epoch: 2 step: 1469, loss is 0.6752806305885315\n",
      "epoch: 2 step: 1470, loss is 1.409386396408081\n",
      "epoch: 2 step: 1471, loss is 1.6605315208435059\n",
      "epoch: 2 step: 1472, loss is 0.7751619815826416\n",
      "epoch: 2 step: 1473, loss is 1.8477119207382202\n",
      "epoch: 2 step: 1474, loss is 1.4396836757659912\n",
      "epoch: 2 step: 1475, loss is 1.5674266815185547\n",
      "epoch: 2 step: 1476, loss is 0.8340597748756409\n",
      "epoch: 2 step: 1477, loss is 0.40971675515174866\n",
      "epoch: 2 step: 1478, loss is 0.16093893349170685\n",
      "epoch: 2 step: 1479, loss is 1.4826635122299194\n",
      "epoch: 2 step: 1480, loss is 0.16887952387332916\n",
      "epoch: 2 step: 1481, loss is 0.17274782061576843\n",
      "epoch: 2 step: 1482, loss is 2.382847309112549\n",
      "epoch: 2 step: 1483, loss is 2.1778810024261475\n",
      "epoch: 2 step: 1484, loss is 0.5655574798583984\n",
      "epoch: 2 step: 1485, loss is 0.553098738193512\n",
      "epoch: 2 step: 1486, loss is 0.16222426295280457\n",
      "epoch: 2 step: 1487, loss is 0.05266032740473747\n",
      "epoch: 2 step: 1488, loss is 1.9604628086090088\n",
      "epoch: 2 step: 1489, loss is 0.48288625478744507\n",
      "epoch: 2 step: 1490, loss is 0.5226907134056091\n",
      "epoch: 2 step: 1491, loss is 2.056093454360962\n",
      "epoch: 2 step: 1492, loss is 0.02644081972539425\n",
      "epoch: 2 step: 1493, loss is 0.45410558581352234\n",
      "epoch: 2 step: 1494, loss is 0.03369303047657013\n",
      "epoch: 2 step: 1495, loss is 0.4812662899494171\n",
      "epoch: 2 step: 1496, loss is 2.824070930480957\n",
      "epoch: 2 step: 1497, loss is 0.38961026072502136\n",
      "epoch: 2 step: 1498, loss is 0.08240316063165665\n",
      "epoch: 2 step: 1499, loss is 0.33677420020103455\n",
      "epoch: 2 step: 1500, loss is 1.8241076469421387\n",
      "epoch: 2 step: 1501, loss is 0.3166802227497101\n",
      "epoch: 2 step: 1502, loss is 0.28472936153411865\n",
      "epoch: 2 step: 1503, loss is 0.4291364848613739\n",
      "epoch: 2 step: 1504, loss is 3.2152185440063477\n",
      "epoch: 2 step: 1505, loss is 1.5924816131591797\n",
      "epoch: 2 step: 1506, loss is 1.2404582500457764\n",
      "epoch: 2 step: 1507, loss is 1.9829275608062744\n",
      "epoch: 2 step: 1508, loss is 0.08336053043603897\n",
      "epoch: 2 step: 1509, loss is 0.4790608584880829\n",
      "epoch: 2 step: 1510, loss is 2.4560720920562744\n",
      "epoch: 2 step: 1511, loss is 0.5804685950279236\n",
      "epoch: 2 step: 1512, loss is 0.13727855682373047\n",
      "epoch: 2 step: 1513, loss is 0.16828882694244385\n",
      "epoch: 2 step: 1514, loss is 0.14979691803455353\n",
      "epoch: 2 step: 1515, loss is 2.936386823654175\n",
      "epoch: 2 step: 1516, loss is 0.10453174263238907\n",
      "epoch: 2 step: 1517, loss is 2.1214938163757324\n",
      "epoch: 2 step: 1518, loss is 0.12295529246330261\n",
      "epoch: 2 step: 1519, loss is 1.7051782608032227\n",
      "epoch: 2 step: 1520, loss is 0.20120610296726227\n",
      "epoch: 2 step: 1521, loss is 2.057638645172119\n",
      "epoch: 2 step: 1522, loss is 0.8711234927177429\n",
      "epoch: 2 step: 1523, loss is 1.4772957563400269\n",
      "epoch: 2 step: 1524, loss is 0.06851073354482651\n",
      "epoch: 2 step: 1525, loss is 0.5937581062316895\n",
      "epoch: 2 step: 1526, loss is 1.6442792415618896\n",
      "epoch: 2 step: 1527, loss is 0.39217451214790344\n",
      "epoch: 2 step: 1528, loss is 1.6134008169174194\n",
      "epoch: 2 step: 1529, loss is 0.16214966773986816\n",
      "epoch: 2 step: 1530, loss is 0.4258440434932709\n",
      "epoch: 2 step: 1531, loss is 0.06113151088356972\n",
      "epoch: 2 step: 1532, loss is 0.36186811327934265\n",
      "epoch: 2 step: 1533, loss is 0.044614650309085846\n",
      "epoch: 2 step: 1534, loss is 0.544924259185791\n",
      "epoch: 2 step: 1535, loss is 1.8022842407226562\n",
      "epoch: 2 step: 1536, loss is 1.6428449153900146\n",
      "epoch: 2 step: 1537, loss is 0.22860963642597198\n",
      "epoch: 2 step: 1538, loss is 1.4757025241851807\n",
      "epoch: 2 step: 1539, loss is 0.08291713148355484\n",
      "epoch: 2 step: 1540, loss is 0.32285916805267334\n",
      "epoch: 2 step: 1541, loss is 0.17312365770339966\n",
      "epoch: 2 step: 1542, loss is 0.45956119894981384\n",
      "epoch: 2 step: 1543, loss is 3.151062250137329\n",
      "epoch: 2 step: 1544, loss is 1.6877477169036865\n",
      "epoch: 2 step: 1545, loss is 1.4331459999084473\n",
      "epoch: 2 step: 1546, loss is 1.6445611715316772\n",
      "epoch: 2 step: 1547, loss is 3.4449117183685303\n",
      "epoch: 2 step: 1548, loss is 1.9251981973648071\n",
      "epoch: 2 step: 1549, loss is 0.5201587080955505\n",
      "epoch: 2 step: 1550, loss is 2.069993734359741\n",
      "epoch: 2 step: 1551, loss is 2.7553892135620117\n",
      "epoch: 2 step: 1552, loss is 1.6428368091583252\n",
      "epoch: 2 step: 1553, loss is 1.3920133113861084\n",
      "epoch: 2 step: 1554, loss is 1.8293778896331787\n",
      "epoch: 2 step: 1555, loss is 0.42517179250717163\n",
      "epoch: 2 step: 1556, loss is 1.4792873859405518\n",
      "epoch: 2 step: 1557, loss is 0.2749653458595276\n",
      "epoch: 2 step: 1558, loss is 0.46450740098953247\n",
      "epoch: 2 step: 1559, loss is 1.4462087154388428\n",
      "epoch: 2 step: 1560, loss is 0.04530620947480202\n",
      "epoch: 2 step: 1561, loss is 0.11524718254804611\n",
      "epoch: 2 step: 1562, loss is 0.3978801369667053\n",
      "epoch: 2 step: 1563, loss is 0.0057372660376131535\n",
      "epoch: 2 step: 1564, loss is 1.8920085430145264\n",
      "epoch: 2 step: 1565, loss is 0.07136313617229462\n",
      "epoch: 2 step: 1566, loss is 2.1265084743499756\n",
      "epoch: 2 step: 1567, loss is 2.484753131866455\n",
      "epoch: 2 step: 1568, loss is 0.10303528606891632\n",
      "epoch: 2 step: 1569, loss is 0.20680637657642365\n",
      "epoch: 2 step: 1570, loss is 2.230501413345337\n",
      "epoch: 2 step: 1571, loss is 0.40455639362335205\n",
      "epoch: 2 step: 1572, loss is 0.07366858422756195\n",
      "epoch: 2 step: 1573, loss is 0.6458368897438049\n",
      "epoch: 2 step: 1574, loss is 1.3140900135040283\n",
      "epoch: 2 step: 1575, loss is 0.367940217256546\n",
      "epoch: 2 step: 1576, loss is 0.5519669651985168\n",
      "epoch: 2 step: 1577, loss is 0.028491917997598648\n",
      "epoch: 2 step: 1578, loss is 0.08170713484287262\n",
      "epoch: 2 step: 1579, loss is 0.046585384756326675\n",
      "epoch: 2 step: 1580, loss is 2.3624353408813477\n",
      "epoch: 2 step: 1581, loss is 0.1417761892080307\n",
      "epoch: 2 step: 1582, loss is 2.6585097312927246\n",
      "epoch: 2 step: 1583, loss is 0.0324646458029747\n",
      "epoch: 2 step: 1584, loss is 0.14096085727214813\n",
      "epoch: 2 step: 1585, loss is 0.08634056150913239\n",
      "epoch: 2 step: 1586, loss is 0.35323774814605713\n",
      "epoch: 2 step: 1587, loss is 0.010349887423217297\n",
      "epoch: 2 step: 1588, loss is 0.4468650817871094\n",
      "epoch: 2 step: 1589, loss is 0.022087061777710915\n",
      "epoch: 2 step: 1590, loss is 0.07716382294893265\n",
      "epoch: 2 step: 1591, loss is 0.12907445430755615\n",
      "epoch: 2 step: 1592, loss is 2.2493691444396973\n",
      "epoch: 2 step: 1593, loss is 0.3015928268432617\n",
      "epoch: 2 step: 1594, loss is 0.3235440254211426\n",
      "epoch: 2 step: 1595, loss is 1.9971554279327393\n",
      "epoch: 2 step: 1596, loss is 0.15614737570285797\n",
      "epoch: 2 step: 1597, loss is 0.07914640009403229\n",
      "epoch: 2 step: 1598, loss is 0.10557115077972412\n",
      "epoch: 2 step: 1599, loss is 0.045244574546813965\n",
      "epoch: 2 step: 1600, loss is 4.124802112579346\n",
      "epoch: 3 step: 1, loss is 1.706357479095459\n",
      "epoch: 3 step: 2, loss is 2.2427492141723633\n",
      "epoch: 3 step: 3, loss is 1.8130016326904297\n",
      "epoch: 3 step: 4, loss is 2.7923665046691895\n",
      "epoch: 3 step: 5, loss is 1.198880672454834\n",
      "epoch: 3 step: 6, loss is 2.0703587532043457\n",
      "epoch: 3 step: 7, loss is 1.103494644165039\n",
      "epoch: 3 step: 8, loss is 1.7698731422424316\n",
      "epoch: 3 step: 9, loss is 1.8094701766967773\n",
      "epoch: 3 step: 10, loss is 2.2840139865875244\n",
      "epoch: 3 step: 11, loss is 0.5318122506141663\n",
      "epoch: 3 step: 12, loss is 0.4766556918621063\n",
      "epoch: 3 step: 13, loss is 1.9301022291183472\n",
      "epoch: 3 step: 14, loss is 3.2076375484466553\n",
      "epoch: 3 step: 15, loss is 1.1237820386886597\n",
      "epoch: 3 step: 16, loss is 1.9549660682678223\n",
      "epoch: 3 step: 17, loss is 1.8162243366241455\n",
      "epoch: 3 step: 18, loss is 1.5521163940429688\n",
      "epoch: 3 step: 19, loss is 2.4276812076568604\n",
      "epoch: 3 step: 20, loss is 0.2511831223964691\n",
      "epoch: 3 step: 21, loss is 0.32272735238075256\n",
      "epoch: 3 step: 22, loss is 1.3983774185180664\n",
      "epoch: 3 step: 23, loss is 0.37801358103752136\n",
      "epoch: 3 step: 24, loss is 1.4813730716705322\n",
      "epoch: 3 step: 25, loss is 2.4636454582214355\n",
      "epoch: 3 step: 26, loss is 2.0872979164123535\n",
      "epoch: 3 step: 27, loss is 0.8697580695152283\n",
      "epoch: 3 step: 28, loss is 0.3725396394729614\n",
      "epoch: 3 step: 29, loss is 1.233883261680603\n",
      "epoch: 3 step: 30, loss is 0.8843379616737366\n",
      "epoch: 3 step: 31, loss is 2.1987013816833496\n",
      "epoch: 3 step: 32, loss is 0.501599907875061\n",
      "epoch: 3 step: 33, loss is 0.09469576179981232\n",
      "epoch: 3 step: 34, loss is 0.2640570402145386\n",
      "epoch: 3 step: 35, loss is 2.1215944290161133\n",
      "epoch: 3 step: 36, loss is 0.15572184324264526\n",
      "epoch: 3 step: 37, loss is 1.567352056503296\n",
      "epoch: 3 step: 38, loss is 0.5330268144607544\n",
      "epoch: 3 step: 39, loss is 0.3698079586029053\n",
      "epoch: 3 step: 40, loss is 0.20357845723628998\n",
      "epoch: 3 step: 41, loss is 1.5286887884140015\n",
      "epoch: 3 step: 42, loss is 2.8085813522338867\n",
      "epoch: 3 step: 43, loss is 1.644290804862976\n",
      "epoch: 3 step: 44, loss is 1.2326701879501343\n",
      "epoch: 3 step: 45, loss is 1.3539658784866333\n",
      "epoch: 3 step: 46, loss is 4.462424278259277\n",
      "epoch: 3 step: 47, loss is 0.5542643070220947\n",
      "epoch: 3 step: 48, loss is 1.3208621740341187\n",
      "epoch: 3 step: 49, loss is 1.2526878118515015\n",
      "epoch: 3 step: 50, loss is 0.7661034464836121\n",
      "epoch: 3 step: 51, loss is 1.847079873085022\n",
      "epoch: 3 step: 52, loss is 2.1570510864257812\n",
      "epoch: 3 step: 53, loss is 1.9307454824447632\n",
      "epoch: 3 step: 54, loss is 0.1170310452580452\n",
      "epoch: 3 step: 55, loss is 0.8012036681175232\n",
      "epoch: 3 step: 56, loss is 1.6528427600860596\n",
      "epoch: 3 step: 57, loss is 0.3330807685852051\n",
      "epoch: 3 step: 58, loss is 1.8350831270217896\n",
      "epoch: 3 step: 59, loss is 2.0024254322052\n",
      "epoch: 3 step: 60, loss is 0.300310343503952\n",
      "epoch: 3 step: 61, loss is 0.06787180155515671\n",
      "epoch: 3 step: 62, loss is 0.5297350883483887\n",
      "epoch: 3 step: 63, loss is 0.17773126065731049\n",
      "epoch: 3 step: 64, loss is 2.060260772705078\n",
      "epoch: 3 step: 65, loss is 2.057948589324951\n",
      "epoch: 3 step: 66, loss is 0.3847101628780365\n",
      "epoch: 3 step: 67, loss is 2.3296122550964355\n",
      "epoch: 3 step: 68, loss is 0.25404447317123413\n",
      "epoch: 3 step: 69, loss is 0.35816872119903564\n",
      "epoch: 3 step: 70, loss is 0.15257082879543304\n",
      "epoch: 3 step: 71, loss is 0.6631478071212769\n",
      "epoch: 3 step: 72, loss is 1.6067460775375366\n",
      "epoch: 3 step: 73, loss is 0.026657436043024063\n",
      "epoch: 3 step: 74, loss is 1.5587947368621826\n",
      "epoch: 3 step: 75, loss is 0.15363042056560516\n",
      "epoch: 3 step: 76, loss is 0.32964277267456055\n",
      "epoch: 3 step: 77, loss is 2.2077603340148926\n",
      "epoch: 3 step: 78, loss is 1.9387574195861816\n",
      "epoch: 3 step: 79, loss is 1.3462889194488525\n",
      "epoch: 3 step: 80, loss is 1.6414742469787598\n",
      "epoch: 3 step: 81, loss is 0.3612935543060303\n",
      "epoch: 3 step: 82, loss is 2.0512404441833496\n",
      "epoch: 3 step: 83, loss is 1.8077216148376465\n",
      "epoch: 3 step: 84, loss is 2.1733624935150146\n",
      "epoch: 3 step: 85, loss is 0.18498624861240387\n",
      "epoch: 3 step: 86, loss is 2.2188174724578857\n",
      "epoch: 3 step: 87, loss is 1.5650089979171753\n",
      "epoch: 3 step: 88, loss is 1.9534075260162354\n",
      "epoch: 3 step: 89, loss is 1.3975542783737183\n",
      "epoch: 3 step: 90, loss is 0.23157472908496857\n",
      "epoch: 3 step: 91, loss is 2.197357416152954\n",
      "epoch: 3 step: 92, loss is 0.7870770692825317\n",
      "epoch: 3 step: 93, loss is 0.03219745308160782\n",
      "epoch: 3 step: 94, loss is 0.16121625900268555\n",
      "epoch: 3 step: 95, loss is 2.081118106842041\n",
      "epoch: 3 step: 96, loss is 1.0916459560394287\n",
      "epoch: 3 step: 97, loss is 0.8222939372062683\n",
      "epoch: 3 step: 98, loss is 0.4542754292488098\n",
      "epoch: 3 step: 99, loss is 0.14246679842472076\n",
      "epoch: 3 step: 100, loss is 3.9147047996520996\n",
      "epoch: 3 step: 101, loss is 0.10999272018671036\n",
      "epoch: 3 step: 102, loss is 0.16129550337791443\n",
      "epoch: 3 step: 103, loss is 2.2013680934906006\n",
      "epoch: 3 step: 104, loss is 0.06297093629837036\n",
      "epoch: 3 step: 105, loss is 1.7912929058074951\n",
      "epoch: 3 step: 106, loss is 1.7590301036834717\n",
      "epoch: 3 step: 107, loss is 1.3886618614196777\n",
      "epoch: 3 step: 108, loss is 1.9563663005828857\n",
      "epoch: 3 step: 109, loss is 1.0164248943328857\n",
      "epoch: 3 step: 110, loss is 1.6688040494918823\n",
      "epoch: 3 step: 111, loss is 0.2891782820224762\n",
      "epoch: 3 step: 112, loss is 1.0699082612991333\n",
      "epoch: 3 step: 113, loss is 0.4671837389469147\n",
      "epoch: 3 step: 114, loss is 0.08719846606254578\n",
      "epoch: 3 step: 115, loss is 1.965529441833496\n",
      "epoch: 3 step: 116, loss is 0.40294700860977173\n",
      "epoch: 3 step: 117, loss is 0.024620944634079933\n",
      "epoch: 3 step: 118, loss is 0.4736385643482208\n",
      "epoch: 3 step: 119, loss is 1.964119553565979\n",
      "epoch: 3 step: 120, loss is 0.04581432044506073\n",
      "epoch: 3 step: 121, loss is 0.9139024615287781\n",
      "epoch: 3 step: 122, loss is 0.5368255376815796\n",
      "epoch: 3 step: 123, loss is 0.6152658462524414\n",
      "epoch: 3 step: 124, loss is 3.019134044647217\n",
      "epoch: 3 step: 125, loss is 0.14212630689144135\n",
      "epoch: 3 step: 126, loss is 2.0975732803344727\n",
      "epoch: 3 step: 127, loss is 0.024941910058259964\n",
      "epoch: 3 step: 128, loss is 0.2570571005344391\n",
      "epoch: 3 step: 129, loss is 0.14930564165115356\n",
      "epoch: 3 step: 130, loss is 0.5700770616531372\n",
      "epoch: 3 step: 131, loss is 1.9698327779769897\n",
      "epoch: 3 step: 132, loss is 0.11471991240978241\n",
      "epoch: 3 step: 133, loss is 0.1295468658208847\n",
      "epoch: 3 step: 134, loss is 0.04258839413523674\n",
      "epoch: 3 step: 135, loss is 0.37865763902664185\n",
      "epoch: 3 step: 136, loss is 0.20319180190563202\n",
      "epoch: 3 step: 137, loss is 0.15872475504875183\n",
      "epoch: 3 step: 138, loss is 0.01656973920762539\n",
      "epoch: 3 step: 139, loss is 0.1619621217250824\n",
      "epoch: 3 step: 140, loss is 0.07781659066677094\n",
      "epoch: 3 step: 141, loss is 0.039617083966732025\n",
      "epoch: 3 step: 142, loss is 2.1036272048950195\n",
      "epoch: 3 step: 143, loss is 0.23723503947257996\n",
      "epoch: 3 step: 144, loss is 1.4121865034103394\n",
      "epoch: 3 step: 145, loss is 1.9979796409606934\n",
      "epoch: 3 step: 146, loss is 0.06685956567525864\n",
      "epoch: 3 step: 147, loss is 0.23686815798282623\n",
      "epoch: 3 step: 148, loss is 2.109341621398926\n",
      "epoch: 3 step: 149, loss is 0.13647183775901794\n",
      "epoch: 3 step: 150, loss is 0.1195756047964096\n",
      "epoch: 3 step: 151, loss is 1.6143312454223633\n",
      "epoch: 3 step: 152, loss is 0.2660774886608124\n",
      "epoch: 3 step: 153, loss is 0.09524192661046982\n",
      "epoch: 3 step: 154, loss is 1.1101680994033813\n",
      "epoch: 3 step: 155, loss is 2.072605609893799\n",
      "epoch: 3 step: 156, loss is 1.7795348167419434\n",
      "epoch: 3 step: 157, loss is 1.9806067943572998\n",
      "epoch: 3 step: 158, loss is 1.9454712867736816\n",
      "epoch: 3 step: 159, loss is 2.278583526611328\n",
      "epoch: 3 step: 160, loss is 1.6697453260421753\n",
      "epoch: 3 step: 161, loss is 0.21987798810005188\n",
      "epoch: 3 step: 162, loss is 1.3178857564926147\n",
      "epoch: 3 step: 163, loss is 0.24523693323135376\n",
      "epoch: 3 step: 164, loss is 0.8516181111335754\n",
      "epoch: 3 step: 165, loss is 0.08261578530073166\n",
      "epoch: 3 step: 166, loss is 0.26714444160461426\n",
      "epoch: 3 step: 167, loss is 0.07593005150556564\n",
      "epoch: 3 step: 168, loss is 1.5637457370758057\n",
      "epoch: 3 step: 169, loss is 2.0167860984802246\n",
      "epoch: 3 step: 170, loss is 0.3816709518432617\n",
      "epoch: 3 step: 171, loss is 0.04397406429052353\n",
      "epoch: 3 step: 172, loss is 0.06439238041639328\n",
      "epoch: 3 step: 173, loss is 0.0165557861328125\n",
      "epoch: 3 step: 174, loss is 1.2682349681854248\n",
      "epoch: 3 step: 175, loss is 0.2696368098258972\n",
      "epoch: 3 step: 176, loss is 0.18380098044872284\n",
      "epoch: 3 step: 177, loss is 3.8089067935943604\n",
      "epoch: 3 step: 178, loss is 0.7420378923416138\n",
      "epoch: 3 step: 179, loss is 1.6601336002349854\n",
      "epoch: 3 step: 180, loss is 0.18102017045021057\n",
      "epoch: 3 step: 181, loss is 1.8122444152832031\n",
      "epoch: 3 step: 182, loss is 1.7362029552459717\n",
      "epoch: 3 step: 183, loss is 2.7239060401916504\n",
      "epoch: 3 step: 184, loss is 0.9830834865570068\n",
      "epoch: 3 step: 185, loss is 1.5668472051620483\n",
      "epoch: 3 step: 186, loss is 1.6537233591079712\n",
      "epoch: 3 step: 187, loss is 0.08837597817182541\n",
      "epoch: 3 step: 188, loss is 0.48725181818008423\n",
      "epoch: 3 step: 189, loss is 3.3513193130493164\n",
      "epoch: 3 step: 190, loss is 1.9564683437347412\n",
      "epoch: 3 step: 191, loss is 1.1692557334899902\n",
      "epoch: 3 step: 192, loss is 0.2359820157289505\n",
      "epoch: 3 step: 193, loss is 1.4261257648468018\n",
      "epoch: 3 step: 194, loss is 2.411975145339966\n",
      "epoch: 3 step: 195, loss is 0.7170433402061462\n",
      "epoch: 3 step: 196, loss is 0.5016823410987854\n",
      "epoch: 3 step: 197, loss is 1.696365237236023\n",
      "epoch: 3 step: 198, loss is 2.220940589904785\n",
      "epoch: 3 step: 199, loss is 1.9407691955566406\n",
      "epoch: 3 step: 200, loss is 1.314096212387085\n",
      "epoch: 3 step: 201, loss is 0.05094423517584801\n",
      "epoch: 3 step: 202, loss is 0.23738417029380798\n",
      "epoch: 3 step: 203, loss is 1.1571123600006104\n",
      "epoch: 3 step: 204, loss is 1.77066969871521\n",
      "epoch: 3 step: 205, loss is 1.8597930669784546\n",
      "epoch: 3 step: 206, loss is 0.3773117661476135\n",
      "epoch: 3 step: 207, loss is 0.0886853039264679\n",
      "epoch: 3 step: 208, loss is 1.021077275276184\n",
      "epoch: 3 step: 209, loss is 0.21381472051143646\n",
      "epoch: 3 step: 210, loss is 0.24206240475177765\n",
      "epoch: 3 step: 211, loss is 0.03856641426682472\n",
      "epoch: 3 step: 212, loss is 0.14987912774085999\n",
      "epoch: 3 step: 213, loss is 1.7896885871887207\n",
      "epoch: 3 step: 214, loss is 1.7905217409133911\n",
      "epoch: 3 step: 215, loss is 1.6518670320510864\n",
      "epoch: 3 step: 216, loss is 0.06842557340860367\n",
      "epoch: 3 step: 217, loss is 0.09499338269233704\n",
      "epoch: 3 step: 218, loss is 0.46333298087120056\n",
      "epoch: 3 step: 219, loss is 0.18606995046138763\n",
      "epoch: 3 step: 220, loss is 0.666874885559082\n",
      "epoch: 3 step: 221, loss is 0.015893209725618362\n",
      "epoch: 3 step: 222, loss is 0.0631745234131813\n",
      "epoch: 3 step: 223, loss is 0.18665438890457153\n",
      "epoch: 3 step: 224, loss is 0.20064863562583923\n",
      "epoch: 3 step: 225, loss is 0.04336525872349739\n",
      "epoch: 3 step: 226, loss is 1.9884097576141357\n",
      "epoch: 3 step: 227, loss is 1.3852033615112305\n",
      "epoch: 3 step: 228, loss is 0.02773633785545826\n",
      "epoch: 3 step: 229, loss is 0.0967462882399559\n",
      "epoch: 3 step: 230, loss is 0.10775430500507355\n",
      "epoch: 3 step: 231, loss is 2.2002079486846924\n",
      "epoch: 3 step: 232, loss is 0.20397040247917175\n",
      "epoch: 3 step: 233, loss is 4.217068672180176\n",
      "epoch: 3 step: 234, loss is 2.5755603313446045\n",
      "epoch: 3 step: 235, loss is 1.9548819065093994\n",
      "epoch: 3 step: 236, loss is 1.460956335067749\n",
      "epoch: 3 step: 237, loss is 0.16296684741973877\n",
      "epoch: 3 step: 238, loss is 1.3210371732711792\n",
      "epoch: 3 step: 239, loss is 0.05865272507071495\n",
      "epoch: 3 step: 240, loss is 0.25823456048965454\n",
      "epoch: 3 step: 241, loss is 1.4032535552978516\n",
      "epoch: 3 step: 242, loss is 0.3292625844478607\n",
      "epoch: 3 step: 243, loss is 2.43808913230896\n",
      "epoch: 3 step: 244, loss is 1.863480567932129\n",
      "epoch: 3 step: 245, loss is 1.8919785022735596\n",
      "epoch: 3 step: 246, loss is 2.5504918098449707\n",
      "epoch: 3 step: 247, loss is 1.0416208505630493\n",
      "epoch: 3 step: 248, loss is 1.2368595600128174\n",
      "epoch: 3 step: 249, loss is 0.9098312854766846\n",
      "epoch: 3 step: 250, loss is 2.1691699028015137\n",
      "epoch: 3 step: 251, loss is 0.9385097622871399\n",
      "epoch: 3 step: 252, loss is 0.26139503717422485\n",
      "epoch: 3 step: 253, loss is 0.4635036289691925\n",
      "epoch: 3 step: 254, loss is 0.8150962591171265\n",
      "epoch: 3 step: 255, loss is 0.0597032830119133\n",
      "epoch: 3 step: 256, loss is 2.1614489555358887\n",
      "epoch: 3 step: 257, loss is 0.9059905409812927\n",
      "epoch: 3 step: 258, loss is 2.486083984375\n",
      "epoch: 3 step: 259, loss is 0.2966880798339844\n",
      "epoch: 3 step: 260, loss is 2.3177096843719482\n",
      "epoch: 3 step: 261, loss is 0.26863840222358704\n",
      "epoch: 3 step: 262, loss is 1.7584282159805298\n",
      "epoch: 3 step: 263, loss is 2.0095691680908203\n",
      "epoch: 3 step: 264, loss is 1.8673323392868042\n",
      "epoch: 3 step: 265, loss is 0.7809489965438843\n",
      "epoch: 3 step: 266, loss is 0.9841904044151306\n",
      "epoch: 3 step: 267, loss is 1.3753992319107056\n",
      "epoch: 3 step: 268, loss is 0.6547583937644958\n",
      "epoch: 3 step: 269, loss is 1.840033769607544\n",
      "epoch: 3 step: 270, loss is 0.0313105434179306\n",
      "epoch: 3 step: 271, loss is 1.6419093608856201\n",
      "epoch: 3 step: 272, loss is 0.21808555722236633\n",
      "epoch: 3 step: 273, loss is 2.2624354362487793\n",
      "epoch: 3 step: 274, loss is 0.5242853164672852\n",
      "epoch: 3 step: 275, loss is 0.581812858581543\n",
      "epoch: 3 step: 276, loss is 0.18658851087093353\n",
      "epoch: 3 step: 277, loss is 0.8120017051696777\n",
      "epoch: 3 step: 278, loss is 0.10985249280929565\n",
      "epoch: 3 step: 279, loss is 0.06751207262277603\n",
      "epoch: 3 step: 280, loss is 0.02612602710723877\n",
      "epoch: 3 step: 281, loss is 0.05495971441268921\n",
      "epoch: 3 step: 282, loss is 1.6425269842147827\n",
      "epoch: 3 step: 283, loss is 3.2503232955932617\n",
      "epoch: 3 step: 284, loss is 0.7174416184425354\n",
      "epoch: 3 step: 285, loss is 1.8816299438476562\n",
      "epoch: 3 step: 286, loss is 1.6125812530517578\n",
      "epoch: 3 step: 287, loss is 0.19001588225364685\n",
      "epoch: 3 step: 288, loss is 0.05762536823749542\n",
      "epoch: 3 step: 289, loss is 0.012873752973973751\n",
      "epoch: 3 step: 290, loss is 0.10382194072008133\n",
      "epoch: 3 step: 291, loss is 0.05618254095315933\n",
      "epoch: 3 step: 292, loss is 1.4985426664352417\n",
      "epoch: 3 step: 293, loss is 2.6979739665985107\n",
      "epoch: 3 step: 294, loss is 0.8488782048225403\n",
      "epoch: 3 step: 295, loss is 0.9088159799575806\n",
      "epoch: 3 step: 296, loss is 1.810624361038208\n",
      "epoch: 3 step: 297, loss is 1.9167170524597168\n",
      "epoch: 3 step: 298, loss is 0.38242754340171814\n",
      "epoch: 3 step: 299, loss is 2.291351556777954\n",
      "epoch: 3 step: 300, loss is 0.7976959943771362\n",
      "epoch: 3 step: 301, loss is 0.029032841324806213\n",
      "epoch: 3 step: 302, loss is 2.085496187210083\n",
      "epoch: 3 step: 303, loss is 0.09809516370296478\n",
      "epoch: 3 step: 304, loss is 0.37857624888420105\n",
      "epoch: 3 step: 305, loss is 0.0222209170460701\n",
      "epoch: 3 step: 306, loss is 0.16484670341014862\n",
      "epoch: 3 step: 307, loss is 0.1358473151922226\n",
      "epoch: 3 step: 308, loss is 0.5967784523963928\n",
      "epoch: 3 step: 309, loss is 0.0400419645011425\n",
      "epoch: 3 step: 310, loss is 2.4237048625946045\n",
      "epoch: 3 step: 311, loss is 0.17826423048973083\n",
      "epoch: 3 step: 312, loss is 1.4916000366210938\n",
      "epoch: 3 step: 313, loss is 0.22085000574588776\n",
      "epoch: 3 step: 314, loss is 3.6642773151397705\n",
      "epoch: 3 step: 315, loss is 0.10748647153377533\n",
      "epoch: 3 step: 316, loss is 2.810410261154175\n",
      "epoch: 3 step: 317, loss is 0.11295800656080246\n",
      "epoch: 3 step: 318, loss is 0.3551015853881836\n",
      "epoch: 3 step: 319, loss is 1.6561143398284912\n",
      "epoch: 3 step: 320, loss is 0.7550910711288452\n",
      "epoch: 3 step: 321, loss is 2.6439690589904785\n",
      "epoch: 3 step: 322, loss is 0.29123491048812866\n",
      "epoch: 3 step: 323, loss is 0.6867237091064453\n",
      "epoch: 3 step: 324, loss is 0.06761948019266129\n",
      "epoch: 3 step: 325, loss is 0.2751767635345459\n",
      "epoch: 3 step: 326, loss is 1.4937970638275146\n",
      "epoch: 3 step: 327, loss is 2.1181013584136963\n",
      "epoch: 3 step: 328, loss is 1.8062372207641602\n",
      "epoch: 3 step: 329, loss is 0.4025084972381592\n",
      "epoch: 3 step: 330, loss is 1.393476963043213\n",
      "epoch: 3 step: 331, loss is 0.4158261716365814\n",
      "epoch: 3 step: 332, loss is 0.09916848689317703\n",
      "epoch: 3 step: 333, loss is 0.14452917873859406\n",
      "epoch: 3 step: 334, loss is 1.757047176361084\n",
      "epoch: 3 step: 335, loss is 0.197457417845726\n",
      "epoch: 3 step: 336, loss is 0.3512631058692932\n",
      "epoch: 3 step: 337, loss is 0.04805427044630051\n",
      "epoch: 3 step: 338, loss is 0.0182900782674551\n",
      "epoch: 3 step: 339, loss is 1.2842895984649658\n",
      "epoch: 3 step: 340, loss is 0.0491238497197628\n",
      "epoch: 3 step: 341, loss is 0.03271837905049324\n",
      "epoch: 3 step: 342, loss is 1.5902976989746094\n",
      "epoch: 3 step: 343, loss is 0.020150592550635338\n",
      "epoch: 3 step: 344, loss is 0.08392859995365143\n",
      "epoch: 3 step: 345, loss is 2.790318012237549\n",
      "epoch: 3 step: 346, loss is 1.1511257886886597\n",
      "epoch: 3 step: 347, loss is 0.36516785621643066\n",
      "epoch: 3 step: 348, loss is 1.3276035785675049\n",
      "epoch: 3 step: 349, loss is 0.23396705090999603\n",
      "epoch: 3 step: 350, loss is 0.5321238040924072\n",
      "epoch: 3 step: 351, loss is 0.3021295666694641\n",
      "epoch: 3 step: 352, loss is 0.13626910746097565\n",
      "epoch: 3 step: 353, loss is 1.9686667919158936\n",
      "epoch: 3 step: 354, loss is 0.1802605241537094\n",
      "epoch: 3 step: 355, loss is 0.33257046341896057\n",
      "epoch: 3 step: 356, loss is 2.3938465118408203\n",
      "epoch: 3 step: 357, loss is 1.566453456878662\n",
      "epoch: 3 step: 358, loss is 2.8730664253234863\n",
      "epoch: 3 step: 359, loss is 1.440044641494751\n",
      "epoch: 3 step: 360, loss is 1.7296526432037354\n",
      "epoch: 3 step: 361, loss is 0.071682870388031\n",
      "epoch: 3 step: 362, loss is 2.0720715522766113\n",
      "epoch: 3 step: 363, loss is 2.1760780811309814\n",
      "epoch: 3 step: 364, loss is 2.0642619132995605\n",
      "epoch: 3 step: 365, loss is 1.4103102684020996\n",
      "epoch: 3 step: 366, loss is 0.3179675042629242\n",
      "epoch: 3 step: 367, loss is 1.9921691417694092\n",
      "epoch: 3 step: 368, loss is 1.9884681701660156\n",
      "epoch: 3 step: 369, loss is 0.4106389880180359\n",
      "epoch: 3 step: 370, loss is 1.809289813041687\n",
      "epoch: 3 step: 371, loss is 0.11981283128261566\n",
      "epoch: 3 step: 372, loss is 1.238582968711853\n",
      "epoch: 3 step: 373, loss is 0.039756860584020615\n",
      "epoch: 3 step: 374, loss is 1.7617392539978027\n",
      "epoch: 3 step: 375, loss is 1.0916348695755005\n",
      "epoch: 3 step: 376, loss is 0.14322811365127563\n",
      "epoch: 3 step: 377, loss is 0.023960085585713387\n",
      "epoch: 3 step: 378, loss is 1.5577149391174316\n",
      "epoch: 3 step: 379, loss is 0.8120275139808655\n",
      "epoch: 3 step: 380, loss is 2.1668167114257812\n",
      "epoch: 3 step: 381, loss is 0.30766910314559937\n",
      "epoch: 3 step: 382, loss is 1.103453516960144\n",
      "epoch: 3 step: 383, loss is 2.099555015563965\n",
      "epoch: 3 step: 384, loss is 1.6217405796051025\n",
      "epoch: 3 step: 385, loss is 0.1229672059416771\n",
      "epoch: 3 step: 386, loss is 2.2180778980255127\n",
      "epoch: 3 step: 387, loss is 0.04026825353503227\n",
      "epoch: 3 step: 388, loss is 1.7002756595611572\n",
      "epoch: 3 step: 389, loss is 0.20589938759803772\n",
      "epoch: 3 step: 390, loss is 0.17510461807250977\n",
      "epoch: 3 step: 391, loss is 2.178165912628174\n",
      "epoch: 3 step: 392, loss is 1.458266258239746\n",
      "epoch: 3 step: 393, loss is 0.21849504113197327\n",
      "epoch: 3 step: 394, loss is 0.3133438229560852\n",
      "epoch: 3 step: 395, loss is 1.4115266799926758\n",
      "epoch: 3 step: 396, loss is 0.06371736526489258\n",
      "epoch: 3 step: 397, loss is 1.303429365158081\n",
      "epoch: 3 step: 398, loss is 2.1153759956359863\n",
      "epoch: 3 step: 399, loss is 1.1289403438568115\n",
      "epoch: 3 step: 400, loss is 1.1777584552764893\n",
      "epoch: 3 step: 401, loss is 2.213400363922119\n",
      "epoch: 3 step: 402, loss is 0.07059706002473831\n",
      "epoch: 3 step: 403, loss is 0.972096860408783\n",
      "epoch: 3 step: 404, loss is 1.0504566431045532\n",
      "epoch: 3 step: 405, loss is 1.545533299446106\n",
      "epoch: 3 step: 406, loss is 1.3218715190887451\n",
      "epoch: 3 step: 407, loss is 0.11425617337226868\n",
      "epoch: 3 step: 408, loss is 0.13751547038555145\n",
      "epoch: 3 step: 409, loss is 0.39233195781707764\n",
      "epoch: 3 step: 410, loss is 0.24715663492679596\n",
      "epoch: 3 step: 411, loss is 0.6402843594551086\n",
      "epoch: 3 step: 412, loss is 1.4580297470092773\n",
      "epoch: 3 step: 413, loss is 0.7686558365821838\n",
      "epoch: 3 step: 414, loss is 1.7225615978240967\n",
      "epoch: 3 step: 415, loss is 3.712783098220825\n",
      "epoch: 3 step: 416, loss is 0.8894025087356567\n",
      "epoch: 3 step: 417, loss is 0.21906918287277222\n",
      "epoch: 3 step: 418, loss is 0.19796130061149597\n",
      "epoch: 3 step: 419, loss is 1.9575875997543335\n",
      "epoch: 3 step: 420, loss is 1.122206211090088\n",
      "epoch: 3 step: 421, loss is 0.6660029292106628\n",
      "epoch: 3 step: 422, loss is 3.8614399433135986\n",
      "epoch: 3 step: 423, loss is 0.11031273007392883\n",
      "epoch: 3 step: 424, loss is 1.8939454555511475\n",
      "epoch: 3 step: 425, loss is 0.06633716076612473\n",
      "epoch: 3 step: 426, loss is 0.06501734256744385\n",
      "epoch: 3 step: 427, loss is 0.4662758708000183\n",
      "epoch: 3 step: 428, loss is 0.30559441447257996\n",
      "epoch: 3 step: 429, loss is 4.483221530914307\n",
      "epoch: 3 step: 430, loss is 0.061963580548763275\n",
      "epoch: 3 step: 431, loss is 2.134899139404297\n",
      "epoch: 3 step: 432, loss is 0.9362921118736267\n",
      "epoch: 3 step: 433, loss is 5.280361175537109\n",
      "epoch: 3 step: 434, loss is 0.7330338358879089\n",
      "epoch: 3 step: 435, loss is 1.982100248336792\n",
      "epoch: 3 step: 436, loss is 0.1252937614917755\n",
      "epoch: 3 step: 437, loss is 1.8695487976074219\n",
      "epoch: 3 step: 438, loss is 1.974236249923706\n",
      "epoch: 3 step: 439, loss is 0.5135555863380432\n",
      "epoch: 3 step: 440, loss is 1.5659184455871582\n",
      "epoch: 3 step: 441, loss is 1.4928499460220337\n",
      "epoch: 3 step: 442, loss is 0.43918338418006897\n",
      "epoch: 3 step: 443, loss is 1.7576227188110352\n",
      "epoch: 3 step: 444, loss is 0.6884051561355591\n",
      "epoch: 3 step: 445, loss is 0.2593086361885071\n",
      "epoch: 3 step: 446, loss is 0.2290826290845871\n",
      "epoch: 3 step: 447, loss is 0.13805951178073883\n",
      "epoch: 3 step: 448, loss is 1.2502981424331665\n",
      "epoch: 3 step: 449, loss is 0.6182621717453003\n",
      "epoch: 3 step: 450, loss is 0.05949067696928978\n",
      "epoch: 3 step: 451, loss is 0.8422807455062866\n",
      "epoch: 3 step: 452, loss is 0.5454021692276001\n",
      "epoch: 3 step: 453, loss is 0.40026912093162537\n",
      "epoch: 3 step: 454, loss is 1.7668652534484863\n",
      "epoch: 3 step: 455, loss is 0.47005975246429443\n",
      "epoch: 3 step: 456, loss is 0.06463747471570969\n",
      "epoch: 3 step: 457, loss is 0.24945387244224548\n",
      "epoch: 3 step: 458, loss is 0.5594465136528015\n",
      "epoch: 3 step: 459, loss is 0.0759088397026062\n",
      "epoch: 3 step: 460, loss is 0.21716995537281036\n",
      "epoch: 3 step: 461, loss is 0.11709869652986526\n",
      "epoch: 3 step: 462, loss is 0.3292504847049713\n",
      "epoch: 3 step: 463, loss is 0.007219062652438879\n",
      "epoch: 3 step: 464, loss is 7.501523017883301\n",
      "epoch: 3 step: 465, loss is 1.2129027843475342\n",
      "epoch: 3 step: 466, loss is 2.0038516521453857\n",
      "epoch: 3 step: 467, loss is 1.5509003400802612\n",
      "epoch: 3 step: 468, loss is 1.2885303497314453\n",
      "epoch: 3 step: 469, loss is 0.7003205418586731\n",
      "epoch: 3 step: 470, loss is 0.4739462435245514\n",
      "epoch: 3 step: 471, loss is 0.4254135489463806\n",
      "epoch: 3 step: 472, loss is 1.2463384866714478\n",
      "epoch: 3 step: 473, loss is 1.7450997829437256\n",
      "epoch: 3 step: 474, loss is 1.237496018409729\n",
      "epoch: 3 step: 475, loss is 0.05184594541788101\n",
      "epoch: 3 step: 476, loss is 0.3780049979686737\n",
      "epoch: 3 step: 477, loss is 1.796217679977417\n",
      "epoch: 3 step: 478, loss is 0.20139676332473755\n",
      "epoch: 3 step: 479, loss is 1.108084797859192\n",
      "epoch: 3 step: 480, loss is 1.9511256217956543\n",
      "epoch: 3 step: 481, loss is 1.8855786323547363\n",
      "epoch: 3 step: 482, loss is 0.3310243487358093\n",
      "epoch: 3 step: 483, loss is 1.6312730312347412\n",
      "epoch: 3 step: 484, loss is 0.7001144886016846\n",
      "epoch: 3 step: 485, loss is 0.23874425888061523\n",
      "epoch: 3 step: 486, loss is 0.0666515976190567\n",
      "epoch: 3 step: 487, loss is 0.9018852114677429\n",
      "epoch: 3 step: 488, loss is 0.05671556666493416\n",
      "epoch: 3 step: 489, loss is 0.22956202924251556\n",
      "epoch: 3 step: 490, loss is 2.437788724899292\n",
      "epoch: 3 step: 491, loss is 0.5739626288414001\n",
      "epoch: 3 step: 492, loss is 0.28415030241012573\n",
      "epoch: 3 step: 493, loss is 0.6594499349594116\n",
      "epoch: 3 step: 494, loss is 0.14311674237251282\n",
      "epoch: 3 step: 495, loss is 0.2557179033756256\n",
      "epoch: 3 step: 496, loss is 2.901599168777466\n",
      "epoch: 3 step: 497, loss is 1.8662774562835693\n",
      "epoch: 3 step: 498, loss is 0.19180341064929962\n",
      "epoch: 3 step: 499, loss is 1.8525114059448242\n",
      "epoch: 3 step: 500, loss is 0.315784215927124\n",
      "epoch: 3 step: 501, loss is 0.30064576864242554\n",
      "epoch: 3 step: 502, loss is 0.3949750065803528\n",
      "epoch: 3 step: 503, loss is 1.232832670211792\n",
      "epoch: 3 step: 504, loss is 0.11719083786010742\n",
      "epoch: 3 step: 505, loss is 0.6586377620697021\n",
      "epoch: 3 step: 506, loss is 2.895988941192627\n",
      "epoch: 3 step: 507, loss is 1.794960856437683\n",
      "epoch: 3 step: 508, loss is 2.9818761348724365\n",
      "epoch: 3 step: 509, loss is 0.3369794189929962\n",
      "epoch: 3 step: 510, loss is 2.418079137802124\n",
      "epoch: 3 step: 511, loss is 0.1286664754152298\n",
      "epoch: 3 step: 512, loss is 0.8909441828727722\n",
      "epoch: 3 step: 513, loss is 0.33856359124183655\n",
      "epoch: 3 step: 514, loss is 1.3853955268859863\n",
      "epoch: 3 step: 515, loss is 0.12817203998565674\n",
      "epoch: 3 step: 516, loss is 2.114450693130493\n",
      "epoch: 3 step: 517, loss is 0.04427792876958847\n",
      "epoch: 3 step: 518, loss is 0.6758090853691101\n",
      "epoch: 3 step: 519, loss is 2.1849353313446045\n",
      "epoch: 3 step: 520, loss is 0.07550500333309174\n",
      "epoch: 3 step: 521, loss is 0.04035000503063202\n",
      "epoch: 3 step: 522, loss is 1.614113450050354\n",
      "epoch: 3 step: 523, loss is 1.9605903625488281\n",
      "epoch: 3 step: 524, loss is 0.10616854578256607\n",
      "epoch: 3 step: 525, loss is 0.20695865154266357\n",
      "epoch: 3 step: 526, loss is 0.08243894577026367\n",
      "epoch: 3 step: 527, loss is 0.10811996459960938\n",
      "epoch: 3 step: 528, loss is 0.20759077370166779\n",
      "epoch: 3 step: 529, loss is 1.0567171573638916\n",
      "epoch: 3 step: 530, loss is 0.3003019392490387\n",
      "epoch: 3 step: 531, loss is 6.53028678894043\n",
      "epoch: 3 step: 532, loss is 1.795042634010315\n",
      "epoch: 3 step: 533, loss is 1.516448736190796\n",
      "epoch: 3 step: 534, loss is 0.18049174547195435\n",
      "epoch: 3 step: 535, loss is 0.11359144747257233\n",
      "epoch: 3 step: 536, loss is 0.09453276544809341\n",
      "epoch: 3 step: 537, loss is 0.07440342009067535\n",
      "epoch: 3 step: 538, loss is 0.3991948664188385\n",
      "epoch: 3 step: 539, loss is 0.5769891738891602\n",
      "epoch: 3 step: 540, loss is 1.4434648752212524\n",
      "epoch: 3 step: 541, loss is 0.07984762638807297\n",
      "epoch: 3 step: 542, loss is 1.9460715055465698\n",
      "epoch: 3 step: 543, loss is 1.6040250062942505\n",
      "epoch: 3 step: 544, loss is 0.830735981464386\n",
      "epoch: 3 step: 545, loss is 0.07845868170261383\n",
      "epoch: 3 step: 546, loss is 1.7536201477050781\n",
      "epoch: 3 step: 547, loss is 1.3821660280227661\n",
      "epoch: 3 step: 548, loss is 0.49793681502342224\n",
      "epoch: 3 step: 549, loss is 0.136266827583313\n",
      "epoch: 3 step: 550, loss is 3.171337842941284\n",
      "epoch: 3 step: 551, loss is 0.13060684502124786\n",
      "epoch: 3 step: 552, loss is 1.236462950706482\n",
      "epoch: 3 step: 553, loss is 0.31500476598739624\n",
      "epoch: 3 step: 554, loss is 1.8635551929473877\n",
      "epoch: 3 step: 555, loss is 0.059427887201309204\n",
      "epoch: 3 step: 556, loss is 0.29084059596061707\n",
      "epoch: 3 step: 557, loss is 0.7625798583030701\n",
      "epoch: 3 step: 558, loss is 3.827543258666992\n",
      "epoch: 3 step: 559, loss is 0.5144470930099487\n",
      "epoch: 3 step: 560, loss is 1.4261412620544434\n",
      "epoch: 3 step: 561, loss is 2.7277016639709473\n",
      "epoch: 3 step: 562, loss is 1.7699733972549438\n",
      "epoch: 3 step: 563, loss is 0.21798136830329895\n",
      "epoch: 3 step: 564, loss is 0.7582992315292358\n",
      "epoch: 3 step: 565, loss is 0.23537474870681763\n",
      "epoch: 3 step: 566, loss is 1.6540567874908447\n",
      "epoch: 3 step: 567, loss is 1.2355965375900269\n",
      "epoch: 3 step: 568, loss is 1.0694224834442139\n",
      "epoch: 3 step: 569, loss is 0.6281249523162842\n",
      "epoch: 3 step: 570, loss is 0.886115312576294\n",
      "epoch: 3 step: 571, loss is 0.10465779155492783\n",
      "epoch: 3 step: 572, loss is 2.2418932914733887\n",
      "epoch: 3 step: 573, loss is 0.4069235622882843\n",
      "epoch: 3 step: 574, loss is 1.287672519683838\n",
      "epoch: 3 step: 575, loss is 1.2083481550216675\n",
      "epoch: 3 step: 576, loss is 1.8594894409179688\n",
      "epoch: 3 step: 577, loss is 0.6131980419158936\n",
      "epoch: 3 step: 578, loss is 1.7309293746948242\n",
      "epoch: 3 step: 579, loss is 1.2321275472640991\n",
      "epoch: 3 step: 580, loss is 0.9737424254417419\n",
      "epoch: 3 step: 581, loss is 3.567774534225464\n",
      "epoch: 3 step: 582, loss is 1.35352623462677\n",
      "epoch: 3 step: 583, loss is 1.926499843597412\n",
      "epoch: 3 step: 584, loss is 1.4964343309402466\n",
      "epoch: 3 step: 585, loss is 0.12854425609111786\n",
      "epoch: 3 step: 586, loss is 2.2263686656951904\n",
      "epoch: 3 step: 587, loss is 0.27841031551361084\n",
      "epoch: 3 step: 588, loss is 2.5524911880493164\n",
      "epoch: 3 step: 589, loss is 1.4159798622131348\n",
      "epoch: 3 step: 590, loss is 1.3414387702941895\n",
      "epoch: 3 step: 591, loss is 0.26362723112106323\n",
      "epoch: 3 step: 592, loss is 0.4181559979915619\n",
      "epoch: 3 step: 593, loss is 1.692762017250061\n",
      "epoch: 3 step: 594, loss is 1.9402596950531006\n",
      "epoch: 3 step: 595, loss is 0.2062658965587616\n",
      "epoch: 3 step: 596, loss is 0.7158535718917847\n",
      "epoch: 3 step: 597, loss is 1.0413098335266113\n",
      "epoch: 3 step: 598, loss is 0.5245518684387207\n",
      "epoch: 3 step: 599, loss is 0.18485614657402039\n",
      "epoch: 3 step: 600, loss is 0.47181272506713867\n",
      "epoch: 3 step: 601, loss is 2.020561456680298\n",
      "epoch: 3 step: 602, loss is 1.6241166591644287\n",
      "epoch: 3 step: 603, loss is 0.1281556785106659\n",
      "epoch: 3 step: 604, loss is 0.6661642789840698\n",
      "epoch: 3 step: 605, loss is 0.30860772728919983\n",
      "epoch: 3 step: 606, loss is 0.6423812508583069\n",
      "epoch: 3 step: 607, loss is 0.059565819799900055\n",
      "epoch: 3 step: 608, loss is 0.10638603568077087\n",
      "epoch: 3 step: 609, loss is 0.01613687351346016\n",
      "epoch: 3 step: 610, loss is 0.9987474679946899\n",
      "epoch: 3 step: 611, loss is 0.09622596204280853\n",
      "epoch: 3 step: 612, loss is 0.12590956687927246\n",
      "epoch: 3 step: 613, loss is 1.3219914436340332\n",
      "epoch: 3 step: 614, loss is 1.9213544130325317\n",
      "epoch: 3 step: 615, loss is 0.10012278705835342\n",
      "epoch: 3 step: 616, loss is 1.8357106447219849\n",
      "epoch: 3 step: 617, loss is 1.2430322170257568\n",
      "epoch: 3 step: 618, loss is 0.5586774349212646\n",
      "epoch: 3 step: 619, loss is 1.1863963603973389\n",
      "epoch: 3 step: 620, loss is 0.008088451810181141\n",
      "epoch: 3 step: 621, loss is 3.154210329055786\n",
      "epoch: 3 step: 622, loss is 0.1851378232240677\n",
      "epoch: 3 step: 623, loss is 0.16015107929706573\n",
      "epoch: 3 step: 624, loss is 0.7361239194869995\n",
      "epoch: 3 step: 625, loss is 0.048882074654102325\n",
      "epoch: 3 step: 626, loss is 0.04679369926452637\n",
      "epoch: 3 step: 627, loss is 3.395857572555542\n",
      "epoch: 3 step: 628, loss is 0.046734996140003204\n",
      "epoch: 3 step: 629, loss is 3.699019432067871\n",
      "epoch: 3 step: 630, loss is 1.6434783935546875\n",
      "epoch: 3 step: 631, loss is 0.37814387679100037\n",
      "epoch: 3 step: 632, loss is 1.9668877124786377\n",
      "epoch: 3 step: 633, loss is 1.769520878791809\n",
      "epoch: 3 step: 634, loss is 2.103381872177124\n",
      "epoch: 3 step: 635, loss is 1.644097089767456\n",
      "epoch: 3 step: 636, loss is 2.4516539573669434\n",
      "epoch: 3 step: 637, loss is 1.8051255941390991\n",
      "epoch: 3 step: 638, loss is 0.32059451937675476\n",
      "epoch: 3 step: 639, loss is 0.8894671201705933\n",
      "epoch: 3 step: 640, loss is 0.3306075930595398\n",
      "epoch: 3 step: 641, loss is 0.5229851603507996\n",
      "epoch: 3 step: 642, loss is 0.11394466459751129\n",
      "epoch: 3 step: 643, loss is 2.1007871627807617\n",
      "epoch: 3 step: 644, loss is 2.270907402038574\n",
      "epoch: 3 step: 645, loss is 0.14553599059581757\n",
      "epoch: 3 step: 646, loss is 0.09507544338703156\n",
      "epoch: 3 step: 647, loss is 0.08853626996278763\n",
      "epoch: 3 step: 648, loss is 1.7341160774230957\n",
      "epoch: 3 step: 649, loss is 1.960463285446167\n",
      "epoch: 3 step: 650, loss is 0.7784706354141235\n",
      "epoch: 3 step: 651, loss is 0.04289839044213295\n",
      "epoch: 3 step: 652, loss is 3.643186569213867\n",
      "epoch: 3 step: 653, loss is 2.5578393936157227\n",
      "epoch: 3 step: 654, loss is 0.9747364521026611\n",
      "epoch: 3 step: 655, loss is 0.5320350527763367\n",
      "epoch: 3 step: 656, loss is 1.5427253246307373\n",
      "epoch: 3 step: 657, loss is 1.6595141887664795\n",
      "epoch: 3 step: 658, loss is 1.8313227891921997\n",
      "epoch: 3 step: 659, loss is 0.5131622552871704\n",
      "epoch: 3 step: 660, loss is 0.23434481024742126\n",
      "epoch: 3 step: 661, loss is 1.5106406211853027\n",
      "epoch: 3 step: 662, loss is 0.11458630114793777\n",
      "epoch: 3 step: 663, loss is 0.23440121114253998\n",
      "epoch: 3 step: 664, loss is 0.9852752685546875\n",
      "epoch: 3 step: 665, loss is 1.1506760120391846\n",
      "epoch: 3 step: 666, loss is 0.139955535531044\n",
      "epoch: 3 step: 667, loss is 2.4700870513916016\n",
      "epoch: 3 step: 668, loss is 1.3366763591766357\n",
      "epoch: 3 step: 669, loss is 0.16966314613819122\n",
      "epoch: 3 step: 670, loss is 0.954886257648468\n",
      "epoch: 3 step: 671, loss is 1.0760389566421509\n",
      "epoch: 3 step: 672, loss is 3.4027087688446045\n",
      "epoch: 3 step: 673, loss is 3.0614655017852783\n",
      "epoch: 3 step: 674, loss is 0.5521240830421448\n",
      "epoch: 3 step: 675, loss is 0.25671815872192383\n",
      "epoch: 3 step: 676, loss is 3.265439987182617\n",
      "epoch: 3 step: 677, loss is 1.7287355661392212\n",
      "epoch: 3 step: 678, loss is 1.2941969633102417\n",
      "epoch: 3 step: 679, loss is 0.251887708902359\n",
      "epoch: 3 step: 680, loss is 0.1912669688463211\n",
      "epoch: 3 step: 681, loss is 1.6872780323028564\n",
      "epoch: 3 step: 682, loss is 0.4407111406326294\n",
      "epoch: 3 step: 683, loss is 0.4810520112514496\n",
      "epoch: 3 step: 684, loss is 0.14643944799900055\n",
      "epoch: 3 step: 685, loss is 2.3566043376922607\n",
      "epoch: 3 step: 686, loss is 2.0711312294006348\n",
      "epoch: 3 step: 687, loss is 1.9741132259368896\n",
      "epoch: 3 step: 688, loss is 1.126371145248413\n",
      "epoch: 3 step: 689, loss is 0.6905966997146606\n",
      "epoch: 3 step: 690, loss is 0.5783847570419312\n",
      "epoch: 3 step: 691, loss is 1.4021990299224854\n",
      "epoch: 3 step: 692, loss is 2.2162551879882812\n",
      "epoch: 3 step: 693, loss is 1.8026435375213623\n",
      "epoch: 3 step: 694, loss is 1.6415091753005981\n",
      "epoch: 3 step: 695, loss is 0.49483129382133484\n",
      "epoch: 3 step: 696, loss is 1.5574761629104614\n",
      "epoch: 3 step: 697, loss is 0.08834335207939148\n",
      "epoch: 3 step: 698, loss is 0.27322134375572205\n",
      "epoch: 3 step: 699, loss is 0.30729562044143677\n",
      "epoch: 3 step: 700, loss is 0.33055174350738525\n",
      "epoch: 3 step: 701, loss is 2.902791976928711\n",
      "epoch: 3 step: 702, loss is 1.3298412561416626\n",
      "epoch: 3 step: 703, loss is 1.3400959968566895\n",
      "epoch: 3 step: 704, loss is 0.28586986660957336\n",
      "epoch: 3 step: 705, loss is 2.567760467529297\n",
      "epoch: 3 step: 706, loss is 0.7903459072113037\n",
      "epoch: 3 step: 707, loss is 1.1335837841033936\n",
      "epoch: 3 step: 708, loss is 0.7158991098403931\n",
      "epoch: 3 step: 709, loss is 0.3639814853668213\n",
      "epoch: 3 step: 710, loss is 0.46115610003471375\n",
      "epoch: 3 step: 711, loss is 1.3030612468719482\n",
      "epoch: 3 step: 712, loss is 2.2310631275177\n",
      "epoch: 3 step: 713, loss is 0.3602197468280792\n",
      "epoch: 3 step: 714, loss is 0.3960365653038025\n",
      "epoch: 3 step: 715, loss is 0.31454601883888245\n",
      "epoch: 3 step: 716, loss is 0.403991162776947\n",
      "epoch: 3 step: 717, loss is 1.7272026538848877\n",
      "epoch: 3 step: 718, loss is 0.43096432089805603\n",
      "epoch: 3 step: 719, loss is 0.7098280787467957\n",
      "epoch: 3 step: 720, loss is 0.34403741359710693\n",
      "epoch: 3 step: 721, loss is 1.0382881164550781\n",
      "epoch: 3 step: 722, loss is 0.12011628597974777\n",
      "epoch: 3 step: 723, loss is 0.5528977513313293\n",
      "epoch: 3 step: 724, loss is 0.759057343006134\n",
      "epoch: 3 step: 725, loss is 0.10963340848684311\n",
      "epoch: 3 step: 726, loss is 0.08079557120800018\n",
      "epoch: 3 step: 727, loss is 0.15298226475715637\n",
      "epoch: 3 step: 728, loss is 0.27519822120666504\n",
      "epoch: 3 step: 729, loss is 1.7452869415283203\n",
      "epoch: 3 step: 730, loss is 0.6911028623580933\n",
      "epoch: 3 step: 731, loss is 1.8926326036453247\n",
      "epoch: 3 step: 732, loss is 0.09768570959568024\n",
      "epoch: 3 step: 733, loss is 2.3973536491394043\n",
      "epoch: 3 step: 734, loss is 1.8905707597732544\n",
      "epoch: 3 step: 735, loss is 2.272440195083618\n",
      "epoch: 3 step: 736, loss is 0.1274898499250412\n",
      "epoch: 3 step: 737, loss is 0.15687349438667297\n",
      "epoch: 3 step: 738, loss is 1.6690387725830078\n",
      "epoch: 3 step: 739, loss is 0.14625944197177887\n",
      "epoch: 3 step: 740, loss is 1.161139965057373\n",
      "epoch: 3 step: 741, loss is 0.4604440927505493\n",
      "epoch: 3 step: 742, loss is 0.497895210981369\n",
      "epoch: 3 step: 743, loss is 1.7404778003692627\n",
      "epoch: 3 step: 744, loss is 1.2068703174591064\n",
      "epoch: 3 step: 745, loss is 1.8209811449050903\n",
      "epoch: 3 step: 746, loss is 2.7615411281585693\n",
      "epoch: 3 step: 747, loss is 1.6617107391357422\n",
      "epoch: 3 step: 748, loss is 0.10739804059267044\n",
      "epoch: 3 step: 749, loss is 0.06691955029964447\n",
      "epoch: 3 step: 750, loss is 1.3447812795639038\n",
      "epoch: 3 step: 751, loss is 0.4155277907848358\n",
      "epoch: 3 step: 752, loss is 0.07089027762413025\n",
      "epoch: 3 step: 753, loss is 1.9275015592575073\n",
      "epoch: 3 step: 754, loss is 1.7339491844177246\n",
      "epoch: 3 step: 755, loss is 0.14497001469135284\n",
      "epoch: 3 step: 756, loss is 2.894357442855835\n",
      "epoch: 3 step: 757, loss is 0.09363499283790588\n",
      "epoch: 3 step: 758, loss is 0.16989853978157043\n",
      "epoch: 3 step: 759, loss is 3.015180826187134\n",
      "epoch: 3 step: 760, loss is 0.23370540142059326\n",
      "epoch: 3 step: 761, loss is 0.3318311274051666\n",
      "epoch: 3 step: 762, loss is 0.48190054297447205\n",
      "epoch: 3 step: 763, loss is 0.9998112916946411\n",
      "epoch: 3 step: 764, loss is 0.501347005367279\n",
      "epoch: 3 step: 765, loss is 0.20641563832759857\n",
      "epoch: 3 step: 766, loss is 0.16914871335029602\n",
      "epoch: 3 step: 767, loss is 0.28145694732666016\n",
      "epoch: 3 step: 768, loss is 1.359373688697815\n",
      "epoch: 3 step: 769, loss is 2.3366446495056152\n",
      "epoch: 3 step: 770, loss is 0.1458558440208435\n",
      "epoch: 3 step: 771, loss is 0.06491389870643616\n",
      "epoch: 3 step: 772, loss is 0.5267720818519592\n",
      "epoch: 3 step: 773, loss is 0.12183566391468048\n",
      "epoch: 3 step: 774, loss is 0.041252847760915756\n",
      "epoch: 3 step: 775, loss is 1.2779114246368408\n",
      "epoch: 3 step: 776, loss is 2.369809627532959\n",
      "epoch: 3 step: 777, loss is 0.1655721813440323\n",
      "epoch: 3 step: 778, loss is 1.9985734224319458\n",
      "epoch: 3 step: 779, loss is 0.6038873195648193\n",
      "epoch: 3 step: 780, loss is 2.082098960876465\n",
      "epoch: 3 step: 781, loss is 1.647362232208252\n",
      "epoch: 3 step: 782, loss is 0.24531668424606323\n",
      "epoch: 3 step: 783, loss is 1.9471310377120972\n",
      "epoch: 3 step: 784, loss is 2.906019687652588\n",
      "epoch: 3 step: 785, loss is 0.25773802399635315\n",
      "epoch: 3 step: 786, loss is 0.1648930013179779\n",
      "epoch: 3 step: 787, loss is 2.9293742179870605\n",
      "epoch: 3 step: 788, loss is 0.11420810967683792\n",
      "epoch: 3 step: 789, loss is 0.12612827122211456\n",
      "epoch: 3 step: 790, loss is 0.04570101201534271\n",
      "epoch: 3 step: 791, loss is 2.0312180519104004\n",
      "epoch: 3 step: 792, loss is 0.0755370631814003\n",
      "epoch: 3 step: 793, loss is 0.08931783586740494\n",
      "epoch: 3 step: 794, loss is 0.08448144048452377\n",
      "epoch: 3 step: 795, loss is 1.4162625074386597\n",
      "epoch: 3 step: 796, loss is 1.4860421419143677\n",
      "epoch: 3 step: 797, loss is 0.14092865586280823\n",
      "epoch: 3 step: 798, loss is 0.41059446334838867\n",
      "epoch: 3 step: 799, loss is 1.881680965423584\n",
      "epoch: 3 step: 800, loss is 0.013957981020212173\n",
      "epoch: 3 step: 801, loss is 1.398136854171753\n",
      "epoch: 3 step: 802, loss is 2.1515421867370605\n",
      "epoch: 3 step: 803, loss is 1.849656343460083\n",
      "epoch: 3 step: 804, loss is 0.1430533081293106\n",
      "epoch: 3 step: 805, loss is 2.2150189876556396\n",
      "epoch: 3 step: 806, loss is 0.757844865322113\n",
      "epoch: 3 step: 807, loss is 1.1541346311569214\n",
      "epoch: 3 step: 808, loss is 0.036471765488386154\n",
      "epoch: 3 step: 809, loss is 0.03699977323412895\n",
      "epoch: 3 step: 810, loss is 0.21311861276626587\n",
      "epoch: 3 step: 811, loss is 0.06014643609523773\n",
      "epoch: 3 step: 812, loss is 1.6300082206726074\n",
      "epoch: 3 step: 813, loss is 0.3981606066226959\n",
      "epoch: 3 step: 814, loss is 0.14299513399600983\n",
      "epoch: 3 step: 815, loss is 2.6972122192382812\n",
      "epoch: 3 step: 816, loss is 2.6924095153808594\n",
      "epoch: 3 step: 817, loss is 1.8416746854782104\n",
      "epoch: 3 step: 818, loss is 0.12802542746067047\n",
      "epoch: 3 step: 819, loss is 0.16660214960575104\n",
      "epoch: 3 step: 820, loss is 0.6045346260070801\n",
      "epoch: 3 step: 821, loss is 0.03901100531220436\n",
      "epoch: 3 step: 822, loss is 0.08068165183067322\n",
      "epoch: 3 step: 823, loss is 0.20848838984966278\n",
      "epoch: 3 step: 824, loss is 0.02081315591931343\n",
      "epoch: 3 step: 825, loss is 0.2027854472398758\n",
      "epoch: 3 step: 826, loss is 3.7364847660064697\n",
      "epoch: 3 step: 827, loss is 0.17121008038520813\n",
      "epoch: 3 step: 828, loss is 3.200183391571045\n",
      "epoch: 3 step: 829, loss is 0.1643340289592743\n",
      "epoch: 3 step: 830, loss is 1.9107861518859863\n",
      "epoch: 3 step: 831, loss is 0.10962710529565811\n",
      "epoch: 3 step: 832, loss is 0.27081620693206787\n",
      "epoch: 3 step: 833, loss is 1.6381865739822388\n",
      "epoch: 3 step: 834, loss is 0.17781378328800201\n",
      "epoch: 3 step: 835, loss is 1.6378827095031738\n",
      "epoch: 3 step: 836, loss is 0.16380824148654938\n",
      "epoch: 3 step: 837, loss is 0.24971513450145721\n",
      "epoch: 3 step: 838, loss is 1.6496949195861816\n",
      "epoch: 3 step: 839, loss is 2.267744302749634\n",
      "epoch: 3 step: 840, loss is 0.14470742642879486\n",
      "epoch: 3 step: 841, loss is 1.829410195350647\n",
      "epoch: 3 step: 842, loss is 0.2005094438791275\n",
      "epoch: 3 step: 843, loss is 0.15125590562820435\n",
      "epoch: 3 step: 844, loss is 0.06128546968102455\n",
      "epoch: 3 step: 845, loss is 0.3036107122898102\n",
      "epoch: 3 step: 846, loss is 1.7392046451568604\n",
      "epoch: 3 step: 847, loss is 3.8051986694335938\n",
      "epoch: 3 step: 848, loss is 0.17424282431602478\n",
      "epoch: 3 step: 849, loss is 1.2405771017074585\n",
      "epoch: 3 step: 850, loss is 0.12370137125253677\n",
      "epoch: 3 step: 851, loss is 0.14859959483146667\n",
      "epoch: 3 step: 852, loss is 0.6021734476089478\n",
      "epoch: 3 step: 853, loss is 0.057988449931144714\n",
      "epoch: 3 step: 854, loss is 0.9562229514122009\n",
      "epoch: 3 step: 855, loss is 0.06858275830745697\n",
      "epoch: 3 step: 856, loss is 0.2284080684185028\n",
      "epoch: 3 step: 857, loss is 0.2571111023426056\n",
      "epoch: 3 step: 858, loss is 0.5830307006835938\n",
      "epoch: 3 step: 859, loss is 0.04501792788505554\n",
      "epoch: 3 step: 860, loss is 1.3679771423339844\n",
      "epoch: 3 step: 861, loss is 0.029566412791609764\n",
      "epoch: 3 step: 862, loss is 2.0990500450134277\n",
      "epoch: 3 step: 863, loss is 1.9086086750030518\n",
      "epoch: 3 step: 864, loss is 2.257629156112671\n",
      "epoch: 3 step: 865, loss is 1.143717646598816\n",
      "epoch: 3 step: 866, loss is 0.15254196524620056\n",
      "epoch: 3 step: 867, loss is 1.5391755104064941\n",
      "epoch: 3 step: 868, loss is 1.3676267862319946\n",
      "epoch: 3 step: 869, loss is 2.3373348712921143\n",
      "epoch: 3 step: 870, loss is 1.638692855834961\n",
      "epoch: 3 step: 871, loss is 0.3049292266368866\n",
      "epoch: 3 step: 872, loss is 1.9928817749023438\n",
      "epoch: 3 step: 873, loss is 0.5945467352867126\n",
      "epoch: 3 step: 874, loss is 0.3607483506202698\n",
      "epoch: 3 step: 875, loss is 0.19373075664043427\n",
      "epoch: 3 step: 876, loss is 0.4790130853652954\n",
      "epoch: 3 step: 877, loss is 0.0031784274615347385\n",
      "epoch: 3 step: 878, loss is 3.133253812789917\n",
      "epoch: 3 step: 879, loss is 0.015438571572303772\n",
      "epoch: 3 step: 880, loss is 1.7135001420974731\n",
      "epoch: 3 step: 881, loss is 1.5870709419250488\n",
      "epoch: 3 step: 882, loss is 0.0724032074213028\n",
      "epoch: 3 step: 883, loss is 0.23104017972946167\n",
      "epoch: 3 step: 884, loss is 0.07968703657388687\n",
      "epoch: 3 step: 885, loss is 0.06779661774635315\n",
      "epoch: 3 step: 886, loss is 0.25879791378974915\n",
      "epoch: 3 step: 887, loss is 0.9758173823356628\n",
      "epoch: 3 step: 888, loss is 3.4298031330108643\n",
      "epoch: 3 step: 889, loss is 0.099523164331913\n",
      "epoch: 3 step: 890, loss is 1.1226543188095093\n",
      "epoch: 3 step: 891, loss is 0.04093845188617706\n",
      "epoch: 3 step: 892, loss is 0.2943715453147888\n",
      "epoch: 3 step: 893, loss is 1.570962905883789\n",
      "epoch: 3 step: 894, loss is 1.8001412153244019\n",
      "epoch: 3 step: 895, loss is 2.0987792015075684\n",
      "epoch: 3 step: 896, loss is 0.32125750184059143\n",
      "epoch: 3 step: 897, loss is 3.3202154636383057\n",
      "epoch: 3 step: 898, loss is 0.10633727163076401\n",
      "epoch: 3 step: 899, loss is 0.5322538018226624\n",
      "epoch: 3 step: 900, loss is 0.7265338897705078\n",
      "epoch: 3 step: 901, loss is 1.637031078338623\n",
      "epoch: 3 step: 902, loss is 1.9209946393966675\n",
      "epoch: 3 step: 903, loss is 0.1789698749780655\n",
      "epoch: 3 step: 904, loss is 2.140587091445923\n",
      "epoch: 3 step: 905, loss is 2.2634944915771484\n",
      "epoch: 3 step: 906, loss is 0.1274605691432953\n",
      "epoch: 3 step: 907, loss is 2.3234291076660156\n",
      "epoch: 3 step: 908, loss is 0.33617424964904785\n",
      "epoch: 3 step: 909, loss is 1.2431868314743042\n",
      "epoch: 3 step: 910, loss is 0.09169292449951172\n",
      "epoch: 3 step: 911, loss is 1.8577933311462402\n",
      "epoch: 3 step: 912, loss is 0.3708208501338959\n",
      "epoch: 3 step: 913, loss is 2.214942216873169\n",
      "epoch: 3 step: 914, loss is 0.47692906856536865\n",
      "epoch: 3 step: 915, loss is 0.006160437595099211\n",
      "epoch: 3 step: 916, loss is 1.5572466850280762\n",
      "epoch: 3 step: 917, loss is 1.0301796197891235\n",
      "epoch: 3 step: 918, loss is 0.04543266445398331\n",
      "epoch: 3 step: 919, loss is 2.0911812782287598\n",
      "epoch: 3 step: 920, loss is 1.636337399482727\n",
      "epoch: 3 step: 921, loss is 0.08331172913312912\n",
      "epoch: 3 step: 922, loss is 1.6339695453643799\n",
      "epoch: 3 step: 923, loss is 0.54547518491745\n",
      "epoch: 3 step: 924, loss is 0.5119947791099548\n",
      "epoch: 3 step: 925, loss is 0.047618117183446884\n",
      "epoch: 3 step: 926, loss is 1.6335806846618652\n",
      "epoch: 3 step: 927, loss is 0.424786239862442\n",
      "epoch: 3 step: 928, loss is 0.5383065342903137\n",
      "epoch: 3 step: 929, loss is 0.19609491527080536\n",
      "epoch: 3 step: 930, loss is 0.5899672508239746\n",
      "epoch: 3 step: 931, loss is 0.0480651780962944\n",
      "epoch: 3 step: 932, loss is 0.17423070967197418\n",
      "epoch: 3 step: 933, loss is 0.13858260214328766\n",
      "epoch: 3 step: 934, loss is 0.06322499364614487\n",
      "epoch: 3 step: 935, loss is 0.7669073343276978\n",
      "epoch: 3 step: 936, loss is 0.009898151271045208\n",
      "epoch: 3 step: 937, loss is 2.1671154499053955\n",
      "epoch: 3 step: 938, loss is 0.10898558795452118\n",
      "epoch: 3 step: 939, loss is 2.512253761291504\n",
      "epoch: 3 step: 940, loss is 1.4172847270965576\n",
      "epoch: 3 step: 941, loss is 1.6318315267562866\n",
      "epoch: 3 step: 942, loss is 4.497256278991699\n",
      "epoch: 3 step: 943, loss is 0.5026870965957642\n",
      "epoch: 3 step: 944, loss is 1.8212676048278809\n",
      "epoch: 3 step: 945, loss is 0.28500741720199585\n",
      "epoch: 3 step: 946, loss is 1.3113073110580444\n",
      "epoch: 3 step: 947, loss is 0.24733304977416992\n",
      "epoch: 3 step: 948, loss is 1.2370461225509644\n",
      "epoch: 3 step: 949, loss is 1.1999256610870361\n",
      "epoch: 3 step: 950, loss is 0.4173657298088074\n",
      "epoch: 3 step: 951, loss is 1.5755770206451416\n",
      "epoch: 3 step: 952, loss is 0.2168666422367096\n",
      "epoch: 3 step: 953, loss is 0.06501131504774094\n",
      "epoch: 3 step: 954, loss is 1.8096450567245483\n",
      "epoch: 3 step: 955, loss is 1.5550196170806885\n",
      "epoch: 3 step: 956, loss is 0.0686274990439415\n",
      "epoch: 3 step: 957, loss is 0.3992723524570465\n",
      "epoch: 3 step: 958, loss is 2.098437547683716\n",
      "epoch: 3 step: 959, loss is 1.235666275024414\n",
      "epoch: 3 step: 960, loss is 0.009949141182005405\n",
      "epoch: 3 step: 961, loss is 0.20298241078853607\n",
      "epoch: 3 step: 962, loss is 0.9453721642494202\n",
      "epoch: 3 step: 963, loss is 1.8277342319488525\n",
      "epoch: 3 step: 964, loss is 0.044741760939359665\n",
      "epoch: 3 step: 965, loss is 1.6434898376464844\n",
      "epoch: 3 step: 966, loss is 1.7645832300186157\n",
      "epoch: 3 step: 967, loss is 0.2550469636917114\n",
      "epoch: 3 step: 968, loss is 1.6632871627807617\n",
      "epoch: 3 step: 969, loss is 0.027307584881782532\n",
      "epoch: 3 step: 970, loss is 0.35103127360343933\n",
      "epoch: 3 step: 971, loss is 1.805860996246338\n",
      "epoch: 3 step: 972, loss is 0.0868893414735794\n",
      "epoch: 3 step: 973, loss is 1.7184696197509766\n",
      "epoch: 3 step: 974, loss is 0.0417826846241951\n",
      "epoch: 3 step: 975, loss is 1.2502801418304443\n",
      "epoch: 3 step: 976, loss is 0.14694830775260925\n",
      "epoch: 3 step: 977, loss is 0.04487033933401108\n",
      "epoch: 3 step: 978, loss is 0.494208961725235\n",
      "epoch: 3 step: 979, loss is 2.283024787902832\n",
      "epoch: 3 step: 980, loss is 2.0154078006744385\n",
      "epoch: 3 step: 981, loss is 0.07597104460000992\n",
      "epoch: 3 step: 982, loss is 0.1016581729054451\n",
      "epoch: 3 step: 983, loss is 2.6023716926574707\n",
      "epoch: 3 step: 984, loss is 0.038385059684515\n",
      "epoch: 3 step: 985, loss is 1.538761854171753\n",
      "epoch: 3 step: 986, loss is 0.9324876666069031\n",
      "epoch: 3 step: 987, loss is 2.9097976684570312\n",
      "epoch: 3 step: 988, loss is 1.7930934429168701\n",
      "epoch: 3 step: 989, loss is 0.00624194648116827\n",
      "epoch: 3 step: 990, loss is 0.09326844662427902\n",
      "epoch: 3 step: 991, loss is 1.1124000549316406\n",
      "epoch: 3 step: 992, loss is 0.2476823478937149\n",
      "epoch: 3 step: 993, loss is 0.052350401878356934\n",
      "epoch: 3 step: 994, loss is 0.19110696017742157\n",
      "epoch: 3 step: 995, loss is 0.0017088347813114524\n",
      "epoch: 3 step: 996, loss is 0.7900692820549011\n",
      "epoch: 3 step: 997, loss is 0.02114129811525345\n",
      "epoch: 3 step: 998, loss is 1.5095221996307373\n",
      "epoch: 3 step: 999, loss is 2.5194802284240723\n",
      "epoch: 3 step: 1000, loss is 0.18844418227672577\n",
      "epoch: 3 step: 1001, loss is 0.005512868519872427\n",
      "epoch: 3 step: 1002, loss is 0.2117021530866623\n",
      "epoch: 3 step: 1003, loss is 0.6283289194107056\n",
      "epoch: 3 step: 1004, loss is 0.26827865839004517\n",
      "epoch: 3 step: 1005, loss is 1.914548397064209\n",
      "epoch: 3 step: 1006, loss is 0.009129328653216362\n",
      "epoch: 3 step: 1007, loss is 0.014805677346885204\n",
      "epoch: 3 step: 1008, loss is 1.4398871660232544\n",
      "epoch: 3 step: 1009, loss is 1.0775986909866333\n",
      "epoch: 3 step: 1010, loss is 1.945420265197754\n",
      "epoch: 3 step: 1011, loss is 0.07907304912805557\n",
      "epoch: 3 step: 1012, loss is 4.337406635284424\n",
      "epoch: 3 step: 1013, loss is 0.05121009051799774\n",
      "epoch: 3 step: 1014, loss is 1.1092854738235474\n",
      "epoch: 3 step: 1015, loss is 1.207597255706787\n",
      "epoch: 3 step: 1016, loss is 2.014857769012451\n",
      "epoch: 3 step: 1017, loss is 0.2440611571073532\n",
      "epoch: 3 step: 1018, loss is 0.09721963107585907\n",
      "epoch: 3 step: 1019, loss is 0.3130469024181366\n",
      "epoch: 3 step: 1020, loss is 3.079439401626587\n",
      "epoch: 3 step: 1021, loss is 0.3289100229740143\n",
      "epoch: 3 step: 1022, loss is 0.7902843952178955\n",
      "epoch: 3 step: 1023, loss is 0.24502496421337128\n",
      "epoch: 3 step: 1024, loss is 1.4236770868301392\n",
      "epoch: 3 step: 1025, loss is 0.389150470495224\n",
      "epoch: 3 step: 1026, loss is 1.6525129079818726\n",
      "epoch: 3 step: 1027, loss is 1.6788657903671265\n",
      "epoch: 3 step: 1028, loss is 0.06908173114061356\n",
      "epoch: 3 step: 1029, loss is 1.7526905536651611\n",
      "epoch: 3 step: 1030, loss is 0.12960760295391083\n",
      "epoch: 3 step: 1031, loss is 2.892025947570801\n",
      "epoch: 3 step: 1032, loss is 0.1633356511592865\n",
      "epoch: 3 step: 1033, loss is 0.0767163410782814\n",
      "epoch: 3 step: 1034, loss is 1.8119125366210938\n",
      "epoch: 3 step: 1035, loss is 0.1087661013007164\n",
      "epoch: 3 step: 1036, loss is 0.46331265568733215\n",
      "epoch: 3 step: 1037, loss is 0.008021876215934753\n",
      "epoch: 3 step: 1038, loss is 0.8410210013389587\n",
      "epoch: 3 step: 1039, loss is 0.007206517271697521\n",
      "epoch: 3 step: 1040, loss is 3.1029999256134033\n",
      "epoch: 3 step: 1041, loss is 2.031430721282959\n",
      "epoch: 3 step: 1042, loss is 0.3879145085811615\n",
      "epoch: 3 step: 1043, loss is 1.6832799911499023\n",
      "epoch: 3 step: 1044, loss is 0.027395159006118774\n",
      "epoch: 3 step: 1045, loss is 3.2783994674682617\n",
      "epoch: 3 step: 1046, loss is 1.9509468078613281\n",
      "epoch: 3 step: 1047, loss is 2.0595600605010986\n",
      "epoch: 3 step: 1048, loss is 0.19752903282642365\n",
      "epoch: 3 step: 1049, loss is 0.09051638096570969\n",
      "epoch: 3 step: 1050, loss is 0.607006311416626\n",
      "epoch: 3 step: 1051, loss is 1.807581901550293\n",
      "epoch: 3 step: 1052, loss is 0.8268686532974243\n",
      "epoch: 3 step: 1053, loss is 1.6017926931381226\n",
      "epoch: 3 step: 1054, loss is 2.67287015914917\n",
      "epoch: 3 step: 1055, loss is 0.3117509186267853\n",
      "epoch: 3 step: 1056, loss is 2.985743999481201\n",
      "epoch: 3 step: 1057, loss is 0.5678382515907288\n",
      "epoch: 3 step: 1058, loss is 1.5758140087127686\n",
      "epoch: 3 step: 1059, loss is 3.305816411972046\n",
      "epoch: 3 step: 1060, loss is 0.1662178784608841\n",
      "epoch: 3 step: 1061, loss is 2.005892515182495\n",
      "epoch: 3 step: 1062, loss is 1.541722059249878\n",
      "epoch: 3 step: 1063, loss is 0.460971474647522\n",
      "epoch: 3 step: 1064, loss is 0.23501735925674438\n",
      "epoch: 3 step: 1065, loss is 2.373317003250122\n",
      "epoch: 3 step: 1066, loss is 0.365005761384964\n",
      "epoch: 3 step: 1067, loss is 1.762312650680542\n",
      "epoch: 3 step: 1068, loss is 0.5710284113883972\n",
      "epoch: 3 step: 1069, loss is 1.6235955953598022\n",
      "epoch: 3 step: 1070, loss is 0.39374348521232605\n",
      "epoch: 3 step: 1071, loss is 0.15149925649166107\n",
      "epoch: 3 step: 1072, loss is 1.5655264854431152\n",
      "epoch: 3 step: 1073, loss is 0.3907598555088043\n",
      "epoch: 3 step: 1074, loss is 2.6914453506469727\n",
      "epoch: 3 step: 1075, loss is 0.32669204473495483\n",
      "epoch: 3 step: 1076, loss is 1.7107319831848145\n",
      "epoch: 3 step: 1077, loss is 0.9324762225151062\n",
      "epoch: 3 step: 1078, loss is 2.7676641941070557\n",
      "epoch: 3 step: 1079, loss is 2.4798390865325928\n",
      "epoch: 3 step: 1080, loss is 1.2391549348831177\n",
      "epoch: 3 step: 1081, loss is 0.9943674206733704\n",
      "epoch: 3 step: 1082, loss is 0.8291730284690857\n",
      "epoch: 3 step: 1083, loss is 1.4204862117767334\n",
      "epoch: 3 step: 1084, loss is 0.2405950278043747\n",
      "epoch: 3 step: 1085, loss is 1.9493807554244995\n",
      "epoch: 3 step: 1086, loss is 1.8055799007415771\n",
      "epoch: 3 step: 1087, loss is 1.3490254878997803\n",
      "epoch: 3 step: 1088, loss is 0.7246608138084412\n",
      "epoch: 3 step: 1089, loss is 1.2435373067855835\n",
      "epoch: 3 step: 1090, loss is 1.600823998451233\n",
      "epoch: 3 step: 1091, loss is 2.2095909118652344\n",
      "epoch: 3 step: 1092, loss is 2.0428309440612793\n",
      "epoch: 3 step: 1093, loss is 0.8789050579071045\n",
      "epoch: 3 step: 1094, loss is 2.253845691680908\n",
      "epoch: 3 step: 1095, loss is 0.4974328577518463\n",
      "epoch: 3 step: 1096, loss is 0.6947211623191833\n",
      "epoch: 3 step: 1097, loss is 0.23039336502552032\n",
      "epoch: 3 step: 1098, loss is 1.7757692337036133\n",
      "epoch: 3 step: 1099, loss is 1.3994927406311035\n",
      "epoch: 3 step: 1100, loss is 0.3863007724285126\n",
      "epoch: 3 step: 1101, loss is 0.627508282661438\n",
      "epoch: 3 step: 1102, loss is 0.2925001382827759\n",
      "epoch: 3 step: 1103, loss is 2.009282112121582\n",
      "epoch: 3 step: 1104, loss is 1.3082548379898071\n",
      "epoch: 3 step: 1105, loss is 1.8438693284988403\n",
      "epoch: 3 step: 1106, loss is 0.36935940384864807\n",
      "epoch: 3 step: 1107, loss is 1.197306513786316\n",
      "epoch: 3 step: 1108, loss is 0.04303108528256416\n",
      "epoch: 3 step: 1109, loss is 1.5573551654815674\n",
      "epoch: 3 step: 1110, loss is 0.22442618012428284\n",
      "epoch: 3 step: 1111, loss is 1.428922414779663\n",
      "epoch: 3 step: 1112, loss is 0.018935978412628174\n",
      "epoch: 3 step: 1113, loss is 0.347150981426239\n",
      "epoch: 3 step: 1114, loss is 0.39562517404556274\n",
      "epoch: 3 step: 1115, loss is 0.07565676420927048\n",
      "epoch: 3 step: 1116, loss is 3.9522128105163574\n",
      "epoch: 3 step: 1117, loss is 0.30599233508110046\n",
      "epoch: 3 step: 1118, loss is 2.0513861179351807\n",
      "epoch: 3 step: 1119, loss is 0.04113433137536049\n",
      "epoch: 3 step: 1120, loss is 0.409811407327652\n",
      "epoch: 3 step: 1121, loss is 0.050980713218450546\n",
      "epoch: 3 step: 1122, loss is 1.1772119998931885\n",
      "epoch: 3 step: 1123, loss is 0.007636165712028742\n",
      "epoch: 3 step: 1124, loss is 0.1286199390888214\n",
      "epoch: 3 step: 1125, loss is 0.31634241342544556\n",
      "epoch: 3 step: 1126, loss is 2.2970900535583496\n",
      "epoch: 3 step: 1127, loss is 0.06584897637367249\n",
      "epoch: 3 step: 1128, loss is 0.43465206027030945\n",
      "epoch: 3 step: 1129, loss is 2.189300060272217\n",
      "epoch: 3 step: 1130, loss is 0.08946021646261215\n",
      "epoch: 3 step: 1131, loss is 0.034103844314813614\n",
      "epoch: 3 step: 1132, loss is 0.19104373455047607\n",
      "epoch: 3 step: 1133, loss is 0.05897890776395798\n",
      "epoch: 3 step: 1134, loss is 0.13632985949516296\n",
      "epoch: 3 step: 1135, loss is 1.6509902477264404\n",
      "epoch: 3 step: 1136, loss is 0.05095250532031059\n",
      "epoch: 3 step: 1137, loss is 2.3270061016082764\n",
      "epoch: 3 step: 1138, loss is 1.8231009244918823\n",
      "epoch: 3 step: 1139, loss is 1.8862159252166748\n",
      "epoch: 3 step: 1140, loss is 0.7538316249847412\n",
      "epoch: 3 step: 1141, loss is 1.6338653564453125\n",
      "epoch: 3 step: 1142, loss is 0.03694968298077583\n",
      "epoch: 3 step: 1143, loss is 3.0030157566070557\n",
      "epoch: 3 step: 1144, loss is 0.4007558524608612\n",
      "epoch: 3 step: 1145, loss is 1.8252578973770142\n",
      "epoch: 3 step: 1146, loss is 0.21291860938072205\n",
      "epoch: 3 step: 1147, loss is 0.02874040976166725\n",
      "epoch: 3 step: 1148, loss is 0.20756462216377258\n",
      "epoch: 3 step: 1149, loss is 2.3845574855804443\n",
      "epoch: 3 step: 1150, loss is 1.8069405555725098\n",
      "epoch: 3 step: 1151, loss is 2.863680601119995\n",
      "epoch: 3 step: 1152, loss is 0.56908118724823\n",
      "epoch: 3 step: 1153, loss is 2.395698308944702\n",
      "epoch: 3 step: 1154, loss is 1.100450038909912\n",
      "epoch: 3 step: 1155, loss is 0.09611248224973679\n",
      "epoch: 3 step: 1156, loss is 1.8123979568481445\n",
      "epoch: 3 step: 1157, loss is 0.24360500276088715\n",
      "epoch: 3 step: 1158, loss is 0.143069326877594\n",
      "epoch: 3 step: 1159, loss is 1.5633025169372559\n",
      "epoch: 3 step: 1160, loss is 1.6823241710662842\n",
      "epoch: 3 step: 1161, loss is 3.804643392562866\n",
      "epoch: 3 step: 1162, loss is 1.9959876537322998\n",
      "epoch: 3 step: 1163, loss is 0.4946865737438202\n",
      "epoch: 3 step: 1164, loss is 0.474773645401001\n",
      "epoch: 3 step: 1165, loss is 0.8577852249145508\n",
      "epoch: 3 step: 1166, loss is 0.8904815912246704\n",
      "epoch: 3 step: 1167, loss is 0.06720326095819473\n",
      "epoch: 3 step: 1168, loss is 0.10318464040756226\n",
      "epoch: 3 step: 1169, loss is 0.3694246709346771\n",
      "epoch: 3 step: 1170, loss is 1.80419921875\n",
      "epoch: 3 step: 1171, loss is 1.6718997955322266\n",
      "epoch: 3 step: 1172, loss is 1.2364336252212524\n",
      "epoch: 3 step: 1173, loss is 4.318500995635986\n",
      "epoch: 3 step: 1174, loss is 1.8436970710754395\n",
      "epoch: 3 step: 1175, loss is 0.8582103848457336\n",
      "epoch: 3 step: 1176, loss is 1.237916350364685\n",
      "epoch: 3 step: 1177, loss is 1.3031538724899292\n",
      "epoch: 3 step: 1178, loss is 1.6437697410583496\n",
      "epoch: 3 step: 1179, loss is 0.27346551418304443\n",
      "epoch: 3 step: 1180, loss is 0.08514794707298279\n",
      "epoch: 3 step: 1181, loss is 0.544809103012085\n",
      "epoch: 3 step: 1182, loss is 0.382855623960495\n",
      "epoch: 3 step: 1183, loss is 0.21237149834632874\n",
      "epoch: 3 step: 1184, loss is 2.1220710277557373\n",
      "epoch: 3 step: 1185, loss is 0.40786850452423096\n",
      "epoch: 3 step: 1186, loss is 0.2260686755180359\n",
      "epoch: 3 step: 1187, loss is 1.414919137954712\n",
      "epoch: 3 step: 1188, loss is 0.37786686420440674\n",
      "epoch: 3 step: 1189, loss is 1.8186395168304443\n",
      "epoch: 3 step: 1190, loss is 2.3089230060577393\n",
      "epoch: 3 step: 1191, loss is 1.7634222507476807\n",
      "epoch: 3 step: 1192, loss is 1.46978759765625\n",
      "epoch: 3 step: 1193, loss is 1.7751469612121582\n",
      "epoch: 3 step: 1194, loss is 2.157003879547119\n",
      "epoch: 3 step: 1195, loss is 0.6731863617897034\n",
      "epoch: 3 step: 1196, loss is 1.8034369945526123\n",
      "epoch: 3 step: 1197, loss is 0.7077224850654602\n",
      "epoch: 3 step: 1198, loss is 0.24740640819072723\n",
      "epoch: 3 step: 1199, loss is 0.19210094213485718\n",
      "epoch: 3 step: 1200, loss is 1.2290207147598267\n",
      "epoch: 3 step: 1201, loss is 1.4407404661178589\n",
      "epoch: 3 step: 1202, loss is 0.2584969401359558\n",
      "epoch: 3 step: 1203, loss is 0.061532557010650635\n",
      "epoch: 3 step: 1204, loss is 1.6625893115997314\n",
      "epoch: 3 step: 1205, loss is 0.180376797914505\n",
      "epoch: 3 step: 1206, loss is 0.07191231846809387\n",
      "epoch: 3 step: 1207, loss is 0.5277050137519836\n",
      "epoch: 3 step: 1208, loss is 0.03996431082487106\n",
      "epoch: 3 step: 1209, loss is 1.0812023878097534\n",
      "epoch: 3 step: 1210, loss is 0.45386284589767456\n",
      "epoch: 3 step: 1211, loss is 0.13494892418384552\n",
      "epoch: 3 step: 1212, loss is 0.010094896890223026\n",
      "epoch: 3 step: 1213, loss is 0.02765296772122383\n",
      "epoch: 3 step: 1214, loss is 0.022052081301808357\n",
      "epoch: 3 step: 1215, loss is 0.00494886701926589\n",
      "epoch: 3 step: 1216, loss is 0.019047681242227554\n",
      "epoch: 3 step: 1217, loss is 0.15526653826236725\n",
      "epoch: 3 step: 1218, loss is 0.5831035375595093\n",
      "epoch: 3 step: 1219, loss is 1.8307913541793823\n",
      "epoch: 3 step: 1220, loss is 0.015278096310794353\n",
      "epoch: 3 step: 1221, loss is 0.25166547298431396\n",
      "epoch: 3 step: 1222, loss is 2.314521551132202\n",
      "epoch: 3 step: 1223, loss is 2.326137065887451\n",
      "epoch: 3 step: 1224, loss is 2.6344637870788574\n",
      "epoch: 3 step: 1225, loss is 0.14720392227172852\n",
      "epoch: 3 step: 1226, loss is 1.210802435874939\n",
      "epoch: 3 step: 1227, loss is 0.5338629484176636\n",
      "epoch: 3 step: 1228, loss is 0.25954002141952515\n",
      "epoch: 3 step: 1229, loss is 0.18014763295650482\n",
      "epoch: 3 step: 1230, loss is 0.03744816035032272\n",
      "epoch: 3 step: 1231, loss is 1.7604451179504395\n",
      "epoch: 3 step: 1232, loss is 2.426417350769043\n",
      "epoch: 3 step: 1233, loss is 1.6675297021865845\n",
      "epoch: 3 step: 1234, loss is 0.6301472783088684\n",
      "epoch: 3 step: 1235, loss is 0.3487395942211151\n",
      "epoch: 3 step: 1236, loss is 1.7546244859695435\n",
      "epoch: 3 step: 1237, loss is 0.189743772149086\n",
      "epoch: 3 step: 1238, loss is 1.9434313774108887\n",
      "epoch: 3 step: 1239, loss is 0.06744487583637238\n",
      "epoch: 3 step: 1240, loss is 0.23031193017959595\n",
      "epoch: 3 step: 1241, loss is 1.817994475364685\n",
      "epoch: 3 step: 1242, loss is 0.02153933420777321\n",
      "epoch: 3 step: 1243, loss is 0.07476212084293365\n",
      "epoch: 3 step: 1244, loss is 0.021542368456721306\n",
      "epoch: 3 step: 1245, loss is 0.387338250875473\n",
      "epoch: 3 step: 1246, loss is 2.6324360370635986\n",
      "epoch: 3 step: 1247, loss is 0.7702010869979858\n",
      "epoch: 3 step: 1248, loss is 1.4750428199768066\n",
      "epoch: 3 step: 1249, loss is 0.24985823035240173\n",
      "epoch: 3 step: 1250, loss is 2.759387731552124\n",
      "epoch: 3 step: 1251, loss is 1.7380073070526123\n",
      "epoch: 3 step: 1252, loss is 0.3886171877384186\n",
      "epoch: 3 step: 1253, loss is 0.11701428890228271\n",
      "epoch: 3 step: 1254, loss is 0.33951321244239807\n",
      "epoch: 3 step: 1255, loss is 0.20385956764221191\n",
      "epoch: 3 step: 1256, loss is 0.5572372078895569\n",
      "epoch: 3 step: 1257, loss is 0.14444167912006378\n",
      "epoch: 3 step: 1258, loss is 0.16636617481708527\n",
      "epoch: 3 step: 1259, loss is 2.333284616470337\n",
      "epoch: 3 step: 1260, loss is 1.6259042024612427\n",
      "epoch: 3 step: 1261, loss is 1.9726662635803223\n",
      "epoch: 3 step: 1262, loss is 0.29745960235595703\n",
      "epoch: 3 step: 1263, loss is 0.14274795353412628\n",
      "epoch: 3 step: 1264, loss is 0.08039183914661407\n",
      "epoch: 3 step: 1265, loss is 0.22085249423980713\n",
      "epoch: 3 step: 1266, loss is 0.03950009122490883\n",
      "epoch: 3 step: 1267, loss is 0.5413077473640442\n",
      "epoch: 3 step: 1268, loss is 0.2251010537147522\n",
      "epoch: 3 step: 1269, loss is 0.07359272241592407\n",
      "epoch: 3 step: 1270, loss is 0.42784950137138367\n",
      "epoch: 3 step: 1271, loss is 0.978228747844696\n",
      "epoch: 3 step: 1272, loss is 2.2440969944000244\n",
      "epoch: 3 step: 1273, loss is 0.33619722723960876\n",
      "epoch: 3 step: 1274, loss is 1.6730961799621582\n",
      "epoch: 3 step: 1275, loss is 0.48465368151664734\n",
      "epoch: 3 step: 1276, loss is 1.6745047569274902\n",
      "epoch: 3 step: 1277, loss is 0.13734403252601624\n",
      "epoch: 3 step: 1278, loss is 0.049369990825653076\n",
      "epoch: 3 step: 1279, loss is 1.5969345569610596\n",
      "epoch: 3 step: 1280, loss is 0.01861507073044777\n",
      "epoch: 3 step: 1281, loss is 0.11566904932260513\n",
      "epoch: 3 step: 1282, loss is 0.0046577295288443565\n",
      "epoch: 3 step: 1283, loss is 0.03162555396556854\n",
      "epoch: 3 step: 1284, loss is 0.013003197498619556\n",
      "epoch: 3 step: 1285, loss is 0.12999288737773895\n",
      "epoch: 3 step: 1286, loss is 0.12330416589975357\n",
      "epoch: 3 step: 1287, loss is 0.024821558967232704\n",
      "epoch: 3 step: 1288, loss is 0.03930308669805527\n",
      "epoch: 3 step: 1289, loss is 0.03880507871508598\n",
      "epoch: 3 step: 1290, loss is 0.028538726270198822\n",
      "epoch: 3 step: 1291, loss is 0.013981256633996964\n",
      "epoch: 3 step: 1292, loss is 0.9362953901290894\n",
      "epoch: 3 step: 1293, loss is 0.28142669796943665\n",
      "epoch: 3 step: 1294, loss is 0.10683876276016235\n",
      "epoch: 3 step: 1295, loss is 0.3351495563983917\n",
      "epoch: 3 step: 1296, loss is 1.6484650373458862\n",
      "epoch: 3 step: 1297, loss is 0.04158693179488182\n",
      "epoch: 3 step: 1298, loss is 1.5476484298706055\n",
      "epoch: 3 step: 1299, loss is 2.510985851287842\n",
      "epoch: 3 step: 1300, loss is 1.7870144844055176\n",
      "epoch: 3 step: 1301, loss is 2.4205336570739746\n",
      "epoch: 3 step: 1302, loss is 0.03696737810969353\n",
      "epoch: 3 step: 1303, loss is 1.9774935245513916\n",
      "epoch: 3 step: 1304, loss is 0.5272893309593201\n",
      "epoch: 3 step: 1305, loss is 0.7763192653656006\n",
      "epoch: 3 step: 1306, loss is 0.18740159273147583\n",
      "epoch: 3 step: 1307, loss is 0.23836542665958405\n",
      "epoch: 3 step: 1308, loss is 0.012240763753652573\n",
      "epoch: 3 step: 1309, loss is 0.18122974038124084\n",
      "epoch: 3 step: 1310, loss is 0.01735067181289196\n",
      "epoch: 3 step: 1311, loss is 3.7410945892333984\n",
      "epoch: 3 step: 1312, loss is 0.789104163646698\n",
      "epoch: 3 step: 1313, loss is 0.42027929425239563\n",
      "epoch: 3 step: 1314, loss is 0.6926886439323425\n",
      "epoch: 3 step: 1315, loss is 1.989516258239746\n",
      "epoch: 3 step: 1316, loss is 0.03827962651848793\n",
      "epoch: 3 step: 1317, loss is 0.8878493905067444\n",
      "epoch: 3 step: 1318, loss is 0.1397935301065445\n",
      "epoch: 3 step: 1319, loss is 1.2361037731170654\n",
      "epoch: 3 step: 1320, loss is 1.9886820316314697\n",
      "epoch: 3 step: 1321, loss is 1.638384461402893\n",
      "epoch: 3 step: 1322, loss is 0.07983672618865967\n",
      "epoch: 3 step: 1323, loss is 1.7545487880706787\n",
      "epoch: 3 step: 1324, loss is 0.05106476694345474\n",
      "epoch: 3 step: 1325, loss is 1.7319118976593018\n",
      "epoch: 3 step: 1326, loss is 2.2755656242370605\n",
      "epoch: 3 step: 1327, loss is 1.848869800567627\n",
      "epoch: 3 step: 1328, loss is 0.6081917881965637\n",
      "epoch: 3 step: 1329, loss is 2.2297191619873047\n",
      "epoch: 3 step: 1330, loss is 0.8080676198005676\n",
      "epoch: 3 step: 1331, loss is 1.7140276432037354\n",
      "epoch: 3 step: 1332, loss is 1.0605614185333252\n",
      "epoch: 3 step: 1333, loss is 0.14143525063991547\n",
      "epoch: 3 step: 1334, loss is 1.5213758945465088\n",
      "epoch: 3 step: 1335, loss is 2.941708564758301\n",
      "epoch: 3 step: 1336, loss is 0.11194469034671783\n",
      "epoch: 3 step: 1337, loss is 1.6345869302749634\n",
      "epoch: 3 step: 1338, loss is 1.8581494092941284\n",
      "epoch: 3 step: 1339, loss is 0.5229414105415344\n",
      "epoch: 3 step: 1340, loss is 0.2815364599227905\n",
      "epoch: 3 step: 1341, loss is 2.6224210262298584\n",
      "epoch: 3 step: 1342, loss is 0.05587167665362358\n",
      "epoch: 3 step: 1343, loss is 0.8995271325111389\n",
      "epoch: 3 step: 1344, loss is 1.735543966293335\n",
      "epoch: 3 step: 1345, loss is 2.0064756870269775\n",
      "epoch: 3 step: 1346, loss is 0.8336215019226074\n",
      "epoch: 3 step: 1347, loss is 1.560441017150879\n",
      "epoch: 3 step: 1348, loss is 1.014952540397644\n",
      "epoch: 3 step: 1349, loss is 1.633986473083496\n",
      "epoch: 3 step: 1350, loss is 1.9160059690475464\n",
      "epoch: 3 step: 1351, loss is 0.3323788046836853\n",
      "epoch: 3 step: 1352, loss is 1.9751322269439697\n",
      "epoch: 3 step: 1353, loss is 1.3218272924423218\n",
      "epoch: 3 step: 1354, loss is 1.5821688175201416\n",
      "epoch: 3 step: 1355, loss is 0.5624237656593323\n",
      "epoch: 3 step: 1356, loss is 0.5274036526679993\n",
      "epoch: 3 step: 1357, loss is 0.03565087169408798\n",
      "epoch: 3 step: 1358, loss is 0.01473848894238472\n",
      "epoch: 3 step: 1359, loss is 1.8263384103775024\n",
      "epoch: 3 step: 1360, loss is 0.6400134563446045\n",
      "epoch: 3 step: 1361, loss is 1.3328361511230469\n",
      "epoch: 3 step: 1362, loss is 0.21881835162639618\n",
      "epoch: 3 step: 1363, loss is 1.6495133638381958\n",
      "epoch: 3 step: 1364, loss is 0.4844225347042084\n",
      "epoch: 3 step: 1365, loss is 0.0021935468539595604\n",
      "epoch: 3 step: 1366, loss is 0.10589493066072464\n",
      "epoch: 3 step: 1367, loss is 1.6350014209747314\n",
      "epoch: 3 step: 1368, loss is 0.03225309029221535\n",
      "epoch: 3 step: 1369, loss is 0.04289267957210541\n",
      "epoch: 3 step: 1370, loss is 0.004429173190146685\n",
      "epoch: 3 step: 1371, loss is 0.36942869424819946\n",
      "epoch: 3 step: 1372, loss is 2.21362566947937\n",
      "epoch: 3 step: 1373, loss is 0.4950823485851288\n",
      "epoch: 3 step: 1374, loss is 0.19606180489063263\n",
      "epoch: 3 step: 1375, loss is 0.05763313174247742\n",
      "epoch: 3 step: 1376, loss is 1.2049472332000732\n",
      "epoch: 3 step: 1377, loss is 3.5144410133361816\n",
      "epoch: 3 step: 1378, loss is 2.010053873062134\n",
      "epoch: 3 step: 1379, loss is 1.4586105346679688\n",
      "epoch: 3 step: 1380, loss is 3.8125739097595215\n",
      "epoch: 3 step: 1381, loss is 0.5311286449432373\n",
      "epoch: 3 step: 1382, loss is 0.18090170621871948\n",
      "epoch: 3 step: 1383, loss is 0.16153621673583984\n",
      "epoch: 3 step: 1384, loss is 1.724174976348877\n",
      "epoch: 3 step: 1385, loss is 0.22189584374427795\n",
      "epoch: 3 step: 1386, loss is 0.03664484992623329\n",
      "epoch: 3 step: 1387, loss is 0.061484355479478836\n",
      "epoch: 3 step: 1388, loss is 2.1108970642089844\n",
      "epoch: 3 step: 1389, loss is 0.08518265187740326\n",
      "epoch: 3 step: 1390, loss is 0.10028056055307388\n",
      "epoch: 3 step: 1391, loss is 0.5993738770484924\n",
      "epoch: 3 step: 1392, loss is 0.1349264234304428\n",
      "epoch: 3 step: 1393, loss is 1.3887869119644165\n",
      "epoch: 3 step: 1394, loss is 0.03856951370835304\n",
      "epoch: 3 step: 1395, loss is 1.4510979652404785\n",
      "epoch: 3 step: 1396, loss is 0.03952747955918312\n",
      "epoch: 3 step: 1397, loss is 2.6823203563690186\n",
      "epoch: 3 step: 1398, loss is 1.8782438039779663\n",
      "epoch: 3 step: 1399, loss is 0.23397450149059296\n",
      "epoch: 3 step: 1400, loss is 0.022878965362906456\n",
      "epoch: 3 step: 1401, loss is 0.08457641303539276\n",
      "epoch: 3 step: 1402, loss is 0.6302331686019897\n",
      "epoch: 3 step: 1403, loss is 0.45299649238586426\n",
      "epoch: 3 step: 1404, loss is 0.02835797518491745\n",
      "epoch: 3 step: 1405, loss is 0.31155651807785034\n",
      "epoch: 3 step: 1406, loss is 0.04184350743889809\n",
      "epoch: 3 step: 1407, loss is 0.11195630580186844\n",
      "epoch: 3 step: 1408, loss is 0.021855806931853294\n",
      "epoch: 3 step: 1409, loss is 1.9417712688446045\n",
      "epoch: 3 step: 1410, loss is 2.9064128398895264\n",
      "epoch: 3 step: 1411, loss is 0.32321327924728394\n",
      "epoch: 3 step: 1412, loss is 0.03776618093252182\n",
      "epoch: 3 step: 1413, loss is 2.0772979259490967\n",
      "epoch: 3 step: 1414, loss is 0.08567538857460022\n",
      "epoch: 3 step: 1415, loss is 0.733452558517456\n",
      "epoch: 3 step: 1416, loss is 1.6343441009521484\n",
      "epoch: 3 step: 1417, loss is 2.699960708618164\n",
      "epoch: 3 step: 1418, loss is 0.09335401654243469\n",
      "epoch: 3 step: 1419, loss is 0.07579866796731949\n",
      "epoch: 3 step: 1420, loss is 3.500541925430298\n",
      "epoch: 3 step: 1421, loss is 0.62272047996521\n",
      "epoch: 3 step: 1422, loss is 3.0989882946014404\n",
      "epoch: 3 step: 1423, loss is 1.6299564838409424\n",
      "epoch: 3 step: 1424, loss is 0.18877962231636047\n",
      "epoch: 3 step: 1425, loss is 0.1507248431444168\n",
      "epoch: 3 step: 1426, loss is 1.0106531381607056\n",
      "epoch: 3 step: 1427, loss is 1.2414720058441162\n",
      "epoch: 3 step: 1428, loss is 0.930920422077179\n",
      "epoch: 3 step: 1429, loss is 2.4970192909240723\n",
      "epoch: 3 step: 1430, loss is 0.3792403042316437\n",
      "epoch: 3 step: 1431, loss is 1.6342103481292725\n",
      "epoch: 3 step: 1432, loss is 0.28422942757606506\n",
      "epoch: 3 step: 1433, loss is 1.4458868503570557\n",
      "epoch: 3 step: 1434, loss is 1.6336538791656494\n",
      "epoch: 3 step: 1435, loss is 1.2400857210159302\n",
      "epoch: 3 step: 1436, loss is 0.6597311496734619\n",
      "epoch: 3 step: 1437, loss is 0.4317965507507324\n",
      "epoch: 3 step: 1438, loss is 0.25054827332496643\n",
      "epoch: 3 step: 1439, loss is 0.6221388578414917\n",
      "epoch: 3 step: 1440, loss is 1.2374083995819092\n",
      "epoch: 3 step: 1441, loss is 0.6536486744880676\n",
      "epoch: 3 step: 1442, loss is 0.045886509120464325\n",
      "epoch: 3 step: 1443, loss is 0.008837987668812275\n",
      "epoch: 3 step: 1444, loss is 0.16232167184352875\n",
      "epoch: 3 step: 1445, loss is 0.37097591161727905\n",
      "epoch: 3 step: 1446, loss is 0.3406119644641876\n",
      "epoch: 3 step: 1447, loss is 6.039700031280518\n",
      "epoch: 3 step: 1448, loss is 1.5770165920257568\n",
      "epoch: 3 step: 1449, loss is 1.9985947608947754\n",
      "epoch: 3 step: 1450, loss is 1.2467215061187744\n",
      "epoch: 3 step: 1451, loss is 0.10652321577072144\n",
      "epoch: 3 step: 1452, loss is 0.28912562131881714\n",
      "epoch: 3 step: 1453, loss is 0.18490895628929138\n",
      "epoch: 3 step: 1454, loss is 2.1910760402679443\n",
      "epoch: 3 step: 1455, loss is 0.1479422003030777\n",
      "epoch: 3 step: 1456, loss is 0.6565646529197693\n",
      "epoch: 3 step: 1457, loss is 0.6645504236221313\n",
      "epoch: 3 step: 1458, loss is 0.40900951623916626\n",
      "epoch: 3 step: 1459, loss is 0.07175909727811813\n",
      "epoch: 3 step: 1460, loss is 1.6332621574401855\n",
      "epoch: 3 step: 1461, loss is 2.14723539352417\n",
      "epoch: 3 step: 1462, loss is 2.082697868347168\n",
      "epoch: 3 step: 1463, loss is 0.20011311769485474\n",
      "epoch: 3 step: 1464, loss is 2.230780839920044\n",
      "epoch: 3 step: 1465, loss is 0.0585491806268692\n",
      "epoch: 3 step: 1466, loss is 0.10928849875926971\n",
      "epoch: 3 step: 1467, loss is 0.6658219695091248\n",
      "epoch: 3 step: 1468, loss is 1.8015491962432861\n",
      "epoch: 3 step: 1469, loss is 0.11144980788230896\n",
      "epoch: 3 step: 1470, loss is 0.33495455980300903\n",
      "epoch: 3 step: 1471, loss is 0.4350360631942749\n",
      "epoch: 3 step: 1472, loss is 1.6322749853134155\n",
      "epoch: 3 step: 1473, loss is 2.916626453399658\n",
      "epoch: 3 step: 1474, loss is 2.312624931335449\n",
      "epoch: 3 step: 1475, loss is 0.21237950026988983\n",
      "epoch: 3 step: 1476, loss is 0.21847587823867798\n",
      "epoch: 3 step: 1477, loss is 0.7112822532653809\n",
      "epoch: 3 step: 1478, loss is 0.2104378640651703\n",
      "epoch: 3 step: 1479, loss is 0.2714839279651642\n",
      "epoch: 3 step: 1480, loss is 0.3085184097290039\n",
      "epoch: 3 step: 1481, loss is 0.3259431719779968\n",
      "epoch: 3 step: 1482, loss is 0.11255182325839996\n",
      "epoch: 3 step: 1483, loss is 0.005904019810259342\n",
      "epoch: 3 step: 1484, loss is 0.026262709870934486\n",
      "epoch: 3 step: 1485, loss is 1.2229353189468384\n",
      "epoch: 3 step: 1486, loss is 2.3960633277893066\n",
      "epoch: 3 step: 1487, loss is 1.349244236946106\n",
      "epoch: 3 step: 1488, loss is 1.5571258068084717\n",
      "epoch: 3 step: 1489, loss is 5.463057994842529\n",
      "epoch: 3 step: 1490, loss is 2.137901782989502\n",
      "epoch: 3 step: 1491, loss is 0.960809051990509\n",
      "epoch: 3 step: 1492, loss is 1.409295678138733\n",
      "epoch: 3 step: 1493, loss is 1.373801350593567\n",
      "epoch: 3 step: 1494, loss is 1.8054449558258057\n",
      "epoch: 3 step: 1495, loss is 0.45881888270378113\n",
      "epoch: 3 step: 1496, loss is 0.6774274706840515\n",
      "epoch: 3 step: 1497, loss is 0.6985452771186829\n",
      "epoch: 3 step: 1498, loss is 0.08780170232057571\n",
      "epoch: 3 step: 1499, loss is 1.8253066539764404\n",
      "epoch: 3 step: 1500, loss is 1.5178947448730469\n",
      "epoch: 3 step: 1501, loss is 0.4538452923297882\n",
      "epoch: 3 step: 1502, loss is 0.4392259418964386\n",
      "epoch: 3 step: 1503, loss is 1.3589885234832764\n",
      "epoch: 3 step: 1504, loss is 1.5490689277648926\n",
      "epoch: 3 step: 1505, loss is 0.13338997960090637\n",
      "epoch: 3 step: 1506, loss is 2.081050395965576\n",
      "epoch: 3 step: 1507, loss is 0.08706407248973846\n",
      "epoch: 3 step: 1508, loss is 1.2387644052505493\n",
      "epoch: 3 step: 1509, loss is 1.5567954778671265\n",
      "epoch: 3 step: 1510, loss is 0.1493818163871765\n",
      "epoch: 3 step: 1511, loss is 0.17680269479751587\n",
      "epoch: 3 step: 1512, loss is 0.32699304819107056\n",
      "epoch: 3 step: 1513, loss is 0.03198007121682167\n",
      "epoch: 3 step: 1514, loss is 0.8861007690429688\n",
      "epoch: 3 step: 1515, loss is 2.6170198917388916\n",
      "epoch: 3 step: 1516, loss is 2.276981830596924\n",
      "epoch: 3 step: 1517, loss is 0.5089154243469238\n",
      "epoch: 3 step: 1518, loss is 0.7725179195404053\n",
      "epoch: 3 step: 1519, loss is 0.16865688562393188\n",
      "epoch: 3 step: 1520, loss is 0.21671384572982788\n",
      "epoch: 3 step: 1521, loss is 0.14512766897678375\n",
      "epoch: 3 step: 1522, loss is 0.5231751203536987\n",
      "epoch: 3 step: 1523, loss is 0.12611019611358643\n",
      "epoch: 3 step: 1524, loss is 4.342587947845459\n",
      "epoch: 3 step: 1525, loss is 0.26347556710243225\n",
      "epoch: 3 step: 1526, loss is 0.015596321783959866\n",
      "epoch: 3 step: 1527, loss is 0.626417338848114\n",
      "epoch: 3 step: 1528, loss is 0.16235673427581787\n",
      "epoch: 3 step: 1529, loss is 0.09986584633588791\n",
      "epoch: 3 step: 1530, loss is 1.4692462682724\n",
      "epoch: 3 step: 1531, loss is 0.0871935486793518\n",
      "epoch: 3 step: 1532, loss is 0.09174393862485886\n",
      "epoch: 3 step: 1533, loss is 4.288549900054932\n",
      "epoch: 3 step: 1534, loss is 1.45229172706604\n",
      "epoch: 3 step: 1535, loss is 0.15447653830051422\n",
      "epoch: 3 step: 1536, loss is 0.9024603366851807\n",
      "epoch: 3 step: 1537, loss is 0.2816595137119293\n",
      "epoch: 3 step: 1538, loss is 0.08706659078598022\n",
      "epoch: 3 step: 1539, loss is 0.30836987495422363\n",
      "epoch: 3 step: 1540, loss is 4.025842189788818\n",
      "epoch: 3 step: 1541, loss is 0.06866823881864548\n",
      "epoch: 3 step: 1542, loss is 0.38416507840156555\n",
      "epoch: 3 step: 1543, loss is 1.869895100593567\n",
      "epoch: 3 step: 1544, loss is 2.641387939453125\n",
      "epoch: 3 step: 1545, loss is 0.1892727166414261\n",
      "epoch: 3 step: 1546, loss is 0.17715156078338623\n",
      "epoch: 3 step: 1547, loss is 0.32047805190086365\n",
      "epoch: 3 step: 1548, loss is 1.276906967163086\n",
      "epoch: 3 step: 1549, loss is 0.20877373218536377\n",
      "epoch: 3 step: 1550, loss is 2.547410726547241\n",
      "epoch: 3 step: 1551, loss is 0.15383762121200562\n",
      "epoch: 3 step: 1552, loss is 3.0185961723327637\n",
      "epoch: 3 step: 1553, loss is 0.7979347705841064\n",
      "epoch: 3 step: 1554, loss is 1.6315358877182007\n",
      "epoch: 3 step: 1555, loss is 0.4244888126850128\n",
      "epoch: 3 step: 1556, loss is 0.2246772199869156\n",
      "epoch: 3 step: 1557, loss is 1.6449049711227417\n",
      "epoch: 3 step: 1558, loss is 1.7728049755096436\n",
      "epoch: 3 step: 1559, loss is 0.13148459792137146\n",
      "epoch: 3 step: 1560, loss is 1.4209203720092773\n",
      "epoch: 3 step: 1561, loss is 0.5802416801452637\n",
      "epoch: 3 step: 1562, loss is 0.12325642257928848\n",
      "epoch: 3 step: 1563, loss is 0.05924611911177635\n",
      "epoch: 3 step: 1564, loss is 1.7901017665863037\n",
      "epoch: 3 step: 1565, loss is 0.06320138275623322\n",
      "epoch: 3 step: 1566, loss is 0.26235634088516235\n",
      "epoch: 3 step: 1567, loss is 1.273925542831421\n",
      "epoch: 3 step: 1568, loss is 0.07538605481386185\n",
      "epoch: 3 step: 1569, loss is 0.21546857059001923\n",
      "epoch: 3 step: 1570, loss is 2.122138261795044\n",
      "epoch: 3 step: 1571, loss is 1.5109467506408691\n",
      "epoch: 3 step: 1572, loss is 1.9783051013946533\n",
      "epoch: 3 step: 1573, loss is 1.8086585998535156\n",
      "epoch: 3 step: 1574, loss is 1.6314679384231567\n",
      "epoch: 3 step: 1575, loss is 0.09308968484401703\n",
      "epoch: 3 step: 1576, loss is 0.2001378983259201\n",
      "epoch: 3 step: 1577, loss is 1.2994210720062256\n",
      "epoch: 3 step: 1578, loss is 0.7038841843605042\n",
      "epoch: 3 step: 1579, loss is 0.10271670669317245\n",
      "epoch: 3 step: 1580, loss is 0.2612718641757965\n",
      "epoch: 3 step: 1581, loss is 1.94448983669281\n",
      "epoch: 3 step: 1582, loss is 1.8142590522766113\n",
      "epoch: 3 step: 1583, loss is 1.9781434535980225\n",
      "epoch: 3 step: 1584, loss is 1.5988434553146362\n",
      "epoch: 3 step: 1585, loss is 2.4697844982147217\n",
      "epoch: 3 step: 1586, loss is 0.38412564992904663\n",
      "epoch: 3 step: 1587, loss is 1.7824385166168213\n",
      "epoch: 3 step: 1588, loss is 0.5458724498748779\n",
      "epoch: 3 step: 1589, loss is 0.10900440067052841\n",
      "epoch: 3 step: 1590, loss is 2.1873342990875244\n",
      "epoch: 3 step: 1591, loss is 1.9626802206039429\n",
      "epoch: 3 step: 1592, loss is 1.0346546173095703\n",
      "epoch: 3 step: 1593, loss is 0.38889437913894653\n",
      "epoch: 3 step: 1594, loss is 2.6660869121551514\n",
      "epoch: 3 step: 1595, loss is 1.1138743162155151\n",
      "epoch: 3 step: 1596, loss is 0.34819355607032776\n",
      "epoch: 3 step: 1597, loss is 2.2667341232299805\n",
      "epoch: 3 step: 1598, loss is 0.1327589452266693\n",
      "epoch: 3 step: 1599, loss is 1.2396142482757568\n",
      "epoch: 3 step: 1600, loss is 2.322626829147339\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:35:24.140369Z",
     "start_time": "2024-07-19T12:35:14.053372Z"
    }
   },
   "cell_type": "code",
   "source": "cassavamodel.eval(val_dataset)",
   "id": "e5da75a2dc227ce8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.5775}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:38:16.113299Z",
     "start_time": "2024-07-19T12:38:16.097294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TestDataset:\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.csv_file = csv_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.csv_file.iloc[index, 0]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ],
   "id": "3212700aedd082c8",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:38:17.631227Z",
     "start_time": "2024-07-19T12:38:17.611227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "test_csv = pd.read_csv('cassava-leaf-disease-classification/sample_submission.csv')\n",
    "test_image_path = os.path.join(basic_root, 'test_images')\n",
    "test_dataset = TestDataset(test_csv, test_image_path, transform=transforms)"
   ],
   "id": "cad4a2ef19788783",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ms_test_dataset = ds.GeneratorDataset(test_dataset, [\"image\"], shuffle=False)\n",
    "ms_test_dataset = ms_test_dataset.batch(1)"
   ],
   "id": "b577807e348435d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:38:27.182310Z",
     "start_time": "2024-07-19T12:38:27.115233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = []\n",
    "for data in ms_test_dataset.create_dict_iterator(output_numpy=True):\n",
    "    image = data[\"image\"]\n",
    "    pred = cassavamodel.predict(Tensor(image))\n",
    "    predicted_label = np.argmax(pred.asnumpy(), axis=1)\n",
    "    predictions.append(predicted_label)\n"
   ],
   "id": "68bd6b207fb6b27e",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:38:42.665024Z",
     "start_time": "2024-07-19T12:38:42.647863Z"
    }
   },
   "cell_type": "code",
   "source": "test_csv['label'] = predictions",
   "id": "b44759bb812baae0",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:40:07.348255Z",
     "start_time": "2024-07-19T12:40:07.334837Z"
    }
   },
   "cell_type": "code",
   "source": "print(test_csv)",
   "id": "9b4e67d48fc64772",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         image_id label\n",
      "0  2216849948.jpg   [3]\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:40:12.494415Z",
     "start_time": "2024-07-19T12:40:12.484801Z"
    }
   },
   "cell_type": "code",
   "source": "test_csv.to_csv('submission.csv', index=False)",
   "id": "3f2dc55344c1e863",
   "outputs": [],
   "execution_count": 49
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
